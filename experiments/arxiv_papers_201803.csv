id,title,abstract,authors,categories,date
http://arxiv.org/abs/1804.05436v1,Hidden Hamiltonian Cycle Recovery via Linear Programming,"We introduce the problem of hidden Hamiltonian cycle recovery, where there is
an unknown Hamiltonian cycle in an $n$-vertex complete graph that needs to be
inferred from noisy edge measurements. The measurements are independent and
distributed according to $\calP_n$ for edges in the cycle and $\calQ_n$
otherwise. This formulation is motivated by a problem in genome assembly, where
the goal is to order a set of contigs (genome subsequences) according to their
positions on the genome using long-range linking measurements between the
contigs. Computing the maximum likelihood estimate in this model reduces to a
Traveling Salesman Problem (TSP). Despite the NP-hardness of TSP, we show that
a simple linear programming (LP) relaxation, namely the fractional $2$-factor
(F2F) LP, recovers the hidden Hamiltonian cycle with high probability as $n \to
\infty$ provided that $\alpha_n - \log n \to \infty$, where $\alpha_n
\triangleq -2 \log \int \sqrt{d P_n d Q_n}$ is the R\'enyi divergence of order
$\frac{1}{2}$. This condition is information-theoretically optimal in the sense
that, under mild distributional assumptions, $\alpha_n \geq (1+o(1)) \log n$ is
necessary for any algorithm to succeed regardless of the computational cost.
  Departing from the usual proof techniques based on dual witness construction,
the analysis relies on the combinatorial characterization (in particular, the
half-integrality) of the extreme points of the F2F polytope. Represented as
bicolored multi-graphs, these extreme points are further decomposed into
simpler ""blossom-type"" structures for the large deviation analysis and counting
arguments. Evaluation of the algorithm on real data shows improvements over
existing approaches.","['Vivek Bagaria', 'Jian Ding', 'David Tse', 'Yihong Wu', 'Jiaming Xu']","['cs.DM', 'cs.DS', 'math.PR', 'stat.ML']",2018-04-15 21:58:02+00:00
http://arxiv.org/abs/1804.05433v1,Adaptivity for Regularized Kernel Methods by Lepskii's Principle,"We address the problem of {\it adaptivity} in the framework of reproducing
kernel Hilbert space (RKHS) regression. More precisely, we analyze estimators
arising from a linear regularization scheme $g_\lam$. In practical
applications, an important task is to choose the regularization parameter
$\lam$ appropriately, i.e. based only on the given data and independently on
unknown structural assumptions on the regression function. An attractive
approach avoiding data-splitting is the {\it Lepskii Principle} (LP), also
known as the {\it Balancing Principle} is this setting. We show that a modified
parameter choice based on (LP) is minimax optimal adaptive, up to
$\log\log(n)$. A convenient result is the fact that balancing in $L^2(\nu)-$
norm, which is easiest, automatically gives optimal balancing in all stronger
norms, interpolating between $L^2(\nu)$ and the RKHS. An analogous result is
open for other classical approaches to data dependent choices of the
regularization parameter, e.g. for Hold-Out.",['Nicole MÃ¼cke'],"['stat.ML', 'cs.LG']",2018-04-15 21:27:04+00:00
http://arxiv.org/abs/1804.05402v1,Approximating the covariance ellipsoid,"We explore ways in which the covariance ellipsoid ${\cal B}=\{v \in
\mathbb{R}^d : \mathbb{E} <X,v>^2 \leq 1\}$ of a centred random vector $X$ in
$\mathbb{R}^d$ can be approximated by a simple set. The data one is given for
constructing the approximating set consists of $X_1,...,X_N$ that are
independent and distributed as $X$.
  We present a general method that can be used to construct such approximations
and implement it for two types of approximating sets. We first construct a
(random) set ${\cal K}$ defined by a union of intersections of slabs
$H_{z,\alpha}=\{v \in \mathbb{R}^d : |<z,v>| \leq \alpha\}$ (and therefore
${\cal K}$ is actually the output of a neural network with two hidden layers).
The slabs are generated using $X_1,...,X_N$, and under minimal assumptions on
$X$ (e.g., $X$ can be heavy-tailed) it suffices that $N = c_1d
\eta^{-4}\log(2/\eta)$ to ensure that $(1-\eta) {\cal K} \subset {\cal B}
\subset (1+\eta){\cal K}$. In some cases (e.g., if $X$ is rotation invariant
and has marginals that are well behaved in some weak sense), a smaller sample
size suffices: $N = c_1d\eta^{-2}\log(2/\eta)$.
  We then show that if the slabs are replaced by randomly generated ellipsoids
defined using $X_1,...,X_N$, the same degree of approximation is true when $N
\geq c_2d\eta^{-2}\log(2/\eta)$.
  The construction we use is based on the small-ball method.",['Shahar Mendelson'],"['stat.ML', 'cs.LG']",2018-04-15 18:07:44+00:00
http://arxiv.org/abs/1804.05345v6,Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds,"We present an efficient coresets-based neural network compression algorithm
that sparsifies the parameters of a trained fully-connected neural network in a
manner that provably approximates the network's output. Our approach is based
on an importance sampling scheme that judiciously defines a sampling
distribution over the neural network parameters, and as a result, retains
parameters of high importance while discarding redundant ones. We leverage a
novel, empirical notion of sensitivity and extend traditional coreset
constructions to the application of compressing parameters. Our theoretical
analysis establishes guarantees on the size and accuracy of the resulting
compressed network and gives rise to generalization bounds that may provide new
insights into the generalization properties of neural networks. We demonstrate
the practical effectiveness of our algorithm on a variety of neural network
configurations and real-world data sets.","['Cenk Baykal', 'Lucas Liebenwein', 'Igor Gilitschenski', 'Dan Feldman', 'Daniela Rus']","['cs.LG', 'cs.DS', 'stat.ML']",2018-04-15 12:22:23+00:00
http://arxiv.org/abs/1804.05320v2,Generative Adversarial Network based Autoencoder: Application to fault detection problem for closed loop dynamical systems,"Fault detection problem for closed loop uncertain dynamical systems, is
investigated in this paper, using different deep learning based methods.
Traditional classifier based method does not perform well, because of the
inherent difficulty of detecting system level faults for closed loop dynamical
system. Specifically, acting controller in any closed loop dynamical system,
works to reduce the effect of system level faults. A novel Generative
Adversarial based deep Autoencoder is designed to classify datasets under
normal and faulty operating conditions. This proposed network performs
significantly well when compared to any available classifier based methods, and
moreover, does not require labeled fault incorporated datasets for training
purpose. Finally, this aforementioned network's performance is tested on a high
complexity building energy system dataset.","['Indrasis Chakraborty', 'Rudrasis Chakraborty', 'Draguna Vrabie']","['cs.LG', 'cs.AI', 'stat.ML']",2018-04-15 08:28:15+00:00
http://arxiv.org/abs/1804.05316v1,From CDF to PDF --- A Density Estimation Method for High Dimensional Data,"CDF2PDF is a method of PDF estimation by approximating CDF. The original idea
of it was previously proposed in [1] called SIC. However, SIC requires
additional hyper-parameter tunning, and no algorithms for computing higher
order derivative from a trained NN are provided in [1]. CDF2PDF improves SIC by
avoiding the time-consuming hyper-parameter tuning part and enabling higher
order derivative computation to be done in polynomial time. Experiments of this
method for one-dimensional data shows promising results.",['Shengdong Zhang'],"['stat.ML', 'cs.LG']",2018-04-15 07:38:11+00:00
http://arxiv.org/abs/1804.05296v3,Adversarial Attacks Against Medical Deep Learning Systems,"The discovery of adversarial examples has raised concerns about the practical
deployment of deep learning systems. In this paper, we demonstrate that
adversarial examples are capable of manipulating deep learning systems across
three clinical domains. For each of our representative medical deep learning
classifiers, both white and black box attacks were highly successful. Our
models are representative of the current state of the art in medical computer
vision and, in some cases, directly reflect architectures already seeing
deployment in real world clinical settings. In addition to the technical
contribution of our paper, we synthesize a large body of knowledge about the
healthcare system to argue that medicine may be uniquely susceptible to
adversarial attacks, both in terms of monetary incentives and technical
vulnerability. To this end, we outline the healthcare economy and the
incentives it creates for fraud and provide concrete examples of how and why
such attacks could be realistically carried out. We urge practitioners to be
aware of current vulnerabilities when deploying deep learning systems in
clinical settings, and encourage the machine learning community to further
investigate the domain-specific characteristics of medical learning systems.","['Samuel G. Finlayson', 'Hyung Won Chung', 'Isaac S. Kohane', 'Andrew L. Beam']","['cs.CR', 'cs.CY', 'cs.LG', 'stat.ML']",2018-04-15 02:33:08+00:00
http://arxiv.org/abs/1804.05834v1,CytonRL: an Efficient Reinforcement Learning Open-source Toolkit Implemented in C++,"This paper presents an open-source enforcement learning toolkit named CytonRL
(https://github.com/arthurxlw/cytonRL). The toolkit implements four recent
advanced deep Q-learning algorithms from scratch using C++ and NVIDIA's
GPU-accelerated libraries. The code is simple and elegant, owing to an
open-source general-purpose neural network library named CytonLib. Benchmark
shows that the toolkit achieves competitive performances on the popular Atari
game of Breakout.",['Xiaolin Wang'],"['cs.LG', 'cs.AI', 'stat.ML']",2018-04-14 23:17:07+00:00
http://arxiv.org/abs/1804.05283v2,OmicsMapNet: Transforming omics data to take advantage of Deep Convolutional Neural Network for discovery,"We developed OmicsMapNet approach to take advantage of existing deep leaning
frameworks to analyze high-dimensional omics data as 2-dimensional images. The
omics data of individual samples were first rearranged into 2D images in which
molecular features related in functions, ontologies, or other relationships
were organized in spatially adjacent and patterned locations. Deep learning
neural networks were trained to classify the images. Molecular features
informative of classes of different phenotypes were subsequently identified. As
an example, we used the KEGG BRITE database to rearrange RNA-Seq expression
data of TCGA diffuse glioma samples as treemaps to capture the functional
hierarchical structure of genes in 2D images. Deep Convolutional Neural
Networks (CNN) were derived using tools from TensorFlow to learn the grade of
TCGA LGG and GBM samples with relatively high accuracy. The most contributory
features in the trained CNN were confirmed in pathway analysis for their
plausible functional involvement.","['Shiyong Ma', 'Zhen Zhang']","['stat.ML', 'cs.AI', 'cs.LG']",2018-04-14 22:22:21+00:00
http://arxiv.org/abs/1804.05271v3,Adaptive Federated Learning in Resource Constrained Edge Computing Systems,"Emerging technologies and applications including Internet of Things (IoT),
social networking, and crowd-sourcing generate large amounts of data at the
network edge. Machine learning models are often built from the collected data,
to enable the detection, classification, and prediction of future events. Due
to bandwidth, storage, and privacy concerns, it is often impractical to send
all the data to a centralized location. In this paper, we consider the problem
of learning model parameters from data distributed across multiple edge nodes,
without sending raw data to a centralized place. Our focus is on a generic
class of machine learning models that are trained using gradient-descent based
approaches. We analyze the convergence bound of distributed gradient descent
from a theoretical point of view, based on which we propose a control algorithm
that determines the best trade-off between local update and global parameter
aggregation to minimize the loss function under a given resource budget. The
performance of the proposed algorithm is evaluated via extensive experiments
with real datasets, both on a networked prototype system and in a larger-scale
simulated environment. The experimentation results show that our proposed
approach performs near to the optimum with various machine learning models and
different data distributions.","['Shiqiang Wang', 'Tiffany Tuor', 'Theodoros Salonidis', 'Kin K. Leung', 'Christian Makaya', 'Ting He', 'Kevin Chan']","['cs.DC', 'cs.LG', 'math.OC', 'stat.ML']",2018-04-14 20:21:48+00:00
http://arxiv.org/abs/1804.05267v1,Low-Precision Floating-Point Schemes for Neural Network Training,"The use of low-precision fixed-point arithmetic along with stochastic
rounding has been proposed as a promising alternative to the commonly used
32-bit floating point arithmetic to enhance training neural networks training
in terms of performance and energy efficiency. In the first part of this paper,
the behaviour of the 12-bit fixed-point arithmetic when training a
convolutional neural network with the CIFAR-10 dataset is analysed, showing
that such arithmetic is not the most appropriate for the training phase. After
that, the paper presents and evaluates, under the same conditions, alternative
low-precision arithmetics, starting with the 12-bit floating-point arithmetic.
These two representations are then leveraged using local scaling in order to
increase accuracy and get closer to the baseline 32-bit floating-point
arithmetic. Finally, the paper introduces a simplified model in which both the
outputs and the gradients of the neural networks are constrained to
power-of-two values, just using 7 bits for their representation. The evaluation
demonstrates a minimal loss in accuracy for the proposed Power-of-Two neural
network, avoiding the use of multiplications and divisions and thereby,
significantly reducing the training time as well as the energy consumption and
memory requirements during the training and inference phases.","['Marc Ortiz', 'AdriÃ¡n Cristal', 'Eduard AyguadÃ©', 'Marc Casas']","['cs.LG', 'cs.NE', 'stat.ML', 'I.2.6; I.5']",2018-04-14 19:10:07+00:00
http://arxiv.org/abs/1804.05251v1,An interpretable LSTM neural network for autoregressive exogenous model,"In this paper, we propose an interpretable LSTM recurrent neural network,
i.e., multi-variable LSTM for time series with exogenous variables. Currently,
widely used attention mechanism in recurrent neural networks mostly focuses on
the temporal aspect of data and falls short of characterizing variable
importance. To this end, our multi-variable LSTM equipped with tensorized
hidden states is developed to learn variable specific representations, which
give rise to both temporal and variable level attention. Preliminary
experiments demonstrate comparable prediction performance of multi-variable
LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable
importance in real datasets characterized by the variable attention is highly
in line with that determined by statistical Granger causality test, which
exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end
framework for both forecasting and knowledge discovery.","['Tian Guo', 'Tao Lin', 'Yao Lu']","['cs.LG', 'stat.ML']",2018-04-14 17:33:46+00:00
http://arxiv.org/abs/1804.05214v1,Fast Optimal Bandwidth Selection for RBF Kernel using Reproducing Kernel Hilbert Space Operators for Kernel Based Classifiers,"Kernel based methods have shown effective performance in many remote sensing
classification tasks. However their performance significantly depend on its
hyper-parameters. The conventional technique to estimate the parameter comes
with high computational complexity. Thus, the objective of this letter is to
propose an fast and efficient method to select the bandwidth parameter of the
Gaussian kernel in the kernel based classification methods. The proposed method
is developed based on the operators in the reproducing kernel Hilbert space and
it is evaluated on Support vector machines and PerTurbo classification method.
Experiments conducted with hyperspectral datasets show that our proposed method
outperforms the state-of-art method in terms in computational time and
classification performance.",['Bharath Bhushan Damodaran'],"['stat.ML', 'cs.LG']",2018-04-14 12:42:09+00:00
http://arxiv.org/abs/1804.05170v2,Model-Free Information Extraction in Enriched Nonlinear Phase-Space,"Detecting anomalies and discovering driving signals is an essential component
of scientific research and industrial practice. Often the underlying mechanism
is highly complex, involving hidden evolving nonlinear dynamics and noise
contamination. When representative physical models and large labeled data sets
are unavailable, as is the case with most real-world applications,
model-dependent Bayesian approaches would yield misleading results, and most
supervised learning machines would also fail to reliably resolve the
intricately evolving systems. Here, we propose an unsupervised machine-learning
approach that operates in a well-constructed function space, whereby the
evolving nonlinear dynamics are captured through a linear functional
representation determined by the Koopman operator. This breakthrough leverages
on the time-feature embedding and the ensuing reconstruction of a phase-space
representation of the dynamics, thereby permitting the reliable identification
of critical global signatures from the whole trajectory. This dramatically
improves over commonly used static local features, which are vulnerable to
unknown transitions or noise. Thanks to its data-driven nature, our method
excludes any prior models and training corpus. We benchmark the astonishing
accuracy of our method on three diverse and challenging problems in: biology,
medicine, and engineering. In all cases, it outperforms existing
state-of-the-art methods. As a new unsupervised information processing
paradigm, it is suitable for ubiquitous nonlinear dynamical systems or
end-users with little expertise, which permits an unbiased excavation of
underlying working principles or intrinsic correlations submerged in unlabeled
data flows.","['Bin Li', 'Yueheng Lan', 'Weisi Guo', 'Chenglin Zhao']","['cs.LG', 'stat.ML']",2018-04-14 05:58:15+00:00
http://arxiv.org/abs/1805.00310v2,On the Limitation of MagNet Defense against $L_1$-based Adversarial Examples,"In recent years, defending adversarial perturbations to natural examples in
order to build robust machine learning models trained by deep neural networks
(DNNs) has become an emerging research field in the conjunction of deep
learning and security. In particular, MagNet consisting of an adversary
detector and a data reformer is by far one of the strongest defenses in the
black-box oblivious attack setting, where the attacker aims to craft
transferable adversarial examples from an undefended DNN model to bypass an
unknown defense module deployed on the same DNN model. Under this setting,
MagNet can successfully defend a variety of attacks in DNNs, including the
high-confidence adversarial examples generated by the Carlini and Wagner's
attack based on the $L_2$ distortion metric. However, in this paper, under the
same attack setting we show that adversarial examples crafted based on the
$L_1$ distortion metric can easily bypass MagNet and mislead the target DNN
image classifiers on MNIST and CIFAR-10. We also provide explanations on why
the considered approach can yield adversarial examples with superior attack
performance and conduct extensive experiments on variants of MagNet to verify
its lack of robustness to $L_1$ distortion based attacks. Notably, our results
substantially weaken the assumption of effective threat models on MagNet that
require knowing the deployed defense technique when attacking DNNs (i.e., the
gray-box attack setting).","['Pei-Hsuan Lu', 'Pin-Yu Chen', 'Kang-Cheng Chen', 'Chia-Mu Yu']","['cs.CV', 'cs.CR', 'cs.LG', 'stat.ML']",2018-04-14 05:44:51+00:00
http://arxiv.org/abs/1804.05146v2,A comparison of methods for model selection when estimating individual treatment effects,"Practitioners in medicine, business, political science, and other fields are
increasingly aware that decisions should be personalized to each patient,
customer, or voter. A given treatment (e.g. a drug or advertisement) should be
administered only to those who will respond most positively, and certainly not
to those who will be harmed by it. Individual-level treatment effects can be
estimated with tools adapted from machine learning, but different models can
yield contradictory estimates. Unlike risk prediction models, however,
treatment effect models cannot be easily evaluated against each other using a
held-out test set because the true treatment effect itself is never directly
observed. Besides outcome prediction accuracy, several metrics that can
leverage held-out data to evaluate treatment effects models have been proposed,
but they are not widely used. We provide a didactic framework that elucidates
the relationships between the different approaches and compare them all using a
variety of simulations of both randomized and observational data. Our results
show that researchers estimating heterogenous treatment effects need not limit
themselves to a single model-fitting algorithm. Instead of relying on a single
method, multiple models fit by a diverse set of algorithms should be evaluated
against each other using an objective function learned from the validation set.
The model minimizing that objective should be used for estimating the
individual treatment effect for future individuals.","['Alejandro Schuler', 'Michael Baiocchi', 'Robert Tibshirani', 'Nigam Shah']","['stat.ML', 'cs.LG']",2018-04-14 01:28:47+00:00
http://arxiv.org/abs/1804.06234v6,Cluster Analysis on Locally Asymptotically Self-similar Processes with Known Number of Clusters,"We conduct cluster analysis on a class of locally asymptotically self-similar
stochastic processes, which includes multifractional Brownian motion as a
representative. When the true number of clusters is supposed to be known, a new
covariance-based dissimilarity measure is introduced, from which we obtain the
approximately asymptotically consistent clustering algorithms. In simulation
studies, clustering data sampled from multifractional Brownian motions with
distinct functional Hurst parameters illustrates the approximated asymptotic
consistency of the proposed algorithms. Clustering global financial markets'
equity indexes returns and sovereign CDS spreads provides a successful real
world application.","['Qidi Peng', 'Nan Rao', 'Ran Zhao']","['stat.ML', 'cs.LG', '62-07, 60G10, 62M10']",2018-04-13 23:09:12+00:00
http://arxiv.org/abs/1804.05133v1,A Latent Gaussian Mixture Model for Clustering Longitudinal Data,"Finite mixture models have become a popular tool for clustering. Amongst
other uses, they have been applied for clustering longitudinal data and
clustering high-dimensional data. In the latter case, a latent Gaussian mixture
model is sometimes used. Although there has been much work on clustering using
latent variables and on clustering longitudinal data, respectively, there has
been a paucity of work that combines these features. An approach is developed
for clustering longitudinal data with many time points based on an extension of
the mixture of common factor analyzers model. A variation of the
expectation-maximization algorithm is used for parameter estimation and the
Bayesian information criterion is used for model selection. The approach is
illustrated using real and simulated data.","['Vanessa S. E. Bierling', 'Paul D. McNicholas']","['stat.ME', 'stat.ML']",2018-04-13 22:40:00+00:00
http://arxiv.org/abs/1804.05120v2,Robust Dual View Deep Agent,"Motivated by recent advance of machine learning using Deep Reinforcement
Learning this paper proposes a modified architecture that produces more robust
agents and speeds up the training process. Our architecture is based on
Asynchronous Advantage Actor-Critic (A3C) algorithm where the total input
dimensionality is halved by dividing the input into two independent streams. We
use ViZDoom, 3D world software that is based on the classical first person
shooter video game, Doom, as a test case. The experiments show that in
comparison to single input agents, the proposed architecture succeeds to have
the same playing performance and shows more robust behavior, achieving
significant reduction in the number of training parameters of almost 30%.","['Ibrahim M. Sobh', 'Nevin M. Darwish']","['cs.LG', 'stat.ML']",2018-04-13 21:13:42+00:00
http://arxiv.org/abs/1804.05092v1,A new robust feature selection method using variance-based sensitivity analysis,"Excluding irrelevant features in a pattern recognition task plays an
important role in maintaining a simpler machine learning model and optimizing
the computational efficiency. Nowadays with the rise of large scale datasets,
feature selection is in great demand as it becomes a central issue when facing
high-dimensional datasets. The present study provides a new measure of saliency
for features by employing a Sensitivity Analysis (SA) technique called the
extended Fourier amplitude sensitivity test, and a well-trained Feedforward
Neural Network (FNN) model, which ultimately leads to the selection of a
promising optimal feature subset. Ideas of the paper are mainly demonstrated
based on adopting FNN model for feature selection in classification problems.
But in the end, a generalization framework is discussed in order to give
insights into the usage in regression problems as well as expressing how other
function approximate models can be deployed. Effectiveness of the proposed
method is verified by result analysis and data visualization for a series of
experiments over several well-known datasets drawn from UCI machine learning
repository.",['Saman Sadeghyan'],"['cs.LG', 'cs.AI', 'stat.ML']",2018-04-13 19:29:40+00:00
http://arxiv.org/abs/1804.05090v1,Regularized Singular Value Decomposition and Application to Recommender System,"Singular value decomposition (SVD) is the mathematical basis of principal
component analysis (PCA). Together, SVD and PCA are one of the most widely used
mathematical formalism/decomposition in machine learning, data mining, pattern
recognition, artificial intelligence, computer vision, signal processing, etc.
In recent applications, regularization becomes an increasing trend. In this
paper, we present a regularized SVD (RSVD), present an efficient computational
algorithm, and provide several theoretical analysis. We show that although RSVD
is non-convex, it has a closed-form global optimal solution. Finally, we apply
RSVD to the application of recommender system and experimental result show that
RSVD outperforms SVD significantly.","['Shuai Zheng', 'Chris Ding', 'Feiping Nie']","['cs.LG', 'cs.IR', 'stat.ML']",2018-04-13 18:54:30+00:00
http://arxiv.org/abs/1804.05020v1,"A Deep Learning Approach to Fast, Format-Agnostic Detection of Malicious Web Content","Malicious web content is a serious problem on the Internet today. In this
paper we propose a deep learning approach to detecting malevolent web pages.
While past work on web content detection has relied on syntactic parsing or on
emulation of HTML and Javascript to extract features, our approach operates
directly on a language-agnostic stream of tokens extracted directly from static
HTML files with a simple regular expression. This makes it fast enough to
operate in high-frequency data contexts like firewalls and web proxies, and
allows it to avoid the attack surface exposure of complex parsing and emulation
code. Unlike well-known approaches such as bag-of-words models, which ignore
spatial information, our neural network examines content at hierarchical
spatial scales, allowing our model to capture locality and yielding superior
accuracy compared to bag-of-words baselines. Our proposed architecture achieves
a 97.5% detection rate at a 0.1% false positive rate, and classifies
small-batched web pages at a rate of over 100 per second on commodity hardware.
The speed and accuracy of our approach makes it appropriate for deployment to
endpoints, firewalls, and web proxies.","['Joshua Saxe', 'Richard Harang', 'Cody Wild', 'Hillary Sanders']","['cs.CR', 'cs.LG', 'stat.ML']",2018-04-13 16:39:24+00:00
http://arxiv.org/abs/1804.05018v1,"Comparatives, Quantifiers, Proportions: A Multi-Task Model for the Learning of Quantities from Vision","The present work investigates whether different quantification mechanisms
(set comparison, vague quantification, and proportional estimation) can be
jointly learned from visual scenes by a multi-task computational model. The
motivation is that, in humans, these processes underlie the same cognitive,
non-symbolic ability, which allows an automatic estimation and comparison of
set magnitudes. We show that when information about lower-complexity tasks is
available, the higher-level proportional task becomes more accurate than when
performed in isolation. Moreover, the multi-task model is able to generalize to
unseen combinations of target/non-target objects. Consistently with behavioral
evidence showing the interference of absolute number in the proportional task,
the multi-task model no longer works when asked to provide the number of target
objects in the scene.","['Sandro Pezzelle', 'Ionut-Teodor Sorodoc', 'Raffaella Bernardi']","['cs.CV', 'cs.LG', 'stat.ML', '68T45']",2018-04-13 16:36:52+00:00
http://arxiv.org/abs/1804.05012v2,Representing smooth functions as compositions of near-identity functions with implications for deep network optimization,"We show that any smooth bi-Lipschitz $h$ can be represented exactly as a
composition $h_m \circ ... \circ h_1$ of functions $h_1,...,h_m$ that are close
to the identity in the sense that each $\left(h_i-\mathrm{Id}\right)$ is
Lipschitz, and the Lipschitz constant decreases inversely with the number $m$
of functions composed. This implies that $h$ can be represented to any accuracy
by a deep residual network whose nonlinear layers compute functions with a
small Lipschitz constant. Next, we consider nonlinear regression with a
composition of near-identity nonlinear maps. We show that, regarding Fr\'echet
derivatives with respect to the $h_1,...,h_m$, any critical point of a
quadratic criterion in this near-identity region must be a global minimizer. In
contrast, if we consider derivatives with respect to parameters of a fixed-size
residual network with sigmoid activation functions, we show that there are
near-identity critical points that are suboptimal, even in the realizable case.
Informally, this means that functional gradient methods for residual networks
cannot get stuck at suboptimal critical points corresponding to near-identity
layers, whereas parametric gradient methods for sigmoidal residual networks
suffer from suboptimal critical points in the near-identity region.","['Peter L. Bartlett', 'Steven N. Evans', 'Philip M. Long']","['cs.LG', 'cs.AI', 'cs.NE', 'math.ST', 'stat.ML', 'stat.TH']",2018-04-13 16:24:17+00:00
http://arxiv.org/abs/1804.04976v1,Online Fall Detection using Recurrent Neural Networks,"Unintentional falls can cause severe injuries and even death, especially if
no immediate assistance is given. The aim of Fall Detection Systems (FDSs) is
to detect an occurring fall. This information can be used to trigger the
necessary assistance in case of injury. This can be done by using either
ambient-based sensors, e.g. cameras, or wearable devices. The aim of this work
is to study the technical aspects of FDSs based on wearable devices and
artificial intelligence techniques, in particular Deep Learning (DL), to
implement an effective algorithm for on-line fall detection. The proposed
classifier is based on a Recurrent Neural Network (RNN) model with underlying
Long Short-Term Memory (LSTM) blocks. The method is tested on the publicly
available SisFall dataset, with extended annotation, and compared with the
results obtained by the SisFall authors.","['Mirto Musci', 'Daniele De Martini', 'Nicola Blago', 'Tullio Facchinetti', 'Marco Piastra']","['cs.CY', 'cs.LG', 'stat.ML']",2018-04-13 14:58:51+00:00
http://arxiv.org/abs/1804.04918v3,Distributed Collaborative Hashing and Its Applications in Ant Financial,"Collaborative filtering, especially latent factor model, has been popularly
used in personalized recommendation. Latent factor model aims to learn user and
item latent factors from user-item historic behaviors. To apply it into real
big data scenarios, efficiency becomes the first concern, including offline
model training efficiency and online recommendation efficiency. In this paper,
we propose a Distributed Collaborative Hashing (DCH) model which can
significantly improve both efficiencies. Specifically, we first propose a
distributed learning framework, following the state-of-the-art parameter server
paradigm, to learn the offline collaborative model. Our model can be learnt
efficiently by distributedly computing subgradients in minibatches on workers
and updating model parameters on servers asynchronously. We then adopt hashing
technique to speedup the online recommendation procedure. Recommendation can be
quickly made through exploiting lookup hash tables. We conduct thorough
experiments on two real large-scale datasets. The experimental results
demonstrate that, comparing with the classic and state-of-the-art (distributed)
latent factor models, DCH has comparable performance in terms of recommendation
accuracy but has both fast convergence speed in offline model training
procedure and realtime efficiency in online recommendation procedure.
Furthermore, the encouraging performance of DCH is also shown for several
real-world applications in Ant Financial.","['Chaochao Chen', 'Ziqi Liu', 'Peilin Zhao', 'Longfei Li', 'Jun Zhou', 'Xiaolong Li']","['cs.LG', 'cs.IR', 'stat.ML']",2018-04-13 12:37:51+00:00
http://arxiv.org/abs/1804.04888v2,Scalable and Interpretable One-class SVMs with Deep Learning and Random Fourier features,"One-class support vector machine (OC-SVM) for a long time has been one of the
most effective anomaly detection methods and extensively adopted in both
research as well as industrial applications. The biggest issue for OC-SVM is
yet the capability to operate with large and high-dimensional datasets due to
optimization complexity. Those problems might be mitigated via dimensionality
reduction techniques such as manifold learning or autoencoder. However,
previous work often treats representation learning and anomaly prediction
separately. In this paper, we propose autoencoder based one-class support
vector machine (AE-1SVM) that brings OC-SVM, with the aid of random Fourier
features to approximate the radial basis kernel, into deep learning context by
combining it with a representation learning architecture and jointly exploit
stochastic gradient descent to obtain end-to-end training. Interestingly, this
also opens up the possible use of gradient-based attribution methods to explain
the decision making for anomaly detection, which has ever been challenging as a
result of the implicit mappings between the input space and the kernel space.
To the best of our knowledge, this is the first work to study the
interpretability of deep learning in anomaly detection. We evaluate our method
on a wide range of unsupervised anomaly detection tasks in which our end-to-end
training architecture achieves a performance significantly better than the
previous work using separate training.","['Minh-Nghia Nguyen', 'Ngo Anh Vien']","['cs.LG', 'stat.ML']",2018-04-13 11:24:33+00:00
http://arxiv.org/abs/1804.04878v1,Learning Contracting Vector Fields For Stable Imitation Learning,"We propose a new non-parametric framework for learning incrementally stable
dynamical systems x' = f(x) from a set of sampled trajectories. We construct a
rich family of smooth vector fields induced by certain classes of matrix-valued
kernels, whose equilibria are placed exactly at a desired set of locations and
whose local contraction and curvature properties at various points can be
explicitly controlled using convex optimization. With curl-free kernels, our
framework may also be viewed as a mechanism to learn potential fields and
gradient flows. We develop large-scale techniques using randomized kernel
approximations in this context. We demonstrate our approach, called contracting
vector fields (CVF), on imitation learning tasks involving complex
point-to-point human handwriting motions.","['Vikas Sindhwani', 'Stephen Tu', 'Mohi Khansari']","['cs.RO', 'cs.LG', 'stat.ML']",2018-04-13 10:40:45+00:00
http://arxiv.org/abs/1804.07262v1,Nonparametric Bayesian label prediction on a large graph using truncated Laplacian regularization,"This article describes an implementation of a nonparametric Bayesian approach
to solving binary classification problems on graphs. We consider a hierarchical
Bayesian approach with a prior that is constructed by truncating a series
expansion of the soft label function using the graph Laplacian eigenfunctions
as basis functions. We compare our truncated prior to the untruncated Laplacian
based prior in simulated and real data examples to illustrate the improved
scalability in terms of size of the underlying graph.","['Jarno Hartog', 'Harry van Zanten']","['stat.CO', 'stat.ML']",2018-04-13 09:36:43+00:00
http://arxiv.org/abs/1804.04849v3,The unreasonable effectiveness of the forget gate,"Given the success of the gated recurrent unit, a natural question is whether
all the gates of the long short-term memory (LSTM) network are necessary.
Previous research has shown that the forget gate is one of the most important
gates in the LSTM. Here we show that a forget-gate-only version of the LSTM
with chrono-initialized biases, not only provides computational savings but
outperforms the standard LSTM on multiple benchmark datasets and competes with
some of the best contemporary models. Our proposed network, the JANET, achieves
accuracies of 99% and 92.5% on the MNIST and pMNIST datasets, outperforming the
standard LSTM which yields accuracies of 98.5% and 91%.","['Jos van der Westhuizen', 'Joan Lasenby']","['cs.NE', 'cs.LG', 'stat.ML']",2018-04-13 09:18:17+00:00
http://arxiv.org/abs/1804.04806v1,Î¼-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching,"NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used
in deep learning. Specifically, cuDNN implements several equivalent convolution
algorithms, whose performance and memory footprint may vary considerably,
depending on the layer dimensions. When an algorithm is automatically selected
by cuDNN, the decision is performed on a per-layer basis, and thus it often
resorts to slower algorithms that fit the workspace size constraints. We
present {\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides
layers' mini-batch computation into several micro-batches. Based on Dynamic
Programming and Integer Linear Programming, {\mu}-cuDNN enables faster
algorithms by decreasing the workspace requirements. At the same time,
{\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples
statistical efficiency from the hardware efficiency safely. We demonstrate the
effectiveness of {\mu}-cuDNN over two frameworks, Caffe and TensorFlow,
achieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2
GPU. These results indicate that using micro-batches can seamlessly increase
the performance of deep learning, while maintaining the same memory footprint.","['Yosuke Oyama', 'Tal Ben-Nun', 'Torsten Hoefler', 'Satoshi Matsuoka']","['cs.LG', 'cs.DC', 'cs.MS', 'cs.NE', 'stat.ML', 'I.2.6']",2018-04-13 07:20:44+00:00
http://arxiv.org/abs/1804.04791v1,"Fast, Parameter free Outlier Identification for Robust PCA","Robust PCA, the problem of PCA in the presence of outliers has been
extensively investigated in the last few years. Here we focus on Robust PCA in
the column sparse outlier model. The existing methods for column sparse outlier
model assumes either the knowledge of the dimension of the lower dimensional
subspace or the fraction of outliers in the system. However in many
applications knowledge of these parameters is not available. Motivated by this
we propose a parameter free outlier identification method for robust PCA which
a) does not require the knowledge of outlier fraction, b) does not require the
knowledge of the dimension of the underlying subspace, c) is computationally
simple and fast. Further, analytical guarantees are derived for outlier
identification and the performance of the algorithm is compared with the
existing state of the art methods.","['Vishnu Menon', 'Sheetal Kalyani']","['stat.ML', 'cs.LG']",2018-04-13 05:35:19+00:00
http://arxiv.org/abs/1804.04780v1,Adversarial Clustering: A Grid Based Clustering Algorithm Against Active Adversaries,"Nowadays more and more data are gathered for detecting and preventing cyber
attacks. In cyber security applications, data analytics techniques have to deal
with active adversaries that try to deceive the data analytics models and avoid
being detected. The existence of such adversarial behavior motivates the
development of robust and resilient adversarial learning techniques for various
tasks. Most of the previous work focused on adversarial classification
techniques, which assumed the existence of a reasonably large amount of
carefully labeled data instances. However, in practice, labeling the data
instances often requires costly and time-consuming human expertise and becomes
a significant bottleneck. Meanwhile, a large number of unlabeled instances can
also be used to understand the adversaries' behavior. To address the above
mentioned challenges, in this paper, we develop a novel grid based adversarial
clustering algorithm. Our adversarial clustering algorithm is able to identify
the core normal regions, and to draw defensive walls around the centers of the
normal objects utilizing game theoretic ideas. Our algorithm also identifies
sub-clusters of attack objects, the overlapping areas within clusters, and
outliers which may be potential anomalies.","['Wutao Wei', 'Bowei Xi', 'Murat Kantarcioglu']","['stat.ML', 'cs.LG']",2018-04-13 04:06:37+00:00
http://arxiv.org/abs/1804.04778v1,Understanding Community Structure in Layered Neural Networks,"A layered neural network is now one of the most common choices for the
prediction of high-dimensional practical data sets, where the relationship
between input and output data is complex and cannot be represented well by
simple conventional models. Its effectiveness is shown in various tasks,
however, the lack of interpretability of the trained result by a layered neural
network has limited its application area.
  In our previous studies, we proposed methods for extracting a simplified
global structure of a trained layered neural network by classifying the units
into communities according to their connection patterns with adjacent layers.
These methods provided us with knowledge about the strength of the relationship
between communities from the existence of bundled connections, which are
determined by threshold processing of the connection ratio between pairs of
communities.
  However, it has been difficult to understand the role of each community
quantitatively by observing the modular structure. We could only know to which
sets of the input and output dimensions each community was mainly connected, by
tracing the bundled connections from the community to the input and output
layers. Another problem is that the finally obtained modular structure is
changed greatly depending on the setting of the threshold hyperparameter used
for determining bundled connections.
  In this paper, we propose a new method for interpreting quantitatively the
role of each community in inference, by defining the effect of each input
dimension on a community, and the effect of a community on each output
dimension. We show experimentally that our proposed method can reveal the role
of each part of a layered neural network by applying the neural networks to
three types of data sets, extracting communities from the trained network, and
applying the proposed method to the community structure.","['Chihiro Watanabe', 'Kaoru Hiramatsu', 'Kunio Kashino']","['stat.ML', 'cs.LG']",2018-04-13 03:10:00+00:00
http://arxiv.org/abs/1804.04775v3,A Compact Network Learning Model for Distribution Regression,"Despite the superior performance of deep learning in many applications,
challenges remain in the area of regression on function spaces. In particular,
neural networks are unable to encode function inputs compactly as each node
encodes just a real value. We propose a novel idea to address this shortcoming:
to encode an entire function in a single network node. To that end, we design a
compact network representation that encodes and propagates functions in single
nodes for the distribution regression task. Our proposed Distribution
Regression Network (DRN) achieves higher prediction accuracies while being much
more compact and uses fewer parameters than traditional neural networks.","['Connie Kou', 'Hwee Kuan Lee', 'Teck Khim Ng']","['cs.LG', 'stat.ML']",2018-04-13 02:31:10+00:00
http://arxiv.org/abs/1804.04758v1,MOVI: A Model-Free Approach to Dynamic Fleet Management,"Modern vehicle fleets, e.g., for ridesharing platforms and taxi companies,
can reduce passengers' waiting times by proactively dispatching vehicles to
locations where pickup requests are anticipated in the future. Yet it is
unclear how to best do this: optimal dispatching requires optimizing over
several sources of uncertainty, including vehicles' travel times to their
dispatched locations, as well as coordinating between vehicles so that they do
not attempt to pick up the same passenger. While prior works have developed
models for this uncertainty and used them to optimize dispatch policies, in
this work we introduce a model-free approach. Specifically, we propose MOVI, a
Deep Q-network (DQN)-based framework that directly learns the optimal vehicle
dispatch policy. Since DQNs scale poorly with a large number of possible
dispatches, we streamline our DQN training and suppose that each individual
vehicle independently learns its own optimal policy, ensuring scalability at
the cost of less coordination between vehicles. We then formulate a centralized
receding-horizon control (RHC) policy to compare with our DQN policies. To
compare these policies, we design and build MOVI as a large-scale realistic
simulator based on 15 million taxi trip records that simulates policy-agnostic
responses to dispatch decisions. We show that the DQN dispatch policy reduces
the number of unserviced requests by 76% compared to without dispatch and 20%
compared to the RHC approach, emphasizing the benefits of a model-free approach
and suggesting that there is limited value to coordinating vehicle actions.
This finding may help to explain the success of ridesharing platforms, for
which drivers make individual decisions.","['Takuma Oda', 'Carlee Joe-Wong']","['cs.LG', 'stat.ML']",2018-04-13 00:54:22+00:00
http://arxiv.org/abs/1804.04732v2,Multimodal Unsupervised Image-to-Image Translation,"Unsupervised image-to-image translation is an important and challenging
problem in computer vision. Given an image in the source domain, the goal is to
learn the conditional distribution of corresponding images in the target
domain, without seeing any pairs of corresponding images. While this
conditional distribution is inherently multimodal, existing approaches make an
overly simplified assumption, modeling it as a deterministic one-to-one
mapping. As a result, they fail to generate diverse outputs from a given source
domain image. To address this limitation, we propose a Multimodal Unsupervised
Image-to-image Translation (MUNIT) framework. We assume that the image
representation can be decomposed into a content code that is domain-invariant,
and a style code that captures domain-specific properties. To translate an
image to another domain, we recombine its content code with a random style code
sampled from the style space of the target domain. We analyze the proposed
framework and establish several theoretical results. Extensive experiments with
comparisons to the state-of-the-art approaches further demonstrates the
advantage of the proposed framework. Moreover, our framework allows users to
control the style of translation outputs by providing an example style image.
Code and pretrained models are available at https://github.com/nvlabs/MUNIT","['Xun Huang', 'Ming-Yu Liu', 'Serge Belongie', 'Jan Kautz']","['cs.CV', 'cs.LG', 'stat.ML']",2018-04-12 21:17:54+00:00
http://arxiv.org/abs/1804.04725v7,Network-based protein structural classification,"Experimental determination of protein function is resource-consuming. As an
alternative, computational prediction of protein function has received
attention. In this context, protein structural classification (PSC) can help,
by allowing for determining structural classes of currently unclassified
proteins based on their features, and then relying on the fact that proteins
with similar structures have similar functions. Existing PSC approaches rely on
sequence-based or direct 3-dimensional (3D) structure-based protein features.
In contrast, we first model 3D structures of proteins as protein structure
networks (PSNs). Then, we use network-based features for PSC. We propose the
use of graphlets, state-of-the-art features in many research areas of network
science, in the task of PSC. Moreover, because graphlets can deal only with
unweighted PSNs, and because accounting for edge weights when constructing PSNs
could improve PSC accuracy, we also propose a deep learning framework that
automatically learns network features from weighted PSNs. When evaluated on a
large set of ~9,400 CATH and ~12,800 SCOP protein domains (spanning 36 PSN
sets), our proposed approaches are superior to existing PSC approaches in terms
of accuracy, with comparable running time.","['Khalique Newaz', 'Mahboobeh Ghalehnovi', 'Arash Rahnama', 'Panos J. Antsaklis', 'Tijana Milenkovic']","['q-bio.MN', 'cs.LG', 'stat.ML']",2018-04-12 20:55:26+00:00
http://arxiv.org/abs/1804.04640v3,Fast Counting in Machine Learning Applications,"We propose scalable methods to execute counting queries in machine learning
applications. To achieve memory and computational efficiency, we abstract
counting queries and their context such that the counts can be aggregated as a
stream. We demonstrate performance and scalability of the resulting approach on
random queries, and through extensive experimentation using Bayesian networks
learning and association rule mining. Our methods significantly outperform
commonly used ADtrees and hash tables, and are practical alternatives for
processing large-scale data.","['Subhadeep Karan', 'Matthew Eichhorn', 'Blake Hurlburt', 'Grant Iraci', 'Jaroslaw Zola']","['stat.ML', 'cs.LG']",2018-04-12 17:34:41+00:00
http://arxiv.org/abs/1804.04622v1,Causal Inference via Kernel Deviance Measures,"Discovering the causal structure among a set of variables is a fundamental
problem in many areas of science. In this paper, we propose Kernel Conditional
Deviance for Causal Inference (KCDC) a fully nonparametric causal discovery
method based on purely observational data. From a novel interpretation of the
notion of asymmetry between cause and effect, we derive a corresponding
asymmetry measure using the framework of reproducing kernel Hilbert spaces.
Based on this, we propose three decision rules for causal discovery. We
demonstrate the wide applicability of our method across a range of diverse
synthetic datasets. Furthermore, we test our method on real-world time series
data and the real-world benchmark dataset Tubingen Cause-Effect Pairs where we
outperform existing state-of-the-art methods.","['Jovana Mitrovic', 'Dino Sejdinovic', 'Yee Whye Teh']","['cs.LG', 'stat.ME', 'stat.ML']",2018-04-12 16:51:04+00:00
http://arxiv.org/abs/1804.04614v1,Impulsive Noise Robust Sparse Recovery via Continuous Mixed Norm,"This paper investigates the problem of sparse signal recovery in the presence
of additive impulsive noise. The heavytailed impulsive noise is well modelled
with stable distributions. Since there is no explicit formulation for the
probability density function of $S\alpha S$ distribution, alternative
approximations like Generalized Gaussian Distribution (GGD) are used which
impose $\ell_p$-norm fidelity on the residual error. In this paper, we exploit
a Continuous Mixed Norm (CMN) for robust sparse recovery instead of
$\ell_p$-norm. We show that in blind conditions, i.e., in case where the
parameters of noise distribution are unknown, incorporating CMN can lead to
near optimal recovery. We apply Alternating Direction Method of Multipliers
(ADMM) for solving the problem induced by utilizing CMN for robust sparse
recovery. In this approach, CMN is replaced with a surrogate function and
Majorization-Minimization technique is incorporated to solve the problem.
Simulation results confirm the efficiency of the proposed method compared to
some recent algorithms in the literature for impulsive noise robust sparse
recovery.","['Amirhossein Javaheri', 'Hadi Zayyani', 'Mario A. T. Figueiredo', 'Farrokh Marvasti']","['eess.SP', 'cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2018-04-12 16:40:07+00:00
http://arxiv.org/abs/1804.04577v3,Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and Some New Implementations,"In this paper we discuss policy iteration methods for approximate solution of
a finite-state discounted Markov decision problem, with a focus on
feature-based aggregation methods and their connection with deep reinforcement
learning schemes. We introduce features of the states of the original problem,
and we formulate a smaller ""aggregate"" Markov decision problem, whose states
relate to the features. We discuss properties and possible implementations of
this type of aggregation, including a new approach to approximate policy
iteration. In this approach the policy improvement operation combines
feature-based aggregation with feature construction using deep neural networks
or other calculations. We argue that the cost function of a policy may be
approximated much more accurately by the nonlinear function of the features
provided by aggregation, than by the linear function of the features provided
by neural network-based reinforcement learning, thereby potentially leading to
more effective policy improvement.",['Dimitri P. Bertsekas'],"['cs.LG', 'stat.ML', '49, 90, 93']",2018-04-12 15:46:12+00:00
http://arxiv.org/abs/1804.04566v2,Latent Geometry Inspired Graph Dissimilarities Enhance Affinity Propagation Community Detection in Complex Networks,"Affinity propagation is one of the most effective unsupervised pattern
recognition algorithms for data clustering in high-dimensional feature space.
However, the numerous attempts to test its performance for community detection
in complex networks have been attaining results very far from the state of the
art methods such as Infomap and Louvain. Yet, all these studies agreed that the
crucial problem is to convert the unweighted network topology in a
'smart-enough' node dissimilarity matrix that is able to properly address the
message passing procedure behind affinity propagation clustering. Here we
introduce a conceptual innovation and we discuss how to leverage network latent
geometry notions in order to design dissimilarity matrices for affinity
propagation community detection. Our results demonstrate that the latent
geometry inspired dissimilarity measures we design bring affinity propagation
to equal or outperform current state of the art methods for community
detection. These findings are solidly proven considering both synthetic
'realistic' networks (with known ground-truth communities) and real networks
(with community metadata), even when the data structure is corrupted by noise
artificially induced by missing or spurious connectivity.","['Carlo Vittorio Cannistraci', 'Alessandro Muscoloni']","['cs.LG', 'cs.SI', 'physics.soc-ph', 'stat.ML']",2018-04-12 15:23:39+00:00
http://arxiv.org/abs/1804.04563v1,Towards integrating spatial localization in convolutional neural networks for brain image segmentation,"Semantic segmentation is an established while rapidly evolving field in
medical imaging. In this paper we focus on the segmentation of brain Magnetic
Resonance Images (MRI) into cerebral structures using convolutional neural
networks (CNN). CNNs achieve good performance by finding effective high
dimensional image features describing the patch content only. In this work, we
propose different ways to introduce spatial constraints into the network to
further reduce prediction inconsistencies.
  A patch based CNN architecture was trained, making use of multiple scales to
gather contextual information. Spatial constraints were introduced within the
CNN through a distance to landmarks feature or through the integration of a
probability atlas. We demonstrate experimentally that using spatial information
helps to reduce segmentation inconsistencies.","['Pierre-Antoine Ganaye', 'MichaÃ«l Sdika', 'Hugues Benoit-Cattin']","['cs.CV', 'stat.ML']",2018-04-12 15:20:48+00:00
http://arxiv.org/abs/1804.04529v1,"Online convex optimization and no-regret learning: Algorithms, guarantees and applications","Spurred by the enthusiasm surrounding the ""Big Data"" paradigm, the
mathematical and algorithmic tools of online optimization have found widespread
use in problems where the trade-off between data exploration and exploitation
plays a predominant role. This trade-off is of particular importance to several
branches and applications of signal processing, such as data mining,
statistical inference, multimedia indexing and wireless communications (to name
but a few). With this in mind, the aim of this tutorial paper is to provide a
gentle introduction to online optimization and learning algorithms that are
asymptotically optimal in hindsight - i.e., they approach the performance of a
virtual algorithm with unlimited computational power and full knowledge of the
future, a property known as no-regret. Particular attention is devoted to
identifying the algorithms' theoretical performance guarantees and to establish
links with classic optimization paradigms (both static and stochastic). To
allow a better understanding of this toolbox, we provide several examples
throughout the tutorial ranging from metric learning to wireless resource
allocation problems.","['E. Veronica Belmega', 'Panayotis Mertikopoulos', 'Romain Negrel', 'Luca Sanguinetti']","['cs.LG', 'cs.IT', 'math.IT', 'math.OC', 'stat.ML', 'Primary 68Q32, 90C90, secondary 68T05, 91A26, 94A12']",2018-04-12 14:22:35+00:00
http://arxiv.org/abs/1804.04659v4,Asynch-SGBDT: Asynchronous Parallel Stochastic Gradient Boosting Decision Tree based on Parameters Server,"In AI research and industry, machine learning is the most widely used tool.
One of the most important machine learning algorithms is Gradient Boosting
Decision Tree, i.e. GBDT whose training process needs considerable
computational resources and time. To shorten GBDT training time, many works
tried to apply GBDT on Parameter Server. However, those GBDT algorithms are
synchronous parallel algorithms which fail to make full use of Parameter
Server. In this paper, we examine the possibility of using asynchronous
parallel methods to train GBDT model and name this algorithm as asynch-SGBDT
(asynchronous parallel stochastic gradient boosting decision tree). Our
theoretical and experimental results indicate that the scalability of
asynch-SGBDT is influenced by the sample diversity of datasets, sampling rate,
step length and the setting of GBDT tree. Experimental results also show
asynch-SGBDT training process reaches a linear speedup in asynchronous parallel
manner when datasets and GBDT trees meet high scalability requirements.","['Cheng Daning', 'Xia Fen', 'Li Shigang', 'Zhang Yunquan']","['cs.LG', 'cs.DC', 'stat.ML']",2018-04-12 14:06:05+00:00
http://arxiv.org/abs/1804.04469v1,Generative models for local network community detection,"Local network community detection aims to find a single community in a large
network, while inspecting only a small part of that network around a given seed
node. This is much cheaper than finding all communities in a network. Most
methods for local community detection are formulated as ad-hoc optimization
problems. In this work, we instead start from a generative model for networks
with community structure. By assuming that the network is uniform, we can
approximate the structure of unobserved parts of the network to obtain a method
for local community detection. We apply this local approximation technique to
two variants of the stochastic block model. To our knowledge, this results in
the first local community detection methods based on probabilistic models.
Interestingly, in the limit, one of the proposed approximations corresponds to
conductance, a popular metric in this field. Experiments on real and synthetic
datasets show comparable or improved results compared to state-of-the-art local
community detection algorithms.",['Twan van Laarhoven'],"['cs.SI', 'stat.ML']",2018-04-12 12:34:57+00:00
http://arxiv.org/abs/1804.04458v1,CubeNet: Equivariance to 3D Rotation and Translation,"3D Convolutional Neural Networks are sensitive to transformations applied to
their input. This is a problem because a voxelized version of a 3D object, and
its rotated clone, will look unrelated to each other after passing through to
the last layer of a network. Instead, an idealized model would preserve a
meaningful representation of the voxelized object, while explaining the
pose-difference between the two inputs. An equivariant representation vector
has two components: the invariant identity part, and a discernable encoding of
the transformation. Models that can't explain pose-differences risk ""diluting""
the representation, in pursuit of optimizing a classification or regression
loss function.
  We introduce a Group Convolutional Neural Network with linear equivariance to
translations and right angle rotations in three dimensions. We call this
network CubeNet, reflecting its cube-like symmetry. By construction, this
network helps preserve a 3D shape's global and local signature, as it is
transformed through successive layers. We apply this network to a variety of 3D
inference problems, achieving state-of-the-art on the ModelNet10 classification
challenge, and comparable performance on the ISBI 2012 Connectome Segmentation
Benchmark. To the best of our knowledge, this is the first 3D rotation
equivariant CNN for voxel representations.","['Daniel Worrall', 'Gabriel Brostow']","['cs.CV', 'cs.AI', 'cs.LG', 'stat.ML']",2018-04-12 12:14:18+00:00
http://arxiv.org/abs/1804.04452v1,Solving Bongard Problems with a Visual Language and Pragmatic Reasoning,"More than 50 years ago Bongard introduced 100 visual concept learning
problems as a testbed for intelligent vision systems. These problems are now
known as Bongard problems. Although they are well known in the cognitive
science and AI communities only moderate progress has been made towards
building systems that can solve a substantial subset of them. In the system
presented here, visual features are extracted through image processing and then
translated into a symbolic visual vocabulary. We introduce a formal language
that allows representing complex visual concepts based on this vocabulary.
Using this language and Bayesian inference, complex visual concepts can be
induced from the examples that are provided in each Bongard problem. Contrary
to other concept learning problems the examples from which concepts are induced
are not random in Bongard problems, instead they are carefully chosen to
communicate the concept, hence requiring pragmatic reasoning. Taking pragmatic
reasoning into account we find good agreement between the concepts with high
posterior probability and the solutions formulated by Bongard himself. While
this approach is far from solving all Bongard problems, it solves the biggest
fraction yet.","['Stefan Depeweg', 'Constantin A. Rothkopf', 'Frank JÃ¤kel']","['stat.ML', 'cs.AI', 'cs.LG']",2018-04-12 12:05:28+00:00
http://arxiv.org/abs/1804.04656v1,3D G-CNNs for Pulmonary Nodule Detection,"Convolutional Neural Networks (CNNs) require a large amount of annotated data
to learn from, which is often difficult to obtain in the medical domain. In
this paper we show that the sample complexity of CNNs can be significantly
improved by using 3D roto-translation group convolutions (G-Convs) instead of
the more conventional translational convolutions. These 3D G-CNNs were applied
to the problem of false positive reduction for pulmonary nodule detection, and
proved to be substantially more effective in terms of performance, sensitivity
to malignant nodules, and speed of convergence compared to a strong and
comparable baseline architecture with regular convolutions, data augmentation
and a similar number of parameters. For every dataset size tested, the G-CNN
achieved a FROC score close to the CNN trained on ten times more data.","['Marysia Winkels', 'Taco S. Cohen']","['cs.LG', 'stat.ML']",2018-04-12 12:02:36+00:00
http://arxiv.org/abs/1804.04448v2,Adversarial Alignment of Class Prediction Uncertainties for Domain Adaptation,"We consider unsupervised domain adaptation: given labelled examples from a
source domain and unlabelled examples from a related target domain, the goal is
to infer the labels of target examples. Under the assumption that features from
pre-trained deep neural networks are transferable across related domains,
domain adaptation reduces to aligning source and target domain at class
prediction uncertainty level. We tackle this problem by introducing a method
based on adversarial learning which forces the label uncertainty predictions on
the target domain to be indistinguishable from those on the source domain.
Pre-trained deep neural networks are used to generate deep features having high
transferability across related domains. We perform an extensive experimental
analysis of the proposed method over a wide set of publicly available
pre-trained deep neural networks. Results of our experiments on domain
adaptation tasks for image classification show that class prediction
uncertainty alignment with features extracted from pre-trained deep neural
networks provides an efficient, robust and effective method for domain
adaptation.","['Jeroen Manders', 'Twan van Laarhoven', 'Elena Marchiori']","['stat.ML', 'cs.LG']",2018-04-12 11:56:42+00:00
http://arxiv.org/abs/1804.04440v1,Temporal Interpolation via Motion Field Prediction,"Navigated 2D multi-slice dynamic Magnetic Resonance (MR) imaging enables high
contrast 4D MR imaging during free breathing and provides in-vivo observations
for treatment planning and guidance. Navigator slices are vital for
retrospective stacking of 2D data slices in this method. However, they also
prolong the acquisition sessions. Temporal interpolation of navigator slices an
be used to reduce the number of navigator acquisitions without degrading
specificity in stacking. In this work, we propose a convolutional neural
network (CNN) based method for temporal interpolation via motion field
prediction. The proposed formulation incorporates the prior knowledge that a
motion field underlies changes in the image intensities over time. Previous
approaches that interpolate directly in the intensity space are prone to
produce blurry images or even remove structures in the images. Our method
avoids such problems and faithfully preserves the information in the image.
Further, an important advantage of our formulation is that it provides an
unsupervised estimation of bi-directional motion fields. We show that these
motion fields can be used to halve the number of registrations required during
4D reconstruction, thus substantially reducing the reconstruction time.","['Lin Zhang', 'Neerav Karani', 'Christine Tanner', 'Ender Konukoglu']","['stat.ML', 'cs.LG']",2018-04-12 11:44:55+00:00
http://arxiv.org/abs/1804.04438v2,Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs,"Many of our core assumptions about how neural networks operate remain
empirically untested. One common assumption is that convolutional neural
networks need to be stable to small translations and deformations to solve
image recognition tasks. For many years, this stability was baked into CNN
architectures by incorporating interleaved pooling layers. Recently, however,
interleaved pooling has largely been abandoned. This raises a number of
questions: Are our intuitions about deformation stability right at all? Is it
important? Is pooling necessary for deformation invariance? If not, how is
deformation invariance achieved in its absence? In this work, we rigorously
test these questions, and find that deformation stability in convolutional
networks is more nuanced than it first appears: (1) Deformation invariance is
not a binary property, but rather that different tasks require different
degrees of deformation stability at different layers. (2) Deformation stability
is not a fixed property of a network and is heavily adjusted over the course of
training, largely through the smoothness of the convolutional filters. (3)
Interleaved pooling layers are neither necessary nor sufficient for achieving
the optimal form of deformation stability for natural image classification. (4)
Pooling confers too much deformation stability for image classification at
initialization, and during training, networks have to learn to counteract this
inductive bias. Together, these findings provide new insights into the role of
interleaved pooling and deformation invariance in CNNs, and demonstrate the
importance of rigorous empirical testing of even our most basic assumptions
about the working of neural networks.","['Avraham Ruderman', 'Neil C. Rabinowitz', 'Ari S. Morcos', 'Daniel Zoran']","['cs.CV', 'cs.LG', 'stat.ML']",2018-04-12 11:44:05+00:00
http://arxiv.org/abs/1804.04435v1,Variational Composite Autoencoders,"Learning in the latent variable model is challenging in the presence of the
complex data structure or the intractable latent variable. Previous variational
autoencoders can be low effective due to the straightforward encoder-decoder
structure. In this paper, we propose a variational composite autoencoder to
sidestep this issue by amortizing on top of the hierarchical latent variable
model. The experimental results confirm the advantages of our model.","['Jiangchao Yao', 'Ivor Tsang', 'Ya Zhang']","['cs.LG', 'stat.ML']",2018-04-12 11:36:42+00:00
http://arxiv.org/abs/1804.04421v1,Regularized Greedy Column Subset Selection,"The Column Subset Selection Problem provides a natural framework for
unsupervised feature selection. Despite being a hard combinatorial optimization
problem, there exist efficient algorithms that provide good approximations. The
drawback of the problem formulation is that it incorporates no form of
regularization, and is therefore very sensitive to noise when presented with
scarce data. In this paper we propose a regularized formulation of this
problem, and derive a correct greedy algorithm that is similar in efficiency to
existing greedy methods for the unregularized problem. We study its adequacy
for feature selection and propose suitable formulations. Additionally, we
derive a lower bound for the error of the proposed problems. Through various
numerical experiments on real and synthetic data, we demonstrate the
significantly increased robustness and stability of our method, as well as the
improved conditioning of its output, all while remaining efficient for
practical use.","['Bruno Ordozgoiti', 'Alberto Mozo', 'JesÃºs GarcÃ­a LÃ³pez de Lacalle']","['cs.LG', 'cs.AI', 'stat.ML']",2018-04-12 10:56:44+00:00
http://arxiv.org/abs/1804.04380v1,Amobee at SemEval-2018 Task 1: GRU Neural Network with a CNN Attention Mechanism for Sentiment Classification,"This paper describes the participation of Amobee in the shared sentiment
analysis task at SemEval 2018. We participated in all the English sub-tasks and
the Spanish valence tasks. Our system consists of three parts: training
task-specific word embeddings, training a model consisting of
gated-recurrent-units (GRU) with a convolution neural network (CNN) attention
mechanism and training stacking-based ensembles for each of the sub-tasks. Our
algorithm reached 3rd and 1st places in the valence ordinal classification
sub-tasks in English and Spanish, respectively.","['Alon Rozental', 'Daniel Fleischer']","['cs.CL', 'stat.ML']",2018-04-12 09:04:50+00:00
http://arxiv.org/abs/1804.04378v2,Fast Gaussian Process Based Gradient Matching for Parameter Identification in Systems of Nonlinear ODEs,"Parameter identification and comparison of dynamical systems is a challenging
task in many fields. Bayesian approaches based on Gaussian process regression
over time-series data have been successfully applied to infer the parameters of
a dynamical system without explicitly solving it. While the benefits in
computational cost are well established, a rigorous mathematical framework has
been missing. We offer a novel interpretation which leads to a better
understanding and improvements in state-of-the-art performance in terms of
accuracy for nonlinear dynamical systems.","['Philippe Wenk', 'Alkis Gotovos', 'Stefan Bauer', 'Nico Gorbach', 'Andreas Krause', 'Joachim M. Buhmann']","['stat.ML', 'cs.LG']",2018-04-12 08:54:20+00:00
http://arxiv.org/abs/1804.04368v3,Regularisation of Neural Networks by Enforcing Lipschitz Continuity,"We investigate the effect of explicitly enforcing the Lipschitz continuity of
neural networks with respect to their inputs. To this end, we provide a simple
technique for computing an upper bound to the Lipschitz constant---for multiple
$p$-norms---of a feed forward neural network composed of commonly used layer
types. Our technique is then used to formulate training a neural network with a
bounded Lipschitz constant as a constrained optimisation problem that can be
solved using projected stochastic gradient methods. Our evaluation study shows
that the performance of the resulting models exceeds that of models trained
with other common regularisers. We also provide evidence that the
hyperparameters are intuitive to tune, demonstrate how the choice of norm for
computing the Lipschitz constant impacts the resulting model, and show that the
performance gains provided by our method are particularly noticeable when only
a small amount of training data is available.","['Henry Gouk', 'Eibe Frank', 'Bernhard Pfahringer', 'Michael J. Cree']","['stat.ML', 'cs.LG']",2018-04-12 08:18:30+00:00
http://arxiv.org/abs/1804.04353v1,Global SNR Estimation of Speech Signals using Entropy and Uncertainty Estimates from Dropout Networks,"This paper demonstrates two novel methods to estimate the global SNR of
speech signals. In both methods, Deep Neural Network-Hidden Markov Model
(DNN-HMM) acoustic model used in speech recognition systems is leveraged for
the additional task of SNR estimation. In the first method, the entropy of the
DNN-HMM output is computed. Recent work on bayesian deep learning has shown
that a DNN-HMM trained with dropout can be used to estimate model uncertainty
by approximating it as a deep Gaussian process. In the second method, this
approximation is used to obtain model uncertainty estimates. Noise specific
regressors are used to predict the SNR from the entropy and model uncertainty.
The DNN-HMM is trained on GRID corpus and tested on different noise profiles
from the DEMAND noise database at SNR levels ranging from -10 dB to 30 dB.","['Rohith Aralikatti', 'Dilip Margam', 'Tanay Sharma', 'Thanda Abhinav', 'Shankar M Venkatesan']","['eess.AS', 'cs.AI', 'eess.SP', 'stat.ML']",2018-04-12 07:15:20+00:00
http://arxiv.org/abs/1804.04333v3,Causal Generative Domain Adaptation Networks,"An essential problem in domain adaptation is to understand and make use of
distribution changes across domains. For this purpose, we first propose a
flexible Generative Domain Adaptation Network (G-DAN) with specific latent
variables to capture changes in the generating process of features across
domains. By explicitly modeling the changes, one can even generate data in new
domains using the generating process with new values for the latent variables
in G-DAN. In practice, the process to generate all features together may
involve high-dimensional latent variables, requiring dealing with distributions
in high dimensions and making it difficult to learn domain changes from few
source domains. Interestingly, by further making use of the causal
representation of joint distributions, we then decompose the joint distribution
into separate modules, each of which involves different low-dimensional latent
variables and can be learned separately, leading to a Causal G-DAN (CG-DAN).
This improves both statistical and computational efficiency of the learning
procedure. Finally, by matching the feature distribution in the target domain,
we can recover the target-domain joint distribution and derive the learning
machine for the target domain. We demonstrate the efficacy of both G-DAN and
CG-DAN in domain generation and cross-domain prediction on both synthetic and
real data experiments.","['Mingming Gong', 'Kun Zhang', 'Biwei Huang', 'Clark Glymour', 'Dacheng Tao', 'Kayhan Batmanghelich']","['stat.ML', 'cs.LG']",2018-04-12 06:10:46+00:00
http://arxiv.org/abs/1804.04324v1,Local reservoir model for choice-based learning,"Decision making based on behavioral and neural observations of living systems
has been extensively studied in brain science, psychology, and other
disciplines. Decision-making mechanisms have also been experimentally
implemented in physical processes, such as single photons and chaotic lasers.
The findings of these experiments suggest that there is a certain common basis
in describing decision making, regardless of its physical realizations. In this
study, we propose a local reservoir model to account for choice-based learning
(CBL). CBL describes decision consistency as a phenomenon where making a
certain decision increases the possibility of making that same decision again
later, which has been intensively investigated in neuroscience, psychology,
etc. Our proposed model is inspired by the viewpoint that a decision is
affected by its local environment, which is referred to as a local reservoir.
If the size of the local reservoir is large enough, consecutive decision making
will not be affected by previous decisions, thus showing lower degrees of
decision consistency in CBL. In contrast, if the size of the local reservoir
decreases, a biased distribution occurs within it, which leads to higher
degrees of decision consistency in CBL. In this study, an analytical approach
on local reservoirs is presented, as well as several numerical demonstrations.
Furthermore, a physical architecture for CBL based on single photons is
discussed, and the effects of local reservoirs is numerically demonstrated.
Decision consistency in human decision-making tasks and in recruiting empirical
data are evaluated based on local reservoir. In summary, the proposed local
reservoir model paves a path toward establishing a foundation for computational
mechanisms and the systematic analysis of decision making on different levels.","['Makoto Naruse', 'Eiji Yamamoto', 'Takashi Nakao', 'Takuma Akimoto', 'Hayato Saigo', 'Kazuya Okamura', 'Izumi Ojima', 'Georg Northoff', 'Hirokazu Hori']","['stat.ML', 'cs.LG', 'physics.data-an', 'physics.optics', 'q-bio.NC']",2018-04-12 05:35:14+00:00
http://arxiv.org/abs/1804.04272v2,Deep Neural Networks Motivated by Partial Differential Equations,"Partial differential equations (PDEs) are indispensable for modeling many
physical phenomena and also commonly used for solving image processing tasks.
In the latter area, PDE-based approaches interpret image data as
discretizations of multivariate functions and the output of image processing
algorithms as solutions to certain PDEs. Posing image processing problems in
the infinite dimensional setting provides powerful tools for their analysis and
solution. Over the last few decades, the reinterpretation of classical image
processing problems through the PDE lens has been creating multiple celebrated
approaches that benefit a vast area of tasks including image segmentation,
denoising, registration, and reconstruction.
  In this paper, we establish a new PDE-interpretation of a class of deep
convolutional neural networks (CNN) that are commonly used to learn from
speech, image, and video data. Our interpretation includes convolution residual
neural networks (ResNet), which are among the most promising approaches for
tasks such as image classification having improved the state-of-the-art
performance in prestigious benchmark challenges. Despite their recent
successes, deep ResNets still face some critical challenges associated with
their design, immense computational costs and memory requirements, and lack of
understanding of their reasoning.
  Guided by well-established PDE theory, we derive three new ResNet
architectures that fall into two new classes: parabolic and hyperbolic CNNs. We
demonstrate how PDE theory can provide new insights and algorithms for deep
learning and demonstrate the competitiveness of three new CNN architectures
using numerical experiments.","['Lars Ruthotto', 'Eldad Haber']","['cs.LG', 'math.OC', 'stat.ML', '65K10, 68T45']",2018-04-12 01:40:55+00:00
http://arxiv.org/abs/1804.04950v2,DeepFM: An End-to-End Wide & Deep Learning Framework for CTR Prediction,"Learning sophisticated feature interactions behind user behaviors is critical
in maximizing CTR for recommender systems. Despite great progress, existing
methods have a strong bias towards low- or high-order interactions, or rely on
expertise feature engineering. In this paper, we show that it is possible to
derive an end-to-end learning model that emphasizes both low- and high-order
feature interactions. The proposed framework, DeepFM, combines the power of
factorization machines for recommendation and deep learning for feature
learning in a new neural network architecture. Compared to the latest Wide &
Deep model from Google, DeepFM has a shared raw feature input to both its
""wide"" and ""deep"" components, with no need of feature engineering besides raw
features. DeepFM, as a general learning framework, can incorporate various
network architectures in its deep component. In this paper, we study two
instances of DeepFM where its ""deep"" component is DNN and PNN respectively, for
which we denote as DeepFM-D and DeepFM-P. Comprehensive experiments are
conducted to demonstrate the effectiveness of DeepFM-D and DeepFM-P over the
existing models for CTR prediction, on both benchmark data and commercial data.
We conduct online A/B test in Huawei App Market, which reveals that DeepFM-D
leads to more than 10% improvement of click-through rate in the production
environment, compared to a well-engineered LR model. We also covered related
practice in deploying our framework in Huawei App Market.","['Huifeng Guo', 'Ruiming Tang', 'Yunming Ye', 'Zhenguo Li', 'Xiuqiang He', 'Zhenhua Dong']","['cs.IR', 'cs.LG', 'stat.ML']",2018-04-12 01:12:13+00:00
http://arxiv.org/abs/1804.04262v1,The Voice Conversion Challenge 2018: Promoting Development of Parallel and Nonparallel Methods,"We present the Voice Conversion Challenge 2018, designed as a follow up to
the 2016 edition with the aim of providing a common framework for evaluating
and comparing different state-of-the-art voice conversion (VC) systems. The
objective of the challenge was to perform speaker conversion (i.e. transform
the vocal identity) of a source speaker to a target speaker while maintaining
linguistic information. As an update to the previous challenge, we considered
both parallel and non-parallel data to form the Hub and Spoke tasks,
respectively. A total of 23 teams from around the world submitted their
systems, 11 of them additionally participated in the optional Spoke task. A
large-scale crowdsourced perceptual evaluation was then carried out to rate the
submitted converted speech in terms of naturalness and similarity to the target
speaker identity. In this paper, we present a brief summary of the
state-of-the-art techniques for VC, followed by a detailed explanation of the
challenge tasks and the results that were obtained.","['Jaime Lorenzo-Trueba', 'Junichi Yamagishi', 'Tomoki Toda', 'Daisuke Saito', 'Fernando Villavicencio', 'Tomi Kinnunen', 'Zhenhua Ling']","['eess.AS', 'cs.CL', 'cs.SD', 'stat.ML']",2018-04-12 00:14:10+00:00
http://arxiv.org/abs/1804.04241v1,Capsules for Object Segmentation,"Convolutional neural networks (CNNs) have shown remarkable results over the
last several years for a wide range of computer vision tasks. A new
architecture recently introduced by Sabour et al., referred to as a capsule
networks with dynamic routing, has shown great initial results for digit
recognition and small image classification. The success of capsule networks
lies in their ability to preserve more information about the input by replacing
max-pooling layers with convolutional strides and dynamic routing, allowing for
preservation of part-whole relationships in the data. This preservation of the
input is demonstrated by reconstructing the input from the output capsule
vectors. Our work expands the use of capsule networks to the task of object
segmentation for the first time in the literature. We extend the idea of
convolutional capsules with locally-connected routing and propose the concept
of deconvolutional capsules. Further, we extend the masked reconstruction to
reconstruct the positive input class. The proposed
convolutional-deconvolutional capsule network, called SegCaps, shows strong
results for the task of object segmentation with substantial decrease in
parameter space. As an example application, we applied the proposed SegCaps to
segment pathological lungs from low dose CT scans and compared its accuracy and
efficiency with other U-Net-based architectures. SegCaps is able to handle
large image sizes (512 x 512) as opposed to baseline capsules (typically less
than 32 x 32). The proposed SegCaps reduced the number of parameters of U-Net
architecture by 95.4% while still providing a better segmentation accuracy.","['Rodney LaLonde', 'Ulas Bagci']","['stat.ML', 'cs.AI', 'cs.CV', 'cs.LG']",2018-04-11 21:57:57+00:00
http://arxiv.org/abs/1804.04235v1,Adafactor: Adaptive Learning Rates with Sublinear Memory Cost,"In several recently proposed stochastic optimization methods (e.g. RMSProp,
Adam, Adadelta), parameter updates are scaled by the inverse square roots of
exponential moving averages of squared past gradients. Maintaining these
per-parameter second-moment estimators requires memory equal to the number of
parameters. For the case of neural network weight matrices, we propose
maintaining only the per-row and per-column sums of these moving averages, and
estimating the per-parameter second moments based on these sums. We demonstrate
empirically that this method produces similar results to the baseline.
Secondly, we show that adaptive methods can produce larger-than-desired updates
when the decay rate of the second moment accumulator is too slow. We propose
update clipping and a gradually increasing decay rate scheme as remedies.
Combining these methods and dropping momentum, we achieve comparable results to
the published Adam regime in training the Transformer model on the WMT 2014
English-German machine translation task, while using very little auxiliary
storage in the optimizer. Finally, we propose scaling the parameter updates
based on the scale of the parameters themselves.","['Noam Shazeer', 'Mitchell Stern']","['cs.LG', 'cs.AI', 'stat.ML']",2018-04-11 21:42:32+00:00
http://arxiv.org/abs/1804.04212v3,Word2Vec applied to Recommendation: Hyperparameters Matter,"Skip-gram with negative sampling, a popular variant of Word2vec originally
designed and tuned to create word embeddings for Natural Language Processing,
has been used to create item embeddings with successful applications in
recommendation. While these fields do not share the same type of data, neither
evaluate on the same tasks, recommendation applications tend to use the same
already tuned hyperparameters values, even if optimal hyperparameters values
are often known to be data and task dependent. We thus investigate the marginal
importance of each hyperparameter in a recommendation setting through large
hyperparameter grid searches on various datasets. Results reveal that
optimizing neglected hyperparameters, namely negative sampling distribution,
number of epochs, subsampling parameter and window-size, significantly improves
performance on a recommendation task, and can increase it by an order of
magnitude. Importantly, we find that optimal hyperparameters configurations for
Natural Language Processing tasks and Recommendation tasks are noticeably
different.","['Hugo Caselles-DuprÃ©', 'Florian Lesaint', 'Jimena Royo-Letelier']","['cs.IR', 'cs.CL', 'cs.LG', 'stat.ML']",2018-04-11 20:37:35+00:00
http://arxiv.org/abs/1804.04206v1,Multi-scale Neural Networks for Retinal Blood Vessels Segmentation,"Existing supervised approaches didn't make use of the low-level features
which are actually effective to this task. And another deficiency is that they
didn't consider the relation between pixels, which means effective features are
not extracted. In this paper, we proposed a novel convolutional neural network
which make sufficient use of low-level features together with high-level
features and involves atrous convolution to get multi-scale features which
should be considered as effective features. Our model is tested on three
standard benchmarks - DRIVE, STARE, and CHASE databases. The results presents
that our model significantly outperforms existing approaches in terms of
accuracy, sensitivity, specificity, the area under the ROC curve and the
highest prediction speed. Our work provides evidence of the power of wide and
deep neural networks in retinal blood vessels segmentation task which could be
applied on other medical images tasks.","['Boheng Zhang', 'Shenglei Huang', 'Shaohan Hu']","['cs.CV', 'cs.LG', 'stat.ML']",2018-04-11 20:25:36+00:00
http://arxiv.org/abs/1804.04205v1,Learning Topics using Semantic Locality,"The topic modeling discovers the latent topic probability of the given text
documents. To generate the more meaningful topic that better represents the
given document, we proposed a new feature extraction technique which can be
used in the data preprocessing stage. The method consists of three steps.
First, it generates the word/word-pair from every single document. Second, it
applies a two-way TF-IDF algorithm to word/word-pair for semantic filtering.
Third, it uses the K-means algorithm to merge the word pairs that have the
similar semantic meaning.
  Experiments are carried out on the Open Movie Database (OMDb), Reuters
Dataset and 20NewsGroup Dataset. The mean Average Precision score is used as
the evaluation metric. Comparing our results with other state-of-the-art topic
models, such as Latent Dirichlet allocation and traditional Restricted
Boltzmann Machines. Our proposed data preprocessing can improve the generated
topic accuracy by up to 12.99\%.","['Ziyi Zhao', 'Krittaphat Pugdeethosapol', 'Sheng Lin', 'Zhe Li', 'Caiwen Ding', 'Yanzhi Wang', 'Qinru Qiu']","['cs.LG', 'cs.CL', 'cs.IR', 'stat.ML']",2018-04-11 20:23:23+00:00
http://arxiv.org/abs/1804.04171v1,KS(conf ): A Light-Weight Test if a ConvNet Operates Outside of Its Specifications,"Computer vision systems for automatic image categorization have become
accurate and reliable enough that they can run continuously for days or even
years as components of real-world commercial applications. A major open problem
in this context, however, is quality control. Good classification performance
can only be expected if systems run under the specific conditions, in
particular data distributions, that they were trained for. Surprisingly, none
of the currently used deep network architectures has a built-in functionality
that could detect if a network operates on data from a distribution that it was
not trained for and potentially trigger a warning to the human users. In this
work, we describe KS(conf), a procedure for detecting such outside of the
specifications operation. Building on statistical insights, its main step is
the applications of a classical Kolmogorov-Smirnov test to the distribution of
predicted confidence values. We show by extensive experiments using ImageNet,
AwA2 and DAVIS data on a variety of ConvNets architectures that KS(conf)
reliably detects out-of-specs situations. It furthermore has a number of
properties that make it an excellent candidate for practical deployment: it is
easy to implement, adds almost no overhead to the system, works with all
networks, including pretrained ones, and requires no a priori knowledge about
how the data distribution could change.","['RÃ©my Sun', 'Christoph H. Lampert']","['stat.ML', 'cs.LG']",2018-04-11 19:05:51+00:00
http://arxiv.org/abs/1804.04168v1,Differentiable Learning of Quantum Circuit Born Machine,"Quantum circuit Born machines are generative models which represent the
probability distribution of classical dataset as quantum pure states.
Computational complexity considerations of the quantum sampling problem suggest
that the quantum circuits exhibit stronger expressibility compared to classical
neural networks. One can efficiently draw samples from the quantum circuits via
projective measurements on qubits. However, similar to the leading implicit
generative models in deep learning, such as the generative adversarial
networks, the quantum circuits cannot provide the likelihood of the generated
samples, which poses a challenge to the training. We devise an efficient
gradient-based learning algorithm for the quantum circuit Born machine by
minimizing the kerneled maximum mean discrepancy loss. We simulated generative
modeling of the Bars-and-Stripes dataset and Gaussian mixture distributions
using deep quantum circuits. Our experiments show the importance of circuit
depth and gradient-based optimization algorithm. The proposed learning
algorithm is runnable on near-term quantum device and can exhibit quantum
advantages for generative modeling.","['Jin-Guo Liu', 'Lei Wang']","['quant-ph', 'cs.LG', 'stat.ML']",2018-04-11 19:01:11+00:00
http://arxiv.org/abs/1804.04118v2,Personalized Dynamics Models for Adaptive Assistive Navigation Systems,"Consider an assistive system that guides visually impaired users through
speech and haptic feedback to their destination. Existing robotic and
ubiquitous navigation technologies (e.g., portable, ground, or wearable
systems) often operate in a generic, user-agnostic manner. However, to minimize
confusion and navigation errors, our real-world analysis reveals a crucial need
to adapt the instructional guidance across different end-users with diverse
mobility skills. To address this practical issue in scalable system design, we
propose a novel model-based reinforcement learning framework for personalizing
the system-user interaction experience. When incrementally adapting the system
to new users, we propose to use a weighted experts model for addressing
data-efficiency limitations in transfer learning with deep models. A real-world
dataset of navigation by blind users is used to show that the proposed approach
allows for (1) more accurate long-term human behavior prediction (up to 20
seconds into the future) through improved reasoning over personal mobility
characteristics, interaction with surrounding obstacles, and the current
navigation goal, and (2) quick adaptation at the onset of learning, when data
is limited.","['Eshed Ohn-Bar', 'Kris Kitani', 'Chieko Asakawa']","['cs.LG', 'cs.CV', 'cs.HC', 'cs.RO', 'stat.ML']",2018-04-11 17:55:00+00:00
http://arxiv.org/abs/1804.04112v1,Beamformed Fingerprint Learning for Accurate Millimeter Wave Positioning,"With millimeter wave wireless communications, the resulting radiation
reflects on most visible objects, creating rich multipath environments, namely
in urban scenarios. The radiation captured by a listening device is thus shaped
by the obstacles encountered, which carry latent information regarding their
relative positions. In this paper, a system to convert the received millimeter
wave radiation into the device's position is proposed, making use of the
aforementioned hidden information. Using deep learning techniques and a
pre-established codebook of beamforming patterns transmitted by a base station,
the simulations show that average estimation errors below 10 meters are
achievable in realistic outdoors scenarios that contain mostly
non-line-of-sight positions, paving the way for new positioning systems.","['JoÃ£o Gante', 'Gabriel FalcÃ£o', 'Leonel Sousa']","['eess.SP', 'cs.CV', 'stat.ML']",2018-04-11 17:36:30+00:00
http://arxiv.org/abs/1804.04097v3,End-to-end Deep Learning of Optical Fiber Communications,"In this paper, we implement an optical fiber communication system as an
end-to-end deep neural network, including the complete chain of transmitter,
channel model, and receiver. This approach enables the optimization of the
transceiver in a single end-to-end process. We illustrate the benefits of this
method by applying it to intensity modulation/direct detection (IM/DD) systems
and show that we can achieve bit error rates below the 6.7\% hard-decision
forward error correction (HD-FEC) threshold. We model all componentry of the
transmitter and receiver, as well as the fiber channel, and apply deep learning
to find transmitter and receiver configurations minimizing the symbol error
rate. We propose and verify in simulations a training method that yields robust
and flexible transceivers that allow---without reconfiguration---reliable
transmission over a large range of link dispersions. The results from
end-to-end deep learning are successfully verified for the first time in an
experiment. In particular, we achieve information rates of 42\,Gb/s below the
HD-FEC threshold at distances beyond 40\,km. We find that our results
outperform conventional IM/DD solutions based on 2 and 4 level pulse amplitude
modulation (PAM2/PAM4) with feedforward equalization (FFE) at the receiver. Our
study is the first step towards end-to-end deep learning-based optimization of
optical fiber communication systems.","['Boris Karanov', 'Mathieu Chagnon', 'FÃ©lix Thouin', 'Tobias A. Eriksson', 'Henning BÃ¼low', 'DomaniÃ§ Lavery', 'Polina Bayvel', 'Laurent Schmalen']","['cs.IT', 'math.IT', 'stat.ML']",2018-04-11 17:07:43+00:00
http://arxiv.org/abs/1804.04048v1,Cost-Aware Learning and Optimization for Opportunistic Spectrum Access,"In this paper, we investigate cost-aware joint learning and optimization for
multi-channel opportunistic spectrum access in a cognitive radio system. We
investigate a discrete time model where the time axis is partitioned into
frames. Each frame consists of a sensing phase, followed by a transmission
phase. During the sensing phase, the user is able to sense a subset of channels
sequentially before it decides to use one of them in the following transmission
phase. We assume the channel states alternate between busy and idle according
to independent Bernoulli random processes from frame to frame. To capture the
inherent uncertainty in channel sensing, we assume the reward of each
transmission when the channel is idle is a random variable. We also associate
random costs with sensing and transmission actions. Our objective is to
understand how the costs and reward of the actions would affect the optimal
behavior of the user in both offline and online settings, and design the
corresponding opportunistic spectrum access strategies to maximize the expected
cumulative net reward (i.e., reward-minus-cost). We start with an offline
setting where the statistics of the channel status, costs and reward are known
beforehand. We show that the the optimal policy exhibits a recursive double
threshold structure, and the user needs to compare the channel statistics with
those thresholds sequentially in order to decide its actions. With such
insights, we then study the online setting, where the statistical information
of the channels, costs and reward are unknown a priori. We judiciously balance
exploration and exploitation, and show that the cumulative regret scales in
O(log T). We also establish a matched lower bound, which implies that our
online algorithm is order-optimal. Simulation results corroborate our
theoretical analysis.","['Chao Gan', 'Ruida Zhou', 'Jing Yang', 'Cong Shen']","['cs.NI', 'cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2018-04-11 15:28:07+00:00
http://arxiv.org/abs/1804.04012v1,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection,"Exploration is a fundamental aspect of Reinforcement Learning, typically
implemented using stochastic action-selection. Exploration, however, can be
more efficient if directed toward gaining new world knowledge. Visit-counters
have been proven useful both in practice and in theory for directed
exploration. However, a major limitation of counters is their locality. While
there are a few model-based solutions to this shortcoming, a model-free
approach is still missing. We propose $E$-values, a generalization of counters
that can be used to evaluate the propagating exploratory value over
state-action trajectories. We compare our approach to commonly used RL
techniques, and show that using $E$-values improves learning and performance
over traditional counters. We also show how our method can be implemented with
function approximation to efficiently learn continuous MDPs. We demonstrate
this by showing that our approach surpasses state of the art performance in the
Freeway Atari 2600 game.","['Leshem Choshen', 'Lior Fox', 'Yonatan Loewenstein']","['cs.LG', 'cs.AI', 'stat.ML']",2018-04-11 14:21:53+00:00
http://arxiv.org/abs/1804.04512v1,DLL: A Blazing Fast Deep Neural Network Library,"Deep Learning Library (DLL) is a new library for machine learning with deep
neural networks that focuses on speed. It supports feed-forward neural networks
such as fully-connected Artificial Neural Networks (ANNs) and Convolutional
Neural Networks (CNNs). It also has very comprehensive support for Restricted
Boltzmann Machines (RBMs) and Convolutional RBMs. Our main motivation for this
work was to propose and evaluate novel software engineering strategies with
potential to accelerate runtime for training and inference. Such strategies are
mostly independent of the underlying deep learning algorithms. On three
different datasets and for four different neural network models, we compared
DLL to five popular deep learning frameworks. Experimentally, it is shown that
the proposed framework is systematically and significantly faster on CPU and
GPU. In terms of classification performance, similar accuracies as the other
frameworks are reported.","['Baptiste Wicht', 'Jean Hennebert', 'Andreas Fischer']","['cs.LG', 'cs.CV', 'stat.ML']",2018-04-11 13:56:07+00:00
http://arxiv.org/abs/1804.03981v1,Compressive Regularized Discriminant Analysis of High-Dimensional Data with Applications to Microarray Studies,"We propose a modification of linear discriminant analysis, referred to as
compressive regularized discriminant analysis (CRDA), for analysis of
high-dimensional datasets. CRDA is specially designed for feature elimination
purpose and can be used as gene selection method in microarray studies. CRDA
lends ideas from $\ell_{q,1}$ norm minimization algorithms in the multiple
measurement vectors (MMV) model and utilizes joint-sparsity promoting hard
thresholding for feature elimination. A regularization of the sample covariance
matrix is also needed as we consider the challenging scenario where the number
of features (variables) is comparable or exceeding the sample size of the
training dataset. A simulation study and four examples of real-life microarray
datasets evaluate the performances of CRDA based classifiers. Overall, the
proposed method gives fewer misclassification errors than its competitors,
while at the same time achieving accurate feature selection.","['Muhammad Naveed Tabassum', 'Esa Ollila']","['stat.ME', 'stat.AP', 'stat.ML']",2018-04-11 13:48:56+00:00
http://arxiv.org/abs/1804.03958v2,Interdependent Gibbs Samplers,"Gibbs sampling, as a model learning method, is known to produce the most
accurate results available in a variety of domains, and is a de facto standard
in these domains. Yet, it is also well known that Gibbs random walks usually
have bottlenecks, sometimes termed ""local maxima"", and thus samplers often
return suboptimal solutions. In this paper we introduce a variation of the
Gibbs sampler which yields high likelihood solutions significantly more often
than the regular Gibbs sampler.
  Specifically, we show that combining multiple samplers, with certain
dependence (coupling) between them, results in higher likelihood solutions.
This side-steps the well known issue of identifiability, which has been the
obstacle to combining samplers in previous work. We evaluate the approach on a
Latent Dirichlet Allocation model, and also on HMM's, where precise computation
of likelihoods and comparisons to the standard EM algorithm are possible.","['Mark Kozdoba', 'Shie Mannor']","['stat.ML', 'cs.LG']",2018-04-11 12:38:50+00:00
http://arxiv.org/abs/1804.03836v3,E-commerce Anomaly Detection: A Bayesian Semi-Supervised Tensor Decomposition Approach using Natural Gradients,"Anomaly Detection has several important applications. In this paper, our
focus is on detecting anomalies in seller-reviewer data using tensor
decomposition. While tensor-decomposition is mostly unsupervised, we formulate
Bayesian semi-supervised tensor decomposition to take advantage of sparse
labeled data. In addition, we use Polya-Gamma data augmentation for the
semi-supervised Bayesian tensor decomposition. Finally, we show that the
P\'olya-Gamma formulation simplifies calculation of the Fisher information
matrix for partial natural gradient learning. Our experimental results show
that our semi-supervised approach outperforms state of the art unsupervised
baselines. And that the partial natural gradient learning outperforms
stochastic gradient learning and Online-EM with sufficient statistics.","['Anil R. Yelundur', 'Srinivasan H. Sengamedu', 'Bamdev Mishra']","['cs.LG', 'stat.ML']",2018-04-11 06:55:06+00:00
http://arxiv.org/abs/1804.03811v1,Estimating Time-Varying Graphical Models,"In this paper, we study time-varying graphical models based on data measured
over a temporal grid. Such models are motivated by the needs to describe and
understand evolving interacting relationships among a set of random variables
in many real applications, for instance the study of how stocks interact with
each other and how such interactions change over time.
  We propose a new model, LOcal Group Graphical Lasso Estimation (loggle),
under the assumption that the graph topology changes gradually over time.
Specifically, loggle uses a novel local group-lasso type penalty to efficiently
incorporate information from neighboring time points and to impose structural
smoothness of the graphs. We implement an ADMM based algorithm to fit the
loggle model. This algorithm utilizes blockwise fast computation and
pseudo-likelihood approximation to improve computational efficiency. An R
package loggle has also been developed.
  We evaluate the performance of loggle by simulation experiments. We also
apply loggle to S&P 500 stock price data and demonstrate that loggle is able to
reveal the interacting relationships among stocks and among industrial sectors
in a time period that covers the recent global financial crisis.","['Jilei Yang', 'Jie Peng']","['stat.ML', 'cs.LG']",2018-04-11 04:54:56+00:00
http://arxiv.org/abs/1804.03797v1,Dynamic Multivariate Functional Data Modeling via Sparse Subspace Learning,"Multivariate functional data from a complex system are naturally
high-dimensional and have complex cross-correlation structure. The complexity
of data structure can be observed as that (1) some functions are strongly
correlated with similar features, while some others may have almost no
cross-correlations with quite diverse features; and (2) the cross-correlation
structure may also change over time due to the system evolution. With this
regard, this paper presents a dynamic subspace learning method for multivariate
functional data modeling. In particular, we consider different functions come
from different subspaces, and only functions of the same subspace have
cross-correlations with each other. The subspaces can be automatically
formulated and learned by reformatting the problem as a sparse regression. By
allowing but regularizing the regression change over time, we can describe the
cross-correlation dynamics. The model can be efficiently estimated by the fast
iterative shrinkage-thresholding algorithm (FISTA), and the features of every
subspace can be extracted using the smooth multi-channel functional PCA.
Numerical studies together with case studies demonstrate the efficiency and
applicability of the proposed methodology.","['Chen Zhang', 'Hao Yan', 'Seungho Lee', 'Jianjun Shi']","['stat.ML', 'cs.LG']",2018-04-11 03:32:16+00:00
http://arxiv.org/abs/1804.03794v1,Differentially Private Confidence Intervals for Empirical Risk Minimization,"The process of data mining with differential privacy produces results that
are affected by two types of noise: sampling noise due to data collection and
privacy noise that is designed to prevent the reconstruction of sensitive
information. In this paper, we consider the problem of designing confidence
intervals for the parameters of a variety of differentially private machine
learning models. The algorithms can provide confidence intervals that satisfy
differential privacy (as well as the more recently proposed concentrated
differential privacy) and can be used with existing differentially private
mechanisms that train models using objective perturbation and output
perturbation.","['Yue Wang', 'Daniel Kifer', 'Jaewoo Lee']","['cs.LG', 'cs.CR', 'stat.ML']",2018-04-11 03:18:17+00:00
http://arxiv.org/abs/1804.04503v2,Unleashing Linear Optimizers for Group-Fair Learning and Optimization,"Most systems and learning algorithms optimize average performance or average
loss -- one reason being computational complexity. However, many objectives of
practical interest are more complex than simply average loss. This arises, for
example, when balancing performance or loss with fairness across people. We
prove that, from a computational perspective, optimizing arbitrary objectives
that take into account performance over a small number of groups is not
significantly harder to optimize than average performance. Our main result is a
polynomial-time reduction that uses a linear optimizer to optimize an arbitrary
(Lipschitz continuous) function of performance over a (constant) number of
possibly-overlapping groups. This includes fairness objectives over small
numbers of groups, and we further point out that other existing notions of
fairness such as individual fairness can be cast as convex optimization and
hence more standard convex techniques can be used. Beyond learning, our
approach applies to multi-objective optimization, more generally.","['Daniel Alabi', 'Nicole Immorlica', 'Adam Tauman Kalai']","['cs.LG', 'cs.DS', 'stat.ML']",2018-04-11 02:51:07+00:00
http://arxiv.org/abs/1804.03782v3,CoT: Cooperative Training for Generative Modeling of Discrete Data,"In this paper, we study the generative models of sequential discrete data. To
tackle the exposure bias problem inherent in maximum likelihood estimation
(MLE), generative adversarial networks (GANs) are introduced to penalize the
unrealistic generated samples. To exploit the supervision signal from the
discriminator, most previous models leverage REINFORCE to address the
non-differentiable problem of sequential discrete data. However, because of the
unstable property of the training signal during the dynamic process of
adversarial training, the effectiveness of REINFORCE, in this case, is hardly
guaranteed. To deal with such a problem, we propose a novel approach called
Cooperative Training (CoT) to improve the training of sequence generative
models. CoT transforms the min-max game of GANs into a joint maximization
framework and manages to explicitly estimate and optimize Jensen-Shannon
divergence. Moreover, CoT works without the necessity of pre-training via MLE,
which is crucial to the success of previous methods. In the experiments,
compared to existing state-of-the-art methods, CoT shows superior or at least
competitive performance on sample quality, diversity, as well as training
stability.","['Sidi Lu', 'Lantao Yu', 'Siyuan Feng', 'Yaoming Zhu', 'Weinan Zhang', 'Yong Yu']","['cs.LG', 'cs.AI', 'cs.CL', 'stat.ML']",2018-04-11 02:10:55+00:00
http://arxiv.org/abs/1804.03761v1,Derivative free optimization via repeated classification,"We develop an algorithm for minimizing a function using $n$ batched function
value measurements at each of $T$ rounds by using classifiers to identify a
function's sublevel set. We show that sufficiently accurate classifiers can
achieve linear convergence rates, and show that the convergence rate is tied to
the difficulty of active learning sublevel sets. Further, we show that the
bootstrap is a computationally efficient approximation to the necessary
classification scheme.
  The end result is a computationally efficient derivative-free algorithm
requiring no tuning that consistently outperforms other approaches on
simulations, standard benchmarks, real-world DNA binding optimization, and
airfoil design problems whenever batched function queries are natural.","['Tatsunori B. Hashimoto', 'Steve Yadlowsky', 'John C. Duchi']","['stat.ML', 'cs.LG']",2018-04-11 00:45:39+00:00
http://arxiv.org/abs/1804.03758v1,Universal Successor Representations for Transfer Reinforcement Learning,"The objective of transfer reinforcement learning is to generalize from a set
of previous tasks to unseen new tasks. In this work, we focus on the transfer
scenario where the dynamics among tasks are the same, but their goals differ.
Although general value function (Sutton et al., 2011) has been shown to be
useful for knowledge transfer, learning a universal value function can be
challenging in practice. To attack this, we propose (1) to use universal
successor representations (USR) to represent the transferable knowledge and (2)
a USR approximator (USRA) that can be trained by interacting with the
environment. Our experiments show that USR can be effectively applied to new
tasks, and the agent initialized by the trained USRA can achieve the goal
considerably faster than random initialization.","['Chen Ma', 'Junfeng Wen', 'Yoshua Bengio']","['cs.AI', 'cs.LG', 'stat.ML']",2018-04-11 00:06:36+00:00
http://arxiv.org/abs/1804.03740v3,Multimodal Sparse Bayesian Dictionary Learning,"This paper addresses the problem of learning dictionaries for multimodal
datasets, i.e. datasets collected from multiple data sources. We present an
algorithm called multimodal sparse Bayesian dictionary learning (MSBDL). MSBDL
leverages information from all available data modalities through a joint
sparsity constraint. The underlying framework offers a considerable amount of
flexibility to practitioners and addresses many of the shortcomings of existing
multimodal dictionary learning approaches. In particular, the procedure
includes the automatic tuning of hyperparameters and is unique in that it
allows the dictionaries for each data modality to have different cardinality, a
significant feature in cases when the dimensionality of data differs across
modalities. MSBDL is scalable and can be used in supervised learning settings.
Theoretical results relating to the convergence of MSBDL are presented and the
numerical results provide evidence of the superior performance of MSBDL on
synthetic and real datasets compared to existing methods.","['Igor Fedorov', 'Bhaskar D. Rao']","['stat.ML', 'cs.LG']",2018-04-10 22:27:21+00:00
http://arxiv.org/abs/1804.03728v2,Tensor Robust Principal Component Analysis with A New Tensor Nuclear Norm,"In this paper, we consider the Tensor Robust Principal Component Analysis
(TRPCA) problem, which aims to exactly recover the low-rank and sparse
components from their sum. Our model is based on the recently proposed
tensor-tensor product (or t-product). Induced by the t-product, we first
rigorously deduce the tensor spectral norm, tensor nuclear norm, and tensor
average rank, and show that the tensor nuclear norm is the convex envelope of
the tensor average rank within the unit ball of the tensor spectral norm. These
definitions, their relationships and properties are consistent with matrix
cases. Equipped with the new tensor nuclear norm, we then solve the TRPCA
problem by solving a convex program and provide the theoretical guarantee for
the exact recovery. Our TRPCA model and recovery guarantee include matrix RPCA
as a special case. Numerical experiments verify our results, and the
applications to image recovery and background modeling problems demonstrate the
effectiveness of our method.","['Canyi Lu', 'Jiashi Feng', 'Yudong Chen', 'Wei Liu', 'Zhouchen Lin', 'Shuicheng Yan']","['stat.ML', 'cs.LG']",2018-04-10 21:29:30+00:00
http://arxiv.org/abs/1804.03720v2,Gotta Learn Fast: A New Benchmark for Generalization in RL,"In this report, we present a new reinforcement learning (RL) benchmark based
on the Sonic the Hedgehog (TM) video game franchise. This benchmark is intended
to measure the performance of transfer learning and few-shot learning
algorithms in the RL domain. We also present and evaluate some baseline
algorithms on the new benchmark.","['Alex Nichol', 'Vicki Pfau', 'Christopher Hesse', 'Oleg Klimov', 'John Schulman']","['cs.LG', 'stat.ML']",2018-04-10 21:09:53+00:00
http://arxiv.org/abs/1804.03635v1,Semantic embeddings for program behavior patterns,"In this paper, we propose a new feature extraction technique for program
execution logs. First, we automatically extract complex patterns from a
program's behavior graph. Then, we embed these patterns into a continuous space
by training an autoencoder. We evaluate the proposed features on a real-world
malicious software detection task. We also find that the embedding space
captures interpretable structures in the space of pattern parts.","['Alexander Chistyakov', 'Ekaterina Lobacheva', 'Arseny Kuznetsov', 'Alexey Romanenko']","['cs.CR', 'stat.ML']",2018-04-10 17:26:54+00:00
http://arxiv.org/abs/1804.03629v1,Probabilistic Prediction of Vehicle Semantic Intention and Motion,"Accurately predicting the possible behaviors of traffic participants is an
essential capability for future autonomous vehicles. The majority of current
researches fix the number of driving intentions by considering only a specific
scenario. However, distinct driving environments usually contain various
possible driving maneuvers. Therefore, a intention prediction method that can
adapt to different traffic scenarios is needed. To further improve the overall
vehicle prediction performance, motion information is usually incorporated with
classified intentions. As suggested in some literature, the methods that
directly predict possible goal locations can achieve better performance for
long-term motion prediction than other approaches due to their automatic
incorporation of environment constraints. Moreover, by obtaining the temporal
information of the predicted destinations, the optimal trajectories for
predicted vehicles as well as the desirable path for ego autonomous vehicle
could be easily generated. In this paper, we propose a Semantic-based Intention
and Motion Prediction (SIMP) method, which can be adapted to any driving
scenarios by using semantic-defined vehicle behaviors. It utilizes a
probabilistic framework based on deep neural network to estimate the
intentions, final locations, and the corresponding time information for
surrounding vehicles. An exemplar real-world scenario was used to implement and
examine the proposed method.","['Yeping Hu', 'Wei Zhan', 'Masayoshi Tomizuka']","['cs.LG', 'stat.ML']",2018-04-10 17:05:53+00:00
http://arxiv.org/abs/1804.03615v1,"Subsampled Optimization: Statistical Guarantees, Mean Squared Error Approximation, and Sampling Method","For optimization on large-scale data, exactly calculating its solution may be
computationally difficulty because of the large size of the data. In this paper
we consider subsampled optimization for fast approximating the exact solution.
In this approach, one gets a surrogate dataset by sampling from the full data,
and then obtains an approximate solution by solving the subsampled optimization
based on the surrogate. One main theoretical contributions are to provide the
asymptotic properties of the approximate solution with respect to the exact
solution as statistical guarantees, and to rigorously derive an accurate
approximation of the mean squared error (MSE) and an approximately unbiased MSE
estimator. These results help us better diagnose the subsampled optimization in
the context that a confidence region on the exact solution is provided using
the approximate solution. The other consequence of our results is to propose an
optimal sampling method, Hessian-based sampling, whose probabilities are
proportional to the norms of Newton directions. Numerical experiments with
least-squares and logistic regression show promising performance, in line with
our results.","['Rong Zhu', 'Jiming Jiang']","['stat.ML', 'cs.LG']",2018-04-10 16:18:10+00:00
http://arxiv.org/abs/1804.03599v1,Understanding disentangling in $Î²$-VAE,"We present new intuitions and theoretical assessments of the emergence of
disentangled representation in variational autoencoders. Taking a
rate-distortion theory perspective, we show the circumstances under which
representations aligned with the underlying generative factors of variation of
data emerge when optimising the modified ELBO bound in $\beta$-VAE, as training
progresses. From these insights, we propose a modification to the training
regime of $\beta$-VAE, that progressively increases the information capacity of
the latent code during training. This modification facilitates the robust
learning of disentangled representations in $\beta$-VAE, without the previous
trade-off in reconstruction accuracy.","['Christopher P. Burgess', 'Irina Higgins', 'Arka Pal', 'Loic Matthey', 'Nick Watters', 'Guillaume Desjardins', 'Alexander Lerchner']","['stat.ML', 'cs.AI', 'cs.LG']",2018-04-10 15:48:18+00:00
http://arxiv.org/abs/1804.03578v1,Towards Training Probabilistic Topic Models on Neuromorphic Multi-chip Systems,"Probabilistic topic models are popular unsupervised learning methods,
including probabilistic latent semantic indexing (pLSI) and latent Dirichlet
allocation (LDA). By now, their training is implemented on general purpose
computers (GPCs), which are flexible in programming but energy-consuming.
Towards low-energy implementations, this paper investigates their training on
an emerging hardware technology called the neuromorphic multi-chip systems
(NMSs). NMSs are very effective for a family of algorithms called spiking
neural networks (SNNs). We present three SNNs to train topic models. The first
SNN is a batch algorithm combining the conventional collapsed Gibbs sampling
(CGS) algorithm and an inference SNN to train LDA. The other two SNNs are
online algorithms targeting at both energy- and storage-limited environments.
The two online algorithms are equivalent with training LDA by using
maximum-a-posterior estimation and maximizing the semi-collapsed likelihood,
respectively. They use novel, tailored ordinary differential equations for
stochastic optimization. We simulate the new algorithms and show that they are
comparable with the GPC algorithms, while being suitable for NMS
implementation. We also propose an extension to train pLSI and a method to
prune the network to obey the limited fan-in of some NMSs.","['Zihao Xiao', 'Jianfei Chen', 'Jun Zhu']","['cs.LG', 'cs.AI', 'cs.ET', 'stat.ML']",2018-04-10 15:01:50+00:00
http://arxiv.org/abs/1804.03515v2,Hyperparameters and Tuning Strategies for Random Forest,"The random forest algorithm (RF) has several hyperparameters that have to be
set by the user, e.g., the number of observations drawn randomly for each tree
and whether they are drawn with or without replacement, the number of variables
drawn randomly for each split, the splitting rule, the minimum number of
samples that a node must contain and the number of trees. In this paper, we
first provide a literature review on the parameters' influence on the
prediction performance and on variable importance measures.
  It is well known that in most cases RF works reasonably well with the default
values of the hyperparameters specified in software packages. Nevertheless,
tuning the hyperparameters can improve the performance of RF. In the second
part of this paper, after a brief overview of tuning strategies we demonstrate
the application of one of the most established tuning strategies, model-based
optimization (MBO). To make it easier to use, we provide the tuneRanger R
package that tunes RF with MBO automatically. In a benchmark study on several
datasets, we compare the prediction performance and runtime of tuneRanger with
other tuning implementations in R and RF with default hyperparameters.","['Philipp Probst', 'Marvin Wright', 'Anne-Laure Boulesteix']","['stat.ML', 'cs.LG']",2018-04-10 13:30:51+00:00
http://arxiv.org/abs/1804.03429v2,Graphical Generative Adversarial Networks,"We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model
structured data. Graphical-GAN conjoins the power of Bayesian networks on
compactly representing the dependency structures among random variables and
that of generative adversarial networks on learning expressive dependency
functions. We introduce a structured recognition model to infer the posterior
distribution of latent variables given observations. We generalize the
Expectation Propagation (EP) algorithm to learn the generative model and
recognition model jointly. Finally, we present two important instances of
Graphical-GAN, i.e. Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN),
which can successfully learn the discrete and temporal structures on visual
datasets, respectively.","['Chongxuan Li', 'Max Welling', 'Jun Zhu', 'Bo Zhang']","['cs.LG', 'cs.CV', 'stat.ML']",2018-04-10 10:12:38+00:00
http://arxiv.org/abs/1804.03346v3,Learning Latent Events from Network Message Logs,"We consider the problem of separating error messages generated in large
distributed data center networks into error events. In such networks, each
error event leads to a stream of messages generated by hardware and software
components affected by the event. These messages are stored in a giant message
log. We consider the unsupervised learning problem of identifying the
signatures of events that generated these messages; here, the signature of an
error event refers to the mixture of messages generated by the event. One of
the main contributions of the paper is a novel mapping of our problem which
transforms it into a problem of topic discovery in documents. Events in our
problem correspond to topics and messages in our problem correspond to words in
the topic discovery problem. However, there is no direct analog of documents.
Therefore, we use a non-parametric change-point detection algorithm, which has
linear computational complexity in the number of messages, to divide the
message log into smaller subsets called episodes, which serve as the
equivalents of documents. After this mapping has been done, we use a well-known
algorithm for topic discovery, called LDA, to solve our problem. We
theoretically analyze the change-point detection algorithm, and show that it is
consistent and has low sample complexity. We also demonstrate the scalability
of our algorithm on a real data set consisting of $97$ million messages
collected over a period of $15$ days, from a distributed data center network
which supports the operations of a large wireless service provider.","['Siddhartha Satpathi', 'Supratim Deb', 'R Srikant', 'He Yan']","['cs.LG', 'stat.ML']",2018-04-10 05:44:53+00:00
http://arxiv.org/abs/1804.03286v1,On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses,"Neural networks are known to be vulnerable to adversarial examples. In this
note, we evaluate the two white-box defenses that appeared at CVPR 2018 and
find they are ineffective: when applying existing techniques, we can reduce the
accuracy of the defended models to 0%.","['Anish Athalye', 'Nicholas Carlini']","['cs.CV', 'cs.CR', 'cs.LG', 'stat.ML']",2018-04-10 04:54:29+00:00
http://arxiv.org/abs/1804.03334v1,TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic Meta-descent,"In this paper, we introduce a method for adapting the step-sizes of temporal
difference (TD) learning. The performance of TD methods often depends on well
chosen step-sizes, yet few algorithms have been developed for setting the
step-size automatically for TD learning. An important limitation of current
methods is that they adapt a single step-size shared by all the weights of the
learning system. A vector step-size enables greater optimization by specifying
parameters on a per-feature basis. Furthermore, adapting parameters at
different rates has the added benefit of being a simple form of representation
learning. We generalize Incremental Delta Bar Delta (IDBD)---a vectorized
adaptive step-size method for supervised learning---to TD learning, which we
name TIDBD. We demonstrate that TIDBD is able to find appropriate step-sizes in
both stationary and non-stationary prediction tasks, outperforming ordinary TD
methods and TD methods with scalar step-size adaptation; we demonstrate that it
can differentiate between features which are relevant and irrelevant for a
given task, performing representation learning; and we show on a real-world
robot prediction task that TIDBD is able to outperform ordinary TD methods and
TD methods augmented with AlphaBound and RMSprop.","['Alex Kearney', 'Vivek Veeriah', 'Jaden B. Travnik', 'Richard S. Sutton', 'Patrick M. Pilarski']","['cs.LG', 'stat.ML']",2018-04-10 04:01:07+00:00
