id,title,abstract,authors,categories,date
http://arxiv.org/abs/2010.00724v1,Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations and visualizations via ParaMonte::Python library,"ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial
and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for
sampling mathematical objective functions, in particular, the posterior
distributions of parameters in Bayesian modeling and analysis in data science,
Machine Learning, and scientific inference in general. In addition to providing
access to fast high-performance serial/parallel Monte Carlo and MCMC sampling
routines, the ParaMonte::Python library provides extensive post-processing and
visualization tools that aim to automate and streamline the process of model
calibration and uncertainty quantification in Bayesian data analysis.
Furthermore, the automatically-enabled restart functionality of
ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future
restart of Monte Carlo simulations, should any interruptions happen. The
ParaMonte::Python library is MIT-licensed and is permanently maintained on
GitHub at
https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.","['Amir Shahmoradi', 'Fatemeh Bagheri', 'Joshua Alexander Osborne']","['cs.MS', 'astro-ph.IM', 'q-bio.QM', 'stat.ML']",2020-10-01 23:26:42+00:00
http://arxiv.org/abs/2010.00718v1,When to Impute? Imputation before and during cross-validation,"Cross-validation (CV) is a technique used to estimate generalization error
for prediction models. For pipeline modeling algorithms (i.e. modeling
procedures with multiple steps), it has been recommended the entire sequence of
steps be carried out during each replicate of CV to mimic the application of
the entire pipeline to an external testing set. While theoretically sound,
following this recommendation can lead to high computational costs when a
pipeline modeling algorithm includes computationally expensive operations, e.g.
imputation of missing values. There is a general belief that unsupervised
variable selection (i.e. ignoring the outcome) can be applied before conducting
CV without incurring bias, but there is less consensus for unsupervised
imputation of missing values. We empirically assessed whether conducting
unsupervised imputation prior to CV would result in biased estimates of
generalization error or result in poorly selected tuning parameters and thus
degrade the external performance of downstream models. Results show that
despite optimistic bias, the reduced variance of imputation before CV compared
to imputation during each replicate of CV leads to a lower overall root mean
squared error for estimation of the true external R-squared and the performance
of models tuned using CV with imputation before versus during each replication
is minimally different. In conclusion, unsupervised imputation before CV
appears valid in certain settings and may be a helpful strategy that enables
analysts to use more flexible imputation techniques without incurring high
computational costs.","['Byron C. Jaeger', 'Nicholas J. Tierney', 'Noah R. Simon']","['stat.ML', 'cs.LG', 'stat.CO']",2020-10-01 23:04:16+00:00
http://arxiv.org/abs/2010.00712v2,Faster Binary Embeddings for Preserving Euclidean Distances,"We propose a fast, distance-preserving, binary embedding algorithm to
transform a high-dimensional dataset $\mathcal{T}\subseteq\mathbb{R}^n$ into
binary sequences in the cube $\{\pm 1\}^m$. When $\mathcal{T}$ consists of
well-spread (i.e., non-sparse) vectors, our embedding method applies a stable
noise-shaping quantization scheme to $A x$ where $A\in\mathbb{R}^{m\times n}$
is a sparse Gaussian random matrix. This contrasts with most binary embedding
methods, which usually use $x\mapsto \mathrm{sign}(Ax)$ for the embedding.
Moreover, we show that Euclidean distances among the elements of $\mathcal{T}$
are approximated by the $\ell_1$ norm on the images of $\{\pm 1\}^m$ under a
fast linear transformation. This again contrasts with standard methods, where
the Hamming distance is used instead. Our method is both fast and memory
efficient, with time complexity $O(m)$ and space complexity $O(m)$. Further, we
prove that the method is accurate and its associated error is comparable to
that of a continuous valued Johnson-Lindenstrauss embedding plus a quantization
error that admits a polynomial decay as the embedding dimension $m$ increases.
Thus the length of the binary codes required to achieve a desired accuracy is
quite small, and we show it can even be compressed further without compromising
the accuracy. To illustrate our results, we test the proposed method on natural
images and show that it achieves strong performance.","['Jinjie Zhang', 'Rayan Saab']","['cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2020-10-01 22:41:41+00:00
http://arxiv.org/abs/2010.00679v2,Implicit Rank-Minimizing Autoencoder,"An important component of autoencoders is the method by which the information
capacity of the latent representation is minimized or limited. In this work,
the rank of the covariance matrix of the codes is implicitly minimized by
relying on the fact that gradient descent learning in multi-layer linear
networks leads to minimum-rank solutions. By inserting a number of extra linear
layers between the encoder and the decoder, the system spontaneously learns
representations with a low effective dimension. The model, dubbed Implicit
Rank-Minimizing Autoencoder (IRMAE), is simple, deterministic, and learns
compact latent spaces. We demonstrate the validity of the method on several
image generation and representation learning tasks.","['Li Jing', 'Jure Zbontar', 'Yann LeCun']","['cs.LG', 'cs.CV', 'stat.ML']",2020-10-01 20:48:52+00:00
http://arxiv.org/abs/2010.04114v2,A Machine Learning Framework for Computing the Most Probable Paths of Stochastic Dynamical Systems,"The emergence of transition phenomena between metastable states induced by
noise plays a fundamental role in a broad range of nonlinear systems. The
computation of the most probable paths is a key issue to understand the
mechanism of transition behaviors. Shooting method is a common technique for
this purpose to solve the Euler-Lagrange equation for the associated action
functional, while losing its efficacy in high-dimensional systems. In the
present work, we develop a machine learning framework to compute the most
probable paths in the sense of Onsager-Machlup action functional theory.
Specifically, we reformulate the boundary value problem of Hamiltonian system
and design a neural network to remedy the shortcomings of shooting method. The
successful applications of our algorithms to several prototypical examples
demonstrate its efficacy and accuracy for stochastic systems with both
(Gaussian) Brownian noise and (non-Gaussian) L\'evy noise. This novel approach
is effective in exploring the internal mechanisms of rare events triggered by
random fluctuations in various scientific fields.","['Yang Li', 'Jinqiao Duan', 'Xianbin Liu']","['math.DS', 'math.PR', 'math.ST', 'nlin.CD', 'physics.comp-ph', 'stat.ML', 'stat.TH']",2020-10-01 20:01:37+00:00
http://arxiv.org/abs/2010.00654v3,VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models,"Energy-based models (EBMs) have recently been successful in representing
complex distributions of small images. However, sampling from them requires
expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high
dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate
samples quickly and are equipped with a latent space that enables fast
traversal of the data manifold. However, VAEs tend to assign high probability
density to regions in data space outside the actual data distribution and often
fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic
composition of a VAE and an EBM that offers the best of both worlds. VAEBM
captures the overall mode structure of the data distribution using a
state-of-the-art VAE and it relies on its EBM component to explicitly exclude
non-data-like regions from the model and refine the image samples. Moreover,
the VAE component in VAEBM allows us to speed up MCMC updates by
reparameterizing them in the VAE's latent space. Our experimental results show
that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on
several benchmark image datasets by a large margin. It can generate
high-quality images as large as 256$\times$256 pixels with short MCMC chains.
We also demonstrate that VAEBM provides complete mode coverage and performs
well in out-of-distribution detection. The source code is available at
https://github.com/NVlabs/VAEBM","['Zhisheng Xiao', 'Karsten Kreis', 'Jan Kautz', 'Arash Vahdat']","['cs.LG', 'cs.CV', 'stat.ML']",2020-10-01 19:28:28+00:00
http://arxiv.org/abs/2010.00636v2,Universal consistency and rates of convergence of multiclass prototype algorithms in metric spaces,"We study universal consistency and convergence rates of simple
nearest-neighbor prototype rules for the problem of multiclass classification
in metric paces. We first show that a novel data-dependent partitioning rule,
named Proto-NN, is universally consistent in any metric space that admits a
universally consistent rule. Proto-NN is a significant simplification of
OptiNet, a recently proposed compression-based algorithm that, to date, was the
only algorithm known to be universally consistent in such a general setting.
Practically, Proto-NN is simpler to implement and enjoys reduced computational
complexity.
  We then proceed to study convergence rates of the excess error probability.
We first obtain rates for the standard $k$-NN rule under a margin condition and
a new generalized-Lipschitz condition. The latter is an extension of a recently
proposed modified-Lipschitz condition from $\mathbb R^d$ to metric spaces.
Similarly to the modified-Lipschitz condition, the new condition avoids any
boundness assumptions on the data distribution. While obtaining rates for
Proto-NN is left open, we show that a second prototype rule that hybridizes
between $k$-NN and Proto-NN achieves the same rates as $k$-NN while enjoying
similar computational advantages as Proto-NN. However, as $k$-NN, this hybrid
rule is not consistent in general.","['László Györfi', 'Roi Weiss']","['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2020-10-01 18:23:22+00:00
http://arxiv.org/abs/2010.00587v3,Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs,"We study the reinforcement learning problem for discounted Markov Decision
Processes (MDPs) under the tabular setting. We propose a model-based algorithm
named UCBVI-$\gamma$, which is based on the \emph{optimism in the face of
uncertainty principle} and the Bernstein-type bonus. We show that
UCBVI-$\gamma$ achieves an $\tilde{O}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$
regret, where $S$ is the number of states, $A$ is the number of actions,
$\gamma$ is the discount factor and $T$ is the number of steps. In addition, we
construct a class of hard MDPs and show that for any algorithm, the expected
regret is at least $\tilde{\Omega}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$.
Our upper bound matches the minimax lower bound up to logarithmic factors,
which suggests that UCBVI-$\gamma$ is nearly minimax optimal for discounted
MDPs.","['Jiafan He', 'Dongruo Zhou', 'Quanquan Gu']","['cs.LG', 'math.OC', 'stat.ML']",2020-10-01 17:57:47+00:00
http://arxiv.org/abs/2010.00581v3,Emergent Social Learning via Multi-agent Reinforcement Learning,"Social learning is a key component of human and animal intelligence. By
taking cues from the behavior of experts in their environment, social learners
can acquire sophisticated behavior and rapidly adapt to new circumstances. This
paper investigates whether independent reinforcement learning (RL) agents in a
multi-agent environment can learn to use social learning to improve their
performance. We find that in most circumstances, vanilla model-free RL agents
do not use social learning. We analyze the reasons for this deficiency, and
show that by imposing constraints on the training environment and introducing a
model-based auxiliary loss we are able to obtain generalized social learning
policies which enable agents to: i) discover complex skills that are not
learned from single-agent training, and ii) adapt online to novel environments
by taking cues from experts present in the new environment. In contrast, agents
trained with model-free RL or imitation learning generalize poorly and do not
succeed in the transfer tasks. By mixing multi-agent and solo training, we can
obtain agents that use social learning to gain skills that they can deploy when
alone, even out-performing agents trained alone from the start.","['Kamal Ndousse', 'Douglas Eck', 'Sergey Levine', 'Natasha Jaques']","['cs.LG', 'cs.AI', 'cs.MA', 'stat.ML']",2020-10-01 17:54:14+00:00
http://arxiv.org/abs/2010.00578v6,Understanding Self-supervised Learning with Dual Deep Networks,"We propose a novel theoretical framework to understand contrastive
self-supervised learning (SSL) methods that employ dual pairs of deep ReLU
networks (e.g., SimCLR). First, we prove that in each SGD update of SimCLR with
various loss functions, including simple contrastive loss, soft Triplet loss
and InfoNCE loss, the weights at each layer are updated by a \emph{covariance
operator} that specifically amplifies initial random selectivities that vary
across data samples but survive averages over data augmentations. To further
study what role the covariance operator plays and which features are learned in
such a process, we model data generation and augmentation processes through a
\emph{hierarchical latent tree model} (HLTM) and prove that the hidden neurons
of deep ReLU networks can learn the latent variables in HLTM, despite the fact
that the network receives \emph{no direct supervision} from these unobserved
latent variables. This leads to a provable emergence of hierarchical features
through the amplification of initially random selectivities through contrastive
SSL. Extensive numerical studies justify our theoretical findings. Code is
released in https://github.com/facebookresearch/luckmatters/tree/master/ssl.","['Yuandong Tian', 'Lantao Yu', 'Xinlei Chen', 'Surya Ganguli']","['cs.LG', 'cs.AI', 'stat.ML']",2020-10-01 17:51:49+00:00
http://arxiv.org/abs/2010.00577v3,Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,"Graph neural networks (GNNs) have become a popular approach to integrating
structural inductive biases into NLP models. However, there has been little
work on interpreting them, and specifically on understanding which parts of the
graphs (e.g. syntactic trees or co-reference structures) contribute to a
prediction. In this work, we introduce a post-hoc method for interpreting the
predictions of GNNs which identifies unnecessary edges. Given a trained GNN
model, we learn a simple classifier that, for every edge in every layer,
predicts if that edge can be dropped. We demonstrate that such a classifier can
be trained in a fully differentiable fashion, employing stochastic gates and
encouraging sparsity through the expected $L_0$ norm. We use our technique as
an attribution method to analyze GNN models for two tasks -- question answering
and semantic role labeling -- providing insights into the information flow in
these models. We show that we can drop a large proportion of edges without
deteriorating the performance of the model, while we can analyse the remaining
edges for interpreting model predictions.","['Michael Sejr Schlichtkrull', 'Nicola De Cao', 'Ivan Titov']","['cs.CL', 'cs.LG', 'stat.ML']",2020-10-01 17:51:19+00:00
http://arxiv.org/abs/2010.00567v1,Deep learning for time series classification,"Time series analysis is a field of data science which is interested in
analyzing sequences of numerical values ordered in time. Time series are
particularly interesting because they allow us to visualize and understand the
evolution of a process over time. Their analysis can reveal trends,
relationships and similarities across the data. There exists numerous fields
containing data in the form of time series: health care (electrocardiogram,
blood sugar, etc.), activity recognition, remote sensing, finance (stock market
price), industry (sensors), etc. Time series classification consists of
constructing algorithms dedicated to automatically label time series data. The
sequential aspect of time series data requires the development of algorithms
that are able to harness this temporal property, thus making the existing
off-the-shelf machine learning models for traditional tabular data suboptimal
for solving the underlying task. In this context, deep learning has emerged in
recent years as one of the most effective methods for tackling the supervised
classification task, particularly in the field of computer vision. The main
objective of this thesis was to study and develop deep neural networks
specifically constructed for the classification of time series data. We thus
carried out the first large scale experimental study allowing us to compare the
existing deep methods and to position them compared other non-deep learning
based state-of-the-art methods. Subsequently, we made numerous contributions in
this area, notably in the context of transfer learning, data augmentation,
ensembling and adversarial attacks. Finally, we have also proposed a novel
architecture, based on the famous Inception network (Google), which ranks among
the most efficient to date.",['Hassan Ismail Fawaz'],"['cs.LG', 'cs.AI', 'stat.ML']",2020-10-01 17:38:40+00:00
http://arxiv.org/abs/2010.00554v2,EigenGame: PCA as a Nash Equilibrium,"We present a novel view on principal component analysis (PCA) as a
competitive game in which each approximate eigenvector is controlled by a
player whose goal is to maximize their own utility function. We analyze the
properties of this PCA game and the behavior of its gradient based updates. The
resulting algorithm -- which combines elements from Oja's rule with a
generalized Gram-Schmidt orthogonalization -- is naturally decentralized and
hence parallelizable through message passing. We demonstrate the scalability of
the algorithm with experiments on large image datasets and neural network
activations. We discuss how this new view of PCA as a differentiable game can
lead to further algorithmic developments and insights.","['Ian Gemp', 'Brian McWilliams', 'Claire Vernade', 'Thore Graepel']","['cs.LG', 'stat.ML']",2020-10-01 17:12:33+00:00
http://arxiv.org/abs/2010.00540v2,Robustness Analysis of Neural Networks via Efficient Partitioning with Applications in Control Systems,"Neural networks (NNs) are now routinely implemented on systems that must
operate in uncertain environments, but the tools for formally analyzing how
this uncertainty propagates to NN outputs are not yet commonplace. Computing
tight bounds on NN output sets (given an input set) provides a measure of
confidence associated with the NN decisions and is essential to deploy NNs on
safety-critical systems. Recent works approximate the propagation of sets
through nonlinear activations or partition the uncertainty set to provide a
guaranteed outer bound on the set of possible NN outputs. However, the bound
looseness causes excessive conservatism and/or the computation is too slow for
online analysis. This paper unifies propagation and partition approaches to
provide a family of robustness analysis algorithms that give tighter bounds
than existing works for the same amount of computation time (or reduced
computational effort for a desired accuracy level). Moreover, we provide new
partitioning techniques that are aware of their current bound estimates and
desired boundary shape (e.g., lower bounds, weighted $\ell_\infty$-ball, convex
hull), leading to further improvements in the computation-tightness tradeoff.
The paper demonstrates the tighter bounds and reduced conservatism of the
proposed robustness analysis framework with examples from model-free RL and
forward kinematics learning.","['Michael Everett', 'Golnaz Habibi', 'Jonathan P. How']","['cs.LG', 'cs.SY', 'eess.SY', 'stat.ML']",2020-10-01 16:51:36+00:00
http://arxiv.org/abs/2010.00539v2,Agnostic Learning of Halfspaces with Gradient Descent via Soft Margins,"We analyze the properties of gradient descent on convex surrogates for the
zero-one loss for the agnostic learning of linear halfspaces. If $\mathsf{OPT}$
is the best classification error achieved by a halfspace, by appealing to the
notion of soft margins we are able to show that gradient descent finds
halfspaces with classification error $\tilde O(\mathsf{OPT}^{1/2}) +
\varepsilon$ in $\mathrm{poly}(d,1/\varepsilon)$ time and sample complexity for
a broad class of distributions that includes log-concave isotropic
distributions as a subclass. Along the way we answer a question recently posed
by Ji et al. (2020) on how the tail behavior of a loss function can affect
sample complexity and runtime guarantees for gradient descent.","['Spencer Frei', 'Yuan Cao', 'Quanquan Gu']","['cs.LG', 'math.OC', 'stat.ML']",2020-10-01 16:48:33+00:00
http://arxiv.org/abs/2010.00525v4,A biologically plausible neural network for multi-channel Canonical Correlation Analysis,"Cortical pyramidal neurons receive inputs from multiple distinct neural
populations and integrate these inputs in separate dendritic compartments. We
explore the possibility that cortical microcircuits implement Canonical
Correlation Analysis (CCA), an unsupervised learning method that projects the
inputs onto a common subspace so as to maximize the correlations between the
projections. To this end, we seek a multi-channel CCA algorithm that can be
implemented in a biologically plausible neural network. For biological
plausibility, we require that the network operates in the online setting and
its synaptic update rules are local. Starting from a novel CCA objective
function, we derive an online optimization algorithm whose optimization steps
can be implemented in a single-layer neural network with multi-compartmental
neurons and local non-Hebbian learning rules. We also derive an extension of
our online CCA algorithm with adaptive output rank and output whitening.
Interestingly, the extension maps onto a neural network whose neural
architecture and synaptic updates resemble neural circuitry and synaptic
plasticity observed experimentally in cortical pyramidal neurons.","['David Lipshutz', 'Yanis Bahroun', 'Siavash Golkar', 'Anirvan M. Sengupta', 'Dmitri B. Chklovskii']","['q-bio.NC', 'cs.NE', 'stat.ML']",2020-10-01 16:17:53+00:00
http://arxiv.org/abs/2010.00522v1,Understanding the Role of Adversarial Regularization in Supervised Learning,"Despite numerous attempts sought to provide empirical evidence of adversarial
regularization outperforming sole supervision, the theoretical understanding of
such phenomena remains elusive. In this study, we aim to resolve whether
adversarial regularization indeed performs better than sole supervision at a
fundamental level. To bring this insight into fruition, we study vanishing
gradient issue, asymptotic iteration complexity, gradient flow and provable
convergence in the context of sole supervision and adversarial regularization.
The key ingredient is a theoretical justification supported by empirical
evidence of adversarial acceleration in gradient descent. In addition,
motivated by a recently introduced unit-wise capacity based generalization
bound, we analyze the generalization error in adversarial framework. Guided by
our observation, we cast doubts on the ability of this measure to explain
generalization. We therefore leave as open questions to explore new measures
that can explain generalization behavior in adversarial learning. Furthermore,
we observe an intriguing phenomenon in the neural embedded vector space while
contrasting adversarial learning with sole supervision.",['Litu Rout'],"['cs.LG', 'cs.CV', 'math.OC', 'stat.ML']",2020-10-01 16:10:05+00:00
http://arxiv.org/abs/2010.00521v2,Why Adversarial Interaction Creates Non-Homogeneous Patterns: A Pseudo-Reaction-Diffusion Model for Turing Instability,"Long after Turing's seminal Reaction-Diffusion (RD) model, the elegance of
his fundamental equations alleviated much of the skepticism surrounding pattern
formation. Though Turing model is a simplification and an idealization, it is
one of the best-known theoretical models to explain patterns as a reminiscent
of those observed in nature. Over the years, concerted efforts have been made
to align theoretical models to explain patterns in real systems. The apparent
difficulty in identifying the specific dynamics of the RD system makes the
problem particularly challenging. Interestingly, we observe Turing-like
patterns in a system of neurons with adversarial interaction. In this study, we
establish the involvement of Turing instability to create such patterns. By
theoretical and empirical studies, we present a pseudo-reaction-diffusion model
to explain the mechanism that may underlie these phenomena. While supervised
learning attains homogeneous equilibrium, this paper suggests that the
introduction of an adversary helps break this homogeneity to create
non-homogeneous patterns at equilibrium. Further, we prove that randomly
initialized gradient descent with over-parameterization can converge
exponentially fast to an $\epsilon$-stationary point even under adversarial
interaction. In addition, different from sole supervision, we show that the
solutions obtained under adversarial interaction are not limited to a tiny
subspace around initialization.",['Litu Rout'],"['cs.LG', 'cs.CV', 'stat.ML']",2020-10-01 16:09:22+00:00
http://arxiv.org/abs/2010.00509v1,Cardea: An Open Automated Machine Learning Framework for Electronic Health Records,"An estimated 180 papers focusing on deep learning and EHR were published
between 2010 and 2018. Despite the common workflow structure appearing in these
publications, no trusted and verified software framework exists, forcing
researchers to arduously repeat previous work. In this paper, we propose
Cardea, an extensible open-source automated machine learning framework
encapsulating common prediction problems in the health domain and allows users
to build predictive models with their own data. This system relies on two
components: Fast Healthcare Interoperability Resources (FHIR) -- a standardized
data structure for electronic health systems -- and several AUTOML frameworks
for automated feature engineering, model selection, and tuning. We augment
these components with an adaptive data assembler and comprehensive data- and
model- auditing capabilities. We demonstrate our framework via 5 prediction
tasks on MIMIC-III and Kaggle datasets, which highlight Cardea's human
competitiveness, flexibility in problem definition, extensive feature
generation capability, adaptable automatic data assembler, and its usability.","['Sarah Alnegheimish', 'Najat Alrashed', 'Faisal Aleissa', 'Shahad Althobaiti', 'Dongyu Liu', 'Mansour Alsaleh', 'Kalyan Veeramachaneni']","['cs.LG', 'stat.ML']",2020-10-01 15:58:13+00:00
http://arxiv.org/abs/2010.00500v2,Ray-based classification framework for high-dimensional data,"While classification of arbitrary structures in high dimensions may require
complete quantitative information, for simple geometrical structures,
low-dimensional qualitative information about the boundaries defining the
structures can suffice. Rather than using dense, multi-dimensional data, we
propose a deep neural network (DNN) classification framework that utilizes a
minimal collection of one-dimensional representations, called \emph{rays}, to
construct the ""fingerprint"" of the structure(s) based on substantially reduced
information. We empirically study this framework using a synthetic dataset of
double and triple quantum dot devices and apply it to the classification
problem of identifying the device state. We show that the performance of the
ray-based classifier is already on par with traditional 2D images for low
dimensional systems, while significantly cutting down the data acquisition
cost.","['Justyna P. Zwolak', 'Sandesh S. Kalantre', 'Thomas McJunkin', 'Brian J. Weber', 'Jacob M. Taylor']","['cs.LG', 'cond-mat.mes-hall', 'cs.CV', 'quant-ph', 'stat.ML']",2020-10-01 15:46:29+00:00
http://arxiv.org/abs/2010.00482v2,Physical Exercise Recommendation and Success Prediction Using Interconnected Recurrent Neural Networks,"Unhealthy behaviors, e.g., physical inactivity and unhealthful food choice,
are the primary healthcare cost drivers in developed countries. Pervasive
computational, sensing, and communication technology provided by smartphones
and smartwatches have made it possible to support individuals in their everyday
lives to develop healthier lifestyles. In this paper, we propose an exercise
recommendation system that also predicts individual success rates. The system,
consisting of two inter-connected recurrent neural networks (RNNs), uses the
history of workouts to recommend the next workout activity for each individual.
The system then predicts the probability of successful completion of the
predicted activity by the individual. The prediction accuracy of this
interconnected-RNN model is assessed on previously published data from a
four-week mobile health experiment and is shown to improve upon previous
predictions from a computational cognitive model.","['Arash Mahyari', 'Peter Pirolli']","['cs.LG', 'cs.AI', 'cs.CV', 'cs.IR', 'cs.IT', 'math.IT', 'stat.ML']",2020-10-01 15:22:59+00:00
http://arxiv.org/abs/2010.00475v2,FSD50K: An Open Dataset of Human-Labeled Sound Events,"Most existing datasets for sound event recognition (SER) are relatively small
and/or domain-specific, with the exception of AudioSet, based on over 2M tracks
from YouTube videos and encompassing over 500 sound classes. However, AudioSet
is not an open dataset as its official release consists of pre-computed audio
features. Downloading the original audio tracks can be problematic due to
YouTube videos gradually disappearing and usage rights issues. To provide an
alternative benchmark dataset and thus foster SER research, we introduce
FSD50K, an open dataset containing over 51k audio clips totalling over 100h of
audio manually labeled using 200 classes drawn from the AudioSet Ontology. The
audio clips are licensed under Creative Commons licenses, making the dataset
freely distributable (including waveforms). We provide a detailed description
of the FSD50K creation process, tailored to the particularities of Freesound
data, including challenges encountered and solutions adopted. We include a
comprehensive dataset characterization along with discussion of limitations and
key factors to allow its audio-informed usage. Finally, we conduct sound event
classification experiments to provide baseline systems as well as insight on
the main factors to consider when splitting Freesound audio data for SER. Our
goal is to develop a dataset to be widely adopted by the community as a new
open benchmark for SER research.","['Eduardo Fonseca', 'Xavier Favory', 'Jordi Pons', 'Frederic Font', 'Xavier Serra']","['cs.SD', 'cs.LG', 'eess.AS', 'stat.ML']",2020-10-01 15:07:25+00:00
http://arxiv.org/abs/2010.00467v3,Bag of Tricks for Adversarial Training,"Adversarial training (AT) is one of the most effective strategies for
promoting model robustness. However, recent benchmarks show that most of the
proposed improvements on AT are less effective than simply early stopping the
training procedure. This counter-intuitive fact motivates us to investigate the
implementation details of tens of AT methods. Surprisingly, we find that the
basic settings (e.g., weight decay, training schedule, etc.) used in these
methods are highly inconsistent. In this work, we provide comprehensive
evaluations on CIFAR-10, focusing on the effects of mostly overlooked training
tricks and hyperparameters for adversarially trained models. Our empirical
observations suggest that adversarial robustness is much more sensitive to some
basic training settings than we thought. For example, a slightly different
value of weight decay can reduce the model robust accuracy by more than 7%,
which is probable to override the potential promotion induced by the proposed
methods. We conclude a baseline training setting and re-implement previous
defenses to achieve new state-of-the-art results. These facts also appeal to
more concerns on the overlooked confounders when benchmarking defenses.","['Tianyu Pang', 'Xiao Yang', 'Yinpeng Dong', 'Hang Su', 'Jun Zhu']","['cs.LG', 'cs.CV', 'stat.ML']",2020-10-01 15:03:51+00:00
http://arxiv.org/abs/2010.00462v1,A survey on natural language processing (nlp) and applications in insurance,"Text is the most widely used means of communication today. This data is
abundant but nevertheless complex to exploit within algorithms. For years,
scientists have been trying to implement different techniques that enable
computers to replicate some mechanisms of human reading. During the past five
years, research disrupted the capacity of the algorithms to unleash the value
of text data. It brings today, many opportunities for the insurance
industry.Understanding those methods and, above all, knowing how to apply them
is a major challenge and key to unleash the value of text data that have been
stored for many years. Processing language with computer brings many new
opportunities especially in the insurance sector where reports are central in
the information used by insurers. SCOR's Data Analytics team has been working
on the implementation of innovative tools or products that enable the use of
the latest research on text analysis. Understanding text mining techniques in
insurance enhances the monitoring of the underwritten risks and many processes
that finally benefit policyholders.This article proposes to explain
opportunities that Natural Language Processing (NLP) are providing to
insurance. It details different methods used today in practice traces back the
story of them. We also illustrate the implementation of certain methods using
open source libraries and python codes that we have developed to facilitate the
use of these techniques.After giving a general overview on the evolution of
text mining during the past few years,we share about how to conduct a full
study with text mining and share some examples to serve those models into
insurance products or services. Finally, we explained in more details every
step that composes a Natural Language Processing study to ensure the reader can
have a deep understanding on the implementation.","['Antoine Ly', 'Benno Uthayasooriyar', 'Tingting Wang']","['stat.ML', 'cs.CL', 'cs.LG']",2020-10-01 14:56:18+00:00
http://arxiv.org/abs/2010.00439v3,Learning Set Functions that are Sparse in Non-Orthogonal Fourier Bases,"Many applications of machine learning on discrete domains, such as learning
preference functions in recommender systems or auctions, can be reduced to
estimating a set function that is sparse in the Fourier domain. In this work,
we present a new family of algorithms for learning Fourier-sparse set
functions. They require at most $nk - k \log_2 k + k$ queries (set function
evaluations), under mild conditions on the Fourier coefficients, where $n$ is
the size of the ground set and $k$ the number of non-zero Fourier coefficients.
In contrast to other work that focused on the orthogonal Walsh-Hadamard
transform, our novel algorithms operate with recently introduced non-orthogonal
Fourier transforms that offer different notions of Fourier-sparsity. These
naturally arise when modeling, e.g., sets of items forming substitutes and
complements. We demonstrate effectiveness on several real-world applications.","['Chris Wendler', 'Andisheh Amrollahi', 'Bastian Seifert', 'Andreas Krause', 'Markus Püschel']","['cs.LG', 'cs.AI', 'cs.DM', 'eess.SP', 'stat.ML']",2020-10-01 14:31:59+00:00
http://arxiv.org/abs/2010.00417v2,"Learning to be safe, in finite time","This paper aims to put forward the concept that learning to take safe actions
in unknown environments, even with probability one guarantees, can be achieved
without the need for an unbounded number of exploratory trials, provided that
one is willing to relax its optimality requirements mildly. We focus on the
canonical multi-armed bandit problem and seek to study the
exploration-preservation trade-off intrinsic within safe learning. More
precisely, by defining a handicap metric that counts the number of unsafe
actions, we provide an algorithm for discarding unsafe machines (or actions),
with probability one, that achieves constant handicap. Our algorithm is rooted
in the classical sequential probability ratio test, redefined here for
continuing tasks. Under standard assumptions on sufficient exploration, our
rule provably detects all unsafe machines in an (expected) finite number of
rounds. The analysis also unveils a trade-off between the number of rounds
needed to secure the environment and the probability of discarding safe
machines. Our decision rule can wrap around any other algorithm to optimize a
specific auxiliary goal since it provides a safe environment to search for
(approximately) optimal policies. Simulations corroborate our theoretical
findings and further illustrate the aforementioned trade-offs.","['Agustin Castellano', 'Juan Bazerque', 'Enrique Mallada']","['cs.LG', 'stat.ML']",2020-10-01 14:03:34+00:00
http://arxiv.org/abs/2010.00406v4,Momentum via Primal Averaging: Theoretical Insights and Learning Rate Schedules for Non-Convex Optimization,"Momentum methods are now used pervasively within the machine learning
community for training non-convex models such as deep neural networks.
Empirically, they out perform traditional stochastic gradient descent (SGD)
approaches. In this work we develop a Lyapunov analysis of SGD with momentum
(SGD+M), by utilizing a equivalent rewriting of the method known as the
stochastic primal averaging (SPA) form. This analysis is much tighter than
previous theory in the non-convex case, and due to this we are able to give
precise insights into when SGD+M may out-perform SGD, and what hyper-parameter
schedules will work and why.",['Aaron Defazio'],"['cs.LG', 'math.OC', 'stat.ML']",2020-10-01 13:46:32+00:00
http://arxiv.org/abs/2010.00402v1,From Trees to Continuous Embeddings and Back: Hyperbolic Hierarchical Clustering,"Similarity-based Hierarchical Clustering (HC) is a classical unsupervised
machine learning algorithm that has traditionally been solved with heuristic
algorithms like Average-Linkage. Recently, Dasgupta reframed HC as a discrete
optimization problem by introducing a global cost function measuring the
quality of a given tree. In this work, we provide the first continuous
relaxation of Dasgupta's discrete optimization problem with provable quality
guarantees. The key idea of our method, HypHC, is showing a direct
correspondence from discrete trees to continuous representations (via the
hyperbolic embeddings of their leaf nodes) and back (via a decoding algorithm
that maps leaf embeddings to a dendrogram), allowing us to search the space of
discrete binary trees with continuous optimization. Building on analogies
between trees and hyperbolic space, we derive a continuous analogue for the
notion of lowest common ancestor, which leads to a continuous relaxation of
Dasgupta's discrete objective. We can show that after decoding, the global
minimizer of our continuous relaxation yields a discrete tree with a (1 +
epsilon)-factor approximation for Dasgupta's optimal tree, where epsilon can be
made arbitrarily small and controls optimization challenges. We experimentally
evaluate HypHC on a variety of HC benchmarks and find that even approximate
solutions found with gradient descent have superior clustering quality than
agglomerative heuristics or other gradient based algorithms. Finally, we
highlight the flexibility of HypHC using end-to-end training in a downstream
classification task.","['Ines Chami', 'Albert Gu', 'Vaggos Chatziafratis', 'Christopher Ré']","['cs.DS', 'cs.LG', 'stat.ML']",2020-10-01 13:43:19+00:00
http://arxiv.org/abs/2010.00401v2,Quasar Detection using Linear Support Vector Machine with Learning From Mistakes Methodology,"The field of Astronomy requires the collection and assimilation of vast
volumes of data. The data handling and processing problem has become severe as
the sheer volume of data produced by scientific instruments each night grows
exponentially. This problem becomes extensive for conventional methods of
processing the data, which was mostly manual, but is the perfect setting for
the use of Machine Learning approaches. While building classifiers for
Astronomy, the cost of losing a rare object like supernovae or quasars to
detection losses is far more severe than having many false positives, given the
rarity and scientific value of these objects. In this paper, a Linear Support
Vector Machine (LSVM) is explored to detect Quasars, which are extremely bright
objects in which a supermassive black hole is surrounded by a luminous
accretion disk. In Astronomy, it is vital to correctly identify quasars, as
they are very rare in nature. Their rarity creates a class-imbalance problem
that needs to be taken into consideration. The class-imbalance problem and high
cost of misclassification are taken into account while designing the
classifier. To achieve this detection, a novel classifier is explored, and its
performance is evaluated. It was observed that LSVM along with Ensemble Bagged
Trees (EBT) achieved a 10x reduction in the False Negative Rate, using the
Learning from Mistakes methodology.","['Aniruddh Herle', 'Janamejaya Channegowda', 'Dinakar Prabhu']","['cs.LG', 'stat.ML']",2020-10-01 13:41:51+00:00
http://arxiv.org/abs/2010.00381v2,Student-Initiated Action Advising via Advice Novelty,"Action advising is a budget-constrained knowledge exchange mechanism between
teacher-student peers that can help tackle exploration and sample inefficiency
problems in deep reinforcement learning (RL). Most recently, student-initiated
techniques that utilise state novelty and uncertainty estimations have obtained
promising results. However, the approaches built on these estimations have some
potential weaknesses. First, they assume that the convergence of the student's
RL model implies less need for advice. This can be misleading in scenarios with
teacher absence early on where the student is likely to learn suboptimally by
itself; yet also ignore the teacher's assistance later. Secondly, the delays
between encountering states and having them to take effect in the RL model
updates in presence of the experience replay dynamics cause a feedback lag in
what the student actually needs advice for. We propose a student-initiated
algorithm that alleviates these by employing Random Network Distillation (RND)
to measure the novelty of a piece of advice. Furthermore, we perform RND
updates only for the advised states to ensure that the student's own learning
does not impair its ability to leverage the teacher. Experiments in GridWorld
and MinAtar show that our approach performs on par with the state-of-the-art
and demonstrates significant advantages in the scenarios where the existing
methods are prone to fail.","['Ercument Ilhan', 'Jeremy Gow', 'Diego Perez-Liebana']","['cs.LG', 'stat.ML']",2020-10-01 13:20:28+00:00
http://arxiv.org/abs/2010.00380v2,Deep matrix factorizations,"Constrained low-rank matrix approximations have been known for decades as
powerful linear dimensionality reduction techniques to be able to extract the
information contained in large data sets in a relevant way. However, such
low-rank approaches are unable to mine complex, interleaved features that
underlie hierarchical semantics. Recently, deep matrix factorization (deep MF)
was introduced to deal with the extraction of several layers of features and
has been shown to reach outstanding performances on unsupervised tasks. Deep MF
was motivated by the success of deep learning, as it is conceptually close to
some neural networks paradigms. In this paper, we present the main models,
algorithms, and applications of deep MF through a comprehensive literature
review. We also discuss theoretical questions and perspectives of research.","['Pierre De Handschutter', 'Nicolas Gillis', 'Xavier Siebert']","['cs.LG', 'stat.ML']",2020-10-01 13:19:01+00:00
http://arxiv.org/abs/2010.00373v2,Task Agnostic Continual Learning Using Online Variational Bayes with Fixed-Point Updates,"Background: Catastrophic forgetting is the notorious vulnerability of neural
networks to the changes in the data distribution during learning. This
phenomenon has long been considered a major obstacle for using learning agents
in realistic continual learning settings. A large body of continual learning
research assumes that task boundaries are known during training. However, only
a few works consider scenarios in which task boundaries are unknown or not well
defined -- task agnostic scenarios. The optimal Bayesian solution for this
requires an intractable online Bayes update to the weights posterior.
Contributions: We aim to approximate the online Bayes update as accurately as
possible. To do so, we derive novel fixed-point equations for the online
variational Bayes optimization problem, for multivariate Gaussian parametric
distributions. By iterating the posterior through these fixed-point equations,
we obtain an algorithm (FOO-VB) for continual learning which can handle
non-stationary data distribution using a fixed architecture and without using
external memory (i.e. without access to previous data). We demonstrate that our
method (FOO-VB) outperforms existing methods in task agnostic scenarios. FOO-VB
Pytorch implementation will be available online.","['Chen Zeno', 'Itay Golan', 'Elad Hoffer', 'Daniel Soudry']","['stat.ML', 'cs.LG']",2020-10-01 13:10:35+00:00
http://arxiv.org/abs/2010.00359v3,Low-Rank and Sparse Enhanced Tucker Decomposition for Tensor Completion,"Tensor completion refers to the task of estimating the missing data from an
incomplete measurement or observation, which is a core problem frequently
arising from the areas of big data analysis, computer vision, and network
engineering. Due to the multidimensional nature of high-order tensors, the
matrix approaches, e.g., matrix factorization and direct matricization of
tensors, are often not ideal for tensor completion and recovery. In this paper,
we introduce a unified low-rank and sparse enhanced Tucker decomposition model
for tensor completion. Our model possesses a sparse regularization term to
promote a sparse core tensor of the Tucker decomposition, which is beneficial
for tensor data compression. Moreover, we enforce low-rank regularization terms
on factor matrices of the Tucker decomposition for inducing the low-rankness of
the tensor with a cheap computational cost. Numerically, we propose a
customized ADMM with enough easy subproblems to solve the underlying model. It
is remarkable that our model is able to deal with different types of real-world
data sets, since it exploits the potential periodicity and inherent correlation
properties appeared in tensors. A series of computational experiments on
real-world data sets, including internet traffic data sets, color images, and
face recognition, demonstrate that our model performs better than many existing
state-of-the-art matricization and tensorization approaches in terms of
achieving higher recovery accuracy.","['Chenjian Pan', 'Chen Ling', 'Hongjin He', 'Liqun Qi', 'Yanwei Xu']","['cs.LG', 'math.OC', 'stat.ML']",2020-10-01 12:45:39+00:00
http://arxiv.org/abs/2010.00351v2,Emergence of a finite-size-scaling function in the supervised learning of the Ising phase transition,"We investigate the connection between the supervised learning of the binary
phase classification in the ferromagnetic Ising model and the standard
finite-size-scaling theory of the second-order phase transition. Proposing a
minimal one-free-parameter neural network model, we analytically formulate the
supervised learning problem for the canonical ensemble being used as a training
data set. We show that just one free parameter is capable enough to describe
the data-driven emergence of the universal finite-size-scaling function in the
network output that is observed in a large neural network, theoretically
validating its critical point prediction for unseen test data from different
underlying lattices yet in the same universality class of the Ising
criticality. We also numerically demonstrate the interpretation with the
proposed one-parameter model by providing an example of finding a critical
point with the learning of the Landau mean-field free energy being applied to
the real data set from the uncorrelated random scale-free graph with a large
degree exponent.","['Dongkyu Kim', 'Dong-Hee Kim']","['cond-mat.stat-mech', 'cs.LG', 'stat.ML']",2020-10-01 12:34:12+00:00
http://arxiv.org/abs/2010.00297v1,Universal time-series forecasting with mixture predictors,"This book is devoted to the problem of sequential probability forecasting,
that is, predicting the probabilities of the next outcome of a growing sequence
of observations given the past. This problem is considered in a very general
setting that unifies commonly used probabilistic and non-probabilistic
settings, trying to make as few as possible assumptions on the mechanism
generating the observations. A common form that arises in various formulations
of this problem is that of mixture predictors, which are formed as a
combination of a finite or infinite set of other predictors attempting to
combine their predictive powers. The main subject of this book are such mixture
predictors, and the main results demonstrate the universality of this method in
a very general probabilistic setting, but also show some of its limitations.
While the problems considered are motivated by practical applications,
involving, for example, financial, biological or behavioural data, this
motivation is left implicit and all the results exposed are theoretical.
  The book targets graduate students and researchers interested in the problem
of sequential prediction, and, more generally, in theoretical analysis of
problems in machine learning and non-parametric statistics, as well as
mathematical and philosophical foundations of these fields.
  The material in this volume is presented in a way that presumes familiarity
with basic concepts of probability and statistics, up to and including
probability distributions over spaces of infinite sequences. Familiarity with
the literature on learning or stochastic processes is not required.",['Daniil Ryabko'],"['cs.LG', 'cs.AI', 'cs.IT', 'math.IT', 'math.ST', 'stat.ML', 'stat.TH']",2020-10-01 10:56:23+00:00
http://arxiv.org/abs/2010.00284v1,Bayesian Policy Search for Stochastic Domains,"AI planning can be cast as inference in probabilistic models, and
probabilistic programming was shown to be capable of policy search in partially
observable domains. Prior work introduces policy search through Markov chain
Monte Carlo in deterministic domains, as well as adapts black-box variational
inference to stochastic domains, however not in the strictly Bayesian sense. In
this work, we cast policy search in stochastic domains as a Bayesian inference
problem and provide a scheme for encoding such problems as nested probabilistic
programs. We argue that probabilistic programs for policy search in stochastic
domains should involve nested conditioning, and provide an adaption of
Lightweight Metropolis-Hastings (LMH) for robust inference in such programs. We
apply the proposed scheme to stochastic domains and show that policies of
similar quality are learned, despite a simpler and more general inference
algorithm. We believe that the proposed variant of LMH is novel and applicable
to a wider class of probabilistic programs with nested conditioning.","['David Tolpin', 'Yuan Zhou', 'Hongseok Yang']","['cs.LG', 'stat.ML']",2020-10-01 10:22:15+00:00
http://arxiv.org/abs/2010.00282v3,Probabilistic Programs with Stochastic Conditioning,"We tackle the problem of conditioning probabilistic programs on distributions
of observable variables. Probabilistic programs are usually conditioned on
samples from the joint data distribution, which we refer to as deterministic
conditioning. However, in many real-life scenarios, the observations are given
as marginal distributions, summary statistics, or samplers. Conventional
probabilistic programming systems lack adequate means for modeling and
inference in such scenarios. We propose a generalization of deterministic
conditioning to stochastic conditioning, that is, conditioning on the marginal
distribution of a variable taking a particular form. To this end, we first
define the formal notion of stochastic conditioning and discuss its key
properties. We then show how to perform inference in the presence of stochastic
conditioning. We demonstrate potential usage of stochastic conditioning on
several case studies which involve various kinds of stochastic conditioning and
are difficult to solve otherwise. Although we present stochastic conditioning
in the context of probabilistic programming, our formalization is general and
applicable to other settings.","['David Tolpin', 'Yuan Zhou', 'Tom Rainforth', 'Hongseok Yang']","['cs.LG', 'cs.PL', 'stat.ML']",2020-10-01 10:17:52+00:00
http://arxiv.org/abs/2010.02004v2,Assessing Robustness of Text Classification through Maximal Safe Radius Computation,"Neural network NLP models are vulnerable to small modifications of the input
that maintain the original meaning but result in a different prediction. In
this paper, we focus on robustness of text classification against word
substitutions, aiming to provide guarantees that the model prediction does not
change if a word is replaced with a plausible alternative, such as a synonym.
As a measure of robustness, we adopt the notion of the maximal safe radius for
a given input text, which is the minimum distance in the embedding space to the
decision boundary. Since computing the exact maximal safe radius is not
feasible in practice, we instead approximate it by computing a lower and upper
bound. For the upper bound computation, we employ Monte Carlo Tree Search in
conjunction with syntactic filtering to analyse the effect of single and
multiple word substitutions. The lower bound computation is achieved through an
adaptation of the linear bounding techniques implemented in tools CNN-Cert and
POPQORN, respectively for convolutional and recurrent network models. We
evaluate the methods on sentiment analysis and news classification models for
four datasets (IMDB, SST, AG News and NEWS) and a range of embeddings, and
provide an analysis of robustness trends. We also apply our framework to
interpretability analysis and compare it with LIME.","['Emanuele La Malfa', 'Min Wu', 'Luca Laurenti', 'Benjie Wang', 'Anthony Hartshorn', 'Marta Kwiatkowska']","['cs.CL', 'cs.LG', 'stat.ML']",2020-10-01 09:46:32+00:00
http://arxiv.org/abs/2010.00262v1,Active Inference or Control as Inference? A Unifying View,"Active inference (AI) is a persuasive theoretical framework from
computational neuroscience that seeks to describe action and perception as
inference-based computation. However, this framework has yet to provide
practical sensorimotor control algorithms that are competitive with alternative
approaches. In this work, we frame active inference through the lens of control
as inference (CaI), a body of work that presents trajectory optimization as
inference. From the wider view of `probabilistic numerics', CaI offers
principled, numerically robust optimal control solvers that provide uncertainty
quantification, and can scale to nonlinear problems with approximate inference.
We show that AI may be framed as partially-observed CaI when the cost function
is defined specifically in the observation states.","['Joe Watson', 'Abraham Imohiosen', 'Jan Peters']","['cs.LG', 'stat.ML']",2020-10-01 09:08:45+00:00
http://arxiv.org/abs/2010.00261v2,NodeSig: Binary Node Embeddings via Random Walk Diffusion,"Graph Representation Learning (GRL) has become a key paradigm in network
analysis, with a plethora of interdisciplinary applications. As the scale of
networks increases, most of the widely used learning-based graph representation
models also face computational challenges. While there is a recent effort
toward designing algorithms that solely deal with scalability issues, most of
them behave poorly in terms of accuracy on downstream tasks. In this paper, we
aim to study models that balance the trade-off between efficiency and accuracy.
In particular, we propose NodeSig, a scalable model that computes binary node
representations. NodeSig exploits random walk diffusion probabilities via
stable random projections towards efficiently computing embeddings in the
Hamming space. Our extensive experimental evaluation on various networks has
demonstrated that the proposed model achieves a good balance between accuracy
and efficiency compared to well-known baseline models on the node
classification and link prediction tasks.","['Abdulkadir Çelikkanat', 'Fragkiskos D. Malliaros', 'Apostolos N. Papadopoulos']","['cs.LG', 'cs.SI', 'stat.ML']",2020-10-01 09:07:37+00:00
http://arxiv.org/abs/2010.00202v2,Heteroscedastic Bayesian Optimisation for Stochastic Model Predictive Control,"Model predictive control (MPC) has been successful in applications involving
the control of complex physical systems. This class of controllers leverages
the information provided by an approximate model of the system's dynamics to
simulate the effect of control actions. MPC methods also present a few
hyper-parameters which may require a relatively expensive tuning process by
demanding interactions with the physical system. Therefore, we investigate
fine-tuning MPC methods in the context of stochastic MPC, which presents extra
challenges due to the randomness of the controller's actions. In these
scenarios, performance outcomes present noise, which is not homogeneous across
the domain of possible hyper-parameter settings, but which varies in an
input-dependent way. To address these issues, we propose a Bayesian
optimisation framework that accounts for heteroscedastic noise to tune
hyper-parameters in control problems. Empirical results on benchmark continuous
control tasks and a physical robot support the proposed framework's suitability
relative to baselines, which do not take heteroscedasticity into account.","['Rel Guzman', 'Rafael Oliveira', 'Fabio Ramos']","['cs.LG', 'cs.RO', 'stat.ML']",2020-10-01 05:31:41+00:00
http://arxiv.org/abs/2010.00163v2,Bayesian Meta-reinforcement Learning for Traffic Signal Control,"In recent years, there has been increasing amount of interest around meta
reinforcement learning methods for traffic signal control, which have achieved
better performance compared with traditional control methods. However, previous
methods lack robustness in adaptation and stability in training process in
complex situations, which largely limits its application in real-world traffic
signal control. In this paper, we propose a novel value-based Bayesian
meta-reinforcement learning framework BM-DQN to robustly speed up the learning
process in new scenarios by utilizing well-trained prior knowledge learned from
existing scenarios. This framework is based on our proposed fast-adaptation
variation to Gradient-EM Bayesian Meta-learning and the fast-update advantage
of DQN, which allows for fast adaptation to new scenarios with continual
learning ability and robustness to uncertainty. The experiments on restricted
2D navigation and traffic signal control show that our proposed framework
adapts more quickly and robustly in new scenarios than previous methods, and
specifically, much better continual learning ability in heterogeneous
scenarios.","['Yayi Zou', 'Zhiwei Qin']","['cs.LG', 'stat.ML']",2020-10-01 01:15:17+00:00
http://arxiv.org/abs/2010.00161v1,Unknown Delay for Adversarial Bandit Setting with Multiple Play,"This paper addresses the problem of unknown delays in adversarial multi-armed
bandit (MAB) with multiple play. Existing work on similar game setting focused
on only the case where the learner selects an arm in each round. However, there
are lots of applications in robotics where a learner needs to select more than
one arm per round. It is therefore worthwhile to investigate the effect of
delay when multiple arms are chosen. The multiple arms chosen per round in this
setting are such that they experience the same amount of delay. There can be an
aggregation of feedback losses from different combinations of arms selected at
different rounds, and the learner is faced with the challenge of associating
the feedback losses to the arms producing them. To address this problem, this
paper proposes a delayed exponential, exploitation and exploration for multiple
play (DEXP3.M) algorithm. The regret bound is only slightly worse than the
regret of DEXP3 already proposed for the single play setting with unknown
delay.",['Olusola T. Odeyomi'],"['cs.LG', 'cs.MA', 'stat.ML']",2020-10-01 01:07:19+00:00
http://arxiv.org/abs/2010.00145v2,Entropy Regularization for Mean Field Games with Learning,"Entropy regularization has been extensively adopted to improve the
efficiency, the stability, and the convergence of algorithms in reinforcement
learning. This paper analyzes both quantitatively and qualitatively the impact
of entropy regularization for Mean Field Game (MFG) with learning in a finite
time horizon. Our study provides a theoretical justification that entropy
regularization yields time-dependent policies and, furthermore, helps
stabilizing and accelerating convergence to the game equilibrium. In addition,
this study leads to a policy-gradient algorithm for exploration in MFG. Under
this algorithm, agents are able to learn the optimal exploration scheduling,
with stable and fast convergence to the game equilibrium.","['Xin Guo', 'Renyuan Xu', 'Thaleia Zariphopoulou']","['math.OC', 'cs.LG', 'stat.ML']",2020-09-30 23:27:11+00:00
http://arxiv.org/abs/2010.00137v2,Efficient sampling from the Bingham distribution,"We give a algorithm for exact sampling from the Bingham distribution
$p(x)\propto \exp(x^\top A x)$ on the sphere $\mathcal S^{d-1}$ with expected
runtime of $\operatorname{poly}(d, \lambda_{\max}(A)-\lambda_{\min}(A))$. The
algorithm is based on rejection sampling, where the proposal distribution is a
polynomial approximation of the pdf, and can be sampled from by explicitly
evaluating integrals of polynomials over the sphere. Our algorithm gives exact
samples, assuming exact computation of an inverse function of a polynomial.
This is in contrast with Markov Chain Monte Carlo algorithms, which are not
known to enjoy rapid mixing on this problem, and only give approximate samples.
  As a direct application, we use this to sample from the posterior
distribution of a rank-1 matrix inference problem in polynomial time.","['Rong Ge', 'Holden Lee', 'Jianfeng Lu', 'Andrej Risteski']","['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2020-09-30 22:48:03+00:00
http://arxiv.org/abs/2010.00130v3,Computing Graph Neural Networks: A Survey from Algorithms to Accelerators,"Graph Neural Networks (GNNs) have exploded onto the machine learning scene in
recent years owing to their capability to model and learn from graph-structured
data. Such an ability has strong implications in a wide variety of fields whose
data is inherently relational, for which conventional neural networks do not
perform well. Indeed, as recent reviews can attest, research in the area of
GNNs has grown rapidly and has lead to the development of a variety of GNN
algorithm variants as well as to the exploration of groundbreaking applications
in chemistry, neurology, electronics, or communication networks, among others.
At the current stage of research, however, the efficient processing of GNNs is
still an open challenge for several reasons. Besides of their novelty, GNNs are
hard to compute due to their dependence on the input graph, their combination
of dense and very sparse operations, or the need to scale to huge graphs in
some applications. In this context, this paper aims to make two main
contributions. On the one hand, a review of the field of GNNs is presented from
the perspective of computing. This includes a brief tutorial on the GNN
fundamentals, an overview of the evolution of the field in the last decade, and
a summary of operations carried out in the multiple phases of different GNN
algorithm variants. On the other hand, an in-depth analysis of current software
and hardware acceleration schemes is provided, from which a hardware-software,
graph-aware, and communication-centric vision for GNN accelerators is
distilled.","['Sergi Abadal', 'Akshay Jain', 'Robert Guirado', 'Jorge López-Alonso', 'Eduard Alarcón']","['cs.LG', 'cs.DC', 'stat.ML']",2020-09-30 22:29:27+00:00
http://arxiv.org/abs/2010.00116v1,Distance Correlation Based Brain Functional Connectivity Estimation and Non-Convex Multi-Task Learning for Developmental fMRI Studies,"Resting-state functional magnetic resonance imaging (rs-fMRI)-derived
functional connectivity patterns have been extensively utilized to delineate
global functional organization of the human brain in health, development, and
neuropsychiatric disorders. In this paper, we investigate how functional
connectivity in males and females differs in an age prediction framework. We
first estimate functional connectivity between regions-of-interest (ROIs) using
distance correlation instead of Pearson's correlation. Distance correlation, as
a multivariate statistical method, explores spatial relations of voxel-wise
time courses within individual ROIs and measures both linear and nonlinear
dependence, capturing more complex information of between-ROI interactions.
Then, a novel non-convex multi-task learning (NC-MTL) model is proposed to
study age-related gender differences in functional connectivity, where age
prediction for each gender group is viewed as one task. Specifically, in the
proposed NC-MTL model, we introduce a composite regularizer with a combination
of non-convex $\ell_{2,1-2}$ and $\ell_{1-2}$ regularization terms for
selecting both common and task-specific features. Finally, we validate the
proposed NC-MTL model along with distance correlation based functional
connectivity on rs-fMRI of the Philadelphia Neurodevelopmental Cohort for
predicting ages of both genders. The experimental results demonstrate that the
proposed NC-MTL model outperforms other competing MTL models in age prediction,
as well as characterizing developmental gender differences in functional
connectivity patterns.","['Li Xiao', 'Biao Cai', 'Gang Qu', 'Julia M. Stephen', 'Tony W. Wilson', 'Vince D. Calhoun', 'Yu-Ping Wang']","['q-bio.QM', 'stat.ML']",2020-09-30 21:48:52+00:00
http://arxiv.org/abs/2010.00081v1,Stage-wise Conservative Linear Bandits,"We study stage-wise conservative linear stochastic bandits: an instance of
bandit optimization, which accounts for (unknown) safety constraints that
appear in applications such as online advertising and medical trials. At each
stage, the learner must choose actions that not only maximize cumulative reward
across the entire time horizon but further satisfy a linear baseline constraint
that takes the form of a lower bound on the instantaneous reward. For this
problem, we present two novel algorithms, stage-wise conservative linear
Thompson Sampling (SCLTS) and stage-wise conservative linear UCB (SCLUCB), that
respect the baseline constraints and enjoy probabilistic regret bounds of order
O(\sqrt{T} \log^{3/2}T) and O(\sqrt{T} \log T), respectively. Notably, the
proposed algorithms can be adjusted with only minor modifications to tackle
different problem variations, such as constraints with bandit-feedback, or an
unknown sequence of baseline actions. We discuss these and other improvements
over the state-of-the-art. For instance, compared to existing solutions, we
show that SCLTS plays the (non-optimal) baseline action at most O(\log{T})
times (compared to O(\sqrt{T})). Finally, we make connections to another
studied form of safety constraints that takes the form of an upper bound on the
instantaneous reward. While this incurs additional complexity to the learning
process as the optimal action is not guaranteed to belong to the safe set at
each round, we show that SCLUCB can properly adjust in this setting via a
simple modification.","['Ahmadreza Moradipari', 'Christos Thrampoulidis', 'Mahnoosh Alizadeh']","['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY', 'stat.ML']",2020-09-30 19:51:37+00:00
http://arxiv.org/abs/2010.00073v1,Adaptive Online Estimation of Piecewise Polynomial Trends,"We consider the framework of non-stationary stochastic optimization [Besbes
et al, 2015] with squared error losses and noisy gradient feedback where the
dynamic regret of an online learner against a time varying comparator sequence
is studied. Motivated from the theory of non-parametric regression, we
introduce a new variational constraint that enforces the comparator sequence to
belong to a discrete $k^{th}$ order Total Variation ball of radius $C_n$. This
variational constraint models comparators that have piece-wise polynomial
structure which has many relevant practical applications [Tibshirani, 2014]. By
establishing connections to the theory of wavelet based non-parametric
regression, we design a polynomial time algorithm that achieves the nearly
optimal dynamic regret of $\tilde{O}(n^{\frac{1}{2k+3}}C_n^{\frac{2}{2k+3}})$.
The proposed policy is adaptive to the unknown radius $C_n$. Further, we show
that the same policy is minimax optimal for several other non-parametric
families of interest.","['Dheeraj Baby', 'Yu-Xiang Wang']","['cs.LG', 'math.OC', 'stat.ML']",2020-09-30 19:30:28+00:00
http://arxiv.org/abs/2010.00071v1,Erratum Concerning the Obfuscated Gradients Attack on Stochastic Activation Pruning,"Stochastic Activation Pruning (SAP) (Dhillon et al., 2018) is a defense to
adversarial examples that was attacked and found to be broken by the
""Obfuscated Gradients"" paper (Athalye et al., 2018). We discover a flaw in the
re-implementation that artificially weakens SAP. When SAP is applied properly,
the proposed attack is not effective. However, we show that a new use of the
BPDA attack technique can still reduce the accuracy of SAP to 0.1%.","['Guneet S. Dhillon', 'Nicholas Carlini']","['cs.LG', 'stat.ML']",2020-09-30 19:26:11+00:00
http://arxiv.org/abs/2010.00064v1,Linear-Sample Learning of Low-Rank Distributions,"Many latent-variable applications, including community detection,
collaborative filtering, genomic analysis, and NLP, model data as generated by
low-rank matrices. Yet despite considerable research, except for very special
cases, the number of samples required to efficiently recover the underlying
matrices has not been known. We determine the onset of learning in several
common latent-variable settings. For all of them, we show that learning
$k\times k$, rank-$r$, matrices to normalized $L_{1}$ distance $\epsilon$
requires $\Omega(\frac{kr}{\epsilon^2})$ samples, and propose an algorithm that
uses ${\cal O}(\frac{kr}{\epsilon^2}\log^2\frac r\epsilon)$ samples, a number
linear in the high dimension, and nearly linear in the, typically low, rank.
The algorithm improves on existing spectral techniques and runs in polynomial
time. The proofs establish new results on the rapid convergence of the spectral
distance between the model and observation matrices, and may be of independent
interest.","['Ayush Jain', 'Alon Orlitsky']","['cs.LG', 'cs.IT', 'math.IT', 'math.ST', 'stat.ML', 'stat.TH']",2020-09-30 19:10:32+00:00
http://arxiv.org/abs/2010.00029v5,RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior,"Flow-based generative models have become an important class of unsupervised
learning approaches. In this work, we incorporate the key ideas of
renormalization group (RG) and sparse prior distribution to design a
hierarchical flow-based generative model, RG-Flow, which can separate
information at different scales of images and extract disentangled
representations at each scale. We demonstrate our method on synthetic
multi-scale image datasets and the CelebA dataset, showing that the
disentangled representations enable semantic manipulation and style mixing of
the images at different scales. To visualize the latent representations, we
introduce receptive fields for flow-based models and show that the receptive
fields of RG-Flow are similar to those of convolutional neural networks. In
addition, we replace the widely adopted isotropic Gaussian prior distribution
by the sparse Laplacian distribution to further enhance the disentanglement of
representations. From a theoretical perspective, our proposed method has
$O(\log L)$ complexity for inpainting of an image with edge length $L$,
compared to previous generative models with $O(L^2)$ complexity.","['Hong-Ye Hu', 'Dian Wu', 'Yi-Zhuang You', 'Bruno Olshausen', 'Yubei Chen']","['cs.LG', 'cond-mat.dis-nn', 'cs.AI', 'cs.CV', 'stat.ML']",2020-09-30 18:04:04+00:00
http://arxiv.org/abs/2009.14822v2,Pea-KD: Parameter-efficient and Accurate Knowledge Distillation on BERT,"How can we efficiently compress a model while maintaining its performance?
Knowledge Distillation (KD) is one of the widely known methods for model
compression. In essence, KD trains a smaller student model based on a larger
teacher model and tries to retain the teacher model's level of performance as
much as possible. However, existing KD methods suffer from the following
limitations. First, since the student model is smaller in absolute size, it
inherently lacks model capacity. Second, the absence of an initial guide for
the student model makes it difficult for the student to imitate the teacher
model to its fullest. Conventional KD methods yield low performance due to
these limitations. In this paper, we propose Pea-KD (Parameter-efficient and
accurate Knowledge Distillation), a novel approach to KD. Pea-KD consists of
two main parts: Shuffled Parameter Sharing (SPS) and Pretraining with Teacher's
Predictions (PTP). Using this combination, we are capable of alleviating the
KD's limitations. SPS is a new parameter sharing method that increases the
student model capacity. PTP is a KD-specialized initialization method, which
can act as a good initial guide for the student. When combined, this method
yields a significant increase in student model's performance. Experiments
conducted on BERT with different datasets and tasks show that the proposed
approach improves the student model's performance by 4.4\% on average in four
GLUE tasks, outperforming existing KD baselines by significant margins.","['Ikhyun Cho', 'U Kang']","['cs.LG', 'stat.ML']",2020-09-30 17:52:15+00:00
http://arxiv.org/abs/2009.14820v1,Gradient Descent-Ascent Provably Converges to Strict Local Minmax Equilibria with a Finite Timescale Separation,"We study the role that a finite timescale separation parameter $\tau$ has on
gradient descent-ascent in two-player non-convex, non-concave zero-sum games
where the learning rate of player 1 is denoted by $\gamma_1$ and the learning
rate of player 2 is defined to be $\gamma_2=\tau\gamma_1$. Existing work
analyzing the role of timescale separation in gradient descent-ascent has
primarily focused on the edge cases of players sharing a learning rate ($\tau
=1$) and the maximizing player approximately converging between each update of
the minimizing player ($\tau \rightarrow \infty$). For the parameter choice of
$\tau=1$, it is known that the learning dynamics are not guaranteed to converge
to a game-theoretically meaningful equilibria in general. In contrast, Jin et
al. (2020) showed that the stable critical points of gradient descent-ascent
coincide with the set of strict local minmax equilibria as
$\tau\rightarrow\infty$. In this work, we bridge the gap between past work by
showing there exists a finite timescale separation parameter $\tau^{\ast}$ such
that $x^{\ast}$ is a stable critical point of gradient descent-ascent for all
$\tau \in (\tau^{\ast}, \infty)$ if and only if it is a strict local minmax
equilibrium. Moreover, we provide an explicit construction for computing
$\tau^{\ast}$ along with corresponding convergence rates and results under
deterministic and stochastic gradient feedback. The convergence results we
present are complemented by a non-convergence result: given a critical point
$x^{\ast}$ that is not a strict local minmax equilibrium, then there exists a
finite timescale separation $\tau_0$ such that $x^{\ast}$ is unstable for all
$\tau\in (\tau_0, \infty)$. Finally, we empirically demonstrate on the CIFAR-10
and CelebA datasets the significant impact timescale separation has on training
performance.","['Tanner Fiez', 'Lillian Ratliff']","['cs.LG', 'cs.GT', 'cs.SY', 'eess.SY', 'stat.ML']",2020-09-30 17:51:28+00:00
http://arxiv.org/abs/2009.14799v4,MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention,"Recent advances in neural forecasting have produced major improvements in
accuracy for probabilistic demand prediction. In this work, we propose novel
improvements to the current state of the art by incorporating changes inspired
by recent advances in Transformer architectures for Natural Language
Processing. We develop a novel decoder-encoder attention for context-alignment,
improving forecasting accuracy by allowing the network to study its own history
based on the context for which it is producing a forecast. We also present a
novel positional encoding that allows the neural network to learn
context-dependent seasonality functions as well as arbitrary holiday distances.
Finally we show that the current state of the art MQ-Forecaster (Wen et al.,
2017) models display excess variability by failing to leverage previous errors
in the forecast to improve accuracy. We propose a novel decoder-self attention
scheme for forecasting that produces significant improvements in the excess
variation of the forecast.","['Carson Eisenach', 'Yagna Patel', 'Dhruv Madeka']","['cs.LG', 'stat.ML']",2020-09-30 17:12:46+00:00
http://arxiv.org/abs/2009.14794v4,Rethinking Attention with Performers,"We introduce Performers, Transformer architectures which can estimate regular
(softmax) full-rank-attention Transformers with provable accuracy, but using
only linear (as opposed to quadratic) space and time complexity, without
relying on any priors such as sparsity or low-rankness. To approximate softmax
attention-kernels, Performers use a novel Fast Attention Via positive
Orthogonal Random features approach (FAVOR+), which may be of independent
interest for scalable kernel methods. FAVOR+ can be also used to efficiently
model kernelizable attention mechanisms beyond softmax. This representational
power is crucial to accurately compare softmax with other kernels for the first
time on large-scale tasks, beyond the reach of regular Transformers, and
investigate optimal attention-kernels. Performers are linear architectures
fully compatible with regular Transformers and with strong theoretical
guarantees: unbiased or nearly-unbiased estimation of the attention matrix,
uniform convergence and low estimation variance. We tested Performers on a rich
set of tasks stretching from pixel-prediction through text models to protein
sequence modeling. We demonstrate competitive results with other examined
efficient sparse and dense attention methods, showcasing effectiveness of the
novel attention-learning paradigm leveraged by Performers.","['Krzysztof Choromanski', 'Valerii Likhosherstov', 'David Dohan', 'Xingyou Song', 'Andreea Gane', 'Tamas Sarlos', 'Peter Hawkins', 'Jared Davis', 'Afroz Mohiuddin', 'Lukasz Kaiser', 'David Belanger', 'Lucy Colwell', 'Adrian Weller']","['cs.LG', 'cs.CL', 'stat.ML']",2020-09-30 17:09:09+00:00
http://arxiv.org/abs/2009.14786v2,Measuring Systematic Generalization in Neural Proof Generation with Transformers,"We are interested in understanding how well Transformer language models
(TLMs) can perform reasoning tasks when trained on knowledge encoded in the
form of natural language. We investigate their systematic generalization
abilities on a logical reasoning task in natural language, which involves
reasoning over relationships between entities grounded in first-order logical
proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to
generate natural language proofs. We test the generated proofs for logical
consistency, along with the accuracy of the final inference. We observe
length-generalization issues when evaluated on longer-than-trained sequences.
However, we observe TLMs improve their generalization performance after being
exposed to longer, exhaustive proofs. In addition, we discover that TLMs are
able to generalize better using backward-chaining proofs compared to their
forward-chaining counterparts, while they find it easier to generate forward
chaining proofs. We observe that models that are not trained to generate proofs
are better at generalizing to problems based on longer proofs. This suggests
that Transformers have efficient internal reasoning strategies that are harder
to interpret. These results highlight the systematic generalization behavior of
TLMs in the context of logical reasoning, and we believe this work motivates
deeper inspection of their underlying reasoning strategies.","['Nicolas Gontier', 'Koustuv Sinha', 'Siva Reddy', 'Christopher Pal']","['cs.LG', 'cs.AI', 'cs.CL', 'stat.ML']",2020-09-30 16:54:37+00:00
http://arxiv.org/abs/2010.07035v1,"MARS-Gym: A Gym framework to model, train, and evaluate Recommender Systems for Marketplaces","Recommender Systems are especially challenging for marketplaces since they
must maximize user satisfaction while maintaining the healthiness and fairness
of such ecosystems. In this context, we observed a lack of resources to design,
train, and evaluate agents that learn by interacting within these environments.
For this matter, we propose MARS-Gym, an open-source framework to empower
researchers and engineers to quickly build and evaluate Reinforcement Learning
agents for recommendations in marketplaces. MARS-Gym addresses the whole
development pipeline: data processing, model design and optimization, and
multi-sided evaluation. We also provide the implementation of a diverse set of
baseline agents, with a metrics-driven analysis of them in the Trivago
marketplace dataset, to illustrate how to conduct a holistic assessment using
the available metrics of recommendation, off-policy estimation, and fairness.
With MARS-Gym, we expect to bridge the gap between academic research and
production systems, as well as to facilitate the design of new algorithms and
applications.","['Marlesson R. O. Santana', 'Luckeciano C. Melo', 'Fernando H. F. Camargo', 'Bruno Brandão', 'Anderson Soares', 'Renan M. Oliveira', 'Sandor Caetano']","['cs.IR', 'cs.HC', 'cs.LG', 'stat.ML', 'I.6.5; H.4.2']",2020-09-30 16:39:31+00:00
http://arxiv.org/abs/2009.14774v2,Consistent regression when oblivious outliers overwhelm,"We consider a robust linear regression model $y=X\beta^* + \eta$, where an
adversary oblivious to the design $X\in \mathbb{R}^{n\times d}$ may choose
$\eta$ to corrupt all but an $\alpha$ fraction of the observations $y$ in an
arbitrary way. Prior to our work, even for Gaussian $X$, no estimator for
$\beta^*$ was known to be consistent in this model except for quadratic sample
size $n \gtrsim (d/\alpha)^2$ or for logarithmic inlier fraction $\alpha\ge
1/\log n$. We show that consistent estimation is possible with nearly linear
sample size and inverse-polynomial inlier fraction. Concretely, we show that
the Huber loss estimator is consistent for every sample size $n=
\omega(d/\alpha^2)$ and achieves an error rate of $O(d/\alpha^2n)^{1/2}$. Both
bounds are optimal (up to constant factors). Our results extend to designs far
beyond the Gaussian case and only require the column span of $X$ to not contain
approximately sparse vectors). (similar to the kind of assumption commonly made
about the kernel space for compressed sensing). We provide two technically
similar proofs. One proof is phrased in terms of strong convexity, extending
work of [Tsakonas et al.'14], and particularly short. The other proof
highlights a connection between the Huber loss estimator and high-dimensional
median computations. In the special case of Gaussian designs, this connection
leads us to a strikingly simple algorithm based on computing coordinate-wise
medians that achieves optimal guarantees in nearly-linear time, and that can
exploit sparsity of $\beta^*$. The model studied here also captures
heavy-tailed noise distributions that may not even have a first moment.","[""Tommaso d'Orsi"", 'Gleb Novikov', 'David Steurer']","['cs.LG', 'stat.ML']",2020-09-30 16:21:34+00:00
http://arxiv.org/abs/2010.02006v7,Interpretable Machine Learning for COVID-19: An Empirical Study on Severity Prediction Task,"The black-box nature of machine learning models hinders the deployment of
some high-accuracy models in medical diagnosis. It is risky to put one's life
in the hands of models that medical researchers do not fully understand.
However, through model interpretation, black-box models can promptly reveal
significant biomarkers that medical practitioners may have overlooked due to
the surge of infected patients in the COVID-19 pandemic.
  This research leverages a database of 92 patients with confirmed SARS-CoV-2
laboratory tests between 18th Jan. 2020 and 5th Mar. 2020, in Zhuhai, China, to
identify biomarkers indicative of severity prediction. Through the
interpretation of four machine learning models, decision tree, random forests,
gradient boosted trees, and neural networks using permutation feature
importance, Partial Dependence Plot (PDP), Individual Conditional Expectation
(ICE), Accumulated Local Effects (ALE), Local Interpretable Model-agnostic
Explanations (LIME), and Shapley Additive Explanation (SHAP), we identify an
increase in N-Terminal pro-Brain Natriuretic Peptide (NTproBNP), C-Reaction
Protein (CRP), and lactic dehydrogenase (LDH), a decrease in lymphocyte (LYM)
is associated with severe infection and an increased risk of death, which is
consistent with recent medical research on COVID-19 and other research using
dedicated models. We further validate our methods on a large open dataset with
5644 confirmed patients from the Hospital Israelita Albert Einstein, at S\~ao
Paulo, Brazil from Kaggle, and unveil leukocytes, eosinophils, and platelets as
three indicative biomarkers for COVID-19.","['Han Wu', 'Wenjie Ruan', 'Jiangtao Wang', 'Dingchang Zheng', 'Bei Liu', 'Yayuan Gen', 'Xiangfei Chai', 'Jian Chen', 'Kunwei Li', 'Shaolin Li', 'Sumi Helal']","['cs.LG', 'stat.ML']",2020-09-30 16:13:41+00:00
http://arxiv.org/abs/2010.00378v2,GraphXCOVID: Explainable Deep Graph Diffusion Pseudo-Labelling for Identifying COVID-19 on Chest X-rays,"Can one learn to diagnose COVID-19 under extreme minimal supervision? Since
the outbreak of the novel COVID-19 there has been a rush for developing
Artificial Intelligence techniques for expert-level disease identification on
Chest X-ray data. In particular, the use of deep supervised learning has become
the go-to paradigm. However, the performance of such models is heavily
dependent on the availability of a large and representative labelled dataset.
The creation of which is a heavily expensive and time consuming task, and
especially imposes a great challenge for a novel disease. Semi-supervised
learning has shown the ability to match the incredible performance of
supervised models whilst requiring a small fraction of the labelled examples.
This makes the semi-supervised paradigm an attractive option for identifying
COVID-19. In this work, we introduce a graph based deep semi-supervised
framework for classifying COVID-19 from chest X-rays. Our framework introduces
an optimisation model for graph diffusion that reinforces the natural relation
among the tiny labelled set and the vast unlabelled data. We then connect the
diffusion prediction output as pseudo-labels that are used in an iterative
scheme in a deep net. We demonstrate, through our experiments, that our model
is able to outperform the current leading supervised model with a tiny fraction
of the labelled examples. Finally, we provide attention maps to accommodate the
radiologist's mental model, better fitting their perceptual and cognitive
abilities. These visualisation aims to assist the radiologist in judging
whether the diagnostic is correct or not, and in consequence to accelerate the
decision.","['Angelica I Aviles-Rivero', 'Philip Sellars', 'Carola-Bibiane Schönlieb', 'Nicolas Papadakis']","['cs.LG', 'cs.CV', 'stat.ML']",2020-09-30 15:38:24+00:00
http://arxiv.org/abs/2009.14738v1,ResGCN: Attention-based Deep Residual Modeling for Anomaly Detection on Attributed Networks,"Effectively detecting anomalous nodes in attributed networks is crucial for
the success of many real-world applications such as fraud and intrusion
detection. Existing approaches have difficulties with three major issues:
sparsity and nonlinearity capturing, residual modeling, and network smoothing.
We propose Residual Graph Convolutional Network (ResGCN), an attention-based
deep residual modeling approach that can tackle these issues: modeling the
attributed networks with GCN allows to capture the sparsity and nonlinearity;
utilizing a deep neural network allows to directly learn residual from the
input, and a residual-based attention mechanism reduces the adverse effect from
anomalous nodes and prevents over-smoothing. Extensive experiments on several
real-world attributed networks demonstrate the effectiveness of ResGCN in
detecting anomalies.","['Yulong Pei', 'Tianjin Huang', 'Werner van Ipenburg', 'Mykola Pechenizkiy']","['cs.LG', 'stat.ML']",2020-09-30 15:24:51+00:00
http://arxiv.org/abs/2009.14737v2,Improving Auto-Augment via Augmentation-Wise Weight Sharing,"The recent progress on automatically searching augmentation policies has
boosted the performance substantially for various tasks. A key component of
automatic augmentation search is the evaluation process for a particular
augmentation policy, which is utilized to return reward and usually runs
thousands of times. A plain evaluation process, which includes full model
training and validation, would be time-consuming. To achieve efficiency, many
choose to sacrifice evaluation reliability for speed. In this paper, we dive
into the dynamics of augmented training of the model. This inspires us to
design a powerful and efficient proxy task based on the Augmentation-Wise
Weight Sharing (AWS) to form a fast yet accurate evaluation process in an
elegant way. Comprehensive analysis verifies the superiority of this approach
in terms of effectiveness and efficiency. The augmentation policies found by
our method achieve superior accuracies compared with existing auto-augmentation
search methods. On CIFAR-10, we achieve a top-1 error rate of 1.24%, which is
currently the best performing single model without extra training data. On
ImageNet, we get a top-1 error rate of 20.36% for ResNet-50, which leads to
3.34% absolute error rate reduction over the baseline augmentation.","['Keyu Tian', 'Chen Lin', 'Ming Sun', 'Luping Zhou', 'Junjie Yan', 'Wanli Ouyang']","['cs.LG', 'cs.CV', 'stat.ML']",2020-09-30 15:23:12+00:00
http://arxiv.org/abs/2009.14720v2,DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles,"Recent research finds CNN models for image classification demonstrate
overlapped adversarial vulnerabilities: adversarial attacks can mislead CNN
models with small perturbations, which can effectively transfer between
different models trained on the same dataset. Adversarial training, as a
general robustness improvement technique, eliminates the vulnerability in a
single model by forcing it to learn robust features. The process is hard, often
requires models with large capacity, and suffers from significant loss on clean
data accuracy. Alternatively, ensemble methods are proposed to induce
sub-models with diverse outputs against a transfer adversarial example, making
the ensemble robust against transfer attacks even if each sub-model is
individually non-robust. Only small clean accuracy drop is observed in the
process. However, previous ensemble training methods are not efficacious in
inducing such diversity and thus ineffective on reaching robust ensemble. We
propose DVERGE, which isolates the adversarial vulnerability in each sub-model
by distilling non-robust features, and diversifies the adversarial
vulnerability to induce diverse outputs against a transfer attack. The novel
diversity metric and training procedure enables DVERGE to achieve higher
robustness against transfer attacks comparing to previous ensemble methods, and
enables the improved robustness when more sub-models are added to the ensemble.
The code of this work is available at https://github.com/zjysteven/DVERGE","['Huanrui Yang', 'Jingyang Zhang', 'Hongliang Dong', 'Nathan Inkawhich', 'Andrew Gardner', 'Andrew Touchet', 'Wesley Wilkes', 'Heath Berry', 'Hai Li']","['cs.LG', 'cs.CR', 'stat.ML']",2020-09-30 14:57:35+00:00
http://arxiv.org/abs/2009.14702v2,Some Remarks on Replicated Simulated Annealing,"Recently authors have introduced the idea of training discrete weights neural
networks using a mix between classical simulated annealing and a replica ansatz
known from the statistical physics literature. Among other points, they claim
their method is able to find robust configurations. In this paper, we analyze
this so-called ""replicated simulated annealing"" algorithm. In particular, we
explicit criteria to guarantee its convergence, and study when it successfully
samples from configurations. We also perform experiments using synthetic and
real data bases.","['Vincent Gripon', 'Matthias Löwe', 'Franck Vermet']","['cs.LG', 'cs.NE', 'math.OC', 'math.PR', 'stat.ML']",2020-09-30 14:33:53+00:00
http://arxiv.org/abs/2009.14701v1,Where Does Trust Break Down? A Quantitative Trust Analysis of Deep Neural Networks via Trust Matrix and Conditional Trust Densities,"The advances and successes in deep learning in recent years have led to
considerable efforts and investments into its widespread ubiquitous adoption
for a wide variety of applications, ranging from personal assistants and
intelligent navigation to search and product recommendation in e-commerce. With
this tremendous rise in deep learning adoption comes questions about the
trustworthiness of the deep neural networks that power these applications.
Motivated to answer such questions, there has been a very recent interest in
trust quantification. In this work, we introduce the concept of trust matrix, a
novel trust quantification strategy that leverages the recently introduced
question-answer trust metric by Wong et al. to provide deeper, more detailed
insights into where trust breaks down for a given deep neural network given a
set of questions. More specifically, a trust matrix defines the expected
question-answer trust for a given actor-oracle answer scenario, allowing one to
quickly spot areas of low trust that needs to be addressed to improve the
trustworthiness of a deep neural network. The proposed trust matrix is simple
to calculate, humanly interpretable, and to the best of the authors' knowledge
is the first to study trust at the actor-oracle answer level. We further extend
the concept of trust densities with the notion of conditional trust densities.
We experimentally leverage trust matrices to study several well-known deep
neural network architectures for image recognition, and further study the trust
density and conditional trust densities for an interesting actor-oracle answer
scenario. The results illustrate that trust matrices, along with conditional
trust densities, can be useful tools in addition to the existing suite of trust
quantification metrics for guiding practitioners and regulators in creating and
certifying deep learning solutions for trusted operation.","['Andrew Hryniowski', 'Xiao Yu Wang', 'Alexander Wong']","['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']",2020-09-30 14:33:43+00:00
http://arxiv.org/abs/2009.14695v2,Global convergence of Negative Correlation Extreme Learning Machine,"Ensemble approaches introduced in the Extreme Learning Machine (ELM)
literature mainly come from methods that relies on data sampling procedures,
under the assumption that the training data are heterogeneously enough to set
up diverse base learners. To overcome this assumption, it was proposed an ELM
ensemble method based on the Negative Correlation Learning (NCL) framework,
called Negative Correlation Extreme Learning Machine (NCELM). This model works
in two stages: i) different ELMs are generated as base learners with random
weights in the hidden layer, and ii) a NCL penalty term with the information of
the ensemble prediction is introduced in each ELM minimization problem,
updating the base learners, iii) second step is iterated until the ensemble
converges.
  Although this NCL ensemble method was validated by an experimental study with
multiple benchmark datasets, no information was given on the conditions about
this convergence. This paper mathematically presents the sufficient conditions
to guarantee the global convergence of NCELM. The update of the ensemble in
each iteration is defined as a contraction mapping function, and through Banach
theorem, global convergence of the ensemble is proved.",['Carlos Perales-González'],"['cs.LG', 'cs.NE', 'stat.ML']",2020-09-30 14:18:10+00:00
http://arxiv.org/abs/2009.14670v1,An Online Learning Algorithm for a Neuro-Fuzzy Classifier with Mixed-Attribute Data,"General fuzzy min-max neural network (GFMMNN) is one of the efficient
neuro-fuzzy systems for data classification. However, one of the downsides of
its original learning algorithms is the inability to handle and learn from the
mixed-attribute data. While categorical features encoding methods can be used
with the GFMMNN learning algorithms, they exhibit a lot of shortcomings. Other
approaches proposed in the literature are not suitable for on-line learning as
they require entire training data available in the learning phase. With the
rapid change in the volume and velocity of streaming data in many application
areas, it is increasingly required that the constructed models can learn and
adapt to the continuous data changes in real-time without the need for their
full retraining or access to the historical data. This paper proposes an
extended online learning algorithm for the GFMMNN. The proposed method can
handle the datasets with both continuous and categorical features. The
extensive experiments confirmed superior and stable classification performance
of the proposed approach in comparison to other relevant learning algorithms
for the GFMM model.","['Thanh Tung Khuat', 'Bogdan Gabrys']","['cs.LG', 'cs.NE', 'stat.ML', '68T30, 68T20, 68T37, 68W27', 'I.2.1; I.2.6; I.2.m; I.5.0; I.5.1; I.5.2; I.5.3; I.5.4']",2020-09-30 13:45:36+00:00
http://arxiv.org/abs/2009.14610v2,Concurrent Neural Network : A model of competition between times series,"Competition between times series often arises in sales prediction, when
similar products are on sale on a marketplace. This article provides a model of
the presence of cannibalization between times series. This model creates a
""competitiveness"" function that depends on external features such as price and
margin. It also provides a theoretical guaranty on the error of the model under
some reasonable conditions, and implement this model using a neural network to
compute this competitiveness function. This implementation outperforms other
traditional time series methods and classical neural networks for market share
prediction on a real-world data set.",['Rémy Garnier'],"['stat.ML', 'cs.LG', 'stat.AP']",2020-09-30 12:34:56+00:00
http://arxiv.org/abs/2009.14606v1,Improving Generalization of Deep Fault Detection Models in the Presence of Mislabeled Data,"Mislabeled samples are ubiquitous in real-world datasets as rule-based or
expert labeling is usually based on incorrect assumptions or subject to biased
opinions. Neural networks can ""memorize"" these mislabeled samples and, as a
result, exhibit poor generalization. This poses a critical issue in fault
detection applications, where not only the training but also the validation
datasets are prone to contain mislabeled samples. In this work, we propose a
novel two-step framework for robust training with label noise. In the first
step, we identify outliers (including the mislabeled samples) based on the
update in the hypothesis space. In the second step, we propose different
approaches to modifying the training data based on the identified outliers and
a data augmentation technique. Contrary to previous approaches, we aim at
finding a robust solution that is suitable for real-world applications, such as
fault detection, where no clean, ""noise-free"" validation dataset is available.
Under an approximate assumption about the upper limit of the label noise, we
significantly improve the generalization ability of the model trained under
massive label noise.","['Katharina Rombach', 'Gabriel Michau', 'Olga Fink']","['cs.LG', 'stat.ML', 'I.5.2; I.2.1']",2020-09-30 12:33:25+00:00
http://arxiv.org/abs/2009.14593v1,The Role of Isomorphism Classes in Multi-Relational Datasets,"Multi-interaction systems abound in nature, from colloidal suspensions to
gene regulatory circuits. These systems can produce complex dynamics and graph
neural networks have been proposed as a method to extract underlying
interactions and predict how systems will evolve. The current training and
evaluation procedures for these models through the use of synthetic
multi-relational datasets however are agnostic to interaction network
isomorphism classes, which produce identical dynamics up to initial conditions.
We extensively analyse how isomorphism class awareness affects these models,
focusing on neural relational inference (NRI) models, which are unique in
explicitly inferring interactions to predict dynamics in the unsupervised
setting. Specifically, we demonstrate that isomorphism leakage overestimates
performance in multi-relational inference and that sampling biases present in
the multi-interaction network generation process can impair generalisation. To
remedy this, we propose isomorphism-aware synthetic benchmarks for model
evaluation. We use these benchmarks to test generalisation abilities and
demonstrate the existence of a threshold sampling frequency of isomorphism
classes for successful learning. In addition, we demonstrate that isomorphism
classes can be utilised through a simple prioritisation scheme to improve model
performance, stability during training and reduce training time.","['Vijja Wichitwechkarn', 'Ben Day', 'Cristian Bodnar', 'Matthew Wales', 'Pietro Liò']","['cs.LG', 'cs.SI', 'physics.soc-ph', 'stat.ML']",2020-09-30 12:15:24+00:00
http://arxiv.org/abs/2009.14588v1,EWS-GCN: Edge Weight-Shared Graph Convolutional Network for Transactional Banking Data,"In this paper, we discuss how modern deep learning approaches can be applied
to the credit scoring of bank clients. We show that information about
connections between clients based on money transfers between them allows us to
significantly improve the quality of credit scoring compared to the approaches
using information about the target client solely. As a final solution, we
develop a new graph neural network model EWS-GCN that combines ideas of graph
convolutional and recurrent neural networks via attention mechanism. The
resulting model allows for robust training and efficient processing of
large-scale data. We also demonstrate that our model outperforms the
state-of-the-art graph neural networks achieving excellent results","['Ivan Sukharev', 'Valentina Shumovskaia', 'Kirill Fedyanin', 'Maxim Panov', 'Dmitry Berestnev']","['stat.ML', 'cs.LG']",2020-09-30 12:09:28+00:00
http://arxiv.org/abs/2009.14575v2,First-order Optimization for Superquantile-based Supervised Learning,"Classical supervised learning via empirical risk (or negative log-likelihood)
minimization hinges upon the assumption that the testing distribution coincides
with the training distribution. This assumption can be challenged in modern
applications of machine learning in which learning machines may operate at
prediction time with testing data whose distribution departs from the one of
the training data. We revisit the superquantile regression method by proposing
a first-order optimization algorithm to minimize a superquantile-based learning
objective. The proposed algorithm is based on smoothing the superquantile
function by infimal convolution. Promising numerical results illustrate the
interest of the approach towards safer supervised learning.","['Yassine Laguel', 'Jérôme Malick', 'Zaid Harchaoui']","['math.OC', 'cs.LG', 'stat.ML']",2020-09-30 11:43:45+00:00
http://arxiv.org/abs/2009.14573v6,Rain-Code Fusion : Code-to-code ConvLSTM Forecasting Spatiotemporal Precipitation,"Recently, flood damage has become a social problem owing to unexperienced
weather conditions arising from climate change. An immediate response to heavy
rain is important for the mitigation of economic losses and also for rapid
recovery. Spatiotemporal precipitation forecasts may enhance the accuracy of
dam inflow prediction, more than 6 hours forward for flood damage mitigation.
However, the ordinary ConvLSTM has the limitation of predictable range more
than 3-timesteps in real-world precipitation forecasting owing to the
irreducible bias between target prediction and ground-truth value. This paper
proposes a rain-code approach for spatiotemporal precipitation code-to-code
forecasting. We propose a novel rainy feature that represents a temporal rainy
process using multi-frame fusion for the timestep reduction. We perform
rain-code studies with various term ranges based on the standard ConvLSTM. We
applied to a dam region within the Japanese rainy term hourly precipitation
data, under 2006 to 2019 approximately 127 thousands hours, every year from May
to October. We apply the radar analysis hourly data on the central broader
region with an area of 136 x 148 km2 . Finally we have provided sensitivity
studies between the rain-code size and hourly accuracy within the several
forecasting range.","['Takato Yasuno', 'Akira Ishii', 'Masazumi Amakata']","['cs.LG', 'physics.ao-ph', 'stat.ML']",2020-09-30 11:33:45+00:00
http://arxiv.org/abs/2009.14572v5,Uncovering Feature Interdependencies in High-Noise Environments with Stepwise Lookahead Decision Forests,"Conventionally, random forests are built from ""greedy"" decision trees which
each consider only one split at a time during their construction. The
sub-optimality of greedy implementation has been well-known, yet mainstream
adoption of more sophisticated tree building algorithms has been lacking. We
examine under what circumstances an implementation of less greedy decision
trees actually yields outperformance. To this end, a ""stepwise lookahead""
variation of the random forest algorithm is presented for its ability to better
uncover binary feature interdependencies. In contrast to the greedy approach,
the decision trees included in this random forest algorithm, each
simultaneously consider three split nodes in tiers of depth two. It is
demonstrated on synthetic data and financial price time series that the
lookahead version significantly outperforms the greedy one when (a) certain
non-linear relationships between feature-pairs are present and (b) if the
signal-to-noise ratio is particularly low. A long-short trading strategy for
copper futures is then backtested by training both greedy and stepwise
lookahead random forests to predict the signs of daily price returns. The
resulting superior performance of the lookahead algorithm is at least partially
explained by the presence of ""XOR-like"" relationships between long-term and
short-term technical indicators. More generally, across all examined datasets,
when no such relationships between features are present, performance across
random forests is similar. Given its enhanced ability to understand the
feature-interdependencies present in complex systems, this lookahead variation
is a useful extension to the toolkit of data scientists, in particular for
financial machine learning, where conditions (a) and (b) are typically met.","['Delilah Donick', 'Sandro Claudio Lera']","['cs.LG', 'stat.ML']",2020-09-30 11:31:10+00:00
http://arxiv.org/abs/2009.14554v1,One Reflection Suffice,"Orthogonal weight matrices are used in many areas of deep learning. Much
previous work attempt to alleviate the additional computational resources it
requires to constrain weight matrices to be orthogonal. One popular approach
utilizes *many* Householder reflections. The only practical drawback is that
many reflections cause low GPU utilization. We mitigate this final drawback by
proving that *one* reflection is sufficient, if the reflection is computed by
an auxiliary neural network.","['Alexander Mathiasen', 'Frederik Hvilshøj']","['cs.LG', 'stat.ML']",2020-09-30 10:52:27+00:00
http://arxiv.org/abs/2009.14552v1,Wasserstein Distributionally Robust Inverse Multiobjective Optimization,"Inverse multiobjective optimization provides a general framework for the
unsupervised learning task of inferring parameters of a multiobjective decision
making problem (DMP), based on a set of observed decisions from the human
expert. However, the performance of this framework relies critically on the
availability of an accurate DMP, sufficient decisions of high quality, and a
parameter space that contains enough information about the DMP. To hedge
against the uncertainties in the hypothetical DMP, the data, and the parameter
space, we investigate in this paper the distributionally robust approach for
inverse multiobjective optimization. Specifically, we leverage the Wasserstein
metric to construct a ball centered at the empirical distribution of these
decisions. We then formulate a Wasserstein distributionally robust inverse
multiobjective optimization problem (WRO-IMOP) that minimizes a worst-case
expected loss function, where the worst case is taken over all distributions in
the Wasserstein ball. We show that the excess risk of the WRO-IMOP estimator
has a sub-linear convergence rate. Furthermore, we propose the semi-infinite
reformulations of the WRO-IMOP and develop a cutting-plane algorithm that
converges to an approximate solution in finite iterations. Finally, we
demonstrate the effectiveness of our method on both a synthetic multiobjective
quadratic program and a real world portfolio optimization problem.","['Chaosheng Dong', 'Bo Zeng']","['math.OC', 'cs.LG', 'stat.ML']",2020-09-30 10:44:07+00:00
http://arxiv.org/abs/2009.14502v1,Stochastic Precision Ensemble: Self-Knowledge Distillation for Quantized Deep Neural Networks,"The quantization of deep neural networks (QDNNs) has been actively studied
for deployment in edge devices. Recent studies employ the knowledge
distillation (KD) method to improve the performance of quantized networks. In
this study, we propose stochastic precision ensemble training for QDNNs (SPEQ).
SPEQ is a knowledge distillation training scheme; however, the teacher is
formed by sharing the model parameters of the student network. We obtain the
soft labels of the teacher by changing the bit precision of the activation
stochastically at each layer of the forward-pass computation. The student model
is trained with these soft labels to reduce the activation quantization noise.
The cosine similarity loss is employed, instead of the KL-divergence, for KD
training. As the teacher model changes continuously by random bit-precision
assignment, it exploits the effect of stochastic ensemble KD. SPEQ outperforms
the existing quantization training methods in various tasks, such as image
classification, question-answering, and transfer learning without the need for
cumbersome teacher networks.","['Yoonho Boo', 'Sungho Shin', 'Jungwook Choi', 'Wonyong Sung']","['cs.LG', 'stat.ML']",2020-09-30 08:38:37+00:00
http://arxiv.org/abs/2009.14499v1,Detecting Autism Spectrum Disorder using Machine Learning,"Autism Spectrum Disorder (ASD), which is a neuro development disorder, is
often accompanied by sensory issues such an over sensitivity or under
sensitivity to sounds and smells or touch. Although its main cause is genetics
in nature, early detection and treatment can help to improve the conditions. In
recent years, machine learning based intelligent diagnosis has been evolved to
complement the traditional clinical methods which can be time consuming and
expensive. The focus of this paper is to find out the most significant traits
and automate the diagnosis process using available classification techniques
for improved diagnosis purpose. We have analyzed ASD datasets of Toddler,
Child, Adolescent and Adult. We determine the best performing classifier for
these binary datasets using the evaluation metrics recall, precision,
F-measures and classification errors. Our finding shows that Sequential minimal
optimization (SMO) based Support Vector Machines (SVM) classifier outperforms
all other benchmark machine learning algorithms in terms of accuracy during the
detection of ASD cases and produces less classification errors compared to
other algorithms. Also, we find that Relief Attributes algorithm is the best to
identify the most significant attributes in ASD datasets.","['Md Delowar Hossain', 'Muhammad Ashad Kabir', 'Adnan Anwar', 'Md Zahidul Islam']","['cs.LG', 'stat.ML']",2020-09-30 08:33:12+00:00
http://arxiv.org/abs/2009.14471v7,PettingZoo: Gym for Multi-Agent Reinforcement Learning,"This paper introduces the PettingZoo library and the accompanying Agent
Environment Cycle (""AEC"") games model. PettingZoo is a library of diverse sets
of multi-agent environments with a universal, elegant Python API. PettingZoo
was developed with the goal of accelerating research in Multi-Agent
Reinforcement Learning (""MARL""), by making work more interchangeable,
accessible and reproducible akin to what OpenAI's Gym library did for
single-agent reinforcement learning. PettingZoo's API, while inheriting many
features of Gym, is unique amongst MARL APIs in that it's based around the
novel AEC games model. We argue, in part through case studies on major problems
in popular MARL environments, that the popular game models are poor conceptual
models of games commonly used in MARL and accordingly can promote confusing
bugs that are hard to detect, and that the AEC games model addresses these
problems.","['J. K. Terry', 'Benjamin Black', 'Nathaniel Grammel', 'Mario Jayakumar', 'Ananth Hari', 'Ryan Sullivan', 'Luis Santos', 'Rodrigo Perez', 'Caroline Horsch', 'Clemens Dieffendahl', 'Niall L. Williams', 'Yashas Lokesh', 'Praveen Ravi']","['cs.LG', 'cs.MA', 'stat.ML']",2020-09-30 06:42:09+00:00
http://arxiv.org/abs/2009.14455v1,Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks,"Graph Neural Networks (GNNs), a generalization of neural networks to
graph-structured data, are often implemented using message passes between
entities of a graph. While GNNs are effective for node classification, link
prediction and graph classification, they are vulnerable to adversarial
attacks, i.e., a small perturbation to the structure can lead to a non-trivial
performance degradation. In this work, we propose Uncertainty Matching GNN
(UM-GNN), that is aimed at improving the robustness of GNN models, particularly
against poisoning attacks to the graph structure, by leveraging epistemic
uncertainties from the message passing framework. More specifically, we propose
to build a surrogate predictor that does not directly access the graph
structure, but systematically extracts reliable knowledge from a standard GNN
through a novel uncertainty-matching strategy. Interestingly, this uncoupling
makes UM-GNN immune to evasion attacks by design, and achieves significantly
improved robustness against poisoning attacks. Using empirical studies with
standard benchmarks and a suite of global and target attacks, we demonstrate
the effectiveness of UM-GNN, when compared to existing baselines including the
state-of-the-art robust GCN.","['Uday Shankar Shanthamallu', 'Jayaraman J. Thiagarajan', 'Andreas Spanias']","['stat.ML', 'cs.CR', 'cs.LG']",2020-09-30 05:29:42+00:00
http://arxiv.org/abs/2009.14454v1,Accurate and Robust Feature Importance Estimation under Distribution Shifts,"With increasing reliance on the outcomes of black-box models in critical
applications, post-hoc explainability tools that do not require access to the
model internals are often used to enable humans understand and trust these
models. In particular, we focus on the class of methods that can reveal the
influence of input features on the predicted outputs. Despite their wide-spread
adoption, existing methods are known to suffer from one or more of the
following challenges: computational complexities, large uncertainties and most
importantly, inability to handle real-world domain shifts. In this paper, we
propose PRoFILE, a novel feature importance estimation method that addresses
all these challenges. Through the use of a loss estimator jointly trained with
the predictive model and a causal objective, PRoFILE can accurately estimate
the feature importance scores even under complex distribution shifts, without
any additional re-training. To this end, we also develop learning strategies
for training the loss estimator, namely contrastive and dropout calibration,
and find that it can effectively detect distribution shifts. Using empirical
studies on several benchmark image and non-image data, we show significant
improvements over state-of-the-art approaches, both in terms of fidelity and
robustness.","['Jayaraman J. Thiagarajan', 'Vivek Narayanaswamy', 'Rushil Anirudh', 'Peer-Timo Bremer', 'Andreas Spanias']","['stat.ML', 'cs.LG']",2020-09-30 05:29:01+00:00
http://arxiv.org/abs/2009.14448v1,Ask-n-Learn: Active Learning via Reliable Gradient Representations for Image Classification,"Deep predictive models rely on human supervision in the form of labeled
training data. Obtaining large amounts of annotated training data can be
expensive and time consuming, and this becomes a critical bottleneck while
building such models in practice. In such scenarios, active learning (AL)
strategies are used to achieve faster convergence in terms of labeling efforts.
Existing active learning employ a variety of heuristics based on uncertainty
and diversity to select query samples. Despite their wide-spread use, in
practice, their performance is limited by a number of factors including
non-calibrated uncertainties, insufficient trade-off between data exploration
and exploitation, presence of confirmation bias etc. In order to address these
challenges, we propose Ask-n-Learn, an active learning approach based on
gradient embeddings obtained using the pesudo-labels estimated in each
iteration of the algorithm. More importantly, we advocate the use of prediction
calibration to obtain reliable gradient embeddings, and propose a data
augmentation strategy to alleviate the effects of confirmation bias during
pseudo-labeling. Through empirical studies on benchmark image classification
tasks (CIFAR-10, SVHN, Fashion-MNIST, MNIST), we demonstrate significant
improvements over state-of-the-art baselines, including the recently proposed
BADGE algorithm.","['Bindya Venkatesh', 'Jayaraman J. Thiagarajan']","['stat.ML', 'cs.CV', 'cs.LG']",2020-09-30 05:19:56+00:00
http://arxiv.org/abs/2009.14444v2,A law of robustness for two-layers neural networks,"We initiate the study of the inherent tradeoffs between the size of a neural
network and its robustness, as measured by its Lipschitz constant. We make a
precise conjecture that, for any Lipschitz activation function and for most
datasets, any two-layers neural network with $k$ neurons that perfectly fit the
data must have its Lipschitz constant larger (up to a constant) than
$\sqrt{n/k}$ where $n$ is the number of datapoints. In particular, this
conjecture implies that overparametrization is necessary for robustness, since
it means that one needs roughly one neuron per datapoint to ensure a
$O(1)$-Lipschitz network, while mere data fitting of $d$-dimensional data
requires only one neuron per $d$ datapoints. We prove a weaker version of this
conjecture when the Lipschitz constant is replaced by an upper bound on it
based on the spectral norm of the weight matrix. We also prove the conjecture
in the high-dimensional regime $n \approx d$ (which we also refer to as the
undercomplete case, since only $k \leq d$ is relevant here). Finally we prove
the conjecture for polynomial activation functions of degree $p$ when $n
\approx d^p$. We complement these findings with experimental evidence
supporting the conjecture.","['Sébastien Bubeck', 'Yuanzhi Li', 'Dheeraj Nagaraj']","['cs.LG', 'stat.ML']",2020-09-30 05:13:12+00:00
http://arxiv.org/abs/2009.14441v1,Spectral Embedding of Graph Networks,"We introduce an unsupervised graph embedding that trades off local node
similarity and connectivity, and global structure. The embedding is based on a
generalized graph Laplacian, whose eigenvectors compactly capture both network
structure and neighborhood proximity in a single representation. The key idea
is to transform the given graph into one whose weights measure the centrality
of an edge by the fraction of the number of shortest paths that pass through
that edge, and employ its spectral proprieties in the representation. Testing
the resulting graph network representation shows significant improvement over
the sate of the art in data analysis tasks including social networks and
material science. We also test our method on node classification from the
human-SARS CoV-2 protein-protein interactome.","['Shay Deutsch', 'Stefano Soatto']","['cs.LG', 'cs.AI', 'stat.ML']",2020-09-30 04:59:10+00:00
http://arxiv.org/abs/2009.14436v1,Online Convex Optimization in Changing Environments and its Application to Resource Allocation,"In the era of the big data, we create and collect lots of data from all
different kinds of sources: the Internet, the sensors, the consumer market, and
so on. Many of the data are coming sequentially, and would like to be processed
and understood quickly. One classic way of analyzing data is based on batch
processing, in which the data is stored and analyzed in an offline fashion.
However, when the volume of the data is too large, it is much more difficult
and time-consuming to do batch processing than sequential processing. What's
more, sequential data is usually changing dynamically, and needs to be
understood on-the-fly in order to capture the changes. Online Convex
Optimization (OCO) is a popular framework that matches the above sequential
data processing requirement. Applications using OCO include online routing,
online auctions, online classification and regression, as well as online
resource allocation. Due to the general applicability of OCO to the sequential
data and the rigorous theoretical guarantee, it has attracted lots of
researchers to develop useful algorithms to fulfill different needs. In this
thesis, we show our contributions to OCO's development by designing algorithms
to adapt to changing environments.",['Jianjun Yuan'],"['cs.LG', 'stat.ML']",2020-09-30 04:53:59+00:00
http://arxiv.org/abs/2009.14416v2,Improved Knowledge Distillation via Full Kernel Matrix Transfer,"Knowledge distillation is an effective way for model compression in deep
learning. Given a large model (i.e., teacher model), it aims to improve the
performance of a compact model (i.e., student model) by transferring the
information from the teacher. Various information for distillation has been
studied. Recently, a number of works propose to transfer the pairwise
similarity between examples to distill relative information. However, most of
efforts are devoted to developing different similarity measurements, while only
a small matrix consisting of examples within a mini-batch is transferred at
each iteration that can be inefficient for optimizing the pairwise similarity
over the whole data set. In this work, we aim to transfer the full similarity
matrix effectively. The main challenge is from the size of the full matrix that
is quadratic to the number of examples. To address the challenge, we decompose
the original full matrix with Nystr{\""{o}}m method. By selecting appropriate
landmark points, our theoretical analysis indicates that the loss for transfer
can be further simplified. Concretely, we find that the difference between the
original full kernel matrices between teacher and student can be well bounded
by that of the corresponding partial matrices, which only consists of
similarities between original examples and landmark points. Compared with the
full matrix, the size of the partial matrix is linear in the number of
examples, which improves the efficiency of optimization significantly. The
empirical study on benchmark data sets demonstrates the effectiveness of the
proposed algorithm. Code is available at \url{https://github.com/idstcv/KDA}.","['Qi Qian', 'Hao Li', 'Juhua Hu']","['cs.LG', 'cs.CV', 'stat.ML']",2020-09-30 04:03:09+00:00
http://arxiv.org/abs/2010.00438v1,Analysis of KNN Density Estimation,"We analyze the $\ell_1$ and $\ell_\infty$ convergence rates of k nearest
neighbor density estimation method. Our analysis includes two different cases
depending on whether the support set is bounded or not. In the first case, the
probability density function has a bounded support and is bounded away from
zero. We show that kNN density estimation is minimax optimal under both
$\ell_1$ and $\ell_\infty$ criteria, if the support set is known. If the
support set is unknown, then the convergence rate of $\ell_1$ error is not
affected, while $\ell_\infty$ error does not converge. In the second case, the
probability density function can approach zero and is smooth everywhere.
Moreover, the Hessian is assumed to decay with the density values. For this
case, our result shows that the $\ell_\infty$ error of kNN density estimation
is nearly minimax optimal. The $\ell_1$ error does not reach the minimax lower
bound, but is better than kernel density estimation.","['Puning Zhao', 'Lifeng Lai']","['stat.ML', 'cs.LG']",2020-09-30 03:33:17+00:00
http://arxiv.org/abs/2009.14397v4,Deep Equals Shallow for ReLU Networks in Kernel Regimes,"Deep networks are often considered to be more expressive than shallow ones in
terms of approximation. Indeed, certain functions can be approximated by deep
networks provably more efficiently than by shallow ones, however, no tractable
algorithms are known for learning such deep models. Separately, a recent line
of work has shown that deep networks trained with gradient descent may behave
like (tractable) kernel methods in a certain over-parameterized regime, where
the kernel is determined by the architecture and initialization, and this paper
focuses on approximation for such kernels. We show that for ReLU activations,
the kernels derived from deep fully-connected networks have essentially the
same approximation properties as their shallow two-layer counterpart, namely
the same eigenvalue decay for the corresponding integral operator. This
highlights the limitations of the kernel framework for understanding the
benefits of such deep architectures. Our main theoretical result relies on
characterizing such eigenvalue decays through differentiability properties of
the kernel function, which also easily applies to the study of other kernels
defined on the sphere.","['Alberto Bietti', 'Francis Bach']","['stat.ML', 'cs.LG']",2020-09-30 02:37:43+00:00
http://arxiv.org/abs/2009.14389v1,Manifold Adaptive Multiple Kernel K-Means for Clustering,"Multiple kernel methods based on k-means aims to integrate a group of kernels
to improve the performance of kernel k-means clustering. However, we observe
that most existing multiple kernel k-means methods exploit the nonlinear
relationship within kernels, whereas the local manifold structure among
multiple kernel space is not sufficiently considered. In this paper, we adopt
the manifold adaptive kernel, instead of the original kernel, to integrate the
local manifold structure of kernels. Thus, the induced multiple manifold
adaptive kernels not only reflect the nonlinear relationship but also the local
manifold structure. We then perform multiple kernel clustering within the
multiple kernel k-means clustering framework. It has been verified that the
proposed method outperforms several state-of-the-art baseline methods on a
variety of data sets.","['Liang Du', 'Haiying Zhang', 'Xin Ren', 'Xiaolin Lv']","['cs.LG', 'stat.ML']",2020-09-30 02:07:53+00:00
http://arxiv.org/abs/2009.14379v1,Few-shot Learning for Time-series Forecasting,"Time-series forecasting is important for many applications. Forecasting
models are usually trained using time-series data in a specific target task.
However, sufficient data in the target task might be unavailable, which leads
to performance degradation. In this paper, we propose a few-shot learning
method that forecasts a future value of a time-series in a target task given a
few time-series in the target task. Our model is trained using time-series data
in multiple training tasks that are different from target tasks. Our model uses
a few time-series to build a forecasting function based on a recurrent neural
network with an attention mechanism. With the attention mechanism, we can
retrieve useful patterns in a small number of time-series for the current
situation. Our model is trained by minimizing an expected test error of
forecasting next timestep values. We demonstrate the effectiveness of the
proposed method using 90 time-series datasets.","['Tomoharu Iwata', 'Atsutoshi Kumagai']","['stat.ML', 'cs.LG']",2020-09-30 01:32:22+00:00
http://arxiv.org/abs/2009.14373v1,Facilitate the Parametric Dimension Reduction by Gradient Clipping,"We extend a well-known dimension reduction method, t-distributed stochastic
neighbor embedding (t-SNE), from non-parametric to parametric by training
neural networks. The main advantage of a parametric technique is the
generalization of handling new data, which is particularly beneficial for
streaming data exploration. However, training a neural network to optimize the
t-SNE objective function frequently fails. Previous methods overcome this
problem by pre-training and then fine-tuning the network. We found that the
training failure comes from the gradient exploding problem, which occurs when
data points distant in high-dimensional space are projected to nearby embedding
positions. Accordingly, we applied the gradient clipping method to solve the
problem. Since the networks are trained by directly optimizing the t-SNE
objective function, our method achieves an embedding quality that is compatible
with the non-parametric t-SNE while enjoying the ability of generalization. Due
to mini-batch network training, our parametric dimension reduction method is
highly efficient. We further extended other non-parametric state-of-the-art
approaches, such as LargeVis and UMAP, to the parametric versions. Experiment
results demonstrate the feasibility of our method. Considering its
practicability, we will soon release the codes for public use.","['Chien-Hsun Lai', 'Yu-Shuen Wang']","['cs.LG', 'stat.ML']",2020-09-30 01:21:22+00:00
http://arxiv.org/abs/2010.01997v1,Immigration Document Classification and Automated Response Generation,"In this paper, we consider the problem of organizing supporting documents
vital to U.S. work visa petitions, as well as responding to Requests For
Evidence (RFE) issued by the U.S.~Citizenship and Immigration Services (USCIS).
Typically, both processes require a significant amount of repetitive manual
effort. To reduce the burden of mechanical work, we apply machine learning
methods to automate these processes, with humans in the loop to review and edit
output for submission. In particular, we use an ensemble of image and text
classifiers to categorize supporting documents. We also use a text classifier
to automatically identify the types of evidence being requested in an RFE, and
used the identified types in conjunction with response templates and extracted
fields to assemble draft responses. Empirical results suggest that our approach
achieves considerable accuracy while significantly reducing processing time.","['Sourav Mukherjee', 'Tim Oates', 'Vince DiMascio', 'Huguens Jean', 'Rob Ares', 'David Widmark', 'Jaclyn Harder']","['cs.LG', 'stat.ML']",2020-09-29 23:45:44+00:00
http://arxiv.org/abs/2009.14343v1,Geometric Matrix Completion: A Functional View,"We propose a totally functional view of geometric matrix completion problem.
Differently from existing work, we propose a novel regularization inspired from
the functional map literature that is more interpretable and theoretically
sound. On synthetic tasks with strong underlying geometric structure, our
framework outperforms state of the art by a huge margin (two order of
magnitude) demonstrating the potential of our approach. On real datasets, we
achieve state-of-the-art results at a fraction of the computational effort of
previous methods. Our code is publicly available at
https://github.com/Not-IITian/functional-matrix-completion","['Abhishek Sharma', 'Maks Ovsjanikov']","['cs.LG', 'cs.CV', 'cs.SI', 'stat.ML']",2020-09-29 23:23:04+00:00
http://arxiv.org/abs/2009.14337v1,StratLearner: Learning a Strategy for Misinformation Prevention in Social Networks,"Given a combinatorial optimization problem taking an input, can we learn a
strategy to solve it from the examples of input-solution pairs without knowing
its objective function? In this paper, we consider such a setting and study the
misinformation prevention problem. Given the examples of attacker-protector
pairs, our goal is to learn a strategy to compute protectors against future
attackers, without the need of knowing the underlying diffusion model. To this
end, we design a structured prediction framework, where the main idea is to
parameterize the scoring function using random features constructed through
distance functions on randomly sampled subgraphs, which leads to a kernelized
scoring function with weights learnable via the large margin method. Evidenced
by experiments, our method can produce near-optimal protectors without using
any information of the diffusion model, and it outperforms other possible
graph-based and learning-based methods by an evident margin.",['Guangmo Tong'],"['cs.LG', 'cs.SI', 'stat.ML']",2020-09-29 22:58:33+00:00
http://arxiv.org/abs/2010.01197v1,Stock2Vec: A Hybrid Deep Learning Framework for Stock Market Prediction with Representation Learning and Temporal Convolutional Network,"We have proposed to develop a global hybrid deep learning framework to
predict the daily prices in the stock market. With representation learning, we
derived an embedding called Stock2Vec, which gives us insight for the
relationship among different stocks, while the temporal convolutional layers
are used for automatically capturing effective temporal patterns both within
and across series. Evaluated on S&P 500, our hybrid framework integrates both
advantages and achieves better performance on the stock price prediction task
than several popular benchmarked models.","['Xing Wang', 'Yijun Wang', 'Bin Weng', 'Aleksandr Vinel']","['q-fin.ST', 'cs.LG', 'stat.ML']",2020-09-29 22:54:30+00:00
http://arxiv.org/abs/2009.14332v5,Multi-hop Attention Graph Neural Network,"Self-attention mechanism in graph neural networks (GNNs) led to
state-of-the-art performance on many graph representation learning tasks.
Currently, at every layer, attention is computed between connected pairs of
nodes and depends solely on the representation of the two nodes. However, such
attention mechanism does not account for nodes that are not directly connected
but provide important network context. Here we propose Multi-hop Attention
Graph Neural Network (MAGNA), a principled way to incorporate multi-hop context
information into every layer of attention computation. MAGNA diffuses the
attention scores across the network, which increases the receptive field for
every layer of the GNN. Unlike previous approaches, MAGNA uses a diffusion
prior on attention values, to efficiently account for all paths between the
pair of disconnected nodes. We demonstrate in theory and experiments that MAGNA
captures large-scale structural information in every layer, and has a low-pass
effect that eliminates noisy high-frequency information from graph data.
Experimental results on node classification as well as the knowledge graph
completion benchmarks show that MAGNA achieves state-of-the-art results: MAGNA
achieves up to 5.7 percent relative error reduction over the previous
state-of-the-art on Cora, Citeseer, and Pubmed. MAGNA also obtains the best
performance on a large-scale Open Graph Benchmark dataset. On knowledge graph
completion MAGNA advances state-of-the-art on WN18RR and FB15k-237 across four
different performance metrics.","['Guangtao Wang', 'Rex Ying', 'Jing Huang', 'Jure Leskovec']","['cs.LG', 'stat.ML']",2020-09-29 22:41:19+00:00
http://arxiv.org/abs/2010.00435v1,"Community detection, pattern recognition, and hypergraph-based learning: approaches using metric geometry and persistent homology","Hypergraph data appear and are hidden in many places in the modern age. They
are data structure that can be used to model many real data examples since
their structures contain information about higher order relations among data
points. One of the main contributions of our paper is to introduce a new
topological structure to hypergraph data which bears a resemblance to a usual
metric space structure. Using this new topological space structure of
hypergraph data, we propose several approaches to study community detection
problem, detecting persistent features arising from homological structure of
hypergraph data. Also based on the topological space structure of hypergraph
data introduced in our paper, we introduce a modified nearest neighbors methods
which is a generalization of the classical nearest neighbors methods from
machine learning. Our modified nearest neighbors methods have an advantage of
being very flexible and applicable even for discrete structures as in
hypergraphs. We then apply our modified nearest neighbors methods to study sign
prediction problem in hypegraph data constructed using our method.","['Dong Quan Ngoc Nguyen', 'Lin Xing', 'Lizhen Lin']","['cs.SI', 'cs.LG', 'stat.AP', 'stat.ML']",2020-09-29 21:20:12+00:00
http://arxiv.org/abs/2009.14311v1,Weight Prediction for Variants of Weighted Directed Networks,"A weighted directed network (WDN) is a directed graph in which each edge is
associated to a unique value called weight. These networks are very suitable
for modeling real-world social networks in which there is an assessment of one
vertex toward other vertices. One of the main problems studied in this paper is
prediction of edge weights in such networks. We introduce, for the first time,
a metric geometry approach to studying edge weight prediction in WDNs. We
modify a usual notion of WDNs, and introduce a new type of WDNs which we coin
the term \textit{almost-weighted directed networks} (AWDNs). AWDNs can capture
the weight information of a network from a given training set. We then
construct a class of metrics (or distances) for AWDNs which equips such
networks with a metric space structure. Using the metric geometry structure of
AWDNs, we propose modified $k$ nearest neighbors (kNN) methods and modified
support-vector machine (SVM) methods which will then be used to predict edge
weights in AWDNs. In many real-world datasets, in addition to edge weights, one
can also associate weights to vertices which capture information of vertices;
association of weights to vertices especially plays an important role in graph
embedding problems. Adopting a similar approach, we introduce two new types of
directed networks in which weights are associated to either a subset of origin
vertices or a subset of terminal vertices . We, for the first time, construct
novel classes of metrics on such networks, and based on these new metrics
propose modified $k$NN and SVM methods for predicting weights of origins and
terminals in these networks. We provide experimental results on several
real-world datasets, using our geometric methodologies.","['Dong Quan Ngoc Nguyen', 'Lin Xing', 'Lizhen Lin']","['cs.SI', 'cs.LG', 'stat.ML']",2020-09-29 21:18:24+00:00
http://arxiv.org/abs/2009.14310v2,Statistical control for spatio-temporal MEG/EEG source imaging with desparsified multi-task Lasso,"Detecting where and when brain regions activate in a cognitive task or in a
given clinical condition is the promise of non-invasive techniques like
magnetoencephalography (MEG) or electroencephalography (EEG). This problem,
referred to as source localization, or source imaging, poses however a
high-dimensional statistical inference challenge. While sparsity promoting
regularizations have been proposed to address the regression problem, it
remains unclear how to ensure statistical control of false detections.
Moreover, M/EEG source imaging requires to work with spatio-temporal data and
autocorrelated noise. To deal with this, we adapt the desparsified Lasso
estimator -- an estimator tailored for high dimensional linear model that
asymptotically follows a Gaussian distribution under sparsity and moderate
feature correlation assumptions -- to temporal data corrupted with
autocorrelated noise. We call it the desparsified multi-task Lasso (d-MTLasso).
We combine d-MTLasso with spatially constrained clustering to reduce data
dimension and with ensembling to mitigate the arbitrary choice of clustering;
the resulting estimator is called ensemble of clustered desparsified multi-task
Lasso (ecd-MTLasso). With respect to the current procedures, the two advantages
of ecd-MTLasso are that i)it offers statistical guarantees and ii)it allows to
trade spatial specificity for sensitivity, leading to a powerful adaptive
method. Extensive simulations on realistic head geometries, as well as
empirical results on various MEG datasets, demonstrate the high recovery
performance of ecd-MTLasso and its primary practical benefit: offer a
statistically principled way to threshold MEG/EEG source maps.","['Jérôme-Alexis Chevalier', 'Alexandre Gramfort', 'Joseph Salmon', 'Bertrand Thirion']","['stat.ML', 'cs.LG', 'stat.AP']",2020-09-29 21:17:16+00:00
