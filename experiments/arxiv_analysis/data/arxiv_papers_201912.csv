id,title,abstract,authors,categories,date
http://arxiv.org/abs/2001.01328v6,Scalable Gradients for Stochastic Differential Equations,"The adjoint sensitivity method scalably computes gradients of solutions to
ordinary differential equations. We generalize this method to stochastic
differential equations, allowing time-efficient and constant-memory computation
of gradients with high-order adaptive solvers. Specifically, we derive a
stochastic differential equation whose solution is the gradient, a
memory-efficient algorithm for caching noise, and conditions under which
numerical solutions converge. In addition, we combine our method with
gradient-based stochastic variational inference for latent stochastic
differential equations. We use our method to fit stochastic dynamics defined by
neural networks, achieving competitive performance on a 50-dimensional motion
capture dataset.","['Xuechen Li', 'Ting-Kam Leonard Wong', 'Ricky T. Q. Chen', 'David Duvenaud']","['cs.LG', 'cs.NA', 'math.NA', 'stat.ML']",2020-01-05 23:05:55+00:00
http://arxiv.org/abs/2001.01249v1,Design of Capacity-Approaching Low-Density Parity-Check Codes using Recurrent Neural Networks,"In this paper, we model Density Evolution (DE) using Recurrent Neural
Networks (RNNs) with the aim of designing capacity-approaching Irregular
Low-Density Parity-Check (LDPC) codes for binary erasure channels. In
particular, we present a method for determining the coefficients of the degree
distributions, characterizing the structure of an LDPC code. We refer to our
RNN architecture as Neural Density Evolution (NDE) and determine the weights of
the RNN that correspond to optimal designs by minimizing a loss function that
enforces the properties of asymptotically optimal design, as well as the
desired structural characteristics of the code. This renders the LDPC design
process highly configurable, as constraints can be added to meet applications'
requirements by means of modifying the loss function. In order to train the
RNN, we generate data corresponding to the expected channel noise. We analyze
the complexity and optimality of NDE theoretically, and compare it with
traditional design methods that employ differential evolution. Simulations
illustrate that NDE improves upon differential evolution both in terms of
asymptotic performance and complexity. Although we focus on asymptotic
settings, we evaluate designs found by NDE for finite codeword lengths and
observe that performance remains satisfactory across a variety of channels.","['Eleni Nisioti', 'Nikolaos Thomos']","['cs.LG', 'stat.ML']",2020-01-05 14:46:47+00:00
http://arxiv.org/abs/2001.01227v1,From Learning to Meta-Learning: Reduced Training Overhead and Complexity for Communication Systems,"Machine learning methods adapt the parameters of a model, constrained to lie
in a given model class, by using a fixed learning procedure based on data or
active observations. Adaptation is done on a per-task basis, and retraining is
needed when the system configuration changes. The resulting inefficiency in
terms of data and training time requirements can be mitigated, if domain
knowledge is available, by selecting a suitable model class and learning
procedure, collectively known as inductive bias. However, it is generally
difficult to encode prior knowledge into an inductive bias, particularly with
black-box model classes such as neural networks. Meta-learning provides a way
to automatize the selection of an inductive bias. Meta-learning leverages data
or active observations from tasks that are expected to be related to future,
and a priori unknown, tasks of interest. With a meta-trained inductive bias,
training of a machine learning model can be potentially carried out with
reduced training data and/or time complexity. This paper provides a high-level
introduction to meta-learning with applications to communication systems.","['Osvaldo Simeone', 'Sangwoo Park', 'Joonhyuk Kang']","['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",2020-01-05 12:54:41+00:00
http://arxiv.org/abs/2001.01216v1,Flexible Log File Parsing using Hidden Markov Models,"We aim to model unknown file processing. As the content of log files often
evolves over time, we established a dynamic statistical model which learns and
adapts processing and parsing rules. First, we limit the amount of unstructured
text by focusing only on those frequent patterns which lead to the desired
output table similar to Vaarandi [10]. Second, we transform the found frequent
patterns and the output stating the parsed table into a Hidden Markov Model
(HMM). We use this HMM as a specific, however, flexible representation of a
pattern for log file processing. With changes in the raw log file distorting
learned patterns, we aim the model to adapt automatically in order to maintain
high quality output. After training our model on one system type, applying the
model and the resulting parsing rule to a different system with slightly
different log file patterns, we achieve an accuracy over 99%.","['Nadine Kuhnert', 'Andreas Maier']","['cs.LG', 'stat.ML']",2020-01-05 11:44:09+00:00
http://arxiv.org/abs/2001.01215v2,A System for Real-Time Interactive Analysis of Deep Learning Training,"Performing diagnosis or exploratory analysis during the training of deep
learning models is challenging but often necessary for making a sequence of
decisions guided by the incremental observations. Currently available systems
for this purpose are limited to monitoring only the logged data that must be
specified before the training process starts. Each time a new information is
desired, a cycle of stop-change-restart is required in the training process.
These limitations make interactive exploration and diagnosis tasks difficult,
imposing long tedious iterations during the model development. We present a new
system that enables users to perform interactive queries on live processes
generating real-time information that can be rendered in multiple formats on
multiple surfaces in the form of several desired visualizations simultaneously.
To achieve this, we model various exploratory inspection and diagnostic tasks
for deep learning training processes as specifications for streams using a
map-reduce paradigm with which many data scientists are already familiar. Our
design achieves generality and extensibility by defining composable primitives
which is a fundamentally different approach than is used by currently available
systems. The open source implementation of our system is available as
TensorWatch project at https://github.com/microsoft/tensorwatch.","['Shital Shah', 'Roland Fernandez', 'Steven Drucker']","['cs.LG', 'cs.HC', 'stat.ML']",2020-01-05 11:33:31+00:00
http://arxiv.org/abs/2001.02127v1,Prediction of MRI Hardware Failures based on Image Features using Time Series Classification,"Already before systems malfunction one has to know if hardware components
will fail in near future in order to counteract in time. Thus, unplanned
downtime is ought to be avoided. In medical imaging, maximizing the system's
uptime is crucial for patients' health and healthcare provider's daily
business. We aim to predict failures of Head/Neck coils used in Magnetic
Resonance Imaging (MRI) by training a statistical model on sequential data
collected over time. As image features depend on the coil's condition, their
deviations from the normal range already hint to future failure. Thus, we used
image features and their variation over time to predict coil damage. After
comparison of different time series classification methods we found Long Short
Term Memorys (LSTMs) to achieve the highest F-score of 86.43% and to tell with
98.33% accuracy if hardware should be replaced.","['Nadine Kuhnert', 'Lea Pflüger', 'Andreas Maier']","['cs.LG', 'eess.IV', 'stat.ML']",2020-01-05 11:25:53+00:00
http://arxiv.org/abs/2001.01213v1,Prediction of MRI Hardware Failures based on Image Features using Ensemble Learning,"In order to ensure trouble-free operation, prediction of hardware failures is
essential. This applies especially to medical systems. Our goal is to determine
hardware which needs to be exchanged before failing. In this work, we focus on
predicting failures of 20-channel Head/Neck coils using image-related
measurements. Thus, we aim to solve a classification problem with two classes,
normal and broken coil. To solve this problem, we use data of two different
levels. One level refers to one-dimensional features per individual coil
channel on which we found a fully connected neural network to perform best. The
other data level uses matrices which represent the overall coil condition and
feeds a different neural network. We stack the predictions of those two
networks and train a Random Forest classifier as the ensemble learner. Thus,
combining insights of both trained models improves the prediction results and
allows us to determine the coil's condition with an F-score of 94.14% and an
accuracy of 99.09%.","['Nadine Kuhnert', 'Lea Pflüger', 'Andreas Maier']","['eess.IV', 'cs.LG', 'stat.ML']",2020-01-05 11:21:28+00:00
http://arxiv.org/abs/2001.01199v2,A Hoeffding Inequality for Finite State Markov Chains and its Applications to Markovian Bandits,"This paper develops a Hoeffding inequality for the partial sums $\sum_{k=1}^n
f (X_k)$, where $\{X_k\}_{k \in \mathbb{Z}_{> 0}}$ is an irreducible Markov
chain on a finite state space $S$, and $f : S \to [a, b]$ is a real-valued
function. Our bound is simple, general, since it only assumes irreducibility
and finiteness of the state space, and powerful. In order to demonstrate its
usefulness we provide two applications in multi-armed bandit problems. The
first is about identifying an approximately best Markovian arm, while the
second is concerned with regret minimization in the context of Markovian
bandits.",['Vrettos Moulos'],"['math.ST', 'cs.LG', 'stat.ML', 'stat.TH']",2020-01-05 09:28:10+00:00
http://arxiv.org/abs/2001.01194v3,Cutoff for exact recovery of Gaussian mixture models,"We determine the information-theoretic cutoff value on separation of cluster
centers for exact recovery of cluster labels in a $K$-component Gaussian
mixture model with equal cluster sizes. Moreover, we show that a semidefinite
programming (SDP) relaxation of the $K$-means clustering method achieves such
sharp threshold for exact recovery without assuming the symmetry of cluster
centers.","['Xiaohui Chen', 'Yun Yang']","['math.ST', 'cs.DS', 'cs.IT', 'math.IT', 'math.PR', 'stat.ML', 'stat.TH']",2020-01-05 08:57:04+00:00
http://arxiv.org/abs/2001.01185v1,CNNTOP: a CNN-based Trajectory Owner Prediction Method,"Trajectory owner prediction is the basis for many applications such as
personalized recommendation, urban planning. Although much effort has been put
on this topic, the results archived are still not good enough. Existing methods
mainly employ RNNs to model trajectories semantically due to the inherent
sequential attribute of trajectories. However, these approaches are weak at
Point of Interest (POI) representation learning and trajectory feature
detection. Thus, the performance of existing solutions is far from the
requirements of practical applications. In this paper, we propose a novel
CNN-based Trajectory Owner Prediction (CNNTOP) method. Firstly, we connect all
POI according to trajectories from all users. The result is a connected graph
that can be used to generate more informative POI sequences than other
approaches. Secondly, we employ the Node2Vec algorithm to encode each POI into
a low-dimensional real value vector. Then, we transform each trajectory into a
fixed-dimensional matrix, which is similar to an image. Finally, a CNN is
designed to detect features and predict the owner of a given trajectory. The
CNN can extract informative features from the matrix representations of
trajectories by convolutional operations, Batch normalization, and $K$-max
pooling operations. Extensive experiments on real datasets demonstrate that
CNNTOP substantially outperforms existing solutions in terms of
macro-Precision, macro-Recall, macro-F1, and accuracy.","['Xucheng Luo', 'Shengyang Li', 'Yuxiang Peng']","['cs.LG', 'stat.ML']",2020-01-05 07:58:28+00:00
http://arxiv.org/abs/2001.01177v1,User Profiling Using Hinge-loss Markov Random Fields,"A variety of approaches have been proposed to automatically infer the
profiles of users from their digital footprint in social media. Most of the
proposed approaches focus on mining a single type of information, while
ignoring other sources of available user-generated content (UGC). In this
paper, we propose a mechanism to infer a variety of user characteristics, such
as, age, gender and personality traits, which can then be compiled into a user
profile. To this end, we model social media users by incorporating and
reasoning over multiple sources of UGC as well as social relations. Our model
is based on a statistical relational learning framework using Hinge-loss Markov
Random Fields (HL-MRFs), a class of probabilistic graphical models that can be
defined using a set of first-order logical rules. We validate our approach on
data from Facebook with more than 5k users and almost 725k relations. We show
how HL-MRFs can be used to develop a generic and extensible user profiling
framework by leveraging textual, visual, and relational content in the form of
status updates, profile pictures and Facebook page likes. Our experimental
results demonstrate that our proposed model successfully incorporates multiple
sources of information and outperforms competing methods that use only one
source of information or an ensemble method across the different sources for
modeling of users in social media.","['Golnoosh Farnadi', 'Lise Getoor', 'Marie-Francine Moens', 'Martine De Cock']","['cs.SI', 'cs.LG', 'stat.ML']",2020-01-05 06:55:51+00:00
http://arxiv.org/abs/2001.04025v1,Universal Successor Features for Transfer Reinforcement Learning,"Transfer in Reinforcement Learning (RL) refers to the idea of applying
knowledge gained from previous tasks to solving related tasks. Learning a
universal value function (Schaul et al., 2015), which generalizes over goals
and states, has previously been shown to be useful for transfer. However,
successor features are believed to be more suitable than values for transfer
(Dayan, 1993; Barreto et al.,2017), even though they cannot directly generalize
to new goals. In this paper, we propose (1) Universal Successor Features (USFs)
to capture the underlying dynamics of the environment while allowing
generalization to unseen goals and (2) a flexible end-to-end model of USFs that
can be trained by interacting with the environment. We show that learning USFs
is compatible with any RL algorithm that learns state values using a temporal
difference method. Our experiments in a simple gridworld and with two MuJoCo
environments show that USFs can greatly accelerate training when learning
multiple tasks and can effectively transfer knowledge to new tasks.","['Chen Ma', 'Dylan R. Ashley', 'Junfeng Wen', 'Yoshua Bengio']","['cs.LG', 'cs.AI', 'stat.ML']",2020-01-05 03:41:06+00:00
http://arxiv.org/abs/2001.01128v1,Locality-Sensitive Hashing for Efficient Web Application Security Testing,"Web application security has become a major concern in recent years, as more
and more content and services are available online. A useful method for
identifying security vulnerabilities is black-box testing, which relies on an
automated crawling of web applications. However, crawling Rich Internet
Applications (RIAs) is a very challenging task. One of the key obstacles
crawlers face is the state similarity problem: how to determine if two
client-side states are equivalent. As current methods do not completely solve
this problem, a successful scan of many real-world RIAs is still not possible.
We present a novel approach to detect redundant content for security testing
purposes. The algorithm applies locality-sensitive hashing using MinHash
sketches in order to analyze the Document Object Model (DOM) structure of web
pages, and to efficiently estimate similarity between them. Our experimental
results show that this approach allows a successful scan of RIAs that cannot be
crawled otherwise.","['Ilan Ben-Bassat', 'Erez Rokah']","['cs.CR', 'cs.LG', 'stat.ML']",2020-01-04 21:05:15+00:00
http://arxiv.org/abs/2001.01127v1,Forecasting Bitcoin closing price series using linear regression and neural networks models,"This paper studies how to forecast daily closing price series of Bitcoin,
using data on prices and volumes of prior days. Bitcoin price behaviour is
still largely unexplored, presenting new opportunities. We compared our results
with two modern works on Bitcoin prices forecasting and with a well-known
recent paper that uses Intel, National Bank shares and Microsoft daily NASDAQ
closing prices spanning a 3-year interval. We followed different approaches in
parallel, implementing both statistical techniques and machine learning
algorithms. The SLR model for univariate series forecast uses only closing
prices, whereas the MLR model for multivariate series uses both price and
volume data. We applied the ADF -Test to these series, which resulted to be
indistinguishable from a random walk. We also used two artificial neural
networks: MLP and LSTM. We then partitioned the dataset into shorter sequences,
representing different price regimes, obtaining best result using more than one
previous price, thus confirming our regime hypothesis. All the models were
evaluated in terms of MAPE and relativeRMSE. They performed well, and were
overall better than those obtained in the benchmarks. Based on the results, it
was possible to demonstrate the efficacy of the proposed methodology and its
contribution to the state-of-the-art.","['Nicola Uras', 'Lodovica Marchesi', 'Michele Marchesi', 'Roberto Tonelli']","['q-fin.ST', 'cs.LG', 'stat.ML']",2020-01-04 21:04:05+00:00
http://arxiv.org/abs/2001.01102v2,MushroomRL: Simplifying Reinforcement Learning Research,"MushroomRL is an open-source Python library developed to simplify the process
of implementing and running Reinforcement Learning (RL) experiments. Compared
to other available libraries, MushroomRL has been created with the purpose of
providing a comprehensive and flexible framework to minimize the effort in
implementing and testing novel RL methodologies. Indeed, the architecture of
MushroomRL is built in such a way that every component of an RL problem is
already provided, and most of the time users can only focus on the
implementation of their own algorithms and experiments. The result is a library
from which RL researchers can significantly benefit in the critical phase of
the empirical analysis of their works. MushroomRL stable code, tutorials and
documentation can be found at https://github.com/MushroomRL/mushroom-rl.","[""Carlo D'Eramo"", 'Davide Tateo', 'Andrea Bonarini', 'Marcello Restelli', 'Jan Peters']","['cs.LG', 'stat.ML']",2020-01-04 17:23:34+00:00
http://arxiv.org/abs/2001.01095v2,High-Dimensional Independence Testing via Maximum and Average Distance Correlations,"This paper introduces and investigates the utilization of maximum and average
distance correlations for multivariate independence testing. We characterize
their consistency properties in high-dimensional settings with respect to the
number of marginally dependent dimensions, assess the advantages of each test
statistic, examine their respective null distributions, and present a fast
chi-square-based testing procedure. The resulting tests are non-parametric and
applicable to both Euclidean distance and the Gaussian kernel as the underlying
metric. To better understand the practical use cases of the proposed tests, we
evaluate the empirical performance of the maximum distance correlation, average
distance correlation, and the original distance correlation across various
multivariate dependence scenarios, as well as conduct a real data experiment to
test the presence of various cancer types and peptide levels in human plasma.","['Cencheng Shen', 'Yuexiao Dong']","['stat.ML', 'cs.LG', 'stat.ME']",2020-01-04 16:21:50+00:00
http://arxiv.org/abs/2001.02121v1,CatBoostLSS -- An extension of CatBoost to probabilistic forecasting,"We propose a new framework of CatBoost that predicts the entire conditional
distribution of a univariate response variable. In particular, CatBoostLSS
models all moments of a parametric distribution (i.e., mean, location, scale
and shape [LSS]) instead of the conditional mean only. Choosing from a wide
range of continuous, discrete and mixed discrete-continuous distributions,
modelling and predicting the entire conditional distribution greatly enhances
the flexibility of CatBoost, as it allows to gain insight into the data
generating process, as well as to create probabilistic forecasts from which
prediction intervals and quantiles of interest can be derived. We present both
a simulation study and real-world examples that demonstrate the benefits of our
approach.",['Alexander März'],"['stat.ML', 'cs.LG', 'stat.ME']",2020-01-04 15:42:44+00:00
http://arxiv.org/abs/2001.01072v3,Empirical Studies on the Properties of Linear Regions in Deep Neural Networks,"A deep neural network (DNN) with piecewise linear activations can partition
the input space into numerous small linear regions, where different linear
functions are fitted. It is believed that the number of these regions
represents the expressivity of the DNN. This paper provides a novel and
meticulous perspective to look into DNNs: Instead of just counting the number
of the linear regions, we study their local properties, such as the inspheres,
the directions of the corresponding hyperplanes, the decision boundaries, and
the relevance of the surrounding regions. We empirically observed that
different optimization techniques lead to completely different linear regions,
even though they result in similar classification accuracies. We hope our study
can inspire the design of novel optimization techniques, and help discover and
analyze the behaviors of DNNs.","['Xiao Zhang', 'Dongrui Wu']","['cs.LG', 'stat.ML']",2020-01-04 12:47:58+00:00
http://arxiv.org/abs/2001.01056v1,Root Cause Detection Among Anomalous Time Series Using Temporal State Alignment,"The recent increase in the scale and complexity of software systems has
introduced new challenges to the time series monitoring and anomaly detection
process. A major drawback of existing anomaly detection methods is that they
lack contextual information to help stakeholders identify the cause of
anomalies. This problem, known as root cause detection, is particularly
challenging to undertake in today's complex distributed software systems since
the metrics under consideration generally have multiple internal and external
dependencies. Significant manual analysis and strong domain expertise is
required to isolate the correct cause of the problem. In this paper, we propose
a method that isolates the root cause of an anomaly by analyzing the patterns
in time series fluctuations. Our method considers the time series as
observations from an underlying process passing through a sequence of
discretized hidden states. The idea is to track the propagation of the effect
when a given problem causes unaligned but homogeneous shifts of the underlying
states. We evaluate our approach by finding the root cause of anomalies in
Zillows clickstream data by identifying causal patterns among a set of observed
fluctuations.","['Sayan Chakraborty', 'Smit Shah', 'Kiumars Soltani', 'Anna Swigart']","['cs.LG', 'stat.AP', 'stat.ML']",2020-01-04 08:31:34+00:00
http://arxiv.org/abs/2001.01051v1,Temporal Tensor Transformation Network for Multivariate Time Series Prediction,"Multivariate time series prediction has applications in a wide variety of
domains and is considered to be a very challenging task, especially when the
variables have correlations and exhibit complex temporal patterns, such as
seasonality and trend. Many existing methods suffer from strong statistical
assumptions, numerical issues with high dimensionality, manual feature
engineering efforts, and scalability. In this work, we present a novel deep
learning architecture, known as Temporal Tensor Transformation Network, which
transforms the original multivariate time series into a higher order of tensor
through the proposed Temporal-Slicing Stack Transformation. This yields a new
representation of the original multivariate time series, which enables the
convolution kernel to extract complex and non-linear features as well as
variable interactional signals from a relatively large temporal region.
Experimental results show that Temporal Tensor Transformation Network
outperforms several state-of-the-art methods on window-based predictions across
various tasks. The proposed architecture also demonstrates robust prediction
performance through an extensive sensitivity analysis.","['Yuya Jeremy Ong', 'Mu Qiao', 'Divyesh Jadav']","['cs.LG', 'stat.ML']",2020-01-04 07:28:55+00:00
http://arxiv.org/abs/2001.01034v4,FrequentNet: A Novel Interpretable Deep Learning Model for Image Classification,"This paper has proposed a new baseline deep learning model of more benefits
for image classification. Different from the convolutional neural network(CNN)
practice where filters are trained by back propagation to represent different
patterns of an image, we are inspired by a method called ""PCANet"" in ""PCANet: A
Simple Deep Learning Baseline for Image Classification?"" to choose filter
vectors from basis vectors in frequency domain like Fourier coefficients or
wavelets without back propagation. Researchers have demonstrated that those
basis in frequency domain can usually provide physical insights, which adds to
the interpretability of the model by analyzing the frequencies selected.
Besides, the training process will also be more time efficient, mathematically
clear and interpretable compared with the ""black-box"" training process of CNN.","['Yifei Li', 'Kuangyan Song', 'Yiming Sun', 'Liao Zhu']","['cs.CV', 'stat.ML']",2020-01-04 04:31:32+00:00
http://arxiv.org/abs/2001.01017v1,Distributed Stochastic Algorithms for High-rate Streaming Principal Component Analysis,"This paper considers the problem of estimating the principal eigenvector of a
covariance matrix from independent and identically distributed data samples in
streaming settings. The streaming rate of data in many contemporary
applications can be high enough that a single processor cannot finish an
iteration of existing methods for eigenvector estimation before a new sample
arrives. This paper formulates and analyzes a distributed variant of the
classical Krasulina's method (D-Krasulina) that can keep up with the high
streaming rate of data by distributing the computational load across multiple
processing nodes. The analysis shows that---under appropriate
conditions---D-Krasulina converges to the principal eigenvector in an
order-wise optimal manner; i.e., after receiving $M$ samples across all nodes,
its estimation error can be $O(1/M)$. In order to reduce the network
communication overhead, the paper also develops and analyzes a mini-batch
extension of D-Krasulina, which is termed DM-Krasulina. The analysis of
DM-Krasulina shows that it can also achieve order-optimal estimation error
rates under appropriate conditions, even when some samples have to be discarded
within the network due to communication latency. Finally, experiments are
performed over synthetic and real-world data to validate the convergence
behaviors of D-Krasulina and DM-Krasulina in high-rate streaming settings.","['Haroon Raja', 'Waheed U. Bajwa']","['cs.LG', 'cs.CV', 'eess.SP', 'math.OC', 'stat.ML']",2020-01-04 00:46:47+00:00
http://arxiv.org/abs/2001.01006v1,Review of Single-cell RNA-seq Data Clustering for Cell Type Identification and Characterization,"In recent years, the advances in single-cell RNA-seq techniques have enabled
us to perform large-scale transcriptomic profiling at single-cell resolution in
a high-throughput manner. Unsupervised learning such as data clustering has
become the central component to identify and characterize novel cell types and
gene expression patterns. In this study, we review the existing single-cell
RNA-seq data clustering methods with critical insights into the related
advantages and limitations. In addition, we also review the upstream
single-cell RNA-seq data processing techniques such as quality control,
normalization, and dimension reduction. We conduct performance comparison
experiments to evaluate several popular single-cell RNA-seq clustering
approaches on two single-cell transcriptomic datasets.","['Shixiong Zhang', 'Xiangtao Li', 'Qiuzhen Lin', 'Ka-Chun Wong']","['q-bio.GN', 'cs.LG', 'q-bio.QM', 'stat.ML']",2020-01-03 22:48:10+00:00
http://arxiv.org/abs/2001.00994v1,Semi-supervised Classification using Attention-based Regularization on Coarse-resolution Data,"Many real-world phenomena are observed at multiple resolutions. Predictive
models designed to predict these phenomena typically consider different
resolutions separately. This approach might be limiting in applications where
predictions are desired at fine resolutions but available training data is
scarce. In this paper, we propose classification algorithms that leverage
supervision from coarser resolutions to help train models on finer resolutions.
The different resolutions are modeled as different views of the data in a
multi-view framework that exploits the complementarity of features across
different views to improve models on both views. Unlike traditional multi-view
learning problems, the key challenge in our case is that there is no one-to-one
correspondence between instances across different views in our case, which
requires explicit modeling of the correspondence of instances across
resolutions. We propose to use the features of instances at different
resolutions to learn the correspondence between instances across resolutions
using an attention mechanism.Experiments on the real-world application of
mapping urban areas using satellite observations and sentiment classification
on text data show the effectiveness of the proposed methods.","['Guruprasad Nayak', 'Rahul Ghosh', 'Xiaowei Jia', 'Varun Mithal', 'Vipin Kumar']","['cs.LG', 'cs.CV', 'cs.IR', 'stat.ML']",2020-01-03 21:29:26+00:00
http://arxiv.org/abs/2001.05839v1,Discoverability in Satellite Imagery: A Good Sentence is Worth a Thousand Pictures,"Small satellite constellations provide daily global coverage of the earth's
landmass, but image enrichment relies on automating key tasks like change
detection or feature searches. For example, to extract text annotations from
raw pixels requires two dependent machine learning models, one to analyze the
overhead image and the other to generate a descriptive caption. We evaluate
seven models on the previously largest benchmark for satellite image captions.
We extend the labeled image samples five-fold, then augment, correct and prune
the vocabulary to approach a rough min-max (minimum word, maximum description).
This outcome compares favorably to previous work with large pre-trained image
models but offers a hundred-fold reduction in model size without sacrificing
overall accuracy (when measured with log entropy loss). These smaller models
provide new deployment opportunities, particularly when pushed to edge
processors, on-board satellites, or distributed ground stations. To quantify a
caption's descriptiveness, we introduce a novel multi-class confusion or error
matrix to score both human-labeled test data and never-labeled images that
include bounding box detection but lack full sentence captions. This work
suggests future captioning strategies, particularly ones that can enrich the
class coverage beyond land use applications and that lessen color-centered and
adjacency adjectives (""green"", ""near"", ""between"", etc.). Many modern language
transformers present novel and exploitable models with world knowledge gleaned
from training from their vast online corpus. One interesting, but easy example
might learn the word association between wind and waves, thus enriching a beach
scene with more than just color descriptions that otherwise might be accessed
from raw pixels without text annotation.","['David Noever', 'Wes Regian', 'Matt Ciolino', 'Josh Kalin', 'Dom Hambrick', 'Kaye Blankenship']","['cs.CV', 'cs.CL', 'cs.LG', 'stat.ML']",2020-01-03 20:41:18+00:00
http://arxiv.org/abs/2001.00926v1,Learning Accurate Integer Transformer Machine-Translation Models,"We describe a method for training accurate Transformer machine-translation
models to run inference using 8-bit integer (INT8) hardware matrix multipliers,
as opposed to the more costly single-precision floating-point (FP32) hardware.
Unlike previous work, which converted only 85 Transformer matrix
multiplications to INT8, leaving 48 out of 133 of them in FP32 because of
unacceptable accuracy loss, we convert them all to INT8 without compromising
accuracy. Tested on the newstest2014 English-to-German translation task, our
INT8 Transformer Base and Transformer Big models yield BLEU scores that are
99.3% to 100% relative to those of the corresponding FP32 models. Our approach
converts all matrix-multiplication tensors from an existing FP32 model into
INT8 tensors by automatically making range-precision trade-offs during
training. To demonstrate the robustness of this approach, we also include
results from INT6 Transformer models.",['Ephrem Wu'],"['cs.LG', 'cs.CL', 'stat.ML']",2020-01-03 18:40:35+00:00
http://arxiv.org/abs/2001.04251v1,Quantum Interference for Counting Clusters,"Counting the number of clusters, when these clusters overlap significantly is
a challenging problem in machine learning. We argue that a purely mathematical
quantum theory, formulated using the path integral technique, when applied to
non-physics modeling leads to non-physics quantum theories that are statistical
in nature. We show that a quantum theory can be a more robust statistical
theory to separate data to count overlapping clusters. The theory is also
confirmed from data simulations.This works identify how quantum theory can be
effective in counting clusters and hope to inspire the field to further apply
such techniques.","['Rohit R Muthyala', 'Davi Geiger', 'Zvi M. Kedem']","['cs.LG', 'quant-ph', 'stat.ML']",2020-01-03 18:13:57+00:00
http://arxiv.org/abs/2001.00921v3,Wide Neural Networks with Bottlenecks are Deep Gaussian Processes,"There has recently been much work on the ""wide limit"" of neural networks,
where Bayesian neural networks (BNNs) are shown to converge to a Gaussian
process (GP) as all hidden layers are sent to infinite width. However, these
results do not apply to architectures that require one or more of the hidden
layers to remain narrow. In this paper, we consider the wide limit of BNNs
where some hidden layers, called ""bottlenecks"", are held at finite width. The
result is a composition of GPs that we term a ""bottleneck neural network
Gaussian process"" (bottleneck NNGP). Although intuitive, the subtlety of the
proof is in showing that the wide limit of a composition of networks is in fact
the composition of the limiting GPs. We also analyze theoretically a
single-bottleneck NNGP, finding that the bottleneck induces dependence between
the outputs of a multi-output network that persists through extreme
post-bottleneck depths, and prevents the kernel of the network from losing
discriminative power at extreme post-bottleneck depths.","['Devanshu Agrawal', 'Theodore Papamarkou', 'Jacob Hinkle']","['stat.ML', 'cs.LG']",2020-01-03 18:13:45+00:00
http://arxiv.org/abs/2001.00893v1,Aleatoric and Epistemic Uncertainty with Random Forests,"Due to the steadily increasing relevance of machine learning for practical
applications, many of which are coming with safety requirements, the notion of
uncertainty has received increasing attention in machine learning research in
the last couple of years. In particular, the idea of distinguishing between two
important types of uncertainty, often refereed to as aleatoric and epistemic,
has recently been studied in the setting of supervised learning. In this paper,
we propose to quantify these uncertainties with random forests. More
specifically, we show how two general approaches for measuring the learner's
aleatoric and epistemic uncertainty in a prediction can be instantiated with
decision trees and random forests as learning algorithms in a classification
setting. In this regard, we also compare random forests with deep neural
networks, which have been used for a similar purpose.","['Mohammad Hossein Shaker', 'Eyke Hüllermeier']","['cs.LG', 'stat.ML']",2020-01-03 17:08:44+00:00
http://arxiv.org/abs/2001.00939v4,Relative Flatness and Generalization,"Flatness of the loss curve is conjectured to be connected to the
generalization ability of machine learning models, in particular neural
networks. While it has been empirically observed that flatness measures
consistently correlate strongly with generalization, it is still an open
theoretical problem why and under which circumstances flatness is connected to
generalization, in particular in light of reparameterizations that change
certain flatness measures but leave generalization unchanged. We investigate
the connection between flatness and generalization by relating it to the
interpolation from representative data, deriving notions of representativeness,
and feature robustness. The notions allow us to rigorously connect flatness and
generalization and to identify conditions under which the connection holds.
Moreover, they give rise to a novel, but natural relative flatness measure that
correlates strongly with generalization, simplifies to ridge regression for
ordinary least squares, and solves the reparameterization issue.","['Henning Petzka', 'Michael Kamp', 'Linara Adilova', 'Cristian Sminchisescu', 'Mario Boley']","['cs.LG', 'stat.ML']",2020-01-03 11:39:03+00:00
http://arxiv.org/abs/2001.00784v1,Optimizing Wireless Systems Using Unsupervised and Reinforced-Unsupervised Deep Learning,"Resource allocation and transceivers in wireless networks are usually
designed by solving optimization problems subject to specific constraints,
which can be formulated as variable or functional optimization. If the
objective and constraint functions of a variable optimization problem can be
derived, standard numerical algorithms can be applied for finding the optimal
solution, which however incur high computational cost when the dimension of the
variable is high. To reduce the on-line computational complexity, learning the
optimal solution as a function of the environment's status by deep neural
networks (DNNs) is an effective approach. DNNs can be trained under the
supervision of optimal solutions, which however, is not applicable to the
scenarios without models or for functional optimization where the optimal
solutions are hard to obtain. If the objective and constraint functions are
unavailable, reinforcement learning can be applied to find the solution of a
functional optimization problem, which is however not tailored to optimization
problems in wireless networks. In this article, we introduce unsupervised and
reinforced-unsupervised learning frameworks for solving both variable and
functional optimization problems without the supervision of the optimal
solutions. When the mathematical model of the environment is completely known
and the distribution of environment's status is known or unknown, we can invoke
unsupervised learning algorithm. When the mathematical model of the environment
is incomplete, we introduce reinforced-unsupervised learning algorithms that
learn the model by interacting with the environment. Our simulation results
confirm the applicability of these learning frameworks by taking a user
association problem as an example.","['Dong Liu', 'Chengjian Sun', 'Chenyang Yang', 'Lajos Hanzo']","['cs.LG', 'stat.ML']",2020-01-03 11:01:52+00:00
http://arxiv.org/abs/2001.00781v1,On the comparability of Pre-trained Language Models,"Recent developments in unsupervised representation learning have successfully
established the concept of transfer learning in NLP. Mainly three forces are
driving the improvements in this area of research: More elaborated
architectures are making better use of contextual information. Instead of
simply plugging in static pre-trained representations, these are learned based
on surrounding context in end-to-end trainable models with more intelligently
designed language modelling objectives. Along with this, larger corpora are
used as resources for pre-training large language models in a self-supervised
fashion which are afterwards fine-tuned on supervised tasks. Advances in
parallel computing as well as in cloud computing, made it possible to train
these models with growing capacities in the same or even in shorter time than
previously established models. These three developments agglomerate in new
state-of-the-art (SOTA) results being revealed in a higher and higher
frequency. It is not always obvious where these improvements originate from, as
it is not possible to completely disentangle the contributions of the three
driving forces. We set ourselves to providing a clear and concise overview on
several large pre-trained language models, which achieved SOTA results in the
last two years, with respect to their use of new architectures and resources.
We want to clarify for the reader where the differences between the models are
and we furthermore attempt to gain some insight into the single contributions
of lexical/computational improvements as well as of architectural changes. We
explicitly do not intend to quantify these contributions, but rather see our
work as an overview in order to identify potential starting points for
benchmark comparisons. Furthermore, we tentatively want to point at potential
possibilities for improvement in the field of open-sourcing and reproducible
research.","['Matthias Aßenmacher', 'Christian Heumann']","['cs.CL', 'cs.LG', 'stat.ML']",2020-01-03 10:53:35+00:00
http://arxiv.org/abs/2001.06081v3,Fourier Transform Approach to Machine Learning III: Fourier Classification,"We propose a Fourier-based learning algorithm for highly nonlinear multiclass
classification. The algorithm is based on a smoothing technique to calculate
the probability distribution of all classes. To obtain the probability
distribution, the density distribution of each class is smoothed by a low-pass
filter separately. The advantage of the Fourier representation is capturing the
nonlinearities of the data distribution without defining any kernel function.
Furthermore, contrary to the support vector machines, it makes a probabilistic
explanation for the classification possible. Moreover, it can treat overlapped
classes as well. Comparing to the logistic regression, it does not require
feature engineering. In general, its computational performance is also very
well for large data sets and in contrast to other algorithms, the typical
overfitting problem does not happen at all. The capability of the algorithm is
demonstrated for multiclass classification with overlapped classes and very
high nonlinearity of the class distributions.",['Soheil Mehrabkhani'],"['cs.LG', 'stat.ML']",2020-01-03 10:29:51+00:00
http://arxiv.org/abs/2001.00766v2,Stability and Memory-loss go Hand-in-Hand: Three Results in Dynamics & Computation,"The search for universal laws that help establish a relationship between
dynamics and computation is driven by recent expansionist initiatives in
biologically inspired computing. A general setting to understand both such
dynamics and computation is a driven dynamical system that responds to a
temporal input. Surprisingly, we find memory-loss a feature of driven systems
to forget their internal states helps provide unambiguous answers to the
following fundamental stability questions that have been unanswered for
decades: what is necessary and sufficient so that slightly different inputs
still lead to mostly similar responses? How does changing the driven system's
parameters affect stability? What is the mathematical definition of the
edge-of-criticality? We anticipate our results to be timely in understanding
and designing biologically inspired computers that are entering an era of
dedicated hardware implementations for neuromorphic computing and
state-of-the-art reservoir computing applications.",['G Manjunath'],"['cs.LG', 'math.DS', 'stat.ML', '37B55, 37C60, 37B99']",2020-01-03 09:28:00+00:00
http://arxiv.org/abs/2001.00570v1,The Real-World-Weight Cross-Entropy Loss Function: Modeling the Costs of Mislabeling,"In this paper, we propose a new metric to measure goodness-of-fit for
classifiers, the Real World Cost function. This metric factors in information
about a real world problem, such as financial impact, that other measures like
accuracy or F1 do not. This metric is also more directly interpretable for
users. To optimize for this metric, we introduce the Real-World- Weight
Crossentropy loss function, in both binary and single-label classification
variants. Both variants allow direct input of real world costs as weights. For
single-label, multicategory classification, our loss function also allows
direct penalization of probabilistic false positives, weighted by label, during
the training of a machine learning model. We compare the design of our loss
function to the binary crossentropy and categorical crossentropy functions, as
well as their weighted variants, to discuss the potential for improvement in
handling a variety of known shortcomings of machine learning, ranging from
imbalanced classes to medical diagnostic error to reinforcement of social bias.
We create scenarios that emulate those issues using the MNIST data set and
demonstrate empirical results of our new loss function. Finally, we sketch a
proof of this function based on Maximum Likelihood Estimation and discuss
future directions.","['Yaoshiang Ho', 'Samuel Wookey']","['cs.LG', 'cs.AI', 'stat.ML']",2020-01-03 08:54:42+00:00
http://arxiv.org/abs/2001.00745v1,Automated Relational Meta-learning,"In order to efficiently learn with small amount of data on new tasks,
meta-learning transfers knowledge learned from previous tasks to the new ones.
However, a critical challenge in meta-learning is the task heterogeneity which
cannot be well handled by traditional globally shared meta-learning methods. In
addition, current task-specific meta-learning methods may either suffer from
hand-crafted structure design or lack the capability to capture complex
relations between tasks. In this paper, motivated by the way of knowledge
organization in knowledge bases, we propose an automated relational
meta-learning (ARML) framework that automatically extracts the cross-task
relations and constructs the meta-knowledge graph. When a new task arrives, it
can quickly find the most relevant structure and tailor the learned structure
knowledge to the meta-learner. As a result, the proposed framework not only
addresses the challenge of task heterogeneity by a learned meta-knowledge
graph, but also increases the model interpretability. We conduct extensive
experiments on 2D toy regression and few-shot image classification and the
results demonstrate the superiority of ARML over state-of-the-art baselines.","['Huaxiu Yao', 'Xian Wu', 'Zhiqiang Tao', 'Yaliang Li', 'Bolin Ding', 'Ruirui Li', 'Zhenhui Li']","['cs.LG', 'stat.ML']",2020-01-03 07:02:25+00:00
http://arxiv.org/abs/2001.00742v1,Decomposable Probability-of-Success Metrics in Algorithmic Search,"Previous studies have used a specific success metric within an algorithmic
search framework to prove machine learning impossibility results. However, this
specific success metric prevents us from applying these results on other forms
of machine learning, e.g. transfer learning. We define decomposable metrics as
a category of success metrics for search problems which can be expressed as a
linear operation on a probability distribution to solve this issue. Using an
arbitrary decomposable metric to measure the success of a search, we
demonstrate theorems which bound success in various ways, generalizing several
existing results in the literature.","['Tyler Sam', 'Jake Williams', 'Abel Tadesse', 'Huey Sun', 'George Montanez']","['stat.ML', 'cs.AI', 'cs.LG']",2020-01-03 06:26:57+00:00
http://arxiv.org/abs/2001.00706v2,"Signatory: differentiable computations of the signature and logsignature transforms, on both CPU and GPU","Signatory is a library for calculating and performing functionality related
to the signature and logsignature transforms. The focus is on machine learning,
and as such includes features such as CPU parallelism, GPU support, and
backpropagation. To our knowledge it is the first GPU-capable library for these
operations. Signatory implements new features not available in previous
libraries, such as efficient precomputation strategies. Furthermore, several
novel algorithmic improvements are introduced, producing substantial real-world
speedups even on the CPU without parallelism. The library operates as a Python
wrapper around C++, and is compatible with the PyTorch ecosystem. It may be
installed directly via \texttt{pip}. Source code, documentation, examples,
benchmarks and tests may be found at
\texttt{\url{https://github.com/patrick-kidger/signatory}}. The license is
Apache-2.0.","['Patrick Kidger', 'Terry Lyons']","['cs.LG', 'stat.ML', '60H30, 68T99, 68N30']",2020-01-03 03:15:58+00:00
http://arxiv.org/abs/2001.00705v1,Fractional Skipping: Towards Finer-Grained Dynamic CNN Inference,"While increasingly deep networks are still in general desired for achieving
state-of-the-art performance, for many specific inputs a simpler network might
already suffice. Existing works exploited this observation by learning to skip
convolutional layers in an input-dependent manner. However, we argue their
binary decision scheme, i.e., either fully executing or completely bypassing
one layer for a specific input, can be enhanced by introducing finer-grained,
""softer"" decisions. We therefore propose a Dynamic Fractional Skipping (DFS)
framework. The core idea of DFS is to hypothesize layer-wise quantization (to
different bitwidths) as intermediate ""soft"" choices to be made between fully
utilizing and skipping a layer. For each input, DFS dynamically assigns a
bitwidth to both weights and activations of each layer, where fully executing
and skipping could be viewed as two ""extremes"" (i.e., full bitwidth and zero
bitwidth). In this way, DFS can ""fractionally"" exploit a layer's expressive
power during input-adaptive inference, enabling finer-grained
accuracy-computational cost trade-offs. It presents a unified view to link
input-adaptive layer skipping and input-adaptive hybrid quantization. Extensive
experimental results demonstrate the superior tradeoff between computational
cost and model expressive power (accuracy) achieved by DFS. More visualizations
also indicate a smooth and consistent transition in the DFS behaviors,
especially the learned choices between layer skipping and different
quantizations when the total computational budgets vary, validating our
hypothesis that layer quantization could be viewed as intermediate variants of
layer skipping. Our source code and supplementary material are available at
\link{https://github.com/Torment123/DFS}.","['Jianghao Shen', 'Yonggan Fu', 'Yue Wang', 'Pengfei Xu', 'Zhangyang Wang', 'Yingyan Lin']","['cs.LG', 'stat.ML']",2020-01-03 03:12:17+00:00
http://arxiv.org/abs/2001.00689v2,A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning,"Despite the growing interest in continual learning, most of its contemporary
works have been studied in a rather restricted setting where tasks are clearly
distinguishable, and task boundaries are known during training. However, if our
goal is to develop an algorithm that learns as humans do, this setting is far
from realistic, and it is essential to develop a methodology that works in a
task-free manner. Meanwhile, among several branches of continual learning,
expansion-based methods have the advantage of eliminating catastrophic
forgetting by allocating new resources to learn new data. In this work, we
propose an expansion-based approach for task-free continual learning. Our
model, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a
set of neural network experts that are in charge of a subset of the data.
CN-DPM expands the number of experts in a principled way under the Bayesian
nonparametric framework. With extensive experiments, we show that our model
successfully performs task-free continual learning for both discriminative and
generative tasks such as image classification and image generation.","['Soochan Lee', 'Junsoo Ha', 'Dongsu Zhang', 'Gunhee Kim']","['cs.LG', 'cs.NE', 'stat.ML']",2020-01-03 02:07:31+00:00
http://arxiv.org/abs/2001.00682v1,Auditing and Debugging Deep Learning Models via Decision Boundaries: Individual-level and Group-level Analysis,"Deep learning models have been criticized for their lack of easy
interpretation, which undermines confidence in their use for important
applications. Nevertheless, they are consistently utilized in many
applications, consequential to humans' lives, mostly because of their better
performance. Therefore, there is a great need for computational methods that
can explain, audit, and debug such models. Here, we use flip points to
accomplish these goals for deep learning models with continuous output scores
(e.g., computed by softmax), used in social applications. A flip point is any
point that lies on the boundary between two output classes: e.g. for a model
with a binary yes/no output, a flip point is any input that generates equal
scores for ""yes"" and ""no"". The flip point closest to a given input is of
particular importance because it reveals the least changes in the input that
would change a model's classification, and we show that it is the solution to a
well-posed optimization problem. Flip points also enable us to systematically
study the decision boundaries of a deep learning classifier. The resulting
insight into the decision boundaries of a deep model can clearly explain the
model's output on the individual-level, via an explanation report that is
understandable by non-experts. We also develop a procedure to understand and
audit model behavior towards groups of people. Flip points can also be used to
alter the decision boundaries in order to improve undesirable behaviors. We
demonstrate our methods by investigating several models trained on standard
datasets used in social applications of machine learning. We also identify the
features that are most responsible for particular classifications and
misclassifications.","['Roozbeh Yousefzadeh', ""Dianne P. O'Leary""]","['cs.LG', 'cs.AI', 'stat.ML']",2020-01-03 01:45:36+00:00
http://arxiv.org/abs/2001.00677v1,Improve Unsupervised Domain Adaptation with Mixup Training,"Unsupervised domain adaptation studies the problem of utilizing a relevant
source domain with abundant labels to build predictive modeling for an
unannotated target domain. Recent work observe that the popular adversarial
approach of learning domain-invariant features is insufficient to achieve
desirable target domain performance and thus introduce additional training
constraints, e.g. cluster assumption. However, these approaches impose the
constraints on source and target domains individually, ignoring the important
interplay between them. In this work, we propose to enforce training
constraints across domains using mixup formulation to directly address the
generalization performance for target data. In order to tackle potentially huge
domain discrepancy, we further propose a feature-level consistency regularizer
to facilitate the inter-domain constraint. When adding intra-domain mixup and
domain adversarial learning, our general framework significantly improves
state-of-the-art performance on several important tasks from both image
classification and human activity recognition.","['Shen Yan', 'Huan Song', 'Nanxiang Li', 'Lincan Zou', 'Liu Ren']","['stat.ML', 'cs.CV', 'cs.LG']",2020-01-03 01:21:27+00:00
http://arxiv.org/abs/2001.00637v1,Bayesian task embedding for few-shot Bayesian optimization,"We describe a method for Bayesian optimization by which one may incorporate
data from multiple systems whose quantitative interrelationships are unknown a
priori. All general (nonreal-valued) features of the systems are associated
with continuous latent variables that enter as inputs into a single metamodel
that simultaneously learns the response surfaces of all of the systems.
Bayesian inference is used to determine appropriate beliefs regarding the
latent variables. We explain how the resulting probabilistic metamodel may be
used for Bayesian optimization tasks and demonstrate its implementation on a
variety of synthetic and real-world examples, comparing its performance under
zero-, one-, and few-shot settings against traditional Bayesian optimization,
which usually requires substantially more data from the system of interest.","['Steven Atkinson', 'Sayan Ghosh', 'Natarajan Chennimalai-Kumar', 'Genghis Khan', 'Liping Wang']","['cs.LG', 'stat.ML']",2020-01-02 21:46:48+00:00
http://arxiv.org/abs/2001.00636v1,Explainable outlier detection through decision tree conditioning,"This work describes an outlier detection procedure (named ""OutlierTree"")
loosely based on the GritBot software developed by RuleQuest research, which
works by evaluating and following supervised decision tree splits on variables,
in whose branches 1-d confidence intervals are constructed for the target
variable and potential outliers flagged according to these confidence
intervals. Under this logic, it's possible to produce human-readable
explanations for why a given value of a variable in an observation can be
considered as outlier, by considering the decision tree branch conditions along
with general distribution statistics among the non-outlier observations that
fell into the same branch, which can then be contrasted against the value which
lies outside the CI. The supervised splits help to ensure that the generated
conditions are not spurious, but rather related to the target variable and
having logical breakpoints.",['David Cortes'],"['stat.ML', 'cs.LG']",2020-01-02 21:45:52+00:00
http://arxiv.org/abs/2001.00631v2,On Large-Scale Dynamic Topic Modeling with Nonnegative CP Tensor Decomposition,"There is currently an unprecedented demand for large-scale temporal data
analysis due to the explosive growth of data. Dynamic topic modeling has been
widely used in social and data sciences with the goal of learning latent topics
that emerge, evolve, and fade over time. Previous work on dynamic topic
modeling primarily employ the method of nonnegative matrix factorization (NMF),
where slices of the data tensor are each factorized into the product of
lower-dimensional nonnegative matrices. With this approach, however,
information contained in the temporal dimension of the data is often neglected
or underutilized. To overcome this issue, we propose instead adopting the
method of nonnegative CANDECOMP/PARAPAC (CP) tensor decomposition (NNCPD),
where the data tensor is directly decomposed into a minimal sum of outer
products of nonnegative vectors, thereby preserving the temporal information.
The viability of NNCPD is demonstrated through application to both synthetic
and real data, where significantly improved results are obtained compared to
those of typical NMF-based methods. The advantages of NNCPD over such
approaches are studied and discussed. To the best of our knowledge, this is the
first time that NNCPD has been utilized for the purpose of dynamic topic
modeling, and our findings will be transformative for both applications and
further developments.","['Miju Ahn', 'Nicole Eikmeier', 'Jamie Haddock', 'Lara Kassab', 'Alona Kryshchenko', 'Kathryn Leonard', 'Deanna Needell', 'R. W. M. A. Madushani', 'Elena Sizikova', 'Chuntian Wang']","['cs.LG', 'stat.ML']",2020-01-02 21:28:10+00:00
http://arxiv.org/abs/2001.00629v1,A Loss-Function for Causal Machine-Learning,"Causal machine-learning is about predicting the net-effect (true-lift) of
treatments. Given the data of a treatment group and a control group, it is
similar to a standard supervised-learning problem. Unfortunately, there is no
similarly well-defined loss function due to the lack of point-wise true values
in the data. Many advances in modern machine-learning are not directly
applicable due to the absence of such loss function.
  We propose a novel method to define a loss function in this context, which is
equal to mean-square-error (MSE) in a standard regression problem. Our loss
function is universally applicable, thus providing a general standard to
evaluate the quality of any model/strategy that predicts the true-lift. We
demonstrate that despite its novel definition, one can still perform gradient
descent directly on this loss function to find the best fit. This leads to a
new way to train any parameter-based model, such as deep neural networks, to
solve causal machine-learning problems without going through the meta-learner
strategy.",['I-Sheng Yang'],"['cs.LG', 'stat.ML']",2020-01-02 21:22:18+00:00
http://arxiv.org/abs/2001.00602v2,Accelerating Smooth Games by Manipulating Spectral Shapes,"We use matrix iteration theory to characterize acceleration in smooth games.
We define the spectral shape of a family of games as the set containing all
eigenvalues of the Jacobians of standard gradient dynamics in the family.
Shapes restricted to the real line represent well-understood classes of
problems, like minimization. Shapes spanning the complex plane capture the
added numerical challenges in solving smooth games. In this framework, we
describe gradient-based methods, such as extragradient, as transformations on
the spectral shape. Using this perspective, we propose an optimal algorithm for
bilinear games. For smooth and strongly monotone operators, we identify a
continuum between convex minimization, where acceleration is possible using
Polyak's momentum, and the worst case where gradient descent is optimal.
Finally, going beyond first-order methods, we propose an accelerated version of
consensus optimization.","['Waïss Azizian', 'Damien Scieur', 'Ioannis Mitliagkas', 'Simon Lacoste-Julien', 'Gauthier Gidel']","['cs.LG', 'math.OC', 'stat.ML', 'G.1.6, I.2.6', 'G.1.6; I.2.6']",2020-01-02 19:21:48+00:00
http://arxiv.org/abs/2001.00594v1,Large-scale Gender/Age Prediction of Tumblr Users,"Tumblr, as a leading content provider and social media, attracts 371 million
monthly visits, 280 million blogs and 53.3 million daily posts. The popularity
of Tumblr provides great opportunities for advertisers to promote their
products through sponsored posts. However, it is a challenging task to target
specific demographic groups for ads, since Tumblr does not require user
information like gender and ages during their registration. Hence, to promote
ad targeting, it is essential to predict user's demography using rich content
such as posts, images and social connections. In this paper, we propose graph
based and deep learning models for age and gender predictions, which take into
account user activities and content features. For graph based models, we come
up with two approaches, network embedding and label propagation, to generate
connection features as well as directly infer user's demography. For deep
learning models, we leverage convolutional neural network (CNN) and multilayer
perceptron (MLP) to prediction users' age and gender. Experimental results on
real Tumblr daily dataset, with hundreds of millions of active users and
billions of following relations, demonstrate that our approaches significantly
outperform the baseline model, by improving the accuracy relatively by 81% for
age, and the AUC and accuracy by 5\% for gender.","['Yao Zhan', 'Changwei Hu', 'Yifan Hu', 'Tejaswi Kasturi', 'Shanmugam Ramasamy', 'Matt Gillingham', 'Keith Yamamoto']","['cs.LG', 'cs.SI', 'stat.ML']",2020-01-02 19:01:45+00:00
http://arxiv.org/abs/2001.00585v2,Self-Supervised Learning of Generative Spin-Glasses with Normalizing Flows,"Spin-glasses are universal models that can capture complex behavior of
many-body systems at the interface of statistical physics and computer science
including discrete optimization, inference in graphical models, and automated
reasoning. Computing the underlying structure and dynamics of such complex
systems is extremely difficult due to the combinatorial explosion of their
state space. Here, we develop deep generative continuous spin-glass
distributions with normalizing flows to model correlations in generic discrete
problems. We use a self-supervised learning paradigm by automatically
generating the data from the spin-glass itself. We demonstrate that key
physical and computational properties of the spin-glass phase can be
successfully learned, including multi-modal steady-state distributions and
topological structures among metastable states. Remarkably, we observe that the
learning itself corresponds to a spin-glass phase transition within the layers
of the trained normalizing flows. The inverse normalizing flows learns to
perform reversible multi-scale coarse-graining operations which are very
different from the typical irreversible renormalization group techniques.","['Gavin S. Hartnett', 'Masoud Mohseni']","['cs.LG', 'cond-mat.dis-nn', 'quant-ph', 'stat.ML']",2020-01-02 19:00:01+00:00
http://arxiv.org/abs/2001.00564v2,Robust Marine Buoy Placement for Ship Detection Using Dropout K-Means,"Marine buoys aid in the battle against Illegal, Unreported and Unregulated
(IUU) fishing by detecting fishing vessels in their vicinity. Marine buoys,
however, may be disrupted by natural causes and buoy vandalism. In this paper,
we formulate marine buoy placement as a clustering problem, and propose dropout
k-means and dropout k-median to improve placement robustness to buoy
disruption.
  We simulated the passage of ships in the Gabonese waters near West Africa
using historical Automatic Identification System (AIS) data, then compared the
ship detection probability of dropout k-means to classic k-means and dropout
k-median to classic k-median. With 5 buoys, the buoy arrangement computed by
classic k-means, dropout k-means, classic k-median and dropout k-median have
ship detection probabilities of 38%, 45%, 48% and 52%.","['Yuting Ng', 'João M. Pereira', 'Denis Garagic', 'Vahid Tarokh']","['cs.LG', 'stat.ML']",2020-01-02 18:55:56+00:00
http://arxiv.org/abs/2001.00563v3,Using Data Imputation for Signal Separation in High Contrast Imaging,"To characterize circumstellar systems in high contrast imaging, the
fundamental step is to construct a best point spread function (PSF) template
for the non-circumstellar signals (i.e., star light and speckles) and separate
it from the observation. With existing PSF construction methods, the
circumstellar signals (e.g., planets, circumstellar disks) are unavoidably
altered by over-fitting and/or self-subtraction, making forward modeling a
necessity to recover these signals. We present a forward modeling--free
solution to these problems with data imputation using sequential non-negative
matrix factorization (DI-sNMF). DI-sNMF first converts this signal separation
problem to a ""missing data"" problem in statistics by flagging the regions which
host circumstellar signals as missing data, then attributes PSF signals to
these regions. We mathematically prove it to have negligible alteration to
circumstellar signals when the imputation region is relatively small, which
thus enables precise measurement for these circumstellar objects. We apply it
to simulated point source and circumstellar disk observations to demonstrate
its proper recovery of them. We apply it to Gemini Planet Imager (GPI) K1-band
observations of the debris disk surrounding HR 4796A, finding a tentative trend
that the dust is more forward scattering as the wavelength increases. We expect
DI-sNMF to be applicable to other general scenarios where the separation of
signals is needed.","['Bin Ren', 'Laurent Pueyo', 'Christine Chen', 'Élodie Choquet', 'John H. Debes', 'Gaspard Duchêne', 'François Ménard', 'Marshall D. Perrin']","['astro-ph.IM', 'astro-ph.EP', 'astro-ph.SR', 'stat.ML']",2020-01-02 18:55:18+00:00
http://arxiv.org/abs/2001.00559v1,A Deep Structural Model for Analyzing Correlated Multivariate Time Series,"Multivariate time series are routinely encountered in real-world
applications, and in many cases, these time series are strongly correlated. In
this paper, we present a deep learning structural time series model which can
(i) handle correlated multivariate time series input, and (ii) forecast the
targeted temporal sequence by explicitly learning/extracting the trend,
seasonality, and event components. The trend is learned via a 1D and 2D
temporal CNN and LSTM hierarchical neural net. The CNN-LSTM architecture can
(i) seamlessly leverage the dependency among multiple correlated time series in
a natural way, (ii) extract the weighted differencing feature for better trend
learning, and (iii) memorize the long-term sequential pattern. The seasonality
component is approximated via a non-liner function of a set of Fourier terms,
and the event components are learned by a simple linear function of regressor
encoding the event dates. We compare our model with several state-of-the-art
methods through a comprehensive set of experiments on a variety of time series
data sets, such as forecasts of Amazon AWS Simple Storage Service (S3) and
Elastic Compute Cloud (EC2) billings, and the closing prices for corporate
stocks in the same category.","['Changwei Hu', 'Yifan Hu', 'Sungyong Seo']","['stat.ML', 'cs.LG']",2020-01-02 18:48:29+00:00
http://arxiv.org/abs/2001.00811v2,Hydrological time series forecasting using simple combinations: Big data testing and investigations on one-year ahead river flow predictability,"Delivering useful hydrological forecasts is critical for urban and
agricultural water management, hydropower generation, flood protection and
management, drought mitigation and alleviation, and river basin planning and
management, among others. In this work, we present and appraise a new simple
and flexible methodology for hydrological time series forecasting. This
methodology relies on (a) at least two individual forecasting methods and (b)
the median combiner of forecasts. The appraisal is made by using a big dataset
consisted of 90-year-long mean annual river flow time series from approximately
600 stations. Covering large parts of North America and Europe, these stations
represent various climate and catchment characteristics, and thus can
collectively support benchmarking. Five individual forecasting methods and 26
variants of the introduced methodology are applied to each time series. The
application is made in one-step ahead forecasting mode. The individual methods
are the last-observation benchmark, simple exponential smoothing, complex
exponential smoothing, automatic autoregressive fractionally integrated moving
average (ARFIMA) and Facebook's Prophet, while the 26 variants are defined by
all the possible combinations (per two, three, four or five) of the five
afore-mentioned methods. The new methodology is identified as well-performing
in the long run, especially when more than two individual forecasting methods
are combined within its framework. Moreover, the possibility of case-informed
integrations of diverse hydrological forecasting methods within systematic
frameworks is algorithmically investigated and discussed. The related
investigations encompass linear regression analyses, which aim at finding
interpretable relationships between the values of a representative forecasting
performance metric and the values of selected river flow statistics...","['Georgia Papacharalampous', 'Hristos Tyralis']","['stat.AP', 'cs.LG', 'stat.ME', 'stat.ML']",2020-01-02 18:45:43+00:00
http://arxiv.org/abs/2001.00543v2,Toward Optimal Adversarial Policies in the Multiplicative Learning System with a Malicious Expert,"We consider a learning system based on the conventional multiplicative weight
(MW) rule that combines experts' advice to predict a sequence of true outcomes.
It is assumed that one of the experts is malicious and aims to impose the
maximum loss on the system. The loss of the system is naturally defined to be
the aggregate absolute difference between the sequence of predicted outcomes
and the true outcomes. We consider this problem under both offline and online
settings. In the offline setting where the malicious expert must choose its
entire sequence of decisions a priori, we show somewhat surprisingly that a
simple greedy policy of always reporting false prediction is asymptotically
optimal with an approximation ratio of $1+O(\sqrt{\frac{\ln N}{N}})$, where $N$
is the total number of prediction stages. In particular, we describe a policy
that closely resembles the structure of the optimal offline policy. For the
online setting where the malicious expert can adaptively make its decisions, we
show that the optimal online policy can be efficiently computed by solving a
dynamic program in $O(N^3)$. Our results provide a new direction for
vulnerability assessment of commonly used learning algorithms to adversarial
attacks where the threat is an integral part of the system.","['S. Rasoul Etesami', 'Negar Kiyavash', 'Vincent Leon', 'H. Vincent Poor']","['cs.LG', 'cs.CR', 'cs.MA', 'stat.ML']",2020-01-02 18:04:46+00:00
http://arxiv.org/abs/2001.00528v2,Non-Parametric Learning of Gaifman Models,"We consider the problem of structure learning for Gaifman models and learn
relational features that can be used to derive feature representations from a
knowledge base. These relational features are first-order rules that are then
partially grounded and counted over local neighborhoods of a Gaifman model to
obtain the feature representations. We propose a method for learning these
relational features for a Gaifman model by using relational tree distances. Our
empirical evaluation on real data sets demonstrates the superiority of our
approach over classical rule-learning.","['Devendra Singh Dhami', 'Siwen Yan', 'Gautam Kunapuli', 'Sriraam Natarajan']","['cs.LG', 'stat.ML']",2020-01-02 17:20:53+00:00
http://arxiv.org/abs/2001.00503v3,Joint Goal and Strategy Inference across Heterogeneous Demonstrators via Reward Network Distillation,"Reinforcement learning (RL) has achieved tremendous success as a general
framework for learning how to make decisions. However, this success relies on
the interactive hand-tuning of a reward function by RL experts. On the other
hand, inverse reinforcement learning (IRL) seeks to learn a reward function
from readily-obtained human demonstrations. Yet, IRL suffers from two major
limitations: 1) reward ambiguity - there are an infinite number of possible
reward functions that could explain an expert's demonstration and 2)
heterogeneity - human experts adopt varying strategies and preferences, which
makes learning from multiple demonstrators difficult due to the common
assumption that demonstrators seeks to maximize the same reward. In this work,
we propose a method to jointly infer a task goal and humans' strategic
preferences via network distillation. This approach enables us to distill a
robust task reward (addressing reward ambiguity) and to model each strategy's
objective (handling heterogeneity). We demonstrate our algorithm can better
recover task reward and strategy rewards and imitate the strategies in two
simulated tasks and a real-world table tennis task.","['Letian Chen', 'Rohan Paleja', 'Muyleng Ghuy', 'Matthew Gombolay']","['cs.LG', 'cs.AI', 'cs.RO', 'stat.ML']",2020-01-02 16:04:21+00:00
http://arxiv.org/abs/2001.09748v3,A Deep Learning Approach to Diagnosing Multiple Sclerosis from Smartphone Data,"Multiple sclerosis (MS) affects the central nervous system with a wide range
of symptoms. MS can, for example, cause pain, changes in mood and fatigue, and
may impair a person's movement, speech and visual functions. Diagnosis of MS
typically involves a combination of complex clinical assessments and tests to
rule out other diseases with similar symptoms. New technologies, such as
smartphone monitoring in free-living conditions, could potentially aid in
objectively assessing the symptoms of MS by quantifying symptom presence and
intensity over long periods of time. Here, we present a deep-learning approach
to diagnosing MS from smartphone-derived digital biomarkers that uses a novel
combination of a multilayer perceptron with neural soft attention to improve
learning of patterns in long-term smartphone monitoring data. Using data from a
cohort of 774 participants, we demonstrate that our deep-learning models are
able to distinguish between people with and without MS with an area under the
receiver operating characteristic curve of 0.88 (95% CI: 0.70, 0.88). Our
experimental results indicate that digital biomarkers derived from smartphone
data could in the future be used as additional diagnostic criteria for MS.","['Patrick Schwab', 'Walter Karlen']","['cs.CY', 'cs.LG', 'stat.ML']",2020-01-02 15:29:16+00:00
http://arxiv.org/abs/2001.00483v1,Reject Illegal Inputs with Generative Classifier Derived from Any Discriminative Classifier,"Generative classifiers have been shown promising to detect illegal inputs
including adversarial examples and out-of-distribution samples. Supervised Deep
Infomax~(SDIM) is a scalable end-to-end framework to learn generative
classifiers. In this paper, we propose a modification of SDIM termed
SDIM-\emph{logit}. Instead of training generative classifier from scratch,
SDIM-\emph{logit} first takes as input the logits produced any given
discriminative classifier, and generate logit representations; then a
generative classifier is derived by imposing statistical constraints on logit
representations. SDIM-\emph{logit} could inherit the performance of the
discriminative classifier without loss. SDIM-\emph{logit} incurs a negligible
number of additional parameters, and can be efficiently trained with base
classifiers fixed. We perform \emph{classification with rejection}, where test
samples whose class conditionals are smaller than pre-chosen thresholds will be
rejected without predictions. Experiments on illegal inputs, including
adversarial examples, samples with common corruptions, and
out-of-distribution~(OOD) samples show that allowed to reject a portion of test
samples, SDIM-\emph{logit} significantly improves the performance on the left
test sets.",['Xin Wang'],"['cs.LG', 'stat.ML']",2020-01-02 15:11:58+00:00
http://arxiv.org/abs/2001.00479v2,Thresholds of descending algorithms in inference problems,"We review recent works on analyzing the dynamics of gradient-based algorithms
in a prototypical statistical inference problem. Using methods and insights
from the physics of glassy systems, these works showed how to understand
quantitatively and qualitatively the performance of gradient-based algorithms.
Here we review the key results and their interpretation in non-technical terms
accessible to a wide audience of physicists in the context of related works.","['Stefano Sarao Mannelli', 'Lenka Zdeborova']","['cs.LG', 'cond-mat.dis-nn', 'stat.ML']",2020-01-02 15:08:40+00:00
http://arxiv.org/abs/2001.00461v1,Reasoning on Knowledge Graphs with Debate Dynamics,"We propose a novel method for automatic reasoning on knowledge graphs based
on debate dynamics. The main idea is to frame the task of triple classification
as a debate game between two reinforcement learning agents which extract
arguments -- paths in the knowledge graph -- with the goal to promote the fact
being true (thesis) or the fact being false (antithesis), respectively. Based
on these arguments, a binary classifier, called the judge, decides whether the
fact is true or false. The two agents can be considered as sparse, adversarial
feature generators that present interpretable evidence for either the thesis or
the antithesis. In contrast to other black-box methods, the arguments allow
users to get an understanding of the decision of the judge. Since the focus of
this work is to create an explainable method that maintains a competitive
predictive accuracy, we benchmark our method on the triple classification and
link prediction task. Thereby, we find that our method outperforms several
baselines on the benchmark datasets FB15k-237, WN18RR, and Hetionet. We also
conduct a survey and find that the extracted arguments are informative for
users.","['Marcel Hildebrandt', 'Jorge Andres Quintero Serna', 'Yunpu Ma', 'Martin Ringsquandl', 'Mitchell Joblin', 'Volker Tresp']","['cs.LG', 'stat.ML']",2020-01-02 14:44:23+00:00
http://arxiv.org/abs/2001.00449v1,Continuous-Discrete Reinforcement Learning for Hybrid Control in Robotics,"Many real-world control problems involve both discrete decision variables -
such as the choice of control modes, gear switching or digital outputs - as
well as continuous decision variables - such as velocity setpoints, control
gains or analogue outputs. However, when defining the corresponding optimal
control or reinforcement learning problem, it is commonly approximated with
fully continuous or fully discrete action spaces. These simplifications aim at
tailoring the problem to a particular algorithm or solver which may only
support one type of action space. Alternatively, expert heuristics are used to
remove discrete actions from an otherwise continuous space. In contrast, we
propose to treat hybrid problems in their 'native' form by solving them with
hybrid reinforcement learning, which optimizes for discrete and continuous
actions simultaneously. In our experiments, we first demonstrate that the
proposed approach efficiently solves such natively hybrid reinforcement
learning problems. We then show, both in simulation and on robotic hardware,
the benefits of removing possibly imperfect expert-designed heuristics. Lastly,
hybrid reinforcement learning encourages us to rethink problem definitions. We
propose reformulating control problems, e.g. by adding meta actions, to improve
exploration or reduce mechanical wear and tear.","['Michael Neunert', 'Abbas Abdolmaleki', 'Markus Wulfmeier', 'Thomas Lampe', 'Jost Tobias Springenberg', 'Roland Hafner', 'Francesco Romano', 'Jonas Buchli', 'Nicolas Heess', 'Martin Riedmiller']","['cs.LG', 'cs.RO', 'stat.ML']",2020-01-02 14:19:33+00:00
http://arxiv.org/abs/2001.00448v1,Inter- and Intra-domain Knowledge Transfer for Related Tasks in Deep Character Recognition,"Pre-training a deep neural network on the ImageNet dataset is a common
practice for training deep learning models, and generally yields improved
performance and faster training times. The technique of pre-training on one
task and then retraining on a new one is called transfer learning. In this
paper we analyse the effectiveness of using deep transfer learning for
character recognition tasks. We perform three sets of experiments with varying
levels of similarity between source and target tasks to investigate the
behaviour of different types of knowledge transfer. We transfer both parameters
and features and analyse their behaviour. Our results demonstrate that no
significant advantage is gained by using a transfer learning approach over a
traditional machine learning approach for our character recognition tasks. This
suggests that using transfer learning does not necessarily presuppose a better
performing model in all cases.","['Nishai Kooverjee', 'Steven James', 'Terence van Zyl']","['cs.LG', 'stat.ML']",2020-01-02 14:18:25+00:00
http://arxiv.org/abs/2001.00396v4,Restricting the Flow: Information Bottlenecks for Attribution,"Attribution methods provide insights into the decision-making of machine
learning models like artificial neural networks. For a given input sample, they
assign a relevance score to each individual input variable, such as the pixels
of an image. In this work we adapt the information bottleneck concept for
attribution. By adding noise to intermediate feature maps we restrict the flow
of information and can quantify (in bits) how much information image regions
provide. We compare our method against ten baselines using three different
metrics on VGG-16 and ResNet-50, and find that our methods outperform all
baselines in five out of six settings. The method's information-theoretic
foundation provides an absolute frame of reference for attribution values
(bits) and a guarantee that regions scored close to zero are not necessary for
the network's decision. For reviews: https://openreview.net/forum?id=S1xWh1rYwB
For code: https://github.com/BioroboticsLab/IBA","['Karl Schulz', 'Leon Sixt', 'Federico Tombari', 'Tim Landgraf']","['stat.ML', 'cs.CV', 'cs.LG']",2020-01-02 11:24:35+00:00
http://arxiv.org/abs/2001.00360v1,Kernelized Support Tensor Train Machines,"Tensor, a multi-dimensional data structure, has been exploited recently in
the machine learning community. Traditional machine learning approaches are
vector- or matrix-based, and cannot handle tensorial data directly. In this
paper, we propose a tensor train (TT)-based kernel technique for the first
time, and apply it to the conventional support vector machine (SVM) for image
classification. Specifically, we propose a kernelized support tensor train
machine that accepts tensorial input and preserves the intrinsic kernel
property. The main contributions are threefold. First, we propose a TT-based
feature mapping procedure that maintains the TT structure in the feature space.
Second, we demonstrate two ways to construct the TT-based kernel function while
considering consistency with the TT inner product and preservation of
information. Third, we show that it is possible to apply different kernel
functions on different data modes. In principle, our method tensorizes the
standard SVM on its input structure and kernel mapping scheme. Extensive
experiments are performed on real-world tensor data, which demonstrates the
superiority of the proposed scheme under few-sample high-dimensional inputs.","['Cong Chen', 'Kim Batselier', 'Wenjian Yu', 'Ngai Wong']","['cs.LG', 'cs.CV', 'stat.ML']",2020-01-02 08:40:15+00:00
http://arxiv.org/abs/2001.08606v1,Deep Technology Tracing for High-tech Companies,"Technological change and innovation are vitally important, especially for
high-tech companies. However, factors influencing their future research and
development (R&D) trends are both complicated and various, leading it a quite
difficult task to make technology tracing for high-tech companies. To this end,
in this paper, we develop a novel data-driven solution, i.e., Deep Technology
Forecasting (DTF) framework, to automatically find the most possible technology
directions customized to each high-tech company. Specially, DTF consists of
three components: Potential Competitor Recognition (PCR), Collaborative
Technology Recognition (CTR), and Deep Technology Tracing (DTT) neural network.
For one thing, PCR and CTR aim to capture competitive relations among
enterprises and collaborative relations among technologies, respectively. For
another, DTT is designed for modeling dynamic interactions between companies
and technologies with the above relations involved. Finally, we evaluate our
DTF framework on real-world patent data, and the experimental results clearly
prove that DTF can precisely help to prospect future technology emphasis of
companies by exploiting hybrid factors.","['Han Wu', 'Kun Zhang', 'Guangyi Lv', 'Qi Liu', 'Runlong Yu', 'Weihao Zhao', 'Enhong Chen', 'Jianhui Ma']","['cs.LG', 'stat.ML']",2020-01-02 07:44:12+00:00
http://arxiv.org/abs/2001.00345v1,"Visual Machine Learning: Insight through Eigenvectors, Chladni patterns and community detection in 2D particulate structures","Machine learning (ML) is quickly emerging as a powerful tool with diverse
applications across an extremely broad spectrum of disciplines and commercial
endeavors. Typically, ML is used as a black box that provides little
illuminating rationalization of its output. In the current work, we aim to
better understand the generic intuition underlying unsupervised ML with a focus
on physical systems. The systems that are studied here as test cases comprise
of six different 2-dimensional (2-D) particulate systems of different
complexities. It is noted that the findings of this study are generic to any
unsupervised ML problem and are not restricted to materials systems alone.
Three rudimentary unsupervised ML techniques are employed on the adjacency
(connectivity) matrix of the six studied systems: (i) using principal
eigenvalue and eigenvectors of the adjacency matrix, (ii) spectral
decomposition, and (iii) a Potts model based community detection technique in
which a modularity function is maximized. We demonstrate that, while solving a
completely classical problem, ML technique produces features that are
distinctly connected to quantum mechanical solutions. Dissecting these features
help us to understand the deep connection between the classical non-linear
world and the quantum mechanical linear world through the kaleidoscope of ML
technique, which might have far reaching consequences both in the arena of
physical sciences and ML.","['Raj Kishore', 'S. Swayamjyoti', 'Shreeja Das', 'Ajay K. Gogineni', 'Zohar Nussinov', 'D. Solenov', 'Kisor K. Sahu']","['cs.LG', 'cond-mat.soft', 'stat.ML']",2020-01-02 07:20:28+00:00
http://arxiv.org/abs/2001.00329v2,On Consequentialism and Fairness,"Recent work on fairness in machine learning has primarily emphasized how to
define, quantify, and encourage ""fair"" outcomes. Less attention has been paid,
however, to the ethical foundations which underlie such efforts. Among the
ethical perspectives that should be taken into consideration is
consequentialism, the position that, roughly speaking, outcomes are all that
matter. Although consequentialism is not free from difficulties, and although
it does not necessarily provide a tractable way of choosing actions (because of
the combined problems of uncertainty, subjectivity, and aggregation), it
nevertheless provides a powerful foundation from which to critique the existing
literature on machine learning fairness. Moreover, it brings to the fore some
of the tradeoffs involved, including the problem of who counts, the pros and
cons of using a policy, and the relative value of the distant future. In this
paper we provide a consequentialist critique of common definitions of fairness
within machine learning, as well as a machine learning perspective on
consequentialism. We conclude with a broader discussion of the issues of
learning and randomization, which have important implications for the ethics of
automated decision making systems.","['Dallas Card', 'Noah A. Smith']","['cs.AI', 'cs.CY', 'cs.LG', 'stat.ML']",2020-01-02 05:39:48+00:00
http://arxiv.org/abs/2001.00308v2,ATHENA: A Framework based on Diverse Weak Defenses for Building Adversarial Defense,"There has been extensive research on developing defense techniques against
adversarial attacks; however, they have been mainly designed for specific model
families or application domains, therefore, they cannot be easily extended.
Based on the design philosophy of ensemble of diverse weak defenses, we propose
ATHENA---a flexible and extensible framework for building generic yet effective
defenses against adversarial attacks. We have conducted a comprehensive
empirical study to evaluate several realizations of ATHENA with four threat
models including zero-knowledge, black-box, gray-box, and white-box. We also
explain (i) why diversity matters, (ii) the generality of the defense
framework, and (iii) the overhead costs incurred by ATHENA.","['Ying Meng', 'Jianhai Su', ""Jason O'Kane"", 'Pooyan Jamshidi']","['cs.LG', 'cs.CR', 'stat.ML']",2020-01-02 03:20:57+00:00
http://arxiv.org/abs/2001.00293v1,Deep Learning for Learning Graph Representations,"Mining graph data has become a popular research topic in computer science and
has been widely studied in both academia and industry given the increasing
amount of network data in the recent years. However, the huge amount of network
data has posed great challenges for efficient analysis. This motivates the
advent of graph representation which maps the graph into a low-dimension vector
space, keeping original graph structure and supporting graph inference. The
investigation on efficient representation of a graph has profound theoretical
significance and important realistic meaning, we therefore introduce some basic
ideas in graph representation/network embedding as well as some representative
models in this chapter.","['Wenwu Zhu', 'Xin Wang', 'Peng Cui']","['cs.LG', 'cs.IR', 'cs.SI', 'stat.ML']",2020-01-02 02:13:28+00:00
http://arxiv.org/abs/2001.00288v2,Online Similarity Learning with Feedback for Invoice Line Item Matching,"The procure to pay process (P2P) in large enterprises is a back-end business
process which deals with the procurement of products and services for
enterprise operations. Procurement is done by issuing purchase orders to
impaneled vendors and invoices submitted by vendors are paid after they go
through a rigorous validation process. Agents orchestrating P2P process often
encounter the problem of matching a product or service descriptions in the
invoice to those in purchase order and verify if the ordered items are what
have been supplied or serviced. For example, the description in the invoice and
purchase order could be TRES 739mL CD KER Smooth and TRES 0.739L CD KER Smth
which look different at word level but refer to the same item. In a typical P2P
process, agents are asked to manually select the products which are similar
before invoices are posted for payment. This step in the business process is
manual, repetitive, cumbersome, and costly. Since descriptions are not
well-formed sentences, we cannot apply existing semantic and syntactic text
similarity approaches directly. In this paper, we present two approaches to
solve the above problem using various types of available agent's recorded
feedback data. If the agent's feedback is in the form of a relative ranking
between descriptions, we use similarity ranking algorithm. If the agent's
feedback is absolute such as match or no-match, we use classification
similarity algorithm. We also present the threats to the validity of our
approach and present a possible remedy making use of product taxonomy and
catalog. We showcase the comparative effectiveness and efficiency of the
proposed approaches over many benchmarks and real-world data sets.","['Chandresh Kumar Maurya', 'Neelamadhav Gantayat', 'Sampath Dechu', 'Tomas Horvath']","['cs.LG', 'stat.ML']",2020-01-02 01:28:56+00:00
http://arxiv.org/abs/2001.00576v1,DAWSON: A Domain Adaptive Few Shot Generation Framework,"Training a Generative Adversarial Networks (GAN) for a new domain from
scratch requires an enormous amount of training data and days of training time.
To this end, we propose DAWSON, a Domain Adaptive FewShot Generation
FrameworkFor GANs based on meta-learning. A major challenge of applying
meta-learning GANs is to obtain gradients for the generator from evaluating it
on development sets due to the likelihood-free nature of GANs. To address this
challenge, we propose an alternative GAN training procedure that naturally
combines the two-step training procedure of GANs and the two-step training
procedure of meta-learning algorithms. DAWSON is a plug-and-play framework that
supports a broad family of meta-learning algorithms and various GANs with
architectural-variants. Based on DAWSON, We also propose MUSIC MATINEE, which
is the first few-shot music generation model. Our experiments show that MUSIC
MATINEE could quickly adapt to new domains with only tens of songs from the
target domains. We also show that DAWSON can learn to generate new digits with
only four samples in the MNIST dataset. We release source codes implementation
of DAWSON in both PyTorch and Tensorflow, generated music samples on two genres
and the lightning video.","['Weixin Liang', 'Zixuan Liu', 'Can Liu']","['cs.LG', 'cs.SD', 'eess.AS', 'stat.ML']",2020-01-02 00:59:10+00:00
http://arxiv.org/abs/2001.00278v2,Motivic clustering schemes for directed graphs,"Motivated by the concept of network motifs we construct certain clustering
methods (functors) which are parametrized by a given collection of motifs (or
representers).","['Facundo Mémoli', 'Guilherme Vituri F. Pinto']","['cs.LG', 'stat.ML']",2020-01-01 23:30:00+00:00
http://arxiv.org/abs/2001.00271v1,Options of Interest: Temporal Abstraction with Interest Functions,"Temporal abstraction refers to the ability of an agent to use behaviours of
controllers which act for a limited, variable amount of time. The options
framework describes such behaviours as consisting of a subset of states in
which they can initiate, an internal policy and a stochastic termination
condition. However, much of the subsequent work on option discovery has ignored
the initiation set, because of difficulty in learning it from data. We provide
a generalization of initiation sets suitable for general function
approximation, by defining an interest function associated with an option. We
derive a gradient-based learning algorithm for interest functions, leading to a
new interest-option-critic architecture. We investigate how interest functions
can be leveraged to learn interpretable and reusable temporal abstractions. We
demonstrate the efficacy of the proposed approach through quantitative and
qualitative results, in both discrete and continuous environments.","['Khimya Khetarpal', 'Martin Klissarov', 'Maxime Chevalier-Boisvert', 'Pierre-Luc Bacon', 'Doina Precup']","['cs.LG', 'cs.AI', 'stat.ML']",2020-01-01 21:24:39+00:00
http://arxiv.org/abs/2001.00265v1,Fast Estimation of Information Theoretic Learning Descriptors using Explicit Inner Product Spaces,"Kernel methods form a theoretically-grounded, powerful and versatile
framework to solve nonlinear problems in signal processing and machine
learning. The standard approach relies on the \emph{kernel trick} to perform
pairwise evaluations of a kernel function, leading to scalability issues for
large datasets due to its linear and superlinear growth with respect to the
training data. Recently, we proposed \emph{no-trick} (NT) kernel adaptive
filtering (KAF) that leverages explicit feature space mappings using
data-independent basis with constant complexity. The inner product defined by
the feature mapping corresponds to a positive-definite finite-rank kernel that
induces a finite-dimensional reproducing kernel Hilbert space (RKHS).
Information theoretic learning (ITL) is a framework where information theory
descriptors based on non-parametric estimator of Renyi entropy replace
conventional second-order statistics for the design of adaptive systems. An
RKHS for ITL defined on a space of probability density functions simplifies
statistical inference for supervised or unsupervised learning. ITL criteria
take into account the higher-order statistical behavior of the systems and
signals as desired. However, this comes at a cost of increased computational
complexity. In this paper, we extend the NT kernel concept to ITL for improved
information extraction from the signal without compromising scalability.
Specifically, we focus on a family of fast, scalable, and accurate estimators
for ITL using explicit inner product space (EIPS) kernels. We demonstrate the
superior performance of EIPS-ITL estimators and combined NT-KAF using EIPS-ITL
cost functions through experiments.","['Kan Li', 'Jose C. Principe']","['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",2020-01-01 20:21:12+00:00
http://arxiv.org/abs/2001.00254v1,A Comprehensive and Modularized Statistical Framework for Gradient Norm Equality in Deep Neural Networks,"In recent years, plenty of metrics have been proposed to identify networks
that are free of gradient explosion and vanishing. However, due to the
diversity of network components and complex serial-parallel hybrid connections
in modern DNNs, the evaluation of existing metrics usually requires strong
assumptions, complex statistical analysis, or has limited application fields,
which constraints their spread in the community. In this paper, inspired by the
Gradient Norm Equality and dynamical isometry, we first propose a novel metric
called Block Dynamical Isometry, which measures the change of gradient norm in
individual block. Because our Block Dynamical Isometry is norm-based, its
evaluation needs weaker assumptions compared with the original dynamical
isometry. To mitigate the challenging derivation, we propose a highly
modularized statistical framework based on free probability. Our framework
includes several key theorems to handle complex serial-parallel hybrid
connections and a library to cover the diversity of network components.
Besides, several sufficient prerequisites are provided. Powered by our metric
and framework, we analyze extensive initialization, normalization, and network
structures. We find that Gradient Norm Equality is a universal philosophy
behind them. Then, we improve some existing methods based on our analysis,
including an activation function selection strategy for initialization
techniques, a new configuration for weight normalization, and a depth-aware way
to derive coefficients in SeLU. Moreover, we propose a novel normalization
technique named second moment normalization, which is theoretically 30% faster
than batch normalization without accuracy loss. Last but not least, our
conclusions and methods are evidenced by extensive experiments on multiple
models over CIFAR10 and ImageNet.","['Zhaodong Chen', 'Lei Deng', 'Bangyan Wang', 'Guoqi Li', 'Yuan Xie']","['cs.LG', 'stat.ML']",2020-01-01 17:56:49+00:00
http://arxiv.org/abs/2001.00248v2,Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies,"We propose and address a novel few-shot RL problem, where a task is
characterized by a subtask graph which describes a set of subtasks and their
dependencies that are unknown to the agent. The agent needs to quickly adapt to
the task over few episodes during adaptation phase to maximize the return in
the test phase. Instead of directly learning a meta-policy, we develop a
Meta-learner with Subtask Graph Inference(MSGI), which infers the latent
parameter of the task by interacting with the environment and maximizes the
return given the latent parameter. To facilitate learning, we adopt an
intrinsic reward inspired by upper confidence bound (UCB) that encourages
efficient exploration. Our experiment results on two grid-world domains and
StarCraft II environments show that the proposed method is able to accurately
infer the latent task parameter, and to adapt more efficiently than existing
meta RL and hierarchical RL methods.","['Sungryull Sohn', 'Hyunjae Woo', 'Jongwook Choi', 'Honglak Lee']","['cs.LG', 'cs.AI', 'stat.ML']",2020-01-01 17:34:00+00:00
http://arxiv.org/abs/2001.00818v1,A Framework for Democratizing AI,"Machine Learning and Artificial Intelligence are considered an integral part
of the Fourth Industrial Revolution. Their impact, and far-reaching
consequences, while acknowledged, are yet to be comprehended. These
technologies are very specialized, and few organizations and select highly
trained professionals have the wherewithal, in terms of money, manpower, and
might, to chart the future. However, concentration of power can lead to
marginalization, causing severe inequalities. Regulatory agencies and
governments across the globe are creating national policies, and laws around
these technologies to protect the rights of the digital citizens, as well as to
empower them. Even private, not-for-profit organizations are also contributing
to democratizing the technologies by making them \emph{accessible} and
\emph{affordable}. However, accessibility and affordability are all but a few
of the facets of democratizing the field. Others include, but not limited to,
\emph{portability}, \emph{explainability}, \emph{credibility}, \emph{fairness},
among others. As one can imagine, democratizing AI is a multi-faceted problem,
and it requires advancements in science, technology and policy. At
\texttt{mlsquare}, we are developing scientific tools in this space.
Specifically, we introduce an opinionated, extensible, \texttt{Python}
framework that provides a single point of interface to a variety of solutions
in each of the categories mentioned above. We present the design details, APIs
of the framework, reference implementations, road map for development, and
guidelines for contributions.","['Shakkeel Ahmed', 'Ravi S. Mula', 'Soma S. Dhavala']","['cs.LG', 'cs.AI', 'stat.ML']",2020-01-01 17:30:14+00:00
http://arxiv.org/abs/2001.00218v3,Lossless Compression of Deep Neural Networks,"Deep neural networks have been successful in many predictive modeling tasks,
such as image and language recognition, where large neural networks are often
used to obtain good accuracy. Consequently, it is challenging to deploy these
networks under limited computational resources, such as in mobile devices. In
this work, we introduce an algorithm that removes units and layers of a neural
network while not changing the output that is produced, which thus implies a
lossless compression. This algorithm, which we denote as LEO (Lossless
Expressiveness Optimization), relies on Mixed-Integer Linear Programming (MILP)
to identify Rectified Linear Units (ReLUs) with linear behavior over the input
domain. By using L1 regularization to induce such behavior, we can benefit from
training over a larger architecture than we would later use in the environment
where the trained neural network is deployed.","['Thiago Serra', 'Abhinav Kumar', 'Srikumar Ramalingam']","['cs.LG', 'cs.DS', 'math.OC', 'stat.ML']",2020-01-01 15:04:43+00:00
http://arxiv.org/abs/2001.00215v12,Histogram Layers for Texture Analysis,"An essential aspect of texture analysis is the extraction of features that
describe the distribution of values in local, spatial regions. We present a
localized histogram layer for artificial neural networks. Instead of computing
global histograms as done previously, the proposed histogram layer directly
computes the local, spatial distribution of features for texture analysis and
parameters for the layer are estimated during backpropagation. We compare our
method with state-of-the-art texture encoding methods such as the Deep Encoding
Network Pooling, Deep Texture Encoding Network, Fisher Vector convolutional
neural network, and Multi-level Texture Encoding and Representation on three
material/texture datasets: (1) the Describable Texture Dataset; (2) an
extension of the ground terrain in outdoor scenes; (3) and a subset of the
Materials in Context dataset. Results indicate that the inclusion of the
proposed histogram layer improves performance. The source code for the
histogram layer is publicly available:
https://github.com/GatorSense/Histogram_Layer.","['Joshua Peeples', 'Weihuang Xu', 'Alina Zare']","['cs.LG', 'cs.CV', 'stat.ML']",2020-01-01 14:41:54+00:00
http://arxiv.org/abs/2001.00191v1,Ensemble emotion recognizing with multiple modal physiological signals,"Physiological signals that provide the objective repression of human
affective states are attracted increasing attention in the emotion recognition
field. However, the single signal is difficult to obtain completely and
accurately description for emotion. Multiple physiological signals fusing
models, building the uniform classification model by means of consistent and
complementary information from different emotions to improve recognition
performance. Original fusing models usually choose the particular
classification method to recognition, which is ignoring different distribution
of multiple signals. Aiming above problems, in this work, we propose an emotion
classification model through multiple modal physiological signals for different
emotions. Features are extracted from EEG, EMG, EOG signals for characterizing
emotional state on valence and arousal levels. For characterization, four bands
filtering theta, beta, alpha, gamma for signal preprocessing are adopted and
three Hjorth parameters are computing as features. To improve classification
performance, an ensemble classifier is built. Experiments are conducted on the
benchmark DEAP datasets. For the two-class task, the best result on arousal is
94.42\%, the best result on valence is 94.02\%, respectively. For the
four-class task, the highest average classification accuracy is 90.74, and it
shows good stability. The influence of different peripheral physiological
signals for results is also analyzed in this paper.","['Jing Zhang', 'Yong Zhang', 'Suhua Zhan', 'Cheng Cheng']","['cs.LG', 'eess.SP', 'stat.ML']",2020-01-01 11:44:43+00:00
http://arxiv.org/abs/2001.00155v2,DeepBeat: A multi-task deep learning approach to assess signal quality and arrhythmia detection in wearable devices,"Wearable devices enable theoretically continuous, longitudinal monitoring of
physiological measurements like step count, energy expenditure, and heart rate.
Although the classification of abnormal cardiac rhythms such as atrial
fibrillation from wearable devices has great potential, commercial algorithms
remain proprietary and tend to focus on heart rate variability derived from
green spectrum LED sensors placed on the wrist where noise remains an unsolved
problem. Here, we develop a multi-task deep learning method to assess signal
quality and arrhythmia event detection in wearable photoplethysmography devices
for real-time detection of atrial fibrillation (AF). We train our algorithm on
over one million simulated unlabeled physiological signals and fine-tune on a
curated dataset of over 500K labeled signals from over 100 individuals from 3
different wearable devices. We demonstrate that in comparison with a
traditional random forest-based approach (precision:0.24, recall:0.58, f1:0.34,
auPRC:0.44) and a single task CNN (precision:0.59, recall:0.69, f1:0.64,
auPRC:0.68) our architecture using unsupervised transfer learning through
convolutional denoising autoencoders dramatically improves the performance of
AF detection in participants at rest (pr:0.94, rc:0.98, f1:0.96, auPRC:0.96).
In addition, we validate algorithm performance on a prospectively derived
replication cohort of ambulatory subjects using data derived from an
independently engineered device. We show that two-stage training can help
address the unbalanced data problem common to biomedical applications where
large well-annotated datasets are scarce. In conclusion, though a combination
of simulation and transfer learning and we develop and apply a multitask
architecture to the problem of AF detection from wearable wrist sensors
demonstrating high levels of accuracy and a solution for the vexing challenge
of mechanical noise.","['Jessica Torres Soto', 'Euan Ashley']","['eess.SP', 'cs.LG', 'stat.ML']",2020-01-01 07:41:28+00:00
http://arxiv.org/abs/2001.00153v1,Dual Adversarial Domain Adaptation,"Unsupervised domain adaptation aims at transferring knowledge from the
labeled source domain to the unlabeled target domain. Previous adversarial
domain adaptation methods mostly adopt the discriminator with binary or
$K$-dimensional output to perform marginal or conditional alignment
independently. Recent experiments have shown that when the discriminator is
provided with domain information in both domains and label information in the
source domain, it is able to preserve the complex multimodal information and
high semantic information in both domains. Following this idea, we adopt a
discriminator with $2K$-dimensional output to perform both domain-level and
class-level alignments simultaneously in a single discriminator. However, a
single discriminator can not capture all the useful information across domains
and the relationships between the examples and the decision boundary are rarely
explored before. Inspired by multi-view learning and latest advances in domain
adaptation, besides the adversarial process between the discriminator and the
feature extractor, we also design a novel mechanism to make two discriminators
pit against each other, so that they can provide diverse information for each
other and avoid generating target features outside the support of the source
domain. To the best of our knowledge, it is the first time to explore a dual
adversarial strategy in domain adaptation. Moreover, we also use the
semi-supervised learning regularization to make the representations more
discriminative. Comprehensive experiments on two real-world datasets verify
that our method outperforms several state-of-the-art domain adaptation methods.","['Yuntao Du', 'Zhiwen Tan', 'Qian Chen', 'Xiaowen Zhang', 'Yirong Yao', 'Chongjun Wang']","['cs.LG', 'stat.ML']",2020-01-01 07:10:09+00:00
http://arxiv.org/abs/2001.00127v2,Reinforcement Learning with Goal-Distance Gradient,"Reinforcement learning usually uses the feedback rewards of environmental to
train agents. But the rewards in the actual environment are sparse, and even
some environments will not rewards. Most of the current methods are difficult
to get good performance in sparse reward or non-reward environments. Although
using shaped rewards is effective when solving sparse reward tasks, it is
limited to specific problems and learning is also susceptible to local optima.
We propose a model-free method that does not rely on environmental rewards to
solve the problem of sparse rewards in the general environment. Our method use
the minimum number of transitions between states as the distance to replace the
rewards of environmental, and proposes a goal-distance gradient to achieve
policy improvement. We also introduce a bridge point planning method based on
the characteristics of our method to improve exploration efficiency, thereby
solving more complex tasks. Experiments show that our method performs better on
sparse reward and local optimal problems in complex environments than previous
work.","['Kai Jiang', 'XiaoLong Qin']","['cs.LG', 'cs.AI', 'stat.ML']",2020-01-01 02:37:34+00:00
http://arxiv.org/abs/2001.00119v2,Long-Term Visitation Value for Deep Exploration in Sparse Reward Reinforcement Learning,"Reinforcement learning with sparse rewards is still an open challenge.
Classic methods rely on getting feedback via extrinsic rewards to train the
agent, and in situations where this occurs very rarely the agent learns slowly
or cannot learn at all. Similarly, if the agent receives also rewards that
create suboptimal modes of the objective function, it will likely prematurely
stop exploring. More recent methods add auxiliary intrinsic rewards to
encourage exploration. However, auxiliary rewards lead to a non-stationary
target for the Q-function. In this paper, we present a novel approach that (1)
plans exploration actions far into the future by using a long-term visitation
count, and (2) decouples exploration and exploitation by learning a separate
function assessing the exploration value of the actions. Contrary to existing
methods which use models of reward and dynamics, our approach is off-policy and
model-free. We further propose new tabular environments for benchmarking
exploration in reinforcement learning. Empirical results on classic and novel
benchmarks show that the proposed approach outperforms existing methods in
environments with sparse rewards, especially in the presence of rewards that
create suboptimal modes of the objective function. Results also suggest that
our approach scales gracefully with the size of the environment. Source code is
available at https://github.com/sparisi/visit-value-explore","['Simone Parisi', 'Davide Tateo', 'Maximilian Hensel', ""Carlo D'Eramo"", 'Jan Peters', 'Joni Pajarinen']","['cs.LG', 'stat.ML']",2020-01-01 01:01:15+00:00
http://arxiv.org/abs/2001.04832v1,Modeling and Counteracting Exposure Bias in Recommender Systems,"What we discover and see online, and consequently our opinions and decisions,
are becoming increasingly affected by automated machine learned predictions.
Similarly, the predictive accuracy of learning machines heavily depends on the
feedback data that we provide them. This mutual influence can lead to
closed-loop interactions that may cause unknown biases which can be exacerbated
after several iterations of machine learning predictions and user feedback.
Machine-caused biases risk leading to undesirable social effects ranging from
polarization to unfairness and filter bubbles.
  In this paper, we study the bias inherent in widely used recommendation
strategies such as matrix factorization. Then we model the exposure that is
borne from the interaction between the user and the recommender system and
propose new debiasing strategies for these systems.
  Finally, we try to mitigate the recommendation system bias by engineering
solutions for several state of the art recommender system models.
  Our results show that recommender systems are biased and depend on the prior
exposure of the user. We also show that the studied bias iteratively decreases
diversity in the output recommendations. Our debiasing method demonstrates the
need for alternative recommendation strategies that take into account the
exposure process in order to reduce bias.
  Our research findings show the importance of understanding the nature of and
dealing with bias in machine learning models such as recommender systems that
interact directly with humans, and are thus causing an increasing influence on
human discovery and decision making","['Sami Khenissi', 'Olfa Nasraoui']","['cs.IR', 'cs.LG', 'stat.ML']",2020-01-01 00:12:34+00:00
http://arxiv.org/abs/2001.00111v2,Interpretable Conservation Law Estimation by Deriving the Symmetries of Dynamics from Trained Deep Neural Networks,"Understanding complex systems with their reduced model is one of the central
roles in scientific activities. Although physics has greatly been developed
with the physical insights of physicists, it is sometimes challenging to build
a reduced model of such complex systems on the basis of insights alone. We
propose a novel framework that can infer the hidden conservation laws of a
complex system from deep neural networks (DNNs) that have been trained with
physical data of the system. The purpose of the proposed framework is not to
analyze physical data with deep learning, but to extract interpretable physical
information from trained DNNs. With Noether's theorem and by an efficient
sampling method, the proposed framework infers conservation laws by extracting
symmetries of dynamics from trained DNNs. The proposed framework is developed
by deriving the relationship between a manifold structure of time-series
dataset and the necessary conditions for Noether's theorem. The feasibility of
the proposed framework has been verified in some primitive cases for which the
conservation law is well known. We also apply the proposed framework to
conservation law estimation for a more practical case that is a large-scale
collective motion system in the metastable state, and we obtain a result
consistent with that of a previous study.",['Yoh-ichi Mototake'],"['physics.data-an', 'cs.LG', 'nlin.PS', 'physics.comp-ph', 'stat.ML']",2019-12-31 23:55:44+00:00
http://arxiv.org/abs/2001.00106v2,PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction,"We propose an algorithm combining calibrated prediction and generalization
bounds from learning theory to construct confidence sets for deep neural
networks with PAC guarantees---i.e., the confidence set for a given input
contains the true label with high probability. We demonstrate how our approach
can be used to construct PAC confidence sets on ResNet for ImageNet, a visual
object tracking model, and a dynamics model for the half-cheetah reinforcement
learning problem.","['Sangdon Park', 'Osbert Bastani', 'Nikolai Matni', 'Insup Lee']","['cs.LG', 'stat.ML']",2019-12-31 23:02:01+00:00
http://arxiv.org/abs/2001.00102v3,The Gambler's Problem and Beyond,"We analyze the Gambler's problem, a simple reinforcement learning problem
where the gambler has the chance to double or lose the bets until the target is
reached. This is an early example introduced in the reinforcement learning
textbook by Sutton and Barto (2018), where they mention an interesting pattern
of the optimal value function with high-frequency components and repeating
non-smooth points. It is however without further investigation. We provide the
exact formula for the optimal value function for both the discrete and the
continuous cases. Though simple as it might seem, the value function is
pathological: fractal, self-similar, derivative taking either zero or infinity,
and not written as elementary functions. It is in fact one of the generalized
Cantor functions, where it holds a complexity that has been uncharted thus far.
Our analyses could provide insights into improving value function
approximation, gradient-based algorithms, and Q-learning, in real applications
and implementations.","['Baoxiang Wang', 'Shuai Li', 'Jiajin Li', 'Siu On Chan']","['stat.ML', 'cs.AI', 'cs.LG']",2019-12-31 22:48:15+00:00
http://arxiv.org/abs/2001.00098v2,Avoiding Spurious Local Minima in Deep Quadratic Networks,"Despite their practical success, a theoretical understanding of the loss
landscape of neural networks has proven challenging due to the
high-dimensional, non-convex, and highly nonlinear structure of such models. In
this paper, we characterize the training landscape of the mean squared error
loss for neural networks with quadratic activation functions. We prove
existence of spurious local minima and saddle points which can be escaped
easily with probability one when the number of neurons is greater than or equal
to the input dimension and the norm of the training samples is used as a
regressor. We prove that deep overparameterized neural networks with quadratic
activations benefit from similar nice landscape properties. Our theoretical
results are independent of data distribution and fill the existing gap in
theory for two-layer quadratic neural networks. Finally, we empirically
demonstrate convergence to a global minimum for these problems.","['Abbas Kazemipour', 'Brett W. Larsen', 'Shaul Druckmann']","['cs.LG', 'math.OC', 'stat.ML']",2019-12-31 22:31:11+00:00
http://arxiv.org/abs/2001.00916v1,Deep Learning-Based Intrusion Detection System for Advanced Metering Infrastructure,"Smart grid is an alternative solution of the conventional power grid which
harnesses the power of the information technology to save the energy and meet
today's environment requirements. Due to the inherent vulnerabilities in the
information technology, the smart grid is exposed to a wide variety of threats
that could be translated into cyber-attacks. In this paper, we develop a deep
learning-based intrusion detection system to defend against cyber-attacks in
the advanced metering infrastructure network. The proposed machine learning
approach is trained and tested extensively on an empirical industrial dataset
which is composed of several attack categories including the scanning, buffer
overflow, and denial of service attacks. Then, an experimental comparison in
terms of detection accuracy is conducted to evaluate the performance of the
proposed approach with Naive Bayes, Support Vector Machine, and Random Forest.
The obtained results suggest that the proposed approaches produce optimal
results comparing to the other algorithms. Finally, we propose a network
architecture to deploy the proposed anomaly-based intrusion detection system
across the Advanced Metering Infrastructure network. In addition, we propose a
network security architecture composed of two types of Intrusion detection
system types, Host and Network-based, deployed across the Advanced Metering
Infrastructure network to inspect the traffic and detect the malicious one at
all the levels.","['Zakaria El Mrabet', 'Mehdi Ezzari', 'Hassan Elghazi', 'Badr Abou El Majd']","['cs.CR', 'cs.LG', 'eess.SP', 'stat.ML']",2019-12-31 21:06:20+00:00
http://arxiv.org/abs/2001.00076v1,Scalable Hierarchical Clustering with Tree Grafting,"We introduce Grinch, a new algorithm for large-scale, non-greedy hierarchical
clustering with general linkage functions that compute arbitrary similarity
between two point sets. The key components of Grinch are its rotate and graft
subroutines that efficiently reconfigure the hierarchy as new points arrive,
supporting discovery of clusters with complex structure. Grinch is motivated by
a new notion of separability for clustering with linkage functions: we prove
that when the model is consistent with a ground-truth clustering, Grinch is
guaranteed to produce a cluster tree containing the ground-truth, independent
of data arrival order. Our empirical results on benchmark and author
coreference datasets (with standard and learned linkage functions) show that
Grinch is more accurate than other scalable methods, and orders of magnitude
faster than hierarchical agglomerative clustering.","['Nicholas Monath', 'Ari Kobren', 'Akshay Krishnamurthy', 'Michael Glass', 'Andrew McCallum']","['cs.LG', 'cs.DS', 'stat.ML']",2019-12-31 20:56:15+00:00
http://arxiv.org/abs/2001.00917v1,A Performance Comparison of Data Mining Algorithms Based Intrusion Detection System for Smart Grid,"Smart grid is an emerging and promising technology. It uses the power of
information technologies to deliver intelligently the electrical power to
customers, and it allows the integration of the green technology to meet the
environmental requirements. Unfortunately, information technologies have its
inherent vulnerabilities and weaknesses that expose the smart grid to a wide
variety of security risks. The Intrusion detection system (IDS) plays an
important role in securing smart grid networks and detecting malicious
activity, yet it suffers from several limitations. Many research papers have
been published to address these issues using several algorithms and techniques.
Therefore, a detailed comparison between these algorithms is needed. This paper
presents an overview of four data mining algorithms used by IDS in Smart Grid.
An evaluation of performance of these algorithms is conducted based on several
metrics including the probability of detection, probability of false alarm,
probability of miss detection, efficiency, and processing time. Results show
that Random Forest outperforms the other three algorithms in detecting attacks
with higher probability of detection, lower probability of false alarm, lower
probability of miss detection, and higher accuracy.","['Zakaria El Mrabet', 'Hassan El Ghazi', 'Naima Kaabouch']","['cs.CR', 'cs.LG', 'eess.SP', 'stat.ML']",2019-12-31 20:48:13+00:00
http://arxiv.org/abs/2001.00071v4,privGAN: Protecting GANs from membership inference attacks at low cost,"Generative Adversarial Networks (GANs) have made releasing of synthetic
images a viable approach to share data without releasing the original dataset.
It has been shown that such synthetic data can be used for a variety of
downstream tasks such as training classifiers that would otherwise require the
original dataset to be shared. However, recent work has shown that the GAN
models and their synthetically generated data can be used to infer the training
set membership by an adversary who has access to the entire dataset and some
auxiliary information. Current approaches to mitigate this problem (such as
DPGAN) lead to dramatically poorer generated sample quality than the original
non--private GANs. Here we develop a new GAN architecture (privGAN), where the
generator is trained not only to cheat the discriminator but also to defend
membership inference attacks. The new mechanism provides protection against
this mode of attack while leading to negligible loss in downstream
performances. In addition, our algorithm has been shown to explicitly prevent
overfitting to the training set, which explains why our protection is so
effective. The main contributions of this paper are: i) we propose a novel GAN
architecture that can generate synthetic data in a privacy preserving manner
without additional hyperparameter tuning and architecture selection, ii) we
provide a theoretical understanding of the optimal solution of the privGAN loss
function, iii) we demonstrate the effectiveness of our model against several
white and black--box attacks on several benchmark datasets, iv) we demonstrate
on three common benchmark datasets that synthetic images generated by privGAN
lead to negligible loss in downstream performance when compared against
non--private GANs.","['Sumit Mukherjee', 'Yixi Xu', 'Anusua Trivedi', 'Juan Lavista Ferres']","['cs.LG', 'cs.CR', 'cs.CV', 'stat.ML']",2019-12-31 20:47:21+00:00
http://arxiv.org/abs/2001.00056v1,Deep Attentive Ranking Networks for Learning to Order Sentences,"We present an attention-based ranking framework for learning to order
sentences given a paragraph. Our framework is built on a bidirectional sentence
encoder and a self-attention based transformer network to obtain an input order
invariant representation of paragraphs. Moreover, it allows seamless training
using a variety of ranking based loss functions, such as pointwise, pairwise,
and listwise ranking. We apply our framework on two tasks: Sentence Ordering
and Order Discrimination. Our framework outperforms various state-of-the-art
methods on these tasks on a variety of evaluation metrics. We also show that it
achieves better results when using pairwise and listwise ranking losses, rather
than the pointwise ranking loss, which suggests that incorporating relative
positions of two or more sentences in the loss function contributes to better
learning.","['Pawan Kumar', 'Dhanajit Brahma', 'Harish Karnick', 'Piyush Rai']","['cs.CL', 'cs.LG', 'stat.ML']",2019-12-31 19:54:27+00:00
http://arxiv.org/abs/1912.13515v2,Stochastic Recursive Variance Reduction for Efficient Smooth Non-Convex Compositional Optimization,"Stochastic compositional optimization arises in many important machine
learning tasks such as value function evaluation in reinforcement learning and
portfolio management. The objective function is the composition of two
expectations of stochastic functions, and is more challenging to optimize than
vanilla stochastic optimization problems. In this paper, we investigate the
stochastic compositional optimization in the general smooth non-convex setting.
We employ a recently developed idea of \textit{Stochastic Recursive Gradient
Descent} to design a novel algorithm named SARAH-Compositional, and prove a
sharp Incremental First-order Oracle (IFO) complexity upper bound for
stochastic compositional optimization: $\mathcal{O}((n+m)^{1/2}
\varepsilon^{-2})$ in the finite-sum case and $\mathcal{O}(\varepsilon^{-3})$
in the online case. Such a complexity is known to be the best one among IFO
complexity results for non-convex stochastic compositional optimization, and is
believed to be optimal. Our experiments validate the theoretical performance of
our algorithm.","['Huizhuo Yuan', 'Xiangru Lian', 'Ji Liu']","['stat.ML', 'cs.LG', 'math.OC']",2019-12-31 18:59:13+00:00
http://arxiv.org/abs/1912.13490v4,A Neurocomputational Account of Flexible Goal-directed Cognition and Consciousness: The Goal-Aligning Representation Internal Manipulation Theory (GARIM),"Goal-directed manipulation of representations is a key element of human
flexible behaviour, while consciousness is often related to several aspects of
higher-order cognition and human flexibility. Currently these two phenomena are
only partially integrated (e.g., see Neurorepresentationalism) and this (a)
limits our understanding of neuro-computational processes that lead conscious
states to produce flexible goal-directed behaviours, (b) prevents a
computational formalisation of conscious goal-directed manipulations of
representations occurring in the brain, and (c) inhibits the exploitation of
this knowledge for modelling and technological purposes. Addressing these
issues, here we extend our `three-component theory of flexible cognition' by
proposing the `Goal-Aligning Representations Internal Manipulation' (GARIM)
theory of conscious and flexible goal-directed cognition. The central idea of
the theory is that conscious states support the active manipulation of
goal-relevant internal representations (e.g., of world states, objects, and
action sequences) to make them more aligned with the pursued goals. This leads
to the generation of the knowledge which is necessary to face novel
situations/goals, thus increasing the flexibility of goal-directed behaviours.
The GARIM theory integrates key aspects of the main theories of consciousness
into the functional neuro-computational framework of goal-directed behaviour.
Moreover, it takes into account the subjective sensation of agency that
accompanies conscious goal-directed processes (`GARIM agency'). The proposal
has also implications for experimental studies on consciousness and clinical
aspects of conscious goal-directed behaviour. Finally, the GARIM theory benefit
technological fields such as autonomous robotics and machine learning (e.g.,
the manipulation process may describe the operations performed by systems based
on transformers).","['Giovanni Granato', 'Gianluca Baldassarre']","['cs.AI', 'cs.LG', 'cs.NE', 'q-bio.NC', 'stat.ML']",2019-12-31 18:45:33+00:00
http://arxiv.org/abs/1912.13480v1,On the Difference Between the Information Bottleneck and the Deep Information Bottleneck,"Combining the Information Bottleneck model with deep learning by replacing
mutual information terms with deep neural nets has proved successful in areas
ranging from generative modelling to interpreting deep neural networks. In this
paper, we revisit the Deep Variational Information Bottleneck and the
assumptions needed for its derivation. The two assumed properties of the data
$X$, $Y$ and their latent representation $T$ take the form of two Markov chains
$T-X-Y$ and $X-T-Y$. Requiring both to hold during the optimisation process can
be limiting for the set of potential joint distributions $P(X,Y,T)$. We
therefore show how to circumvent this limitation by optimising a lower bound
for $I(T;Y)$ for which only the latter Markov chain has to be satisfied. The
actual mutual information consists of the lower bound which is optimised in
DVIB and cognate models in practice and of two terms measuring how much the
former requirement $T-X-Y$ is violated. Finally, we propose to interpret the
family of information bottleneck models as directed graphical models and show
that in this framework the original and deep information bottlenecks are
special cases of a fundamental IB model.","['Aleksander Wieczorek', 'Volker Roth']","['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",2019-12-31 18:31:42+00:00
http://arxiv.org/abs/1912.13472v1,Revisiting Landscape Analysis in Deep Neural Networks: Eliminating Decreasing Paths to Infinity,"Traditional landscape analysis of deep neural networks aims to show that no
sub-optimal local minima exist in some appropriate sense. From this, one may be
tempted to conclude that descent algorithms which escape saddle points will
reach a good local minimum. However, basic optimization theory tell us that it
is also possible for a descent algorithm to diverge to infinity if there are
paths leading to infinity, along which the loss function decreases. It is not
clear whether for non-linear neural networks there exists one setting that no
bad local-min and no decreasing paths to infinity can be simultaneously
achieved. In this paper, we give the first positive answer to this question.
More specifically, for a large class of over-parameterized deep neural networks
with appropriate regularizers, the loss function has no bad local minima and no
decreasing paths to infinity. The key mathematical trick is to show that the
set of regularizers which may be undesirable can be viewed as the image of a
Lipschitz continuous mapping from a lower-dimensional Euclidean space to a
higher-dimensional Euclidean space, and thus has zero measure.","['Shiyu Liang', 'Ruoyu Sun', 'R. Srikant']","['cs.LG', 'stat.ML']",2019-12-31 18:17:34+00:00
http://arxiv.org/abs/1912.13465v1,Reward-Conditioned Policies,"Reinforcement learning offers the promise of automating the acquisition of
complex behavioral skills. However, compared to commonly used and
well-understood supervised learning methods, reinforcement learning algorithms
can be brittle, difficult to use and tune, and sensitive to seemingly innocuous
implementation decisions. In contrast, imitation learning utilizes standard and
well-understood supervised learning methods, but requires near-optimal expert
data. Can we learn effective policies via supervised learning without
demonstrations? The main idea that we explore in this work is that non-expert
trajectories collected from sub-optimal policies can be viewed as optimal
supervision, not for maximizing the reward, but for matching the reward of the
given trajectory. By then conditioning the policy on the numerical value of the
reward, we can obtain a policy that generalizes to larger returns. We show how
such an approach can be derived as a principled method for policy search,
discuss several variants, and compare the method experimentally to a variety of
current reinforcement learning methods on standard benchmarks.","['Aviral Kumar', 'Xue Bin Peng', 'Sergey Levine']","['cs.LG', 'stat.ML']",2019-12-31 18:07:43+00:00
http://arxiv.org/abs/1912.13464v1,Model Inversion Networks for Model-Based Optimization,"In this work, we aim to solve data-driven optimization problems, where the
goal is to find an input that maximizes an unknown score function given access
to a dataset of inputs with corresponding scores. When the inputs are
high-dimensional and valid inputs constitute a small subset of this space
(e.g., valid protein sequences or valid natural images), such model-based
optimization problems become exceptionally difficult, since the optimizer must
avoid out-of-distribution and invalid inputs. We propose to address such
problem with model inversion networks (MINs), which learn an inverse mapping
from scores to inputs. MINs can scale to high-dimensional input spaces and
leverage offline logged data for both contextual and non-contextual
optimization problems. MINs can also handle both purely offline data sources
and active data collection. We evaluate MINs on tasks from the Bayesian
optimization literature, high-dimensional model-based optimization problems
over images and protein designs, and contextual bandit optimization from logged
data.","['Aviral Kumar', 'Sergey Levine']","['cs.LG', 'stat.ML']",2019-12-31 18:06:49+00:00
