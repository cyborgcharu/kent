id,title,abstract,authors,categories,date
http://arxiv.org/abs/1909.03347v2,Concentration of kernel matrices with application to kernel spectral clustering,"We study the concentration of random kernel matrices around their mean. We
derive nonasymptotic exponential concentration inequalities for Lipschitz
kernels assuming that the data points are independent draws from a class of
multivariate distributions on $\mathbb R^d$, including the strongly log-concave
distributions under affine transformations. A feature of our result is that the
data points need not have identical distributions or zero mean, which is key in
certain applications such as clustering. Our bound for the Lipschitz kernels is
dimension-free and sharp up to constants. For comparison, we also derive the
companion result for the Euclidean (inner product) kernel for a class of
sub-Gaussian distributions. A notable difference between the two cases is that,
in contrast to the Euclidean kernel, in the Lipschitz case, the concentration
inequality does not depend on the mean of the underlying vectors. As an
application of these inequalities, we derive a bound on the misclassification
rate of a kernel spectral clustering (KSC) algorithm, under a perturbed
nonparametric mixture model. We show an example where this bound establishes
the high-dimensional consistency (as $d \to \infty$) of the KSC, when applied
with a Gaussian kernel, to a noisy model of nested nonlinear manifolds.","['Arash A. Amini', 'Zahra S. Razaee']","['math.ST', 'cs.LG', 'stat.ML', 'stat.TH']",2019-09-07 22:56:55+00:00
http://arxiv.org/abs/1909.03334v4,On the Need for Topology-Aware Generative Models for Manifold-Based Defenses,"Machine-learning (ML) algorithms or models, especially deep neural networks
(DNNs), have shown significant promise in several areas. However, researchers
have recently demonstrated that ML algorithms, especially DNNs, are vulnerable
to adversarial examples (slightly perturbed samples that cause
misclassification). The existence of adversarial examples has hindered the
deployment of ML algorithms in safety-critical sectors, such as security.
Several defenses for adversarial examples exist in the literature. One of the
important classes of defenses are manifold-based defenses, where a sample is
``pulled back"" into the data manifold before classifying. These defenses rely
on the assumption that data lie in a manifold of a lower dimension than the
input space. These defenses use a generative model to approximate the input
distribution. In this paper, we investigate the following question: do the
generative models used in manifold-based defenses need to be topology-aware? We
suggest the answer is yes, and we provide theoretical and empirical evidence to
support our claim.","['Uyeong Jang', 'Susmit Jha', 'Somesh Jha']","['cs.LG', 'cs.CR', 'stat.ML']",2019-09-07 20:36:17+00:00
http://arxiv.org/abs/1909.03332v1,On the clustering of correlated random variables,"In this work, the possibility of clustering correlated random variables was
examined, both because of their mutual similarity and because of their
similarity to the principal components. The k-means algorithm and spectral
algorithms were used for clustering. For spectral methods, the similarity
matrix was both the matrix of relation established on the level of correlation
and the matrix of coefficients of determination. For four different sets of
data, different ways of measuring the disimilarity of variables were analyzed,
and the impact of the diversity of initial points on the efficiency of the
k-means algorithm was analyzed.","['Zenon Gniazdowski', 'Dawid Kaliszewski']","['cs.LG', 'stat.ML']",2019-09-07 20:27:40+00:00
http://arxiv.org/abs/1909.05667v1,Explainable Deep Learning for Video Recognition Tasks: A Framework & Recommendations,"The popularity of Deep Learning for real-world applications is ever-growing.
With the introduction of high performance hardware, applications are no longer
limited to image recognition. With the introduction of more complex problems
comes more and more complex solutions, and the increasing need for explainable
AI. Deep Neural Networks for Video tasks are amongst the most complex models,
with at least twice the parameters of their Image counterparts. However,
explanations for these models are often ill-adapted to the video domain. The
current work in explainability for video models is still overshadowed by Image
techniques, while Video Deep Learning itself is quickly gaining on methods for
still images. This paper seeks to highlight the need for explainability methods
designed with video deep learning models, and by association spatio-temporal
input in mind, by first illustrating the cutting edge for video deep learning,
and then noting the scarcity of research into explanations for these methods.","['Liam Hiley', 'Alun Preece', 'Yulia Hicks']","['cs.LG', 'cs.CV', 'cs.HC', 'eess.IV', 'stat.ML']",2019-09-07 19:34:48+00:00
http://arxiv.org/abs/1909.05207v3,Introduction to Online Convex Optimization,"This manuscript portrays optimization as a process. In many practical
applications the environment is so complex that it is infeasible to lay out a
comprehensive theoretical model and use classical algorithmic theory and
mathematical optimization. It is necessary as well as beneficial to take a
robust approach, by applying an optimization method that learns as one goes
along, learning from experience as more aspects of the problem are observed.
This view of optimization as a process has become prominent in varied fields
and has led to some spectacular success in modeling and systems that are now
part of our daily lives.",['Elad Hazan'],"['cs.LG', 'math.OC', 'stat.ML']",2019-09-07 19:06:23+00:00
http://arxiv.org/abs/1909.03316v3,Multi-Target Multiple Instance Learning for Hyperspectral Target Detection,"In remote sensing, it is often challenging to acquire or collect a large
dataset that is accurately labeled. This difficulty is usually due to several
issues, including but not limited to the study site's spatial area and
accessibility, errors in the global positioning system (GPS), and mixed pixels
caused by an image's spatial resolution. We propose an approach, with two
variations, that estimates multiple target signatures from training samples
with imprecise labels: Multi-Target Multiple Instance Adaptive Cosine Estimator
(Multi-Target MI-ACE) and Multi-Target Multiple Instance Spectral Match Filter
(Multi-Target MI-SMF). The proposed methods address the problems above by
directly considering the multiple-instance, imprecisely labeled dataset. They
learn a dictionary of target signatures that optimizes detection against a
background using the Adaptive Cosine Estimator (ACE) and Spectral Match Filter
(SMF). Experiments were conducted to test the proposed algorithms using a
simulated hyperspectral dataset, the MUUFL Gulfport hyperspectral dataset
collected over the University of Southern Mississippi-Gulfpark Campus, and the
AVIRIS hyperspectral dataset collected over Santa Barbara County, California.
Both simulated and real hyperspectral target detection experiments show the
proposed algorithms are effective at learning target signatures and performing
target detection.","['Susan Meerdink', 'James Bocinsky', 'Alina Zare', 'Nicholas Kroeger', 'Connor McCurley', 'Daniel Shats', 'Paul Gader']","['eess.IV', 'cs.LG', 'stat.ML']",2019-09-07 18:30:54+00:00
http://arxiv.org/abs/1909.03306v3,A scalable constructive algorithm for the optimization of neural network architectures,"We propose a new scalable method to optimize the architecture of an
artificial neural network. The proposed algorithm, called Greedy Search for
Neural Network Architecture, aims to determine a neural network with minimal
number of layers that is at least as performant as neural networks of the same
structure identified by other hyperparameter search algorithms in terms of
accuracy and computational cost. Numerical results performed on benchmark
datasets show that, for these datasets, our method outperforms state-of-the-art
hyperparameter optimization algorithms in terms of attainable predictive
performance by the selected neural network architecture, and time-to-solution
for the hyperparameter optimization to complete.","['Massimiliano Lupo Pasini', 'Junqi Yin', 'Ying Wai Li', 'Markus Eisenbach']","['cs.LG', 'cs.NE', 'stat.ML', '68T01, 68Q32, 68T05, 68T10, 68W20']",2019-09-07 17:22:28+00:00
http://arxiv.org/abs/1909.03302v1,On the Optimality of Gaussian Kernel Based Nonparametric Tests against Smooth Alternatives,"Nonparametric tests via kernel embedding of distributions have witnessed a
great deal of practical successes in recent years. However, statistical
properties of these tests are largely unknown beyond consistency against a
fixed alternative. To fill in this void, we study here the asymptotic
properties of goodness-of-fit, homogeneity and independence tests using
Gaussian kernels, arguably the most popular and successful among such tests.
Our results provide theoretical justifications for this common practice by
showing that tests using Gaussian kernel with an appropriately chosen scaling
parameter are minimax optimal against smooth alternatives in all three
settings. In addition, our analysis also pinpoints the importance of choosing a
diverging scaling parameter when using Gaussian kernels and suggests a
data-driven choice of the scaling parameter that yields tests optimal, up to an
iterated logarithmic factor, over a wide range of smooth alternatives.
Numerical experiments are also presented to further demonstrate the practical
merits of the methodology.","['Tong Li', 'Ming Yuan']","['math.ST', 'stat.ME', 'stat.ML', 'stat.TH']",2019-09-07 16:43:20+00:00
http://arxiv.org/abs/1909.03287v1,A Non-Negative Factorization approach to node pooling in Graph Convolutional Neural Networks,"The paper discusses a pooling mechanism to induce subsampling in graph
structured data and introduces it as a component of a graph convolutional
neural network. The pooling mechanism builds on the Non-Negative Matrix
Factorization (NMF) of a matrix representing node adjacency and node similarity
as adaptively obtained through the vertices embedding learned by the model.
Such mechanism is applied to obtain an incrementally coarser graph where nodes
are adaptively pooled into communities based on the outcomes of the
non-negative factorization. The empirical analysis on graph classification
benchmarks shows how such coarsening process yields significant improvements in
the predictive performance of the model with respect to its non-pooled
counterpart.","['Davide Bacciu', 'Luigi Di Sotto']","['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']",2019-09-07 15:27:49+00:00
http://arxiv.org/abs/1909.03276v2,Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions,"Various factorization-based methods have been proposed to leverage
second-order, or higher-order cross features for boosting the performance of
predictive models. They generally enumerate all the cross features under a
predefined maximum order, and then identify useful feature interactions through
model training, which suffer from two drawbacks. First, they have to make a
trade-off between the expressiveness of higher-order cross features and the
computational cost, resulting in suboptimal predictions. Second, enumerating
all the cross features, including irrelevant ones, may introduce noisy feature
combinations that degrade model performance. In this work, we propose the
Adaptive Factorization Network (AFN), a new model that learns arbitrary-order
cross features adaptively from data. The core of AFN is a logarithmic
transformation layer to convert the power of each feature in a feature
combination into the coefficient to be learned. The experimental results on
four real datasets demonstrate the superior predictive performance of AFN
against the start-of-the-arts.","['Weiyu Cheng', 'Yanyan Shen', 'Linpeng Huang']","['cs.LG', 'cs.AI', 'cs.IR', 'stat.ML']",2019-09-07 14:30:43+00:00
http://arxiv.org/abs/1909.03267v2,A Tree-based Dictionary Learning Framework,"We propose a new outline for adaptive dictionary learning methods for sparse
encoding based on a hierarchical clustering of the training data. Through
recursive application of a clustering method, the data is organized into a
binary partition tree representing a multiscale structure. The dictionary atoms
are defined adaptively based on the data clusters in the partition tree. This
approach can be interpreted as a generalization of a discrete Haar wavelet
transform. Furthermore, any prior knowledge on the wanted structure of the
dictionary elements can be simply incorporated. The computational complexity of
our proposed algorithm depends on the employed clustering method and on the
chosen similarity measure between data points. Thanks to the multiscale
properties of the partition tree, our dictionary is structured: when using
Orthogonal Matching Pursuit to reconstruct patches from a natural image,
dictionary atoms corresponding to nodes being closer to the root node in the
tree have a tendency to be used with greater coefficients.","['Renato Budinich', 'Gerlind Plonka']","['cs.LG', 'stat.ML', '94A12, 94A08, 68U10, 65D18']",2019-09-07 13:48:23+00:00
http://arxiv.org/abs/1909.03261v1,Active learning to optimise time-expensive algorithm selection,"Hard optimisation problems such as Boolean Satisfiability typically have long
solving times and can usually be solved by many algorithms, although the
performance can vary widely in practice. Research has shown that no single
algorithm outperforms all the others; thus, it is crucial to select the best
algorithm for a given problem. Supervised machine learning models can
accurately predict which solver is best for a given problem, but they require
first to run every solver in the portfolio for all examples available to create
labelled data. As this approach cannot scale, we developed an active learning
framework that addresses this problem by constructing an optimal training set,
so that the learner can achieve higher or equal performances with less training
data. Our work proves that active learning is beneficial for algorithm
selection techniques and provides practical guidance to incorporate into
existing systems.","['Riccardo Volpato', 'Guangyan Song']","['cs.LG', 'cs.AI', 'stat.ML']",2019-09-07 12:33:31+00:00
http://arxiv.org/abs/1909.05948v1,Unsupervised Image Regression for Heterogeneous Change Detection,"Change detection in heterogeneous multitemporal satellite images is an
emerging and challenging topic in remote sensing. In particular, one of the
main challenges is to tackle the problem in an unsupervised manner. In this
paper we propose an unsupervised framework for bitemporal heterogeneous change
detection based on the comparison of affinity matrices and image regression.
First, our method quantifies the similarity of affinity matrices computed from
co-located image patches in the two images. This is done to automatically
identify pixels that are likely to be unchanged. With the identified pixels as
pseudo-training data, we learn a transformation to map the first image to the
domain of the other image, and vice versa. Four regression methods are selected
to carry out the transformation: Gaussian process regression, support vector
regression, random forest regression, and a recently proposed kernel regression
method called homogeneous pixel transformation. To evaluate the potentials and
limitations of our framework, and also the benefits and disadvantages of each
regression method, we perform experiments on two real data sets. The results
indicate that the comparison of the affinity matrices can already be considered
a change detection method by itself. However, image regression is shown to
improve the results obtained by the previous step alone and produces accurate
change detection maps despite of the heterogeneity of the multitemporal input
data. Notably, the random forest regression approach excels by achieving
similar accuracy as the other methods, but with a significantly lower
computational cost and with fast and robust tuning of hyperparameters.","['Luigi T. Luppino', 'Filippo M. Bianchi', 'Gabriele Moser', 'Stian N. Anfinsen']","['cs.CV', 'cs.LG', 'eess.IV', 'stat.ML']",2019-09-07 12:26:11+00:00
http://arxiv.org/abs/1909.03253v1,NuClick: From Clicks in the Nuclei to Nuclear Boundaries,"Best performing nuclear segmentation methods are based on deep learning
algorithms that require a large amount of annotated data. However, collecting
annotations for nuclear segmentation is a very labor-intensive and
time-consuming task. Thereby, providing a tool that can facilitate and speed up
this procedure is very demanding. Here we propose a simple yet efficient
framework based on convolutional neural networks, named NuClick, which can
precisely segment nuclei boundaries by accepting a single point position (or
click) inside each nucleus. Based on the clicked positions, inclusion and
exclusion maps are generated which comprise 2D Gaussian distributions centered
on those positions. These maps serve as guiding signals for the network as they
are concatenated to the input image. The inclusion map focuses on the desired
nucleus while the exclusion map indicates neighboring nuclei and improve the
results of segmentation in scenes with nuclei clutter. The NuClick not only
facilitates collecting more annotation from unseen data but also leads to
superior segmentation output for deep models. It is also worth mentioning that
an instance segmentation model trained on NuClick generated labels was able to
rank first in LYON19 challenge.","['Mostafa Jahanifar', 'Navid Alemi Koohbanani', 'Nasir Rajpoot']","['q-bio.QM', 'cs.LG', 'eess.IV', 'stat.ML']",2019-09-07 11:52:19+00:00
http://arxiv.org/abs/1909.03245v3,Regularized Anderson Acceleration for Off-Policy Deep Reinforcement Learning,"Model-free deep reinforcement learning (RL) algorithms have been widely used
for a range of complex control tasks. However, slow convergence and sample
inefficiency remain challenging problems in RL, especially when handling
continuous and high-dimensional state spaces. To tackle this problem, we
propose a general acceleration method for model-free, off-policy deep RL
algorithms by drawing the idea underlying regularized Anderson acceleration
(RAA), which is an effective approach to accelerating the solving of fixed
point problems with perturbations. Specifically, we first explain how policy
iteration can be applied directly with Anderson acceleration. Then we extend
RAA to the case of deep RL by introducing a regularization term to control the
impact of perturbation induced by function approximation errors. We further
propose two strategies, i.e., progressive update and adaptive restart, to
enhance the performance. The effectiveness of our method is evaluated on a
variety of benchmark tasks, including Atari 2600 and MuJoCo. Experimental
results show that our approach substantially improves both the learning speed
and final performance of state-of-the-art deep RL algorithms.","['Wenjie Shi', 'Shiji Song', 'Hui Wu', 'Ya-Chu Hsu', 'Cheng Wu', 'Gao Huang']","['cs.LG', 'cs.AI', 'stat.ML']",2019-09-07 11:18:32+00:00
http://arxiv.org/abs/1909.03242v2,MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims,"We contribute the largest publicly available dataset of naturally occurring
factual claims for the purpose of automatic claim verification. It is collected
from 26 fact checking websites in English, paired with textual sources and rich
metadata, and labelled for veracity by human expert journalists. We present an
in-depth analysis of the dataset, highlighting characteristics and challenges.
Further, we present results for automatic veracity prediction, both with
established baselines and with a novel method for joint ranking of evidence
pages and predicting veracity that outperforms all baselines. Significant
performance increases are achieved by encoding evidence, and by modelling
metadata. Our best-performing model achieves a Macro F1 of 49.2%, showing that
this is a challenging testbed for claim veracity prediction.","['Isabelle Augenstein', 'Christina Lioma', 'Dongsheng Wang', 'Lucas Chaves Lima', 'Casper Hansen', 'Christian Hansen', 'Jakob Grue Simonsen']","['cs.CL', 'cs.IR', 'cs.LG', 'stat.ML']",2019-09-07 10:57:29+00:00
http://arxiv.org/abs/1909.03228v1,HeteSpaceyWalk: A Heterogeneous Spacey Random Walk for Heterogeneous Information Network Embedding,"Heterogeneous information network (HIN) embedding has gained increasing
interests recently. However, the current way of random-walk based HIN embedding
methods have paid few attention to the higher-order Markov chain nature of
meta-path guided random walks, especially to the stationarity issue. In this
paper, we systematically formalize the meta-path guided random walk as a
higher-order Markov chain process, and present a heterogeneous personalized
spacey random walk to efficiently and effectively attain the expected
stationary distribution among nodes. Then we propose a generalized scalable
framework to leverage the heterogeneous personalized spacey random walk to
learn embeddings for multiple types of nodes in an HIN guided by a meta-path, a
meta-graph, and a meta-schema respectively. We conduct extensive experiments in
several heterogeneous networks and demonstrate that our methods substantially
outperform the existing state-of-the-art network embedding algorithms.","['Yu He', 'Yangqiu Song', 'Jianxin Li', 'Cheng Ji', 'Jian Peng', 'Hao Peng']","['cs.LG', 'cs.SI', 'stat.ML']",2019-09-07 09:46:11+00:00
http://arxiv.org/abs/1909.03212v2,AutoML for Contextual Bandits,"Contextual Bandits is one of the widely popular techniques used in
applications such as personalization, recommendation systems, mobile health,
causal marketing etc . As a dynamic approach, it can be more efficient than
standard A/B testing in minimizing regret. We propose an end to end automated
meta-learning pipeline to approximate the optimal Q function for contextual
bandits problems. We see that our model is able to perform much better than
random exploration, being more regret efficient and able to converge with a
limited number of samples, while remaining very general and easy to use due to
the meta-learning approach. We used a linearly annealed e-greedy exploration
policy to define the exploration vs exploitation schedule. We tested the system
on a synthetic environment to characterize it fully and we evaluated it on some
open source datasets to benchmark against prior work. We see that our model
outperforms or performs comparatively to other models while requiring no tuning
nor feature engineering.","['Praneet Dutta', 'Joe Cheuk', 'Jonathan S Kim', 'Massimo Mascaro']","['cs.LG', 'cs.AI', 'stat.ML']",2019-09-07 08:18:03+00:00
http://arxiv.org/abs/1909.03211v2,Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View,"Graph Neural Networks (GNNs) have achieved promising performance on a wide
range of graph-based tasks. Despite their success, one severe limitation of
GNNs is the over-smoothing issue (indistinguishable representations of nodes in
different classes). In this work, we present a systematic and quantitative
study on the over-smoothing issue of GNNs. First, we introduce two quantitative
metrics, MAD and MADGap, to measure the smoothness and over-smoothness of the
graph nodes representations, respectively. Then, we verify that smoothing is
the nature of GNNs and the critical factor leading to over-smoothness is the
low information-to-noise ratio of the message received by the nodes, which is
partially determined by the graph topology. Finally, we propose two methods to
alleviate the over-smoothing issue from the topological view: (1) MADReg which
adds a MADGap-based regularizer to the training objective;(2) AdaGraph which
optimizes the graph topology based on the model predictions. Extensive
experiments on 7 widely-used graph datasets with 10 typical GNN models show
that the two proposed methods are effective for relieving the over-smoothing
issue, thus improving the performance of various GNN models.","['Deli Chen', 'Yankai Lin', 'Wei Li', 'Peng Li', 'Jie Zhou', 'Xu Sun']","['cs.LG', 'cs.SI', 'stat.ML']",2019-09-07 08:14:41+00:00
http://arxiv.org/abs/1909.03209v2,Transferable Neural Processes for Hyperparameter Optimization,"Automated machine learning aims to automate the whole process of machine
learning, including model configuration. In this paper, we focus on automated
hyperparameter optimization (HPO) based on sequential model-based optimization
(SMBO). Though conventional SMBO algorithms work well when abundant HPO trials
are available, they are far from satisfactory in practical applications where a
trial on a huge dataset may be so costly that an optimal hyperparameter
configuration is expected to return in as few trials as possible. Observing
that human experts draw on their expertise in a machine learning model by
trying configurations that once performed well on other datasets, we are
inspired to speed up HPO by transferring knowledge from historical HPO trials
on other datasets. We propose an end-to-end and efficient HPO algorithm named
as Transfer Neural Processes (TNP), which achieves transfer learning by
incorporating trials on other datasets, initializing the model with
well-generalized parameters, and learning an initial set of hyperparameters to
evaluate. Experiments on extensive OpenML datasets and three computer vision
datasets show that the proposed model can achieve state-of-the-art performance
in at least one order of magnitude less trials.","['Ying Wei', 'Peilin Zhao', 'Huaxiu Yao', 'Junzhou Huang']","['cs.LG', 'cs.AI', 'stat.ML']",2019-09-07 08:10:08+00:00
http://arxiv.org/abs/1909.03204v1,Multi Pseudo Q-learning Based Deterministic Policy Gradient for Tracking Control of Autonomous Underwater Vehicles,"This paper investigates trajectory tracking problem for a class of
underactuated autonomous underwater vehicles (AUVs) with unknown dynamics and
constrained inputs. Different from existing policy gradient methods which
employ single actor-critic but cannot realize satisfactory tracking control
accuracy and stable learning, our proposed algorithm can achieve high-level
tracking control accuracy of AUVs and stable learning by applying a hybrid
actors-critics architecture, where multiple actors and critics are trained to
learn a deterministic policy and action-value function, respectively.
Specifically, for the critics, the expected absolute Bellman error based
updating rule is used to choose the worst critic to be updated in each time
step. Subsequently, to calculate the loss function with more accurate target
value for the chosen critic, Pseudo Q-learning, which uses sub-greedy policy to
replace the greedy policy in Q-learning, is developed for continuous action
spaces, and Multi Pseudo Q-learning (MPQ) is proposed to reduce the
overestimation of action-value function and to stabilize the learning. As for
the actors, deterministic policy gradient is applied to update the weights, and
the final learned policy is defined as the average of all actors to avoid large
but bad updates. Moreover, the stability analysis of the learning is given
qualitatively. The effectiveness and generality of the proposed MPQ-based
Deterministic Policy Gradient (MPQ-DPG) algorithm are verified by the
application on AUV with two different reference trajectories. And the results
demonstrate high-level tracking control accuracy and stable learning of
MPQ-DPG. Besides, the results also validate that increasing the number of the
actors and critics will further improve the performance.","['Wenjie Shi', 'Shiji Song', 'Cheng Wu', 'C. L. Philip Chen']","['cs.LG', 'cs.AI', 'stat.ML']",2019-09-07 07:18:41+00:00
http://arxiv.org/abs/1909.03200v1,Mature GAIL: Imitation Learning for Low-level and High-dimensional Input using Global Encoder and Cost Transformation,"Recently, GAIL framework and various variants have shown remarkable
possibilities for solving practical MDP problems. However, detailed researches
of low-level, and high-dimensional state input in this framework, such as image
sequences, has not been conducted. Furthermore, the cost function learned in
the traditional GAIL frame-work only lies on a negative range, acting as a
non-penalized reward and making the agent difficult to learn the optimal
policy. In this paper, we propose a new algorithm based on the GAIL framework
that includes a global encoder and the reward penalization mechanism. The
global encoder solves two issues that arise when applying GAIL framework to
high-dimensional image state. Also, it is shown that the penalization mechanism
provides more adequate reward to the agent, resulting in stable performance
improvement. Our approach's potential can be backed up by the fact that it is
generally applicable to variants of GAIL framework. We conducted in-depth
experiments by applying our methods to various variants of the GAIL framework.
And, the results proved that our method significantly improves the performances
when it comes to low-level and high-dimensional tasks.","['Wonsup Shin', 'Hyolim Kang', 'Sunghoon Hong']","['cs.LG', 'stat.ML']",2019-09-07 07:01:59+00:00
http://arxiv.org/abs/1909.03198v1,Soft Policy Gradient Method for Maximum Entropy Deep Reinforcement Learning,"Maximum entropy deep reinforcement learning (RL) methods have been
demonstrated on a range of challenging continuous tasks. However, existing
methods either suffer from severe instability when training on large off-policy
data or cannot scale to tasks with very high state and action dimensionality
such as 3D humanoid locomotion. Besides, the optimality of desired Boltzmann
policy set for non-optimal soft value function is not persuasive enough. In
this paper, we first derive soft policy gradient based on entropy regularized
expected reward objective for RL with continuous actions. Then, we present an
off-policy actor-critic, model-free maximum entropy deep RL algorithm called
deep soft policy gradient (DSPG) by combining soft policy gradient with soft
Bellman equation. To ensure stable learning while eliminating the need of two
separate critics for soft value functions, we leverage double sampling approach
to making the soft Bellman equation tractable. The experimental results
demonstrate that our method outperforms in performance over off-policy prior
methods.","['Wenjie Shi', 'Shiji Song', 'Cheng Wu']","['cs.LG', 'cs.AI', 'stat.ML']",2019-09-07 06:53:01+00:00
http://arxiv.org/abs/1909.03194v3,On Sample Complexity Upper and Lower Bounds for Exact Ranking from Noisy Comparisons,"This paper studies the problem of finding the exact ranking from noisy
comparisons. A comparison over a set of $m$ items produces a noisy outcome
about the most preferred item, and reveals some information about the ranking.
By repeatedly and adaptively choosing items to compare, we want to fully rank
the items with a certain confidence, and use as few comparisons as possible.
Different from most previous works, in this paper, we have three main
novelties: (i) compared to prior works, our upper bounds (algorithms) and lower
bounds on the sample complexity (aka number of comparisons) require the minimal
assumptions on the instances, and are not restricted to specific models; (ii)
we give lower bounds and upper bounds on instances with unequal noise levels;
and (iii) this paper aims at the exact ranking without knowledge on the
instances, while most of the previous works either focus on approximate
rankings or study exact ranking but require prior knowledge. We first derive
lower bounds for pairwise ranking (i.e., compare two items each time), and then
propose (nearly) optimal pairwise ranking algorithms. We further make
extensions to listwise ranking (i.e., comparing multiple items each time).
Numerical results also show our improvements against the state of the art.","['Wenbo Ren', 'Jia Liu', 'Ness B. Shroff']","['cs.LG', 'stat.ML']",2019-09-07 06:13:33+00:00
http://arxiv.org/abs/1909.03184v2,Auto-GNN: Neural Architecture Search of Graph Neural Networks,"Graph neural networks (GNN) has been successfully applied to operate on the
graph-structured data. Given a specific scenario, rich human expertise and
tremendous laborious trials are usually required to identify a suitable GNN
architecture. It is because the performance of a GNN architecture is
significantly affected by the choice of graph convolution components, such as
aggregate function and hidden dimension. Neural architecture search (NAS) has
shown its potential in discovering effective deep architectures for learning
tasks in image and language modeling. However, existing NAS algorithms cannot
be directly applied to the GNN search problem. First, the search space of GNN
is different from the ones in existing NAS work. Second, the representation
learning capacity of GNN architecture changes obviously with slight
architecture modifications. It affects the search efficiency of traditional
search methods. Third, widely used techniques in NAS such as parameter sharing
might become unstable in GNN.
  To bridge the gap, we propose the automated graph neural networks (AGNN)
framework, which aims to find an optimal GNN architecture within a predefined
search space. A reinforcement learning based controller is designed to greedily
validate architectures via small steps. AGNN has a novel parameter sharing
strategy that enables homogeneous architectures to share parameters, based on a
carefully-designed homogeneity definition. Experiments on real-world benchmark
datasets demonstrate that the GNN architecture identified by AGNN achieves the
best performance, comparing with existing handcrafted models and tradistional
search methods.","['Kaixiong Zhou', 'Qingquan Song', 'Xiao Huang', 'Xia Hu']","['cs.LG', 'stat.ML']",2019-09-07 04:10:41+00:00
http://arxiv.org/abs/1909.03172v1,Towards Understanding the Importance of Noise in Training Neural Networks,"Numerous empirical evidence has corroborated that the noise plays a crucial
rule in effective and efficient training of neural networks. The theory behind,
however, is still largely unknown. This paper studies this fundamental problem
through training a simple two-layer convolutional neural network model.
Although training such a network requires solving a nonconvex optimization
problem with a spurious local optimum and a global optimum, we prove that
perturbed gradient descent and perturbed mini-batch stochastic gradient
algorithms in conjunction with noise annealing is guaranteed to converge to a
global optimum in polynomial time with arbitrary initialization. This implies
that the noise enables the algorithm to efficiently escape from the spurious
local optimum. Numerical experiments are provided to support our theory.","['Mo Zhou', 'Tianyi Liu', 'Yan Li', 'Dachao Lin', 'Enlu Zhou', 'Tuo Zhao']","['cs.LG', 'math.OC', 'stat.ML']",2019-09-07 02:36:46+00:00
http://arxiv.org/abs/1909.03166v1,Equalizing Recourse across Groups,"The rise in machine learning-assisted decision-making has led to concerns
about the fairness of the decisions and techniques to mitigate problems of
discrimination. If a negative decision is made about an individual (denying a
loan, rejecting an application for housing, and so on) justice dictates that we
be able to ask how we might change circumstances to get a favorable decision
the next time. Moreover, the ability to change circumstances (a better
education, improved credentials) should not be limited to only those with
access to expensive resources. In other words, \emph{recourse} for negative
decisions should be considered a desirable value that can be equalized across
(demographically defined) groups. This paper describes how to build models that
make accurate predictions while still ensuring that the penalties for a
negative outcome do not disadvantage different groups disproportionately. We
measure recourse as the distance of an individual from the decision boundary of
a classifier. We then introduce a regularized objective to minimize the
difference in recourse across groups. We explore linear settings and further
extend recourse to non-linear settings as well as model-agnostic settings where
the exact distance from boundary cannot be calculated. Our results show that we
can successfully decrease the unfairness in recourse while maintaining
classifier performance.","['Vivek Gupta', 'Pegah Nokhiz', 'Chitradeep Dutta Roy', 'Suresh Venkatasubramanian']","['cs.LG', 'cs.AI', 'cs.CY', 'stat.ML']",2019-09-07 01:50:06+00:00
http://arxiv.org/abs/1909.05371v2,GMLS-Nets: A framework for learning from unstructured data,"Data fields sampled on irregularly spaced points arise in many applications
in the sciences and engineering. For regular grids, Convolutional Neural
Networks (CNNs) have been successfully used to gaining benefits from weight
sharing and invariances. We generalize CNNs by introducing methods for data on
unstructured point clouds based on Generalized Moving Least Squares (GMLS).
GMLS is a non-parametric technique for estimating linear bounded functionals
from scattered data, and has recently been used in the literature for solving
partial differential equations. By parameterizing the GMLS estimator, we obtain
learning methods for operators with unstructured stencils. In GMLS-Nets the
necessary calculations are local, readily parallelizable, and the estimator is
supported by a rigorous approximation theory. We show how the framework may be
used for unstructured physical data sets to perform functional regression to
identify associated differential operators and to regress quantities of
interest. The results suggest the architectures to be an attractive foundation
for data-driven model development in scientific machine learning applications.","['Nathaniel Trask', 'Ravi G. Patel', 'Ben J. Gross', 'Paul J. Atzberger']","['cs.LG', 'math.DS', 'physics.data-an', 'stat.ML']",2019-09-07 01:07:33+00:00
http://arxiv.org/abs/1909.05097v1,Spectral Non-Convex Optimization for Dimension Reduction with Hilbert-Schmidt Independence Criterion,"The Hilbert Schmidt Independence Criterion (HSIC) is a kernel dependence
measure that has applications in various aspects of machine learning.
Conveniently, the objectives of different dimensionality reduction applications
using HSIC often reduce to the same optimization problem. However, the
nonconvexity of the objective function arising from non-linear kernels poses a
serious challenge to optimization efficiency and limits the potential of
HSIC-based formulations. As a result, only linear kernels have been
computationally tractable in practice. This paper proposes a spectral-based
optimization algorithm that extends beyond the linear kernel. The algorithm
identifies a family of suitable kernels and provides the first and second-order
local guarantees when a fixed point is reached. Furthermore, we propose a
principled initialization strategy, thereby removing the need to repeat the
algorithm at random initialization points. Compared to state-of-the-art
optimization algorithms, our empirical results on real data show a run-time
improvement by as much as a factor of $10^5$ while consistently achieving lower
cost and classification/clustering errors. The implementation source code is
publicly available on https://github.com/endsley.","['Chieh Wu', 'Jared Miller', 'Yale Chang', 'Mario Sznaier', 'Jennifer Dy']","['stat.ML', 'cs.LG', 'stat.AP', 'stat.CO']",2019-09-06 20:41:04+00:00
http://arxiv.org/abs/1909.03118v2,Trading-Off Static and Dynamic Regret in Online Least-Squares and Beyond,"Recursive least-squares algorithms often use forgetting factors as a
heuristic to adapt to non-stationary data streams. The first contribution of
this paper rigorously characterizes the effect of forgetting factors for a
class of online Newton algorithms. For exp-concave and strongly convex
objectives, the algorithms achieve the dynamic regret of $\max\{O(\log
T),O(\sqrt{TV})\}$, where $V$ is a bound on the path length of the comparison
sequence. In particular, we show how classic recursive least-squares with a
forgetting factor achieves this dynamic regret bound. By varying $V$, we obtain
a trade-off between static and dynamic regret. In order to obtain more
computationally efficient algorithms, our second contribution is a novel
gradient descent step size rule for strongly convex functions. Our gradient
descent rule recovers the order optimal dynamic regret bounds described above.
For smooth problems, we can also obtain static regret of $O(T^{1-\beta})$ and
dynamic regret of $O(T^\beta V^*)$, where $\beta \in (0,1)$ and $V^*$ is the
path length of the sequence of minimizers. By varying $\beta$, we obtain a
trade-off between static and dynamic regret.","['Jianjun Yuan', 'Andrew Lamperski']","['cs.LG', 'stat.ML']",2019-09-06 20:28:00+00:00
http://arxiv.org/abs/1909.04503v4,ArduCode: Predictive Framework for Automation Engineering,"Automation engineering is the task of integrating, via software, various
sensors, actuators, and controls for automating a real-world process. Today,
automation engineering is supported by a suite of software tools including
integrated development environments (IDE), hardware configurators, compilers,
and runtimes. These tools focus on the automation code itself, but leave the
automation engineer unassisted in their decision making. This can lead to
increased time for software development because of imperfections in decision
making leading to multiple iterations between software and hardware. To address
this, this paper defines multiple challenges often faced in automation
engineering and propose solutions using machine learning to assist engineers
tackle such challenges. We show that machine learning can be leveraged to
assist the automation engineer in classifying automation, finding similar code
snippets, and reasoning about the hardware selection of sensors and actuators.
We validate our architecture on two real datasets consisting of 2,927 Arduino
projects, and 683 Programmable Logic Controller (PLC) projects. Our results
show that paragraph embedding techniques can be utilized to classify automation
using code snippets with precision close to human annotation, giving an
F1-score of 72%. Further, we show that such embedding techniques can help us
find similar code snippets with high accuracy. Finally, we use autoencoder
models for hardware recommendation and achieve a p@3 of 0.79 and p@5 of 0.95.","['Arquimedes Canedo', 'Palash Goyal', 'Di Huang', 'Amit Pandey', 'Gustavo Quiros']","['cs.SE', 'cs.LG', 'stat.ML']",2019-09-06 20:19:05+00:00
http://arxiv.org/abs/1909.03115v1,Machine Learning Approaches for Detecting the Depression from Resting-State Electroencephalogram (EEG): A Review Study,"In this paper, we aimed at reviewing present literature on employing
nonlinear analysis in combination with machine learning methods, in depression
detection or prediction task. We are focusing on an affordable data-driven
approach, applicable for everyday clinical practice, and in particular, those
based on electroencephalographic (EEG) recordings. Among those studies
utilizing EEG, we are discussing a group of applications used for detecting the
depression based on the resting state EEG (detection studies) and
interventional studies (using stimulus in their protocols or aiming to predict
the outcome of therapy). We conclude with a discussion and review of guidelines
to improve the reliability of developed models that could serve the improvement
of diagnostic and more accurate treatment of depression.","['Milena Čukić Radenković', 'Victoria Lopez Lopez']","['eess.SP', 'cs.LG', 'nlin.CD', 'stat.ML']",2019-09-06 20:11:38+00:00
http://arxiv.org/abs/1909.05370v1,An Auxiliary Classifier Generative Adversarial Framework for Relation Extraction,"Relation extraction models suffer from limited qualified training data. Using
human annotators to label sentences is too expensive and does not scale well
especially when dealing with large datasets. In this paper, we use Auxiliary
Classifier Generative Adversarial Networks (AC-GANs) to generate high-quality
relational sentences and to improve the performance of relation classifier in
end-to-end models. In AC-GAN, the discriminator gives not only a probability
distribution over the real source, but also a probability distribution over the
relation labels. This helps to generate meaningful relational sentences.
Experimental results show that our proposed data augmentation method
significantly improves the performance of relation extraction compared to
state-of-the-art methods",['Yun Zhao'],"['cs.CL', 'cs.LG', 'stat.ML']",2019-09-06 19:24:51+00:00
http://arxiv.org/abs/1909.03093v3,Solving Interpretable Kernel Dimension Reduction,"Kernel dimensionality reduction (KDR) algorithms find a low dimensional
representation of the original data by optimizing kernel dependency measures
that are capable of capturing nonlinear relationships. The standard strategy is
to first map the data into a high dimensional feature space using kernels prior
to a projection onto a low dimensional space. While KDR methods can be easily
solved by keeping the most dominant eigenvectors of the kernel matrix, its
features are no longer easy to interpret. Alternatively, Interpretable KDR
(IKDR) is different in that it projects onto a subspace \textit{before} the
kernel feature mapping, therefore, the projection matrix can indicate how the
original features linearly combine to form the new features. Unfortunately, the
IKDR objective requires a non-convex manifold optimization that is difficult to
solve and can no longer be solved by eigendecomposition. Recently, an efficient
iterative spectral (eigendecomposition) method (ISM) has been proposed for this
objective in the context of alternative clustering. However, ISM only provides
theoretical guarantees for the Gaussian kernel. This greatly constrains ISM's
usage since any kernel method using ISM is now limited to a single kernel. This
work extends the theoretical guarantees of ISM to an entire family of kernels,
thereby empowering ISM to solve any kernel method of the same objective. In
identifying this family, we prove that each kernel within the family has a
surrogate $\Phi$ matrix and the optimal projection is formed by its most
dominant eigenvectors. With this extension, we establish how a wide range of
IKDR applications across different learning paradigms can be solved by ISM. To
support reproducible results, the source code is made publicly available on
\url{https://github.com/chieh-neu/ISM_supervised_DR}.","['Chieh Wu', 'Jared Miller', 'Yale Chang', 'Mario Sznaier', 'Jennifer Dy']","['stat.ML', 'cs.LG']",2019-09-06 19:11:45+00:00
http://arxiv.org/abs/1909.03091v1,"A framework for seizure detection using effective connectivity, graph theory and deep modular neural networks","Objective
  The electrical characteristics of the EEG signals can be used for seizure
detection. Statistical independence between different brain regions is measured
by functional brain connectivity (FBC). Specific directional effects can't
consider by FBC and thus effective brain connectivity (EBC) is used to measure
causal intervention between one neuronal region and the rest of the neuronal
regions. Our main purpose is to provide a reliable automatic seizure detection
approach.
  Methods
  In this study, three new methods are provided. Deep modular neural network
(DMNN) is developed based on a combination of various EBC classification
results in the different frequencies. Another method is named ""modular
effective neural networks (MENN)"". This method combines the classification
results of the three different EBC in the specific frequency. ""Modular
frequency neural networks (MFNN)"" is another method that combines the
classification results of the specific EBC in the seven different frequencies.
  Results
  The mean accuracy of the MFNN are 97.14%, 98.53%, and 97.91% using directed
transfer function, directed coherence, and generalized partial directed
coherence, respectively. Using the MENN, the highest mean accuracy is 98.34%.
Finally, DMNN has the highest mean accuracy which is equal to 99.43. To our
best knowledge, the proposed method is a new method that provides the high
accuracy in comparison to other studies which used MIT-CHB database.
  Conclusion and significance
  The knowledge of structure-function relationships between different areas of
the brain is necessary for characterizing the underlying dynamics. Hence,
features based on EBC can provide a reliable automatic seizure detection
approach.","['Behnaz Akbarian', 'Abbas Erfanian']","['q-bio.NC', 'cs.LG', 'stat.ML']",2019-09-06 19:01:08+00:00
http://arxiv.org/abs/1909.03044v1,Deep learning with sentence embeddings pre-trained on biomedical corpora improves the performance of finding similar sentences in electronic medical records,"Capturing sentence semantics plays a vital role in a range of text mining
applications. Despite continuous efforts on the development of related datasets
and models in the general domain, both datasets and models are limited in
biomedical and clinical domains. The BioCreative/OHNLP organizers have made the
first attempt to annotate 1,068 sentence pairs from clinical notes and have
called for a community effort to tackle the Semantic Textual Similarity
(BioCreative/OHNLP STS) challenge. We developed models using traditional
machine learning and deep learning approaches. For the post challenge, we focus
on two models: the Random Forest and the Encoder Network. We applied sentence
embeddings pre-trained on PubMed abstracts and MIMIC-III clinical notes and
updated the Random Forest and the Encoder Network accordingly. The official
results demonstrated our best submission was the ensemble of eight models. It
achieved a Person correlation coefficient of 0.8328, the highest performance
among 13 submissions from 4 teams. For the post challenge, the performance of
both Random Forest and the Encoder Network was improved; in particular, the
correlation of the Encoder Network was improved by ~13%. During the challenge
task, no end-to-end deep learning models had better performance than machine
learning models that take manually-crafted features. In contrast, with the
sentence embeddings pre-trained on biomedical corpora, the Encoder Network now
achieves a correlation of ~0.84, which is higher than the original best model.
The ensembled model taking the improved versions of the Random Forest and
Encoder Network as inputs further increased performance to 0.8528. Deep
learning models with sentence embeddings pre-trained on biomedical corpora
achieve the highest performance on the test set.","['Qingyu Chen', 'Jingcheng Du', 'Sun Kim', 'W. John Wilbur', 'Zhiyong Lu']","['cs.CL', 'cs.LG', 'stat.ML']",2019-09-06 17:56:01+00:00
http://arxiv.org/abs/1909.03039v3,Improved Hierarchical Patient Classification with Language Model Pretraining over Clinical Notes,"Clinical notes in electronic health records contain highly heterogeneous
writing styles, including non-standard terminology or abbreviations. Using
these notes in predictive modeling has traditionally required preprocessing
(e.g. taking frequent terms or topic modeling) that removes much of the
richness of the source data. We propose a pretrained hierarchical recurrent
neural network model that parses minimally processed clinical notes in an
intuitive fashion, and show that it improves performance for discharge
diagnosis classification tasks on the Medical Information Mart for Intensive
Care III (MIMIC-III) dataset, compared to models that treat the notes as an
unordered collection of terms or that conduct no pretraining. We also apply an
attribution technique to examples to identify the words that the model uses to
make its prediction, and show the importance of the words' nearby context.","['Jonas Kemp', 'Alvin Rajkomar', 'Andrew M. Dai']","['cs.LG', 'cs.CL', 'stat.ML']",2019-09-06 17:49:56+00:00
http://arxiv.org/abs/1909.03037v1,Quantized Fisher Discriminant Analysis,"This paper proposes a new subspace learning method, named Quantized Fisher
Discriminant Analysis (QFDA), which makes use of both machine learning and
information theory. There is a lack of literature for combination of machine
learning and information theory and this paper tries to tackle this gap. QFDA
finds a subspace which discriminates the uniformly quantized images in the
Discrete Cosine Transform (DCT) domain at least as well as discrimination of
non-quantized images by Fisher Discriminant Analysis (FDA) while the images
have been compressed. This helps the user to throw away the original images and
keep the compressed images instead without noticeable loss of classification
accuracy. We propose a cost function whose minimization can be interpreted as
rate-distortion optimization in information theory. We also propose quantized
Fisherfaces for facial analysis in QFDA. Our experiments on AT&T face dataset
and Fashion MNIST dataset show the effectiveness of this subspace learning
method.","['Benyamin Ghojogh', 'Ali Saheb Pasand', 'Fakhri Karray', 'Mark Crowley']","['stat.ML', 'cs.IT', 'cs.LG', 'eess.IV', 'math.IT']",2019-09-06 17:46:21+00:00
http://arxiv.org/abs/1909.03069v1,Differential Equation Units: Learning Functional Forms of Activation Functions from Data,"Most deep neural networks use simple, fixed activation functions, such as
sigmoids or rectified linear units, regardless of domain or network structure.
We introduce differential equation units (DEUs), an improvement to modern
neural networks, which enables each neuron to learn a particular nonlinear
activation function from a family of solutions to an ordinary differential
equation. Specifically, each neuron may change its functional form during
training based on the behavior of the other parts of the network. We show that
using neurons with DEU activation functions results in a more compact network
capable of achieving comparable, if not superior, performance when is compared
to much larger networks.","['MohamadAli Torkamani', 'Shiv Shankar', 'Amirmohammad Rooshenas', 'Phillip Wallis']","['cs.LG', 'stat.ML']",2019-09-06 17:06:15+00:00
http://arxiv.org/abs/1909.03013v1,Approaching Machine Learning Fairness through Adversarial Network,"Fairness is becoming a rising concern w.r.t. machine learning model
performance. Especially for sensitive fields such as criminal justice and loan
decision, eliminating the prediction discrimination towards a certain group of
population (characterized by sensitive features like race and gender) is
important for enhancing the trustworthiness of model. In this paper, we present
a new general framework to improve machine learning fairness. The goal of our
model is to minimize the influence of sensitive feature from the perspectives
of both the data input and the predictive model. In order to achieve this goal,
we reformulate the data input by removing the sensitive information and
strengthen model fairness by minimizing the marginal contribution of the
sensitive feature. We propose to learn the non-sensitive input via sampling
among features and design an adversarial network to minimize the dependence
between the reformulated input and the sensitive information. Extensive
experiments on three benchmark datasets suggest that our model achieve better
results than related state-of-the-art methods with respect to both fairness
metrics and prediction performance.","['Xiaoqian Wang', 'Heng Huang']","['cs.LG', 'stat.ML']",2019-09-06 16:55:05+00:00
http://arxiv.org/abs/1909.03012v2,One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques,"As artificial intelligence and machine learning algorithms make further
inroads into society, calls are increasing from multiple stakeholders for these
algorithms to explain their outputs. At the same time, these stakeholders,
whether they be affected citizens, government regulators, domain experts, or
system developers, present different requirements for explanations. Toward
addressing these needs, we introduce AI Explainability 360
(http://aix360.mybluemix.net/), an open-source software toolkit featuring eight
diverse and state-of-the-art explainability methods and two evaluation metrics.
Equally important, we provide a taxonomy to help entities requiring
explanations to navigate the space of explanation methods, not only those in
the toolkit but also in the broader literature on explainability. For data
scientists and other users of the toolkit, we have implemented an extensible
software architecture that organizes methods according to their place in the AI
modeling pipeline. We also discuss enhancements to bring research innovations
closer to consumers of explanations, ranging from simplified, more accessible
versions of algorithms, to tutorials and an interactive web demo to introduce
AI explainability to different audiences and application domains. Together, our
toolkit and taxonomy can help identify gaps where more explainability methods
are needed and provide a platform to incorporate them as they are developed.","['Vijay Arya', 'Rachel K. E. Bellamy', 'Pin-Yu Chen', 'Amit Dhurandhar', 'Michael Hind', 'Samuel C. Hoffman', 'Stephanie Houde', 'Q. Vera Liao', 'Ronny Luss', 'Aleksandra Mojsilović', 'Sami Mourad', 'Pablo Pedemonte', 'Ramya Raghavendra', 'John Richards', 'Prasanna Sattigeri', 'Karthikeyan Shanmugam', 'Moninder Singh', 'Kush R. Varshney', 'Dennis Wei', 'Yunfeng Zhang']","['cs.AI', 'cs.CV', 'cs.HC', 'stat.ML']",2019-09-06 16:53:01+00:00
http://arxiv.org/abs/1909.03848v1,Distributed creation of Machine learning agents for Blockchain analysis,"Creating efficient deep neural networks involves repetitive manual
optimization of the topology and the hyperparameters. This human intervention
significantly inhibits the process. Recent publications propose various Neural
Architecture Search (NAS) algorithms that automate this work. We have applied a
customized NAS algorithm with network morphism and Bayesian optimization to the
problem of cryptocurrency predictions, where it achieved results on par with
our best manually designed models. This is consistent with the findings of
other teams, while several known experiments suggest that given enough
computing power, NAS algorithms can surpass state-of-the-art neural network
models designed by humans. In this paper, we propose a blockchain network
protocol that incentivises independent computing nodes to run NAS algorithms
and compete in finding better neural network models for a particular task. If
implemented, such network can be an autonomous and self-improving source of
machine learning models, significantly boosting and democratizing the access to
AI capabilities for many industries.","['Zvezdin Besarabov', 'Todor Kolev']","['cs.LG', 'cs.CR', 'cs.DC', 'stat.ML']",2019-09-06 16:52:03+00:00
http://arxiv.org/abs/1909.03011v1,RNN Architecture Learning with Sparse Regularization,"Neural models for NLP typically use large numbers of parameters to reach
state-of-the-art performance, which can lead to excessive memory usage and
increased runtime. We present a structure learning method for learning sparse,
parameter-efficient NLP models. Our method applies group lasso to rational RNNs
(Peng et al., 2018), a family of models that is closely connected to weighted
finite-state automata (WFSAs). We take advantage of rational RNNs' natural
grouping of the weights, so the group lasso penalty directly removes WFSA
states, substantially reducing the number of parameters in the model. Our
experiments on a number of sentiment analysis datasets, using both GloVe and
BERT embeddings, show that our approach learns neural structures which have
fewer parameters without sacrificing performance relative to parameter-rich
baselines. Our method also highlights the interpretable properties of rational
RNNs. We show that sparsifying such models makes them easier to visualize, and
we present models that rely exclusively on as few as three WFSAs after pruning
more than 90% of the weights. We publicly release our code.","['Jesse Dodge', 'Roy Schwartz', 'Hao Peng', 'Noah A. Smith']","['cs.CL', 'cs.LG', 'stat.ML']",2019-09-06 16:51:21+00:00
http://arxiv.org/abs/1909.03009v2,Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field Approximation,"Explaining how overparametrized neural networks simultaneously achieve low
risk and zero empirical risk on benchmark datasets is an open problem.
PAC-Bayes bounds optimized using variational inference (VI) have been recently
proposed as a promising direction in obtaining non-vacuous bounds. We show
empirically that this approach gives negligible gains when modeling the
posterior as a Gaussian with diagonal covariance--known as the mean-field
approximation. We investigate common explanations, such as the failure of VI
due to problems in optimization or choosing a suboptimal prior. Our results
suggest that investigating richer posteriors is the most promising direction
forward.",['Konstantinos Pitas'],"['cs.LG', 'stat.ML']",2019-09-06 16:43:49+00:00
http://arxiv.org/abs/1909.03004v1,Show Your Work: Improved Reporting of Experimental Results,"Research in natural language processing proceeds, in part, by demonstrating
that new models achieve superior performance (e.g., accuracy) on held-out test
data, compared to previous results. In this paper, we demonstrate that test-set
performance scores alone are insufficient for drawing accurate conclusions
about which model performs best. We argue for reporting additional details,
especially performance on validation data obtained during model development. We
present a novel technique for doing so: expected validation performance of the
best-found model as a function of computation budget (i.e., the number of
hyperparameter search trials or the overall training time). Using our approach,
we find multiple recent model comparisons where authors would have reached a
different conclusion if they had used more (or less) computation. Our approach
also allows us to estimate the amount of computation required to obtain a given
accuracy; applying it to several recently published results yields massive
variation across papers, from hours to weeks. We conclude with a set of best
practices for reporting experimental results which allow for robust future
comparisons, and provide code to allow researchers to use our technique.","['Jesse Dodge', 'Suchin Gururangan', 'Dallas Card', 'Roy Schwartz', 'Noah A. Smith']","['cs.LG', 'cs.CL', 'stat.ME', 'stat.ML']",2019-09-06 16:40:42+00:00
http://arxiv.org/abs/1909.02998v3,A review on ranking problems in statistical learning,"Ranking problems, also known as preference learning problems, define a widely
spread class of statistical learning problems with many applications, including
fraud detection, document ranking, medicine, credit risk screening, image
ranking or media memorability. In this article, we systematically review
different types of instance ranking problems, i.e., ranking problems that
require the prediction of an order of the response variables, and the
corresponding loss functions resp. goodness criteria. We discuss the
difficulties when trying to optimize those criteria. As for a detailed and
comprehensive overview of existing machine learning techniques to solve such
ranking problems, we systemize existing techniques and recapitulate the
corresponding optimization problems in a unified notation. We also discuss to
which of the ranking problems the respective algorithms are tailored and
identify their strengths and limitations. Computational aspects and open
research problems are also considered.",['Tino Werner'],"['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2019-09-06 16:24:23+00:00
http://arxiv.org/abs/1909.02982v2,DRLViz: Understanding Decisions and Memory in Deep Reinforcement Learning,"We present DRLViz, a visual analytics interface to interpret the internal
memory of an agent (e.g. a robot) trained using deep reinforcement learning.
This memory is composed of large temporal vectors updated when the agent moves
in an environment and is not trivial to understand due to the number of
dimensions, dependencies to past vectors, spatial/temporal correlations, and
co-correlation between dimensions. It is often referred to as a black box as
only inputs (images) and outputs (actions) are intelligible for humans. Using
DRLViz, experts are assisted to interpret decisions using memory reduction
interactions, and to investigate the role of parts of the memory when errors
have been made (e.g. wrong direction). We report on DRLViz applied in the
context of video games simulators (ViZDoom) for a navigation scenario with item
gathering tasks. We also report on experts evaluation using DRLViz, and
applicability of DRLViz to other scenarios and navigation problems beyond
simulation games, as well as its contribution to black box models
interpretability and explainability in the field of visual analytics.","['Theo Jaunet', 'Romain Vuillemot', 'Christian Wolf']","['cs.LG', 'cs.AI', 'cs.HC', 'cs.NE', 'stat.ML']",2019-09-06 15:56:39+00:00
http://arxiv.org/abs/1909.02977v1,Parallel Computation of Graph Embeddings,"Graph embedding aims at learning a vector-based representation of vertices
that incorporates the structure of the graph. This representation then enables
inference of graph properties. Existing graph embedding techniques, however, do
not scale well to large graphs. We therefore propose a framework for parallel
computation of a graph embedding using a cluster of compute nodes with resource
constraints. We show how to distribute any existing embedding technique by
first splitting a graph for any given set of constrained compute nodes and then
reconciling the embedding spaces derived for these subgraphs. We also propose a
new way to evaluate the quality of graph embeddings that is independent of a
specific inference task. Based thereon, we give a formal bound on the
difference between the embeddings derived by centralised and parallel
computation. Experimental results illustrate that our approach for parallel
computation scales well, while largely maintaining the embedding quality.","['Chi Thang Duong', 'Hongzhi Yin', 'Thanh Dat Hoang', 'Truong Giang Le Ba', 'Matthias Weidlich', 'Quoc Viet Hung Nguyen', 'Karl Aberer']","['cs.LG', 'cs.SI', 'stat.ML']",2019-09-06 15:41:44+00:00
http://arxiv.org/abs/1909.12235v1,Video Surveillance of Highway Traffic Events by Deep Learning Architectures,"In this paper we describe a video surveillance system able to detect traffic
events in videos acquired by fixed videocameras on highways. The events of
interest consist in a specific sequence of situations that occur in the video,
as for instance a vehicle stopping on the emergency lane. Hence, the detection
of these events requires to analyze a temporal sequence in the video stream. We
compare different approaches that exploit architectures based on Recurrent
Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). A first
approach extracts vectors of features, mostly related to motion, from each
video frame and exploits a RNN fed with the resulting sequence of vectors. The
other approaches are based directly on the sequence of frames, that are
eventually enriched with pixel-wise motion information. The obtained stream is
processed by an architecture that stacks a CNN and a RNN, and we also
investigate a transfer-learning-based model. The results are very promising and
the best architecture will be tested online in real operative conditions.","['Matteo Tiezzi', 'Stefano Melacci', 'Marco Maggini', 'Angelo Frosini']","['cs.CV', 'cs.LG', 'stat.ML']",2019-09-06 15:36:02+00:00
http://arxiv.org/abs/1909.02971v1,Automated Polysomnography Analysis for Detection of Non-Apneic and Non-Hypopneic Arousals using Feature Engineering and a Bidirectional LSTM Network,"Objective: The aim of this study is to develop an automated classification
algorithm for polysomnography (PSG) recordings to detect non-apneic and
non-hypopneic arousals. Our particular focus is on detecting the respiratory
effort-related arousals (RERAs) which are very subtle respiratory events that
do not meet the criteria for apnea or hypopnea, and are more challenging to
detect. Methods: The proposed algorithm is based on a bidirectional long
short-term memory (BiLSTM) classifier and 465 multi-domain features, extracted
from multimodal clinical time series. The features consist of a set of
physiology-inspired features (n = 75), obtained by multiple steps of feature
selection and expert analysis, and a set of physiology-agnostic features (n =
390), derived from scattering transform. Results: The proposed algorithm is
validated on the 2018 PhysioNet challenge dataset. The overall performance in
terms of the area under the precision-recall curve (AUPRC) is 0.50 on the
hidden test dataset. This result is tied for the second-best score during the
follow-up and official phases of the 2018 PhysioNet challenge. Conclusions: The
results demonstrate that it is possible to automatically detect subtle
non-apneic/non-hypopneic arousal events from PSG recordings. Significance:
Automatic detection of subtle respiratory events such as RERAs together with
other non-apneic/non-hypopneic arousals will allow detailed annotations of
large PSG databases. This contributes to a better retrospective analysis of
sleep data, which may also improve the quality of treatment.","['Ali Bahrami Rad', 'Morteza Zabihi', 'Zheng Zhao', 'Moncef Gabbouj', 'Aggelos K. Katsaggelos', 'Simo Särkkä']","['eess.SP', 'cs.LG', 'stat.ML']",2019-09-06 15:29:54+00:00
http://arxiv.org/abs/1909.02963v4,Regression Under Human Assistance,"Decisions are increasingly taken by both humans and machine learning models.
However, machine learning models are currently trained for full automation --
they are not aware that some of the decisions may still be taken by humans. In
this paper, we take a first step towards the development of machine learning
models that are optimized to operate under different automation levels. More
specifically, we first introduce the problem of ridge regression under human
assistance and show that it is NP-hard. Then, we derive an alternative
representation of the corresponding objective function as a difference of
nondecreasing submodular functions. Building on this representation, we further
show that the objective is nondecreasing and satisfies $\alpha$-submodularity,
a recently introduced notion of approximate submodularity. These properties
allow a simple and efficient greedy algorithm to enjoy approximation guarantees
at solving the problem. Experiments on synthetic and real-world data from two
important applications -- medical diagnosis and content moderation-demonstrate
that our algorithm outsources to humans those samples in which the prediction
error of the ridge regression model would have been the highest if it had to
make a prediction, it outperforms several competitive baselines, and its
performance is robust with respect to several design choices and
hyperparameters used in the experiments.","['Abir De', 'Nastaran Okati', 'Paramita Koley', 'Niloy Ganguly', 'Manuel Gomez-Rodriguez']","['cs.LG', 'stat.ML']",2019-09-06 15:08:52+00:00
http://arxiv.org/abs/1909.05367v3,Learning in Text Streams: Discovery and Disambiguation of Entity and Relation Instances,"We consider a scenario where an artificial agent is reading a stream of text
composed of a set of narrations, and it is informed about the identity of some
of the individuals that are mentioned in the text portion that is currently
being read. The agent is expected to learn to follow the narrations, thus
disambiguating mentions and discovering new individuals. We focus on the case
in which individuals are entities and relations, and we propose an end-to-end
trainable memory network that learns to discover and disambiguate them in an
online manner, performing one-shot learning, and dealing with a small number of
sparse supervisions. Our system builds a not-given-in-advance knowledge base,
and it improves its skills while reading unsupervised text. The model deals
with abrupt changes in the narration, taking into account their effects when
resolving co-references. We showcase the strong disambiguation and discovery
skills of our model on a corpus of Wikipedia documents and on a newly
introduced dataset, that we make publicly available.","['Marco Maggini', 'Giuseppe Marra', 'Stefano Melacci', 'Andrea Zugarini']","['cs.CL', 'cs.LG', 'stat.ML']",2019-09-06 15:01:07+00:00
http://arxiv.org/abs/1909.02950v2,Supervised Multimodal Bitransformers for Classifying Images and Text,"Self-supervised bidirectional transformer models such as BERT have led to
dramatic improvements in a wide variety of textual classification tasks. The
modern digital world is increasingly multimodal, however, and textual
information is often accompanied by other modalities such as images. We
introduce a supervised multimodal bitransformer model that fuses information
from text and image encoders, and obtain state-of-the-art performance on
various multimodal classification benchmark tasks, outperforming strong
baselines, including on hard test sets specifically designed to measure
multimodal performance.","['Douwe Kiela', 'Suvrat Bhooshan', 'Hamed Firooz', 'Ethan Perez', 'Davide Testuggine']","['cs.CL', 'cs.CV', 'cs.LG', 'stat.ML']",2019-09-06 14:59:18+00:00
http://arxiv.org/abs/1909.02940v4,Reinforcement Learning for Joint Optimization of Multiple Rewards,"Finding optimal policies which maximize long term rewards of Markov Decision
Processes requires the use of dynamic programming and backward induction to
solve the Bellman optimality equation. However, many real-world problems
require optimization of an objective that is non-linear in cumulative rewards
for which dynamic programming cannot be applied directly. For example, in a
resource allocation problem, one of the objectives is to maximize long-term
fairness among the users. We notice that when an agent aim to optimize some
function of the sum of rewards is considered, the problem loses its Markov
nature. This paper addresses and formalizes the problem of optimizing a
non-linear function of the long term average of rewards. We propose model-based
and model-free algorithms to learn the policy, where the model-based policy is
shown to achieve a regret of $\Tilde{O}\left(LKDS\sqrt{\frac{A}{T}}\right)$ for
$K$ objectives combined with a concave $L$-Lipschitz function. Further, using
the fairness in cellular base-station scheduling, and queueing system
scheduling as examples, the proposed algorithm is shown to significantly
outperform the conventional RL approaches.","['Mridul Agarwal', 'Vaneet Aggarwal']","['cs.LG', 'cs.AI', 'cs.GT', 'cs.IT', 'cs.MA', 'math.IT', 'stat.ML']",2019-09-06 14:48:07+00:00
http://arxiv.org/abs/1909.02939v1,Optimizing Generalized Rate Metrics through Game Equilibrium,"We present a general framework for solving a large class of learning problems
with non-linear functions of classification rates. This includes problems where
one wishes to optimize a non-decomposable performance metric such as the
F-measure or G-mean, and constrained training problems where the classifier
needs to satisfy non-linear rate constraints such as predictive parity
fairness, distribution divergences or churn ratios. We extend previous
two-player game approaches for constrained optimization to a game between three
players to decouple the classifier rates from the non-linear objective, and
seek to find an equilibrium of the game. Our approach generalizes many existing
algorithms, and makes possible new algorithms with more flexibility and tighter
handling of non-linear rate constraints. We provide convergence guarantees for
convex functions of rates, and show how our methodology can be extended to
handle sums of ratios of rates. Experiments on different fairness tasks confirm
the efficacy of our approach.","['Harikrishna Narasimhan', 'Andrew Cotter', 'Maya Gupta']","['cs.LG', 'cs.GT', 'stat.ML']",2019-09-06 14:47:33+00:00
http://arxiv.org/abs/1909.03830v1,Compact Autoregressive Network,"Autoregressive networks can achieve promising performance in many sequence
modeling tasks with short-range dependence. However, when handling
high-dimensional inputs and outputs, the huge amount of parameters in the
network lead to expensive computational cost and low learning efficiency. The
problem can be alleviated slightly by introducing one more narrow hidden layer
to the network, but the sample size required to achieve a certain training
error is still large. To address this challenge, we rearrange the weight
matrices of a linear autoregressive network into a tensor form, and then make
use of Tucker decomposition to represent low-rank structures. This leads to a
novel compact autoregressive network, called Tucker AutoRegressive (TAR) net.
Interestingly, the TAR net can be applied to sequences with long-range
dependence since the dimension along the sequential order is reduced.
Theoretical studies show that the TAR net improves the learning efficiency, and
requires much fewer samples for model training. Experiments on synthetic and
real-world datasets demonstrate the promising performance of the proposed
compact network.","['Di Wang', 'Feiqing Huang', 'Jingyu Zhao', 'Guodong Li', 'Guangjian Tian']","['cs.LG', 'cs.NE', 'stat.ML']",2019-09-06 14:20:08+00:00
http://arxiv.org/abs/1909.02918v2,Blackbox Attacks on Reinforcement Learning Agents Using Approximated Temporal Information,"Recent research on reinforcement learning (RL) has suggested that trained
agents are vulnerable to maliciously crafted adversarial samples. In this work,
we show how such samples can be generalised from White-box and Grey-box attacks
to a strong Black-box case, where the attacker has no knowledge of the agents,
their training parameters and their training methods. We use
sequence-to-sequence models to predict a single action or a sequence of future
actions that a trained agent will make. First, we show our approximation model,
based on time-series information from the agent, consistently predicts RL
agents' future actions with high accuracy in a Black-box setup on a wide range
of games and RL algorithms. Second, we find that although adversarial samples
are transferable from the target model to our RL agents, they often outperform
random Gaussian noise only marginally. This highlights a serious methodological
deficiency in previous work on such agents; random jamming should have been
taken as the baseline for evaluation. Third, we propose a novel use for
adversarial samplesin Black-box attacks of RL agents: they can be used to
trigger a trained agent to misbehave after a specific time delay. This appears
to be a genuinely new type of attack. It potentially enables an attacker to use
devices controlled by RL agents as time bombs.","['Yiren Zhao', 'Ilia Shumailov', 'Han Cui', 'Xitong Gao', 'Robert Mullins', 'Ross Anderson']","['cs.LG', 'cs.CR', 'cs.CV', 'stat.ML']",2019-09-06 14:06:21+00:00
http://arxiv.org/abs/1909.02900v2,On the Estimation of Network Complexity: Dimension of Graphons,"Network complexity has been studied for over half a century and has found a
wide range of applications. Many methods have been developed to characterize
and estimate the complexity of networks. However, there has been little
research with statistical guarantees. In this paper, we develop a statistical
theory of graph complexity in a general model of random graphs, the so-called
graphon model.
  Given a graphon, we endow the latent space of the nodes with the neighborhood
distance that measures the propensity of two nodes to be connected with similar
nodes. Our complexity index is then based on the covering number and the
Minkowski dimension of (a purified version of) this metric space. Although the
latent space is not identifiable, these indices turn out to be identifiable.
This notion of complexity has simple interpretations on popular examples of
random graphs: it matches the number of communities in stochastic block models;
the dimension of the Euclidean space in random geometric graphs; the regularity
of the link function in H\""older graphon models.
  From a single observation of the graph, we construct an estimator of the
neighborhood-distance and show universal non-asymptotic bounds for its risk,
matching minimax lower bounds. Based on this estimated distance, we compute the
corresponding covering number and Minkowski dimension and we provide optimal
non-asymptotic error bounds for these two plug-in estimators.",['Yann Issartel'],"['stat.ML', 'cs.LG', 'cs.SI', 'math.ST', 'stat.TH']",2019-09-06 13:35:39+00:00
http://arxiv.org/abs/1909.02877v1,"Gradient Q$(σ, λ)$: A Unified Algorithm with Function Approximation for Reinforcement Learning","Full-sampling (e.g., Q-learning) and pure-expectation (e.g., Expected Sarsa)
algorithms are efficient and frequently used techniques in reinforcement
learning. Q$(\sigma,\lambda)$ is the first approach unifies them with
eligibility trace through the sampling degree $\sigma$. However, it is limited
to the tabular case, for large-scale learning, the Q$(\sigma,\lambda)$ is too
expensive to require a huge volume of tables to accurately storage value
functions. To address above problem, we propose a GQ$(\sigma,\lambda)$ that
extends tabular Q$(\sigma,\lambda)$ with linear function approximation. We
prove the convergence of GQ$(\sigma,\lambda)$. Empirical results on some
standard domains show that GQ$(\sigma,\lambda)$ with a combination of
full-sampling with pure-expectation reach a better performance than
full-sampling and pure-expectation methods.","['Long Yang', 'Yu Zhang', 'Qian Zheng', 'Pengfei Li', 'Gang Pan']","['cs.LG', 'stat.ML']",2019-09-06 12:54:03+00:00
http://arxiv.org/abs/1909.07444v1,Student Performance Prediction with Optimum Multilabel Ensemble Model,"One of the important measures of quality of education is the performance of
students in the academic settings. Nowadays, abundant data is stored in
educational institutions about students which can help to discover insight on
how students are learning and how to improve their performance ahead of time
using data mining techniques. In this paper, we developed a student performance
prediction model that predicts the performance of high school students for the
next semester for five courses. We modeled our prediction system as a
multi-label classification task and used support vector machine (SVM), Random
Forest (RF), K-nearest Neighbors (KNN), and Mult-layer perceptron (MLP) as
base-classifiers to train our model. We further improved the performance of the
prediction model using state-of-the-art partitioning schemes to divide the
label space into smaller spaces and use Label Powerset (LP) transformation
method to transform each labelset into a multi-class classification task. The
proposed model achieved better performance in terms of different evaluation
metrics when compared to other multi-label learning tasks such as binary
relevance and classifier chains.","['Ephrem Admasu Yekun', 'Abrahaley Teklay']","['cs.CY', 'cs.LG', 'stat.ML']",2019-09-06 11:59:26+00:00
http://arxiv.org/abs/1909.02827v2,Master your Metrics with Calibration,"Machine learning models deployed in real-world applications are often
evaluated with precision-based metrics such as F1-score or AUC-PR (Area Under
the Curve of Precision Recall). Heavily dependent on the class prior, such
metrics make it difficult to interpret the variation of a model's performance
over different subpopulations/subperiods in a dataset. In this paper, we
propose a way to calibrate the metrics so that they can be made invariant to
the prior. We conduct a large number of experiments on balanced and imbalanced
data to assess the behavior of calibrated metrics and show that they improve
interpretability and provide a better control over what is really measured. We
describe specific real-world use-cases where calibration is beneficial such as,
for instance, model monitoring in production, reporting, or fairness
evaluation.","['Wissam Siblini', 'Jordan Fréry', 'Liyun He-Guelton', 'Frédéric Oblé', 'Yi-Qing Wang']","['cs.LG', 'stat.ML']",2019-09-06 11:44:39+00:00
http://arxiv.org/abs/1909.02820v1,Bayes-Factor-VAE: Hierarchical Bayesian Deep Auto-Encoder Models for Factor Disentanglement,"We propose a family of novel hierarchical Bayesian deep auto-encoder models
capable of identifying disentangled factors of variability in data. While many
recent attempts at factor disentanglement have focused on sophisticated
learning objectives within the VAE framework, their choice of a standard normal
as the latent factor prior is both suboptimal and detrimental to performance.
Our key observation is that the disentangled latent variables responsible for
major sources of variability, the relevant factors, can be more appropriately
modeled using long-tail distributions. The typical Gaussian priors are, on the
other hand, better suited for modeling of nuisance factors. Motivated by this,
we extend the VAE to a hierarchical Bayesian model by introducing hyper-priors
on the variances of Gaussian latent priors, mimicking an infinite mixture,
while maintaining tractable learning and inference of the traditional VAEs.
This analysis signifies the importance of partitioning and treating in a
different manner the latent dimensions corresponding to relevant factors and
nuisances. Our proposed models, dubbed Bayes-Factor-VAEs, are shown to
outperform existing methods both quantitatively and qualitatively in terms of
latent disentanglement across several challenging benchmark tasks.","['Minyoung Kim', 'Yuting Wang', 'Pritish Sahu', 'Vladimir Pavlovic']","['cs.LG', 'cs.CV', 'stat.ML']",2019-09-06 11:20:42+00:00
http://arxiv.org/abs/1909.04491v2,Graph-based data clustering via multiscale community detection,"We present a graph-theoretical approach to data clustering, which combines
the creation of a graph from the data with Markov Stability, a multiscale
community detection framework. We show how the multiscale capabilities of the
method allow the estimation of the number of clusters, as well as alleviating
the sensitivity to the parameters in graph construction. We use both synthetic
and benchmark real datasets to compare and evaluate several graph construction
methods and clustering algorithms, and show that multiscale graph-based
clustering achieves improved performance compared to popular clustering methods
without the need to set externally the number of clusters.","['Zijing Liu', 'Mauricio Barahona']","['cs.IR', 'cs.LG', 'physics.data-an', 'stat.ML']",2019-09-06 10:44:26+00:00
http://arxiv.org/abs/1909.02811v2,Graph Representation Ensemble Learning,"Representation learning on graphs has been gaining attention due to its wide
applicability in predicting missing links, and classifying and recommending
nodes. Most embedding methods aim to preserve certain properties of the
original graph in the low dimensional space. However, real world graphs have a
combination of several properties which are difficult to characterize and
capture by a single approach. In this work, we introduce the problem of graph
representation ensemble learning and provide a first of its kind framework to
aggregate multiple graph embedding methods efficiently. We provide analysis of
our framework and analyze -- theoretically and empirically -- the dependence
between state-of-the-art embedding methods. We test our models on the node
classification task on four real world graphs and show that proposed ensemble
approaches can outperform the state-of-the-art methods by up to 8% on macro-F1.
We further show that the approach is even more beneficial for underrepresented
classes providing an improvement of up to 12%.","['Palash Goyal', 'Di Huang', 'Sujit Rokka Chhetri', 'Arquimedes Canedo', 'Jaya Shree', 'Evan Patterson']","['cs.SI', 'cs.LG', 'stat.ML']",2019-09-06 10:43:05+00:00
http://arxiv.org/abs/1909.02803v3,Personalization of Deep Learning,"We discuss training techniques, objectives and metrics toward personalization
of deep learning models. In machine learning, personalization addresses the
goal of a trained model to target a particular individual by optimizing one or
more performance metrics, while conforming to certain constraints. To
personalize, we investigate three methods of ``curriculum learning`` and two
approaches for data grouping, i.e., augmenting the data of an individual by
adding similar data identified with an auto-encoder. We show that both
``curriculuum learning'' and ``personalized'' data augmentation lead to
improved performance on data of an individual. Mostly, this comes at the cost
of reduced performance on a more general, broader dataset.","['Johannes Schneider', 'Michail Vlachos']","['cs.LG', 'stat.ML']",2019-09-06 10:17:25+00:00
http://arxiv.org/abs/1909.03835v3,Data Sanity Check for Deep Learning Systems via Learnt Assertions,"Reliability is a critical consideration to DL-based systems. But the
statistical nature of DL makes it quite vulnerable to invalid inputs, i.e.,
those cases that are not considered in the training phase of a DL model. This
paper proposes to perform data sanity check to identify invalid inputs, so as
to enhance the reliability of DL-based systems. We design and implement a tool
to detect behavior deviation of a DL model when processing an input case. This
tool extracts the data flow footprints and conducts an assertion-based
validation mechanism. The assertions are built automatically, which are
specifically-tailored for DL model data flow analysis. Our experiments
conducted with real-world scenarios demonstrate that such an assertion-based
data sanity check mechanism is effective in identifying invalid input cases.","['Haochuan Lu', 'Huanlin Xu', 'Nana Liu', 'Yangfan Zhou', 'Xin Wang']","['cs.LG', 'stat.ML']",2019-09-06 10:15:21+00:00
http://arxiv.org/abs/1909.02775v1,Set Flow: A Permutation Invariant Normalizing Flow,"We present a generative model that is defined on finite sets of exchangeable,
potentially high dimensional, data. As the architecture is an extension of
RealNVPs, it inherits all its favorable properties, such as being invertible
and allowing for exact log-likelihood evaluation. We show that this
architecture is able to learn finite non-i.i.d. set data distributions, learn
statistical dependencies between entities of the set and is able to train and
sample with variable set sizes in a computationally efficient manner.
Experiments on 3D point clouds show state-of-the art likelihoods.","['Kashif Rasul', 'Ingmar Schuster', 'Roland Vollgraf', 'Urs Bergmann']","['cs.LG', 'stat.ML']",2019-09-06 09:00:24+00:00
http://arxiv.org/abs/1909.02769v2,Adaptive Trust Region Policy Optimization: Global Convergence and Faster Rates for Regularized MDPs,"Trust region policy optimization (TRPO) is a popular and empirically
successful policy search algorithm in Reinforcement Learning (RL) in which a
surrogate problem, that restricts consecutive policies to be 'close' to one
another, is iteratively solved. Nevertheless, TRPO has been considered a
heuristic algorithm inspired by Conservative Policy Iteration (CPI). We show
that the adaptive scaling mechanism used in TRPO is in fact the natural ""RL
version"" of traditional trust-region methods from convex analysis. We first
analyze TRPO in the planning setting, in which we have access to the model and
the entire state space. Then, we consider sample-based TRPO and establish
$\tilde O(1/\sqrt{N})$ convergence rate to the global optimum. Importantly, the
adaptive scaling mechanism allows us to analyze TRPO in regularized MDPs for
which we prove fast rates of $\tilde O(1/N)$, much like results in convex
optimization. This is the first result in RL of better rates when regularizing
the instantaneous cost or reward.","['Lior Shani', 'Yonathan Efroni', 'Shie Mannor']","['cs.LG', 'math.OC', 'stat.ML']",2019-09-06 08:43:38+00:00
http://arxiv.org/abs/1909.02768v1,"Pairwise Learning to Rank by Neural Networks Revisited: Reconstruction, Theoretical Analysis and Practical Performance","We present a pairwise learning to rank approach based on a neural net, called
DirectRanker, that generalizes the RankNet architecture. We show mathematically
that our model is reflexive, antisymmetric, and transitive allowing for
simplified training and improved performance. Experimental results on the LETOR
MSLR-WEB10K, MQ2007 and MQ2008 datasets show that our model outperforms
numerous state-of-the-art methods, while being inherently simpler in structure
and using a pairwise approach only.","['Marius Köppel', 'Alexander Segner', 'Martin Wagener', 'Lukas Pensel', 'Andreas Karwath', 'Stefan Kramer']","['cs.IR', 'cs.LG', 'stat.ML']",2019-09-06 08:42:58+00:00
http://arxiv.org/abs/1909.02750v1,Differentially Private Precision Matrix Estimation,"In this paper, we study the problem of precision matrix estimation when the
dataset contains sensitive information. In the differential privacy framework,
we develop a differentially private ridge estimator by perturbing the sample
covariance matrix. Then we develop a differentially private graphical lasso
estimator by using the alternating direction method of multipliers (ADMM)
algorithm. The theoretical results and empirical results that show the utility
of the proposed methods are also provided.","['Wenqing Su', 'Xiao Guo', 'Hai Zhang']","['stat.ML', 'cs.CR', 'cs.LG']",2019-09-06 07:46:12+00:00
http://arxiv.org/abs/1909.02749v1,Video Interpolation and Prediction with Unsupervised Landmarks,"Prediction and interpolation for long-range video data involves the complex
task of modeling motion trajectories for each visible object, occlusions and
dis-occlusions, as well as appearance changes due to viewpoint and lighting.
Optical flow based techniques generalize but are suitable only for short
temporal ranges. Many methods opt to project the video frames to a low
dimensional latent space, achieving long-range predictions. However, these
latent representations are often non-interpretable, and therefore difficult to
manipulate. This work poses video prediction and interpolation as unsupervised
latent structure inference followed by a temporal prediction in this latent
space. The latent representations capture foreground semantics without explicit
supervision such as keypoints or poses. Further, as each landmark can be mapped
to a coordinate indicating where a semantic part is positioned, we can reliably
interpolate within the coordinate domain to achieve predictable motion
interpolation. Given an image decoder capable of mapping these landmarks back
to the image domain, we are able to achieve high-quality long-range video
interpolation and extrapolation by operating on the landmark representation
space.","['Kevin J. Shih', 'Aysegul Dundar', 'Animesh Garg', 'Robert Pottorf', 'Andrew Tao', 'Bryan Catanzaro']","['cs.CV', 'cs.LG', 'stat.ML']",2019-09-06 07:40:27+00:00
http://arxiv.org/abs/1909.02747v1,Eelgrass beds and oyster farming at a lagoon before and after the Great East Japan Earthquake 2011: potential to apply deep learning at a coastal area,"There is a small number of case studies of automatic land cover
classification on the coastal area. Here, I test extraction of seagrass beds,
sandy area, oyster farming rafts at Mangoku-ura Lagoon, Miyagi, Japan by
comparing manual tracing, simple image segmentation, and image transformation
using deep learning. The result was used to extract the changes before and
after the earthquake and tsunami. The output resolution was best in the image
transformation method, which showed more than 69% accuracy for vegetation
classification by an assessment using random points on independent test data.
The distribution of oyster farming rafts was detected by the segmentation
model. Assessment of the change before and after the earthquake by the manual
tracing and image transformation result revealed increase of sand area and
decrease of the vegetation. By the segmentation model only the decrease of the
oyster farming was detected. These results demonstrate the potential to extract
the spatial pattern of these elements after an earthquake and tsunami. Index
Terms: Great East Japan Earthquake of 2011, Land use land cover (LULC),
Zosteracea seagrass, cultured oyster, deep learning, Mangoku Bay",['Takehisa Yamakita'],"['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2019-09-06 07:34:58+00:00
http://arxiv.org/abs/1909.02746v2,NEAR: Neighborhood Edge AggregatoR for Graph Classification,"Learning graph-structured data with graph neural networks (GNNs) has been
recently emerging as an important field because of its wide applicability in
bioinformatics, chemoinformatics, social network analysis and data mining.
Recent GNN algorithms are based on neural message passing, which enables GNNs
to integrate local structures and node features recursively. However, past GNN
algorithms based on 1-hop neighborhood neural message passing are exposed to a
risk of loss of information on local structures and relationships. In this
paper, we propose Neighborhood Edge AggregatoR (NEAR), a framework that
aggregates relations between the nodes in the neighborhood via edges. NEAR,
which can be orthogonally combined with Graph Isomorphism Network (GIN), gives
integrated information that describes which nodes in the neighborhood are
connected. Therefore, NEAR can reflect additional information of a local
structure of each node beyond the nodes themselves in 1-hop neighborhood.
Experimental results on multiple graph classification tasks show that our
algorithm makes a good improvement over other existing 1-hop based GNN-based
algorithms.","['Cheolhyeong Kim', 'Haeseong Moon', 'Hyung Ju Hwang']","['cs.LG', 'stat.ML']",2019-09-06 07:22:50+00:00
http://arxiv.org/abs/1909.02729v5,A Baseline for Few-Shot Image Classification,"Fine-tuning a deep network trained with the standard cross-entropy loss is a
strong baseline for few-shot learning. When fine-tuned transductively, this
outperforms the current state-of-the-art on standard datasets such as
Mini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100 with the same
hyper-parameters. The simplicity of this approach enables us to demonstrate the
first few-shot learning results on the ImageNet-21k dataset. We find that using
a large number of meta-training classes results in high few-shot accuracies
even for a large number of few-shot classes. We do not advocate our approach as
the solution for few-shot learning, but simply use the results to highlight
limitations of current benchmarks and few-shot protocols. We perform extensive
studies on benchmark datasets to propose a metric that quantifies the
""hardness"" of a few-shot episode. This metric can be used to report the
performance of few-shot algorithms in a more systematic way.","['Guneet S. Dhillon', 'Pratik Chaudhari', 'Avinash Ravichandran', 'Stefano Soatto']","['cs.LG', 'cs.CV', 'stat.ML']",2019-09-06 06:14:03+00:00
http://arxiv.org/abs/1909.02712v4,Decentralized Stochastic Gradient Tracking for Non-convex Empirical Risk Minimization,"This paper studies a decentralized stochastic gradient tracking (DSGT)
algorithm for non-convex empirical risk minimization problems over a
peer-to-peer network of nodes, which is in sharp contrast to the existing DSGT
only for convex problems. To ensure exact convergence and handle the variance
among decentralized datasets, each node performs a stochastic gradient (SG)
tracking step by using a mini-batch of samples, where the batch size is
designed to be proportional to the size of the local dataset. We explicitly
evaluate the convergence rate of DSGT with respect to the number of iterations
in terms of algebraic connectivity of the network, mini-batch size, gradient
variance, etc. Under certain conditions, we further show that DSGT has a
network independence property in the sense that the network topology only
affects the convergence rate up to a constant factor. Hence, the convergence
rate of DSGT can be comparable to the centralized SGD method. Moreover, a
linear speedup of DSGT with respect to the number of nodes is achievable for
some scenarios. Numerical experiments for neural networks and logistic
regression problems on CIFAR-10 finally illustrate the advantages of DSGT.","['Jiaqi Zhang', 'Keyou You']","['cs.LG', 'cs.DC', 'cs.MA', 'cs.SY', 'eess.SY', 'stat.ML']",2019-09-06 05:05:45+00:00
http://arxiv.org/abs/1909.02707v4,Restricted Minimum Error Entropy Criterion for Robust Classification,"The minimum error entropy (MEE) criterion has been verified as a powerful
approach for non-Gaussian signal processing and robust machine learning.
However, the implementation of MEE on robust classification is rather a vacancy
in the literature. The original MEE only focuses on minimizing the Renyi's
quadratic entropy of the error probability distribution function (PDF), which
could cause failure in noisy classification tasks. To this end, we analyze the
optimal error distribution in the presence of outliers for those classifiers
with continuous errors, and introduce a simple codebook to restrict MEE so that
it drives the error PDF towards the desired case. Half-quadratic based
optimization and convergence analysis of the new learning criterion, called
restricted MEE (RMEE), are provided. Experimental results with logistic
regression and extreme learning machine are presented to verify the desirable
robustness of RMEE.","['Yuanhao Li', 'Badong Chen', 'Natsue Yoshimura', 'Yasuharu Koike']","['cs.LG', 'stat.ML']",2019-09-06 04:18:57+00:00
http://arxiv.org/abs/1909.02705v2,Efficient Multivariate Bandit Algorithm with Path Planning,"In this paper, we solve the arms exponential exploding issue in multivariate
Multi-Armed Bandit (Multivariate-MAB) problem when the arm dimension hierarchy
is considered. We propose a framework called path planning (TS-PP) which
utilizes decision graph/trees to model arm reward success rate with m-way
dimension interaction, and adopts Thompson sampling (TS) for heuristic search
of arm selection. Naturally, it is quite straightforward to combat the curse of
dimensionality using a serial processes that operates sequentially by focusing
on one dimension per each process. For our best acknowledge, we are the first
to solve Multivariate-MAB problem using graph path planning strategy and
deploying alike Monte-Carlo tree search ideas. Our proposed method utilizing
tree models has advantages comparing with traditional models such as general
linear regression. Simulation studies validate our claim by achieving faster
convergence speed, better efficient optimal arm allocation and lower cumulative
regret.","['Keyu Nie', 'Zezhong Zhang', 'Ted Tao Yuan', 'Rong Song', 'Pauline Berry Burke']","['cs.LG', 'stat.ML']",2019-09-06 04:16:00+00:00
http://arxiv.org/abs/1909.05073v4,PCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for Real-time Execution on Mobile Devices,"Model compression techniques on Deep Neural Network (DNN) have been widely
acknowledged as an effective way to achieve acceleration on a variety of
platforms, and DNN weight pruning is a straightforward and effective method.
There are currently two mainstreams of pruning methods representing two
extremes of pruning regularity: non-structured, fine-grained pruning can
achieve high sparsity and accuracy, but is not hardware friendly; structured,
coarse-grained pruning exploits hardware-efficient structures in pruning, but
suffers from accuracy drop when the pruning rate is high. In this paper, we
introduce PCONV, comprising a new sparsity dimension, -- fine-grained pruning
patterns inside the coarse-grained structures. PCONV comprises two types of
sparsities, Sparse Convolution Patterns (SCP) which is generated from
intra-convolution kernel pruning and connectivity sparsity generated from
inter-convolution kernel pruning. Essentially, SCP enhances accuracy due to its
special vision properties, and connectivity sparsity increases pruning rate
while maintaining balanced workload on filter computation. To deploy PCONV, we
develop a novel compiler-assisted DNN inference framework and execute PCONV
models in real-time without accuracy compromise, which cannot be achieved in
prior work. Our experimental results show that, PCONV outperforms three
state-of-art end-to-end DNN frameworks, TensorFlow-Lite, TVM, and Alibaba
Mobile Neural Network with speedup up to 39.2x, 11.4x, and 6.3x, respectively,
with no accuracy loss. Mobile devices can achieve real-time inference on
large-scale DNNs.","['Xiaolong Ma', 'Fu-Ming Guo', 'Wei Niu', 'Xue Lin', 'Jian Tang', 'Kaisheng Ma', 'Bin Ren', 'Yanzhi Wang']","['cs.LG', 'cs.CV', 'cs.DC', 'cs.NE', 'stat.ML']",2019-09-06 03:58:29+00:00
http://arxiv.org/abs/1909.02702v1,Port-Hamiltonian Approach to Neural Network Training,"Neural networks are discrete entities: subdivided into discrete layers and
parametrized by weights which are iteratively optimized via difference
equations. Recent work proposes networks with layer outputs which are no longer
quantized but are solutions of an ordinary differential equation (ODE);
however, these networks are still optimized via discrete methods (e.g. gradient
descent). In this paper, we explore a different direction: namely, we propose a
novel framework for learning in which the parameters themselves are solutions
of ODEs. By viewing the optimization process as the evolution of a
port-Hamiltonian system, we can ensure convergence to a minimum of the
objective function. Numerical experiments have been performed to show the
validity and effectiveness of the proposed methods.","['Stefano Massaroli', 'Michael Poli', 'Federico Califano', 'Angela Faragasso', 'Jinkyoo Park', 'Atsushi Yamashita', 'Hajime Asama']","['cs.NE', 'cs.LG', 'cs.SY', 'eess.SY', 'stat.ML']",2019-09-06 03:31:40+00:00
http://arxiv.org/abs/1909.02688v5,AutoGMM: Automatic and Hierarchical Gaussian Mixture Modeling in Python,"Background: Gaussian mixture modeling is a fundamental tool in clustering, as
well as discriminant analysis and semiparametric density estimation. However,
estimating the optimal model for any given number of components is an NP-hard
problem, and estimating the number of components is in some respects an even
harder problem. Findings: In R, a popular package called mclust addresses both
of these problems. However, Python has lacked such a package. We therefore
introduce AutoGMM, a Python algorithm for automatic Gaussian mixture modeling,
and its hierarchical version, HGMM. AutoGMM builds upon scikit-learn's
AgglomerativeClustering and GaussianMixture classes, with certain modifications
to make the results more stable. Empirically, on several different
applications, AutoGMM performs approximately as well as mclust, and sometimes
better. Conclusions: AutoMM, a freely available Python package, enables
efficient Gaussian mixture modeling by automatically selecting the
initialization, number of clusters and covariance constraints.","['Thomas L. Athey', 'Tingshan Liu', 'Benjamin D. Pedigo', 'Joshua T. Vogelstein']","['cs.LG', 'stat.ML']",2019-09-06 01:45:27+00:00
http://arxiv.org/abs/1909.02682v2,Efficient Communication in Multi-Agent Reinforcement Learning via Variance Based Control,"Multi-agent reinforcement learning (MARL) has recently received considerable
attention due to its applicability to a wide range of real-world applications.
However, achieving efficient communication among agents has always been an
overarching problem in MARL. In this work, we propose Variance Based Control
(VBC), a simple yet efficient technique to improve communication efficiency in
MARL. By limiting the variance of the exchanged messages between agents during
the training phase, the noisy component in the messages can be eliminated
effectively, while the useful part can be preserved and utilized by the agents
for better performance. Our evaluation using a challenging set of StarCraft II
benchmarks indicates that our method achieves $2-10\times$ lower in
communication overhead than state-of-the-art MARL algorithms, while allowing
agents to better collaborate by developing sophisticated strategies.","['Sai Qian Zhang', 'Qi Zhang', 'Jieyu Lin']","['cs.LG', 'stat.ML']",2019-09-06 00:26:05+00:00
http://arxiv.org/abs/1909.03891v1,On Data-Selective Learning,"Adaptive filters are applied in several electronic and communication devices
like smartphones, advanced headphones, DSP chips, smart antenna, and
teleconference systems. Also, they have application in many areas such as
system identification, channel equalization, noise reduction, echo
cancellation, interference cancellation, signal prediction, and stock market.
Therefore, reducing the energy consumption of the adaptive filtering algorithms
has great importance, particularly in green technologies and in devices using
battery.
  In this thesis, data-selective adaptive filters, in particular the
set-membership (SM) adaptive filters, are the tools to reach the goal. There
are well known SM adaptive filters in literature. This work introduces new
algorithms based on the classical ones in order to improve their performances
and reduce the number of required arithmetic operations at the same time.
Therefore, firstly, we analyze the robustness of the classical SM adaptive
filtering algorithms. Secondly, we extend the SM technique to trinion and
quaternion systems. Thirdly, by combining SM filtering and partial-updating, we
introduce a new improved set-membership affine projection algorithm with
constrained step size to improve its stability behavior. Fourthly, we propose
some new least-mean-square (LMS) based and recursive least-squares based
adaptive filtering algorithms with low computational complexity for sparse
systems. Finally, we derive some feature LMS algorithms to exploit the hidden
sparsity in the parameters.",['Hamed Yazdanpanah'],"['eess.SP', 'cs.LG', 'stat.ML']",2019-09-06 00:04:46+00:00
http://arxiv.org/abs/1909.09036v2,Hyper-Graph-Network Decoders for Block Codes,"Neural decoders were shown to outperform classical message passing techniques
for short BCH codes. In this work, we extend these results to much larger
families of algebraic block codes, by performing message passing with graph
neural networks. The parameters of the sub-network at each variable-node in the
Tanner graph are obtained from a hypernetwork that receives the absolute values
of the current message as input. To add stability, we employ a simplified
version of the arctanh activation that is based on a high order Taylor
approximation of this activation function. Our results show that for a large
number of algebraic block codes, from diverse families of codes (BCH, LDPC,
Polar), the decoding obtained with our method outperforms the vanilla belief
propagation method as well as other learning techniques from the literature.","['Eliya Nachmani', 'Lior Wolf']","['cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2019-09-05 21:47:35+00:00
http://arxiv.org/abs/1909.02642v1,Intensity augmentation for domain transfer of whole breast segmentation in MRI,"The segmentation of the breast from the chest wall is an important first step
in the analysis of breast magnetic resonance images. 3D U-nets have been shown
to obtain high segmentation accuracy and appear to generalize well when trained
on one scanner type and tested on another scanner, provided that a very similar
T1-weighted MR protocol is used. There has, however, been little work
addressing the problem of domain adaptation when image intensities or patient
orientation differ markedly between the training set and an unseen test set. To
overcome the domain shift we propose to apply extensive intensity augmentation
in addition to geometric augmentation during training. We explored both style
transfer and a novel intensity remapping approach as intensity augmentation
strategies. For our experiments, we trained a 3D U-net on T1-weighted scans and
tested on T2-weighted scans. By applying intensity augmentation we increased
segmentation performance from a DSC of 0.71 to 0.90. This performance is very
close to the baseline performance of training and testing on T2-weighted scans
(0.92). Furthermore, we applied our network to an independent test set made up
of publicly available scans acquired using a T1-weighted TWIST sequence and a
different coil configuration. On this dataset we obtained a performance of
0.89, close to the inter-observer variability of the ground truth segmentations
(0.92). Our results show that using intensity augmentation in addition to
geometric augmentation is a suitable method to overcome the intensity domain
shift and we expect it to be useful for a wide range of segmentation tasks.","['Linde S. Hesse', 'Grey Kuling', 'Mitko Veta', 'Anne L. Martel']","['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2019-09-05 21:40:02+00:00
http://arxiv.org/abs/1909.03892v1,A Variational Bayes Approach to Adaptive Radio Tomography,"Radio tomographic imaging (RTI) is an emerging technology for localization of
physical objects in a geographical area covered by wireless networks. With
attenuation measurements collected at spatially distributed sensors, RTI
capitalizes on spatial loss fields (SLFs) measuring the absorption of radio
frequency waves at spatial locations along the propagation path. These SLFs can
be utilized for interference management in wireless communication networks,
environmental monitoring, and survivor localization after natural disasters
such as earthquakes. Key to the success of RTI is to accurately model shadowing
as the weighted line integral of the SLF. To learn the SLF exhibiting
statistical heterogeneity induced by spatially diverse environments, the
present work develops a Bayesian framework entailing a piecewise homogeneous
SLF with an underlying hidden Markov random field model. Utilizing variational
Bayes techniques, the novel approach yields efficient field estimators at
affordable complexity. A data-adaptive sensor selection strategy is also
introduced to collect informative measurements for effective reconstruction of
the SLF. Numerical tests using synthetic and real datasets demonstrate the
capabilities of the proposed approach to radio tomography and channel-gain
estimation.","['Donghoon Lee', 'Georgios B. Giannakis']","['eess.SP', 'cs.LG', 'stat.ML']",2019-09-05 21:32:40+00:00
http://arxiv.org/abs/1909.02636v1,Contextual Minimum-Norm Estimates (CMNE): A Deep Learning Method for Source Estimation in Neuronal Networks,"Magnetoencephalography (MEG) and Electroencephalography (EEG) source
estimates have thus far mostly been derived sample by sample, i.e., independent
of each other in time. However, neuronal assemblies are heavily interconnected,
constraining the temporal evolution of neural activity in space as detected by
MEG and EEG. The observed neural currents are thus highly context dependent.
Here, a new method is presented which integrates predictive deep learning
networks with the Minimum-Norm Estimates (MNE) approach. Specifically, we
employ Long Short-Term Memory (LSTM) networks, a type of recurrent neural
network, for predicting brain activity. Because we use past activity (context)
in the estimation, we call our method Contextual MNE (CMNE). We demonstrate
that these contextual algorithms can be used for predicting activity based on
previous brain states and when used in conjunction with MNE, they lead to more
accurate source estimation. To evaluate the performance of CMNE, it was tested
on simulated and experimental data from human auditory evoked response
experiments.","['Christoph Dinh', 'John GW Samuelsson', 'Alexander Hunold', 'Matti S Hämäläinen', 'Sheraz Khan']","['q-bio.QM', 'cs.LG', 'stat.ML']",2019-09-05 21:14:20+00:00
http://arxiv.org/abs/1909.02625v3,On the Acceleration of Deep Learning Model Parallelism with Staleness,"Training the deep convolutional neural network for computer vision problems
is slow and inefficient, especially when it is large and distributed across
multiple devices. The inefficiency is caused by the backpropagation algorithm's
forward locking, backward locking, and update locking problems. Existing
solutions for acceleration either can only handle one locking problem or lead
to severe accuracy loss or memory inefficiency. Moreover, none of them consider
the straggler problem among devices. In this paper, we propose Layer-wise
Staleness and a novel efficient training algorithm, Diversely Stale Parameters
(DSP), to address these challenges. We also analyze the convergence of DSP with
two popular gradient-based methods and prove that both of them are guaranteed
to converge to critical points for non-convex problems. Finally, extensive
experimental results on training deep learning models demonstrate that our
proposed DSP algorithm can achieve significant training speedup with stronger
robustness than compared methods.","['An Xu', 'Zhouyuan Huo', 'Heng Huang']","['cs.LG', 'cs.DC', 'stat.ML']",2019-09-05 20:41:06+00:00
http://arxiv.org/abs/1909.02603v2,Additive function approximation in the brain,"Many biological learning systems such as the mushroom body, hippocampus, and
cerebellum are built from sparsely connected networks of neurons. For a new
understanding of such networks, we study the function spaces induced by sparse
random features and characterize what functions may and may not be learned. A
network with $d$ inputs per neuron is found to be equivalent to an additive
model of order $d$, whereas with a degree distribution the network combines
additive terms of different orders. We identify three specific advantages of
sparsity: additive function approximation is a powerful inductive bias that
limits the curse of dimensionality, sparse networks are stable to outlier noise
in the inputs, and sparse random features are scalable. Thus, even simple brain
architectures can be powerful function approximators. Finally, we hope that
this work helps popularize kernel theories of networks among computational
neuroscientists.",['Kameron Decker Harris'],"['cs.NE', 'cs.LG', 'q-bio.NC', 'stat.ML']",2019-09-05 19:07:33+00:00
http://arxiv.org/abs/1909.02583v2,Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement Learning Agents,"Robustness of Deep Reinforcement Learning (DRL) algorithms towards
adversarial attacks in real world applications such as those deployed in
cyber-physical systems (CPS) are of increasing concern. Numerous studies have
investigated the mechanisms of attacks on the RL agent's state space.
Nonetheless, attacks on the RL agent's action space (AS) (corresponding to
actuators in engineering systems) are equally perverse; such attacks are
relatively less studied in the ML literature. In this work, we first frame the
problem as an optimization problem of minimizing the cumulative reward of an RL
agent with decoupled constraints as the budget of attack. We propose a
white-box Myopic Action Space (MAS) attack algorithm that distributes the
attacks across the action space dimensions. Next, we reformulate the
optimization problem above with the same objective function, but with a
temporally coupled constraint on the attack budget to take into account the
approximated dynamics of the agent. This leads to the white-box Look-ahead
Action Space (LAS) attack algorithm that distributes the attacks across the
action and temporal dimensions. Our results shows that using the same amount of
resources, the LAS attack deteriorates the agent's performance significantly
more than the MAS attack. This reveals the possibility that with limited
resource, an adversary can utilize the agent's dynamics to malevolently craft
attacks that causes the agent to fail. Additionally, we leverage these attack
strategies as a possible tool to gain insights on the potential vulnerabilities
of DRL agents.","['Xian Yeow Lee', 'Sambit Ghadai', 'Kai Liang Tan', 'Chinmay Hegde', 'Soumik Sarkar']","['cs.LG', 'cs.AI', 'cs.CR', 'stat.ML']",2019-09-05 18:04:04+00:00
http://arxiv.org/abs/1909.02553v4,Smooth Contextual Bandits: Bridging the Parametric and Non-differentiable Regret Regimes,"We study a nonparametric contextual bandit problem where the expected reward
functions belong to a H\""older class with smoothness parameter $\beta$. We show
how this interpolates between two extremes that were previously studied in
isolation: non-differentiable bandits ($\beta\leq1$), where rate-optimal regret
is achieved by running separate non-contextual bandits in different context
regions, and parametric-response bandits (satisfying $\beta=\infty$), where
rate-optimal regret can be achieved with minimal or no exploration due to
infinite extrapolatability. We develop a novel algorithm that carefully adjusts
to all smoothness settings and we prove its regret is rate-optimal by
establishing matching upper and lower bounds, recovering the existing results
at the two extremes. In this sense, our work bridges the gap between the
existing literature on parametric and non-differentiable contextual bandit
problems and between bandit algorithms that exclusively use global or local
information, shedding light on the crucial interplay of complexity and regret
in contextual bandits.","['Yichun Hu', 'Nathan Kallus', 'Xiaojie Mao']","['stat.ML', 'cs.AI', 'cs.LG', 'math.OC', 'math.ST', 'stat.TH']",2019-09-05 17:51:14+00:00
http://arxiv.org/abs/1909.02506v3,$\sqrt{n}$-Regret for Learning in Markov Decision Processes with Function Approximation and Low Bellman Rank,"In this paper, we consider the problem of online learning of Markov decision
processes (MDPs) with very large state spaces. Under the assumptions of
realizable function approximation and low Bellman ranks, we develop an online
learning algorithm that learns the optimal value function while at the same
time achieving very low cumulative regret during the learning process. Our
learning algorithm, Adaptive Value-function Elimination (AVE), is inspired by
the policy elimination algorithm proposed in (Jiang et al., 2017), known as
OLIVE. One of our key technical contributions in AVE is to formulate the
elimination steps in OLIVE as contextual bandit problems. This technique
enables us to apply the active elimination and expert weighting methods from
(Dudik et al., 2011), instead of the random action exploration scheme used in
the original OLIVE algorithm, for more efficient exploration and better control
of the regret incurred in each policy elimination step. To the best of our
knowledge, this is the first $\sqrt{n}$-regret result for reinforcement
learning in stochastic MDPs with general value function approximation.","['Kefan Dong', 'Jian Peng', 'Yining Wang', 'Yuan Zhou']","['cs.LG', 'stat.ML']",2019-09-05 16:20:41+00:00
http://arxiv.org/abs/1909.02496v2,The Benefits of Diversity: Permutation Recovery in Unlabeled Sensing from Multiple Measurement Vectors,"In ""Unlabeled Sensing"", one observes a set of linear measurements of an
underlying signal with incomplete or missing information about their ordering,
which can be modeled in terms of an unknown permutation. Previous work on the
case of a single noisy measurement vector has exposed two main challenges: 1) a
high requirement concerning the \emph{signal-to-noise ratio} ($\snr$), i.e.,
approximately of the order of $n^{5}$, and 2) a massive computational burden in
light of NP-hardness in general.
  In this paper, we study the case of \emph{multiple} noisy measurement vectors
(MMVs) resulting from a \emph{common} permutation and investigate to what
extent the number of MMVs $m$ facilitates permutation recovery by ""borrowing
strength"". The above two challenges have at least partially been resolved
within our work. First, we show that a large stable rank of the signal
significantly reduces the required snr which can drop from a polynomial in $n$
for $m = 1$ to a constant for $m = \Omega(\log n)$, where $m$ denotes the
number of MMVs and $n$ denotes the number of measurements per MV. This bound is
shown to be sharp and is associated with a phase transition phenomenon. Second,
we propose a computational scheme for recovering the unknown permutation in
practice. For the ""oracle case"" with the known signal, the maximum likelihood
(ML) estimator reduces to a linear assignment problem whose global optimum can
be obtained efficiently. For the case in which both the signal and permutation
are unknown, the problem is reformulated as a bi-convex optimization problem
with an auxiliary variable, which can be solved by the Alternating Direction
Method of Multipliers (ADMM). Numerical experiments based on the proposed
computational scheme confirm the tightness of our theoretical analysis.","['Hang Zhang', 'Martin Slawski', 'Ping Li']","['cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2019-09-05 15:55:59+00:00
http://arxiv.org/abs/1909.02564v1,Classification with Costly Features as a Sequential Decision-Making Problem,"This work focuses on a specific classification problem, where the information
about a sample is not readily available, but has to be acquired for a cost, and
there is a per-sample budget. Inspired by real-world use-cases, we analyze
average and hard variations of a directly specified budget. We postulate the
problem in its explicit formulation and then convert it into an equivalent MDP,
that can be solved with deep reinforcement learning. Also, we evaluate a
real-world inspired setting with sparse training dataset with missing features.
The presented method performs robustly well in all settings across several
distinct datasets, outperforming other prior-art algorithms. The method is
flexible, as showcased with all mentioned modifications and can be improved
with any domain independent advancement in RL.","['Jaromír Janisch', 'Tomáš Pevný', 'Viliam Lisý']","['cs.LG', 'cs.AI', 'stat.ML']",2019-09-05 14:46:40+00:00
http://arxiv.org/abs/1909.02453v3,Best Practices for Scientific Research on Neural Architecture Search,"Finding a well-performing architecture is often tedious for both DL
practitioners and researchers, leading to tremendous interest in the automation
of this task by means of neural architecture search (NAS). Although the
community has made major strides in developing better NAS methods, the quality
of scientific empirical evaluations in the young field of NAS is still lacking
behind that of other areas of machine learning. To address this issue, we
describe a set of possible issues and ways to avoid them, leading to the NAS
best practices checklist available at http://automl.org/nas_checklist.pdf.","['Marius Lindauer', 'Frank Hutter']","['cs.LG', 'stat.ML']",2019-09-05 14:39:27+00:00
http://arxiv.org/abs/1909.02563v1,DeepEvolution: A Search-Based Testing Approach for Deep Neural Networks,"The increasing inclusion of Deep Learning (DL) models in safety-critical
systems such as autonomous vehicles have led to the development of multiple
model-based DL testing techniques. One common denominator of these testing
techniques is the automated generation of test cases, e.g., new inputs
transformed from the original training data with the aim to optimize some test
adequacy criteria. So far, the effectiveness of these approaches has been
hindered by their reliance on random fuzzing or transformations that do not
always produce test cases with a good diversity. To overcome these limitations,
we propose, DeepEvolution, a novel search-based approach for testing DL models
that relies on metaheuristics to ensure a maximum diversity in generated test
cases. We assess the effectiveness of DeepEvolution in testing computer-vision
DL models and found that it significantly increases the neuronal coverage of
generated test cases. Moreover, using DeepEvolution, we could successfully find
several corner-case behaviors. Finally, DeepEvolution outperformed Tensorfuzz
(a coverage-guided fuzzing tool developed at Google Brain) in detecting latent
defects introduced during the quantization of the models. These results suggest
that search-based approaches can help build effective testing tools for DL
systems.","['Houssem Ben Braiek', 'Foutse khomh']","['cs.LG', 'cs.CV', 'stat.ML']",2019-09-05 13:42:08+00:00
http://arxiv.org/abs/1909.02387v1,Machine-Learning-Driven New Geologic Discoveries at Mars Rover Landing Sites: Jezero and NE Syrtis,"A hierarchical Bayesian classifier is trained at pixel scale with spectral
data from the CRISM (Compact Reconnaissance Imaging Spectrometer for Mars)
imagery. Its utility in detecting rare phases is demonstrated with new geologic
discoveries near the Mars-2020 rover landing site. Akaganeite is found in
sediments on the Jezero crater floor and in fluvial deposits at NE Syrtis.
Jarosite and silica are found on the Jezero crater floor while
chlorite-smectite and Al phyllosilicates are found in the Jezero crater walls.
These detections point to a multi-stage, multi-chemistry history of water in
Jezero crater and the surrounding region and provide new information for
guiding the Mars-2020 rover's landed exploration. In particular, the
akaganeite, silica, and jarosite in the floor deposits suggest either a later
episode of salty, Fe-rich waters that post-date Jezero delta or groundwater
alteration of portions of the Jezero sedimentary sequence.","['Murat Dundar', 'Bethany L. Ehlmann', 'Ellen K. Leask']","['astro-ph.EP', 'cs.LG', 'stat.ML']",2019-09-05 13:22:16+00:00
http://arxiv.org/abs/1909.02562v1,TFCheck : A TensorFlow Library for Detecting Training Issues in Neural Network Programs,"The increasing inclusion of Machine Learning (ML) models in safety critical
systems like autonomous cars have led to the development of multiple
model-based ML testing techniques. One common denominator of these testing
techniques is their assumption that training programs are adequate and
bug-free. These techniques only focus on assessing the performance of the
constructed model using manually labeled data or automatically generated data.
However, their assumptions about the training program are not always true as
training programs can contain inconsistencies and bugs. In this paper, we
examine training issues in ML programs and propose a catalog of verification
routines that can be used to detect the identified issues, automatically. We
implemented the routines in a Tensorflow-based library named TFCheck. Using
TFCheck, practitioners can detect the aforementioned issues automatically. To
assess the effectiveness of TFCheck, we conducted a case study with real-world,
mutants, and synthetic training programs. Results show that TFCheck can
successfully detect training issues in ML code implementations.","['Houssem Ben Braiek', 'Foutse Khomh']","['cs.LG', 'cs.CV', 'cs.NE', 'stat.ML']",2019-09-05 13:21:22+00:00
http://arxiv.org/abs/1909.02384v2,Training High-Performance and Large-Scale Deep Neural Networks with Full 8-bit Integers,"Deep neural network (DNN) quantization converting floating-point (FP) data in
the network to integers (INT) is an effective way to shrink the model size for
memory saving and simplify the operations for compute acceleration. Recently,
researches on DNN quantization develop from inference to training, laying a
foundation for the online training on accelerators. However, existing schemes
leaving batch normalization (BN) untouched during training are mostly
incomplete quantization that still adopts high precision FP in some parts of
the data paths. Currently, there is no solution that can use only low bit-width
INT data during the whole training process of large-scale DNNs with acceptable
accuracy. In this work, through decomposing all the computation steps in DNNs
and fusing three special quantization functions to satisfy the different
precision requirements, we propose a unified complete quantization framework
termed as ``WAGEUBN'' to quantize DNNs involving all data paths including W
(Weights), A (Activation), G (Gradient), E (Error), U (Update), and BN.
Moreover, the Momentum optimizer is also quantized to realize a completely
quantized framework. Experiments on ResNet18/34/50 models demonstrate that
WAGEUBN can achieve competitive accuracy on the ImageNet dataset. For the first
time, the study of quantization in large-scale DNNs is advanced to the full
8-bit INT level. In this way, all the operations in the training and inference
can be bit-wise operations, pushing towards faster processing speed, decreased
memory cost, and higher energy efficiency. Our throughout quantization
framework has great potential for future efficient portable devices with online
learning ability.","['Yukuan Yang', 'Shuang Wu', 'Lei Deng', 'Tianyi Yan', 'Yuan Xie', 'Guoqi Li']","['cs.LG', 'stat.ML']",2019-09-05 13:17:38+00:00
http://arxiv.org/abs/1909.02373v3,LSMI-Sinkhorn: Semi-supervised Mutual Information Estimation with Optimal Transport,"Estimating mutual information is an important statistics and machine learning
problem. To estimate the mutual information from data, a common practice is
preparing a set of paired samples $\{(\mathbf{x}_i,\mathbf{y}_i)\}_{i=1}^n
\stackrel{\mathrm{i.i.d.}}{\sim} p(\mathbf{x},\mathbf{y})$. However, in many
situations, it is difficult to obtain a large number of data pairs. To address
this problem, we propose the semi-supervised Squared-loss Mutual Information
(SMI) estimation method using a small number of paired samples and the
available unpaired ones. We first represent SMI through the density ratio
function, where the expectation is approximated by the samples from marginals
and its assignment parameters. The objective is formulated using the optimal
transport problem and quadratic programming. Then, we introduce the
Least-Squares Mutual Information with Sinkhorn (LSMI-Sinkhorn) algorithm for
efficient optimization. Through experiments, we first demonstrate that the
proposed method can estimate the SMI without a large number of paired samples.
Then, we show the effectiveness of the proposed LSMI-Sinkhorn algorithm on
various types of machine learning problems such as image matching and photo
album summarization. Code can be found at
https://github.com/csyanbin/LSMI-Sinkhorn.","['Yanbin Liu', 'Makoto Yamada', 'Yao-Hung Hubert Tsai', 'Tam Le', 'Ruslan Salakhutdinov', 'Yi Yang']","['stat.ML', 'cs.LG']",2019-09-05 12:58:20+00:00
http://arxiv.org/abs/1909.02363v1,Understanding ML driven HPC: Applications and Infrastructure,"We recently outlined the vision of ""Learning Everywhere"" which captures the
possibility and impact of how learning methods and traditional HPC methods can
be coupled together. A primary driver of such coupling is the promise that
Machine Learning (ML) will give major performance improvements for traditional
HPC simulations. Motivated by this potential, the ML around HPC class of
integration is of particular significance. In a related follow-up paper, we
provided an initial taxonomy for integrating learning around HPC methods. In
this paper, which is part of the Learning Everywhere series, we discuss ""how""
learning methods and HPC simulations are being integrated to enhance effective
performance of computations. This paper identifies several modes ---
substitution, assimilation, and control, in which learning methods integrate
with HPC simulations and provide representative applications in each mode. This
paper discusses some open research questions and we hope will motivate and
clear the ground for MLaroundHPC benchmarks.","['Geoffrey Fox', 'Shantenu Jha']","['cs.LG', 'cs.DC', 'physics.comp-ph', 'stat.ML']",2019-09-05 12:47:48+00:00
