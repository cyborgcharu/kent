id,title,abstract,authors,categories,date
http://arxiv.org/abs/2009.00690v1,Improved Bilevel Model: Fast and Optimal Algorithm with Theoretical Guarantee,"Due to the hierarchical structure of many machine learning problems, bilevel
programming is becoming more and more important recently, however, the
complicated correlation between the inner and outer problem makes it extremely
challenging to solve. Although several intuitive algorithms based on the
automatic differentiation have been proposed and obtained success in some
applications, not much attention has been paid to finding the optimal
formulation of the bilevel model. Whether there exists a better formulation is
still an open problem. In this paper, we propose an improved bilevel model
which converges faster and better compared to the current formulation. We
provide theoretical guarantee and evaluation results over two tasks: Data
Hyper-Cleaning and Hyper Representation Learning. The empirical results show
that our model outperforms the current bilevel model with a great margin.
\emph{This is a concurrent work with \citet{liu2020generic} and we submitted to
ICML 2020. Now we put it on the arxiv for record.}","['Junyi Li', 'Bin Gu', 'Heng Huang']","['cs.LG', 'cs.AI', 'stat.ML']",2020-09-01 20:52:57+00:00
http://arxiv.org/abs/2009.00666v2,"Robust, Accurate Stochastic Optimization for Variational Inference","We consider the problem of fitting variational posterior approximations using
stochastic optimization methods. The performance of these approximations
depends on (1) how well the variational family matches the true posterior
distribution,(2) the choice of divergence, and (3) the optimization of the
variational objective. We show that even in the best-case scenario when the
exact posterior belongs to the assumed variational family, common stochastic
optimization methods lead to poor variational approximations if the problem
dimension is moderately large. We also demonstrate that these methods are not
robust across diverse model types. Motivated by these findings, we develop a
more robust and accurate stochastic optimization framework by viewing the
underlying optimization algorithm as producing a Markov chain. Our approach is
theoretically motivated and includes a diagnostic for convergence and a novel
stopping rule, both of which are robust to noisy evaluations of the objective
function. We show empirically that the proposed framework works well on a
diverse set of models: it can automatically detect stochastic optimization
failure or inaccurate variational approximation","['Akash Kumar Dhaka', 'Alejandro Catalina', 'Michael Riis Andersen', 'Måns Magnusson', 'Jonathan H. Huggins', 'Aki Vehtari']","['cs.LG', 'stat.ME', 'stat.ML']",2020-09-01 19:12:11+00:00
http://arxiv.org/abs/2009.00647v4,Lifelong Graph Learning,"Graph neural networks (GNN) are powerful models for many graph-structured
tasks. Existing models often assume that the complete structure of the graph is
available during training. In practice, however, graph-structured data is
usually formed in a streaming fashion so that learning a graph continuously is
often necessary. In this paper, we bridge GNN and lifelong learning by
converting a continual graph learning problem to a regular graph learning
problem so GNN can inherit the lifelong learning techniques developed for
convolutional neural networks (CNN). We propose a new topology, the feature
graph, which takes features as new nodes and turns nodes into independent
graphs. This successfully converts the original problem of node classification
to graph classification. In the experiments, we demonstrate the efficiency and
effectiveness of feature graph networks (FGN) by continuously learning a
sequence of classical graph datasets. We also show that FGN achieves superior
performance in two applications, i.e., lifelong human action recognition with
wearable devices and feature matching. To the best of our knowledge, FGN is the
first method to bridge graph learning and lifelong learning via a novel graph
topology. Source code is available at https://github.com/wang-chen/LGL","['Chen Wang', 'Yuheng Qiu', 'Dasong Gao', 'Sebastian Scherer']","['cs.LG', 'stat.ML']",2020-09-01 18:21:34+00:00
http://arxiv.org/abs/2009.00606v5,Semi-Supervised Empirical Risk Minimization: Using unlabeled data to improve prediction,"We present a general methodology for using unlabeled data to design semi
supervised learning (SSL) variants of the Empirical Risk Minimization (ERM)
learning process. Focusing on generalized linear regression, we analyze of the
effectiveness of our SSL approach in improving prediction performance. The key
ideas are carefully considering the null model as a competitor, and utilizing
the unlabeled data to determine signal-noise combinations where SSL outperforms
both supervised learning and the null model. We then use SSL in an adaptive
manner based on estimation of the signal and noise. In the special case of
linear regression with Gaussian covariates, we prove that the non-adaptive SSL
version is in fact not capable of improving on both the supervised estimator
and the null model simultaneously, beyond a negligible O(1/n) term. On the
other hand, the adaptive model presented in this work, can achieve a
substantial improvement over both competitors simultaneously, under a variety
of settings. This is shown empirically through extensive simulations, and
extended to other scenarios, such as non-Gaussian covariates, misspecified
linear regression, or generalized linear regression with non-linear link
functions.","['Oren Yuval', 'Saharon Rosset']","['stat.ML', 'cs.LG', 'stat.ME']",2020-09-01 17:55:51+00:00
http://arxiv.org/abs/2009.00585v1,Variational Mixture of Normalizing Flows,"In the past few years, deep generative models, such as generative adversarial
networks \autocite{GAN}, variational autoencoders \autocite{vaepaper}, and
their variants, have seen wide adoption for the task of modelling complex data
distributions. In spite of the outstanding sample quality achieved by those
early methods, they model the target distributions \emph{implicitly}, in the
sense that the probability density functions induced by them are not explicitly
accessible. This fact renders those methods unfit for tasks that require, for
example, scoring new instances of data with the learned distributions.
Normalizing flows have overcome this limitation by leveraging the
change-of-variables formula for probability density functions, and by using
transformations designed to have tractable and cheaply computable Jacobians.
Although flexible, this framework lacked (until recently
\autocites{semisuplearning_nflows, RAD}) a way to introduce discrete structure
(such as the one found in mixtures) in the models it allows to construct, in an
unsupervised scenario. The present work overcomes this by using normalizing
flows as components in a mixture model and devising an end-to-end training
procedure for such a model. This procedure is based on variational inference,
and uses a variational posterior parameterized by a neural network. As will
become clear, this model naturally lends itself to (multimodal) density
estimation, semi-supervised learning, and clustering. The proposed model is
illustrated on two synthetic datasets, as well as on a real-world dataset.
Keywords: Deep generative models, normalizing flows, variational inference,
probabilistic modelling, mixture models.","['Guilherme G. P. Freitas Pires', 'Mário A. T. Figueiredo']","['stat.ML', 'cs.LG']",2020-09-01 17:20:08+00:00
http://arxiv.org/abs/2009.00565v1,Performance-Agnostic Fusion of Probabilistic Classifier Outputs,"We propose a method for combining probabilistic outputs of classifiers to
make a single consensus class prediction when no further information about the
individual classifiers is available, beyond that they have been trained for the
same task. The lack of relevant prior information rules out typical
applications of Bayesian or Dempster-Shafer methods, and the default approach
here would be methods based on the principle of indifference, such as the sum
or product rule, which essentially weight all classifiers equally. In contrast,
our approach considers the diversity between the outputs of the various
classifiers, iteratively updating predictions based on their correspondence
with other predictions until the predictions converge to a consensus decision.
The intuition behind this approach is that classifiers trained for the same
task should typically exhibit regularities in their outputs on a new task; the
predictions of classifiers which differ significantly from those of others are
thus given less credence using our approach. The approach implicitly assumes a
symmetric loss function, in that the relative cost of various prediction errors
are not taken into account. Performance of the model is demonstrated on
different benchmark datasets. Our proposed method works well in situations
where accuracy is the performance metric; however, it does not output
calibrated probabilities, so it is not suitable in situations where such
probabilities are required for further processing.","['Jordan F. Masakuna', 'Simukai W. Utete', 'Steve Kroon']","['cs.LG', 'stat.ML']",2020-09-01 16:53:29+00:00
http://arxiv.org/abs/2009.08956v1,Exploration in two-stage recommender systems,"Two-stage recommender systems are widely adopted in industry due to their
scalability and maintainability. These systems produce recommendations in two
steps: (i) multiple nominators preselect a small number of items from a large
pool using cheap-to-compute item embeddings; (ii) with a richer set of
features, a ranker rearranges the nominated items and serves them to the user.
A key challenge of this setup is that optimal performance of each stage in
isolation does not imply optimal global performance. In response to this issue,
Ma et al. (2020) proposed a nominator training objective importance weighted by
the ranker's probability of recommending each item. In this work, we focus on
the complementary issue of exploration. Modeled as a contextual bandit problem,
we find LinUCB (a near optimal exploration strategy for single-stage systems)
may lead to linear regret when deployed in two-stage recommenders. We therefore
propose a method of synchronising the exploration strategies between the ranker
and the nominators. Our algorithm only relies on quantities already computed by
standard LinUCB at each stage and can be implemented in three lines of
additional code. We end by demonstrating the effectiveness of our algorithm
experimentally.","['Jiri Hron', 'Karl Krauth', 'Michael I. Jordan', 'Niki Kilbertus']","['cs.IR', 'cs.LG', 'stat.ML']",2020-09-01 16:52:51+00:00
http://arxiv.org/abs/2009.00540v1,Training Deep Neural Networks with Constrained Learning Parameters,"Today's deep learning models are primarily trained on CPUs and GPUs. Although
these models tend to have low error, they consume high power and utilize large
amount of memory owing to double precision floating point learning parameters.
Beyond the Moore's law, a significant portion of deep learning tasks would run
on edge computing systems, which will form an indispensable part of the entire
computation fabric. Subsequently, training deep learning models for such
systems will have to be tailored and adopted to generate models that have the
following desirable characteristics: low error, low memory, and low power. We
believe that deep neural networks (DNNs), where learning parameters are
constrained to have a set of finite discrete values, running on neuromorphic
computing systems would be instrumental for intelligent edge computing systems
having these desirable characteristics. To this extent, we propose the
Combinatorial Neural Network Training Algorithm (CoNNTrA), that leverages a
coordinate gradient descent-based approach for training deep learning models
with finite discrete learning parameters. Next, we elaborate on the theoretical
underpinnings and evaluate the computational complexity of CoNNTrA. As a proof
of concept, we use CoNNTrA to train deep learning models with ternary learning
parameters on the MNIST, Iris and ImageNet data sets and compare their
performance to the same models trained using Backpropagation. We use following
performance metrics for the comparison: (i) Training error; (ii) Validation
error; (iii) Memory usage; and (iv) Training time. Our results indicate that
CoNNTrA models use 32x less memory and have errors at par with the
Backpropagation models.","['Prasanna Date', 'Christopher D. Carothers', 'John E. Mitchell', 'James A. Hendler', 'Malik Magdon-Ismail']","['cs.LG', 'cs.CV', 'stat.ML', '68T07, 90C27', 'I.2.6']",2020-09-01 16:20:11+00:00
http://arxiv.org/abs/2009.00538v1,Stochastic Graph Recurrent Neural Network,"Representation learning over graph structure data has been widely studied due
to its wide application prospects. However, previous methods mainly focus on
static graphs while many real-world graphs evolve over time. Modeling such
evolution is important for predicting properties of unseen networks. To resolve
this challenge, we propose SGRNN, a novel neural architecture that applies
stochastic latent variables to simultaneously capture the evolution in node
attributes and topology. Specifically, deterministic states are separated from
stochastic states in the iterative process to suppress mutual interference.
With semi-implicit variational inference integrated to SGRNN, a non-Gaussian
variational distribution is proposed to help further improve the performance.
In addition, to alleviate KL-vanishing problem in SGRNN, a simple and
interpretable structure is proposed based on the lower bound of KL-divergence.
Extensive experiments on real-world datasets demonstrate the effectiveness of
the proposed model. Code is available at
https://github.com/StochasticGRNN/SGRNN.","['Tijin Yan', 'Hongwei Zhang', 'Zirui Li', 'Yuanqing Xia']","['stat.ML', 'cs.LG']",2020-09-01 16:14:30+00:00
http://arxiv.org/abs/2009.00534v1,Improved Weighted Random Forest for Classification Problems,"Several studies have shown that combining machine learning models in an
appropriate way will introduce improvements in the individual predictions made
by the base models. The key to make well-performing ensemble model is in the
diversity of the base models. Of the most common solutions for introducing
diversity into the decision trees are bagging and random forest. Bagging
enhances the diversity by sampling with replacement and generating many
training data sets, while random forest adds selecting a random number of
features as well. This has made the random forest a winning candidate for many
machine learning applications. However, assuming equal weights for all base
decision trees does not seem reasonable as the randomization of sampling and
input feature selection may lead to different levels of decision-making
abilities across base decision trees. Therefore, we propose several algorithms
that intend to modify the weighting strategy of regular random forest and
consequently make better predictions. The designed weighting frameworks include
optimal weighted random forest based on ac-curacy, optimal weighted random
forest based on the area under the curve (AUC), performance-based weighted
random forest, and several stacking-based weighted random forest models. The
numerical results show that the proposed models are able to introduce
significant improvements compared to regular random forest.","['Mohsen Shahhosseini', 'Guiping Hu']","['cs.LG', 'stat.ML']",2020-09-01 16:08:45+00:00
http://arxiv.org/abs/2009.00520v1,Unsupervised Domain Adaptation with Progressive Adaptation of Subspaces,"Unsupervised Domain Adaptation (UDA) aims to classify unlabeled target domain
by transferring knowledge from labeled source domain with domain shift. Most of
the existing UDA methods try to mitigate the adverse impact induced by the
shift via reducing domain discrepancy. However, such approaches easily suffer a
notorious mode collapse issue due to the lack of labels in target domain.
Naturally, one of the effective ways to mitigate this issue is to reliably
estimate the pseudo labels for target domain, which itself is hard. To overcome
this, we propose a novel UDA method named Progressive Adaptation of Subspaces
approach (PAS) in which we utilize such an intuition that appears much
reasonable to gradually obtain reliable pseudo labels. Speci fically, we
progressively and steadily refine the shared subspaces as bridge of knowledge
transfer by adaptively anchoring/selecting and leveraging those target samples
with reliable pseudo labels. Subsequently, the refined subspaces can in turn
provide more reliable pseudo-labels of the target domain, making the mode
collapse highly mitigated. Our thorough evaluation demonstrates that PAS is not
only effective for common UDA, but also outperforms the state-of-the arts for
more challenging Partial Domain Adaptation (PDA) situation, where the source
label set subsumes the target one.","['Weikai Li', 'Songcan Chen']","['cs.LG', 'cs.CV', 'stat.ML', '68T10', 'I.2.6']",2020-09-01 15:40:50+00:00
http://arxiv.org/abs/2009.00505v1,Graph Embedding with Data Uncertainty,"spectral-based subspace learning is a common data preprocessing step in many
machine learning pipelines. The main aim is to learn a meaningful low
dimensional embedding of the data. However, most subspace learning methods do
not take into consideration possible measurement inaccuracies or artifacts that
can lead to data with high uncertainty. Thus, learning directly from raw data
can be misleading and can negatively impact the accuracy. In this paper, we
propose to model artifacts in training data using probability distributions;
each data point is represented by a Gaussian distribution centered at the
original data point and having a variance modeling its uncertainty. We
reformulate the Graph Embedding framework to make it suitable for learning from
distributions and we study as special cases the Linear Discriminant Analysis
and the Marginal Fisher Analysis techniques. Furthermore, we propose two
schemes for modeling data uncertainty based on pair-wise distances in an
unsupervised and a supervised contexts.","['Firas Laakom', 'Jenni Raitoharju', 'Nikolaos Passalis', 'Alexandros Iosifidis', 'Moncef Gabbouj']","['cs.LG', 'cs.AI', 'math.SP', 'stat.ML']",2020-09-01 15:08:23+00:00
http://arxiv.org/abs/2009.01046v1,Generalisation of Cyberbullying Detection,"Cyberbullying is a problem in today's ubiquitous online communities.
Filtering it out of online conversations has proven a challenge, and efforts
have led to the creation of many different datasets, all offered as resources
to train classifiers. Through these datasets, we will explore the variety of
definitions of cyberbullying behaviors and the impact of these differences on
the portability of one classifier to another community. By analyzing the
similarities between datasets, we also gain insight on the generalization power
of the classifiers trained from them. A study of ensemble models combining
these classifiers will help us understand how they interact with each other.","['Khoury Richard', 'Larochelle Marc-André']","['cs.CL', 'cs.LG', 'stat.ML']",2020-09-01 14:57:17+00:00
http://arxiv.org/abs/2009.00497v1,From Clicks to Conversions: Recommendation for long-term reward,"Recommender systems are often optimised for short-term reward: a
recommendation is considered successful if a reward (e.g. a click) can be
observed immediately after the recommendation. The advantage of this framework
is that with some reasonable (although questionable) assumptions, it allows
familiar supervised learning tools to be used for the recommendation task.
However, it means that long-term business metrics, e.g. sales or retention are
ignored. In this paper we introduce a framework for modeling long-term rewards
in the RecoGym simulation environment. We use this newly introduced
functionality to showcase problems introduced by the last-click attribution
scheme in the case of conversion-optimized recommendations and propose a simple
extension that leads to state-of-the-art results.","['Philomène Chagniot', 'Flavian Vasile', 'David Rohde']","['cs.IR', 'stat.ML']",2020-09-01 14:53:57+00:00
http://arxiv.org/abs/2009.00401v3,Time-Varying Parameters as Ridge Regressions,"Time-varying parameters (TVPs) models are frequently used in economics to
capture structural change. I highlight a rather underutilized fact -- that
these are actually ridge regressions. Instantly, this makes computations,
tuning, and implementation much easier than in the state-space paradigm. Among
other things, solving the equivalent dual ridge problem is computationally very
fast even in high dimensions, and the crucial ""amount of time variation"" is
tuned by cross-validation. Evolving volatility is dealt with using a two-step
ridge regression. I consider extensions that incorporate sparsity (the
algorithm selects which parameters vary and which do not) and reduced-rank
restrictions (variation is tied to a factor model). To demonstrate the
usefulness of the approach, I use it to study the evolution of monetary policy
in Canada using large time-varying local projections. The application requires
the estimation of about 4600 TVPs, a task well within the reach of the new
method.",['Philippe Goulet Coulombe'],"['econ.EM', 'stat.AP', 'stat.ML']",2020-09-01 13:07:04+00:00
http://arxiv.org/abs/2009.00387v2,Boosting Share Routing for Multi-task Learning,"Multi-task learning (MTL) aims to make full use of the knowledge contained in
multi-task supervision signals to improve the overall performance. How to make
the knowledge of multiple tasks shared appropriately is an open problem for
MTL. Most existing deep MTL models are based on parameter sharing. However,
suitable sharing mechanism is hard to design as the relationship among tasks is
complicated. In this paper, we propose a general framework called Multi-Task
Neural Architecture Search (MTNAS) to efficiently find a suitable sharing route
for a given MTL problem. MTNAS modularizes the sharing part into multiple
layers of sub-networks. It allows sparse connection among these sub-networks
and soft sharing based on gating is enabled for a certain route. Benefiting
from such setting, each candidate architecture in our search space defines a
dynamic sparse sharing route which is more flexible compared with full-sharing
in previous approaches. We show that existing typical sharing approaches are
sub-graphs in our search space. Extensive experiments on three real-world
recommendation datasets demonstrate MTANS achieves consistent improvement
compared with single-task models and typical multi-task methods while
maintaining high computation efficiency. Furthermore, in-depth experiments
demonstrates that MTNAS can learn suitable sparse route to mitigate negative
transfer.","['Xiaokai Chen', 'Xiaoguang Gu', 'Libo Fu']","['cs.LG', 'stat.ML']",2020-09-01 12:37:19+00:00
http://arxiv.org/abs/2009.00365v1,"Rank-one partitioning: formalization, illustrative examples, and a new cluster enhancing strategy","In this paper, we introduce and formalize a rank-one partitioning learning
paradigm that unifies partitioning methods that proceed by summarizing a data
set using a single vector that is further used to derive the final clustering
partition. Using this unification as a starting point, we propose a novel
algorithmic solution for the partitioning problem based on rank-one matrix
factorization and denoising of piecewise constant signals. Finally, we propose
an empirical demonstration of our findings and demonstrate the robustness of
the proposed denoising step. We believe that our work provides a new point of
view for several unsupervised learning techniques that helps to gain a deeper
understanding about the general mechanisms of data partitioning.","['Charlotte Laclau', 'Franck Iutzeler', 'Ievgen Redko']","['cs.LG', 'stat.ML']",2020-09-01 11:37:28+00:00
http://arxiv.org/abs/2009.00351v1,Advancing from Predictive Maintenance to Intelligent Maintenance with AI and IIoT,"As Artificial Intelligent (AI) technology advances and increasingly large
amounts of data become readily available via various Industrial Internet of
Things (IIoT) projects, we evaluate the state of the art of predictive
maintenance approaches and propose our innovative framework to improve the
current practice. The paper first reviews the evolution of reliability
modelling technology in the past 90 years and discusses major technologies
developed in industry and academia. We then introduce the next generation
maintenance framework - Intelligent Maintenance, and discuss its key
components. This AI and IIoT based Intelligent Maintenance framework is
composed of (1) latest machine learning algorithms including probabilistic
reliability modelling with deep learning, (2) real-time data collection,
transfer, and storage through wireless smart sensors, (3) Big Data
technologies, (4) continuously integration and deployment of machine learning
models, (5) mobile device and AR/VR applications for fast and better
decision-making in the field. Particularly, we proposed a novel probabilistic
deep learning reliability modelling approach and demonstrate it in the Turbofan
Engine Degradation Dataset.","['Haining Zheng', 'Antonio R. Paiva', 'Chris S. Gurciullo']","['cs.LG', 'cs.AI', 'stat.ML']",2020-09-01 11:10:13+00:00
http://arxiv.org/abs/2009.00329v3,Learning explanations that are hard to vary,"In this paper, we investigate the principle that `good explanations are hard
to vary' in the context of deep learning. We show that averaging gradients
across examples -- akin to a logical OR of patterns -- can favor memorization
and `patchwork' solutions that sew together different strategies, instead of
identifying invariances. To inspect this, we first formalize a notion of
consistency for minima of the loss surface, which measures to what extent a
minimum appears only when examples are pooled. We then propose and
experimentally validate a simple alternative algorithm based on a logical AND,
that focuses on invariances and prevents memorization in a set of real-world
tasks. Finally, using a synthetic dataset with a clear distinction between
invariant and spurious mechanisms, we dissect learning signals and compare this
approach to well-established regularizers.","['Giambattista Parascandolo', 'Alexander Neitz', 'Antonio Orvieto', 'Luigi Gresele', 'Bernhard Schölkopf']","['cs.LG', 'stat.ML']",2020-09-01 10:17:48+00:00
http://arxiv.org/abs/2009.00298v3,Universal Approximation Property of Quantum Machine Learning Models in Quantum-Enhanced Feature Spaces,"Encoding classical data into quantum states is considered a quantum feature
map to map classical data into a quantum Hilbert space. This feature map
provides opportunities to incorporate quantum advantages into machine learning
algorithms to be performed on near-term intermediate-scale quantum computers.
The crucial idea is using the quantum Hilbert space as a quantum-enhanced
feature space in machine learning models. While the quantum feature map has
demonstrated its capability when combined with linear classification models in
some specific applications, its expressive power from the theoretical
perspective remains unknown. We prove that the machine learning models induced
from the quantum-enhanced feature space are universal approximators of
continuous functions under typical quantum feature maps. We also study the
capability of quantum feature maps in the classification of disjoint regions.
Our work enables an important theoretical analysis to ensure that machine
learning algorithms based on quantum feature maps can handle a broad class of
machine learning tasks. In light of this, one can design a quantum machine
learning model with more powerful expressivity.","['Takahiro Goto', 'Quoc Hoan Tran', 'Kohei Nakajima']","['quant-ph', 'cs.LG', 'stat.ML']",2020-09-01 09:09:29+00:00
http://arxiv.org/abs/2009.00296v1,Developing Constrained Neural Units Over Time,"In this paper we present a foundational study on a constrained method that
defines learning problems with Neural Networks in the context of the principle
of least cognitive action, which very much resembles the principle of least
action in mechanics. Starting from a general approach to enforce constraints
into the dynamical laws of learning, this work focuses on an alternative way of
defining Neural Networks, that is different from the majority of existing
approaches. In particular, the structure of the neural architecture is defined
by means of a special class of constraints that are extended also to the
interaction with data, leading to ""architectural"" and ""input-related""
constraints, respectively. The proposed theory is cast into the time domain, in
which data are presented to the network in an ordered manner, that makes this
study an important step toward alternative ways of processing continuous
streams of data with Neural Networks. The connection with the classic
Backpropagation-based update rule of the weights of networks is discussed,
showing that there are conditions under which our approach degenerates to
Backpropagation. Moreover, the theory is experimentally evaluated on a simple
problem that allows us to deeply study several aspects of the theory itself and
to show the soundness of the model.","['Alessandro Betti', 'Marco Gori', 'Simone Marullo', 'Stefano Melacci']","['cs.LG', 'stat.ML']",2020-09-01 09:07:25+00:00
http://arxiv.org/abs/2009.00278v3,Scaling Up Deep Neural Network Optimization for Edge Inference,"Deep neural networks (DNNs) have been increasingly deployed on and integrated
with edge devices, such as mobile phones, drones, robots and wearables. To run
DNN inference directly on edge devices (a.k.a. edge inference) with a
satisfactory performance, optimizing the DNN design (e.g., network architecture
and quantization policy) is crucial. While state-of-the-art DNN designs have
leveraged performance predictors to speed up the optimization process, they are
device-specific (i.e., each predictor for only one target device) and hence
cannot scale well in the presence of extremely diverse edge devices. Moreover,
even with performance predictors, the optimizer (e.g., search-based
optimization) can still be time-consuming when optimizing DNNs for many
different devices. In this work, we propose two approaches to scaling up DNN
optimization. In the first approach, we reuse the performance predictors built
on a proxy device, and leverage the performance monotonicity to scale up the
DNN optimization without re-building performance predictors for each different
device. In the second approach, we build scalable performance predictors that
can estimate the resulting performance (e.g., inference
accuracy/latency/energy) given a DNN-device pair, and use a neural
network-based automated optimizer that takes both device features and
optimization parameters as input and then directly outputs the optimal DNN
design without going through a lengthy optimization process for each individual
device.","['Bingqian Lu', 'Jianyi Yang', 'Shaolei Ren']","['cs.LG', 'stat.ML']",2020-09-01 07:47:22+00:00
http://arxiv.org/abs/2009.00254v1,Boosting House Price Predictions using Geo-Spatial Network Embedding,"Real estate contributes significantly to all major economies around the
world. In particular, house prices have a direct impact on stakeholders,
ranging from house buyers to financing companies. Thus, a plethora of
techniques have been developed for real estate price prediction. Most of the
existing techniques rely on different house features to build a variety of
prediction models to predict house prices. Perceiving the effect of spatial
dependence on house prices, some later works focused on introducing spatial
regression models for improving prediction performance. However, they fail to
take into account the geo-spatial context of the neighborhood amenities such as
how close a house is to a train station, or a highly-ranked school, or a
shopping center. Such contextual information may play a vital role in users'
interests in a house and thereby has a direct influence on its price. In this
paper, we propose to leverage the concept of graph neural networks to capture
the geo-spatial context of the neighborhood of a house. In particular, we
present a novel method, the Geo-Spatial Network Embedding (GSNE), that learns
the embeddings of houses and various types of Points of Interest (POIs) in the
form of multipartite networks, where the houses and the POIs are represented as
attributed nodes and the relationships between them as edges. Extensive
experiments with a large number of regression techniques show that the
embeddings produced by our proposed GSNE technique consistently and
significantly improve the performance of the house price prediction task
regardless of the downstream regression model.","['Sarkar Snigdha Sarathi Das', 'Mohammed Eunus Ali', 'Yuan-Fang Li', 'Yong-Bin Kang', 'Timos Sellis']","['cs.LG', 'stat.ML']",2020-09-01 06:17:21+00:00
http://arxiv.org/abs/2010.00661v1,"Machine Learning in Generation, Detection, and Mitigation of Cyberattacks in Smart Grid: A Survey","Smart grid (SG) is a complex cyber-physical system that utilizes modern cyber
and physical equipment to run at an optimal operating point. Cyberattacks are
the principal threats confronting the usage and advancement of the
state-of-the-art systems. The advancement of SG has added a wide range of
technologies, equipment, and tools to make the system more reliable, efficient,
and cost-effective. Despite attaining these goals, the threat space for the
adversarial attacks has also been expanded because of the extensive
implementation of the cyber networks. Due to the promising computational and
reasoning capability, machine learning (ML) is being used to exploit and defend
the cyberattacks in SG by the attackers and system operators, respectively. In
this paper, we perform a comprehensive summary of cyberattacks generation,
detection, and mitigation schemes by reviewing state-of-the-art research in the
SG domain. Additionally, we have summarized the current research in a
structured way using tabular format. We also present the shortcomings of the
existing works and possible future research direction based on our
investigation.","['Nur Imtiazul Haque', 'Md Hasan Shahriar', 'Md Golam Dastgir', 'Anjan Debnath', 'Imtiaz Parvez', 'Arif Sarwat', 'Mohammad Ashiqur Rahman']","['cs.CR', 'cs.LG', 'cs.SY', 'eess.SP', 'eess.SY', 'stat.ML']",2020-09-01 05:16:51+00:00
http://arxiv.org/abs/2009.00237v1,An in-depth comparison of methods handling mixed-attribute data for general fuzzy min-max neural network,"A general fuzzy min-max (GFMM) neural network is one of the efficient
neuro-fuzzy systems for classification problems. However, a disadvantage of
most of the current learning algorithms for GFMM is that they can handle
effectively numerical valued features only. Therefore, this paper provides some
potential approaches to adapting GFMM learning algorithms for classification
problems with mixed-type or only categorical features as they are very common
in practical applications and often carry very useful information. We will
compare and assess three main methods of handling datasets with mixed features,
including the use of encoding methods, the combination of the GFMM model with
other classifiers, and employing the specific learning algorithms for both
types of features. The experimental results showed that the target and
James-Stein are appropriate categorical encoding methods for learning
algorithms of GFMM models, while the combination of GFMM neural networks and
decision trees is a flexible way to enhance the classification performance of
GFMM models on datasets with the mixed features. The learning algorithms with
the mixed-type feature abilities are potential approaches to deal with
mixed-attribute data in a natural way, but they need further improvement to
achieve a better classification accuracy. Based on the analysis, we also
identify the strong and weak points of different methods and propose potential
research directions.","['Thanh Tung Khuat', 'Bogdan Gabrys']","['cs.LG', 'stat.ML', '68T30, 68T20, 68T37, 68W27', 'I.2.1; I.2.6; I.2.m; I.5.0; I.5.1; I.5.2; I.5.3; I.5.4']",2020-09-01 05:12:22+00:00
http://arxiv.org/abs/2009.01721v2,Max-value Entropy Search for Multi-Objective Bayesian Optimization with Constraints,"We consider the problem of constrained multi-objective blackbox optimization
using expensive function evaluations, where the goal is to approximate the true
Pareto set of solutions satisfying a set of constraints while minimizing the
number of function evaluations. For example, in aviation power system design
applications, we need to find the designs that trade-off total energy and the
mass while satisfying specific thresholds for motor temperature and voltage of
cells. This optimization requires performing expensive computational
simulations to evaluate designs. In this paper, we propose a new approach
referred as {\em Max-value Entropy Search for Multi-objective Optimization with
Constraints (MESMOC)} to solve this problem. MESMOC employs an output-space
entropy based acquisition function to efficiently select the sequence of inputs
for evaluation to uncover high-quality pareto-set solutions while satisfying
constraints.
  We apply MESMOC to two real-world engineering design applications to
demonstrate its effectiveness over state-of-the-art algorithms.","['Syrine Belakaria', 'Aryan Deshwal', 'Janardhan Rao Doppa']","['cs.LG', 'cs.AI', 'stat.ML']",2020-09-01 05:00:01+00:00
http://arxiv.org/abs/2009.05147v1,Practical Cross-modal Manifold Alignment for Grounded Language,"We propose a cross-modality manifold alignment procedure that leverages
triplet loss to jointly learn consistent, multi-modal embeddings of
language-based concepts of real-world items. Our approach learns these
embeddings by sampling triples of anchor, positive, and negative data points
from RGB-depth images and their natural language descriptions. We show that our
approach can benefit from, but does not require, post-processing steps such as
Procrustes analysis, in contrast to some of our baselines which require it for
reasonable performance. We demonstrate the effectiveness of our approach on two
datasets commonly used to develop robotic-based grounded language learning
systems, where our approach outperforms four baselines, including a
state-of-the-art approach, across five evaluation metrics.","['Andre T. Nguyen', 'Luke E. Richards', 'Gaoussou Youssouf Kebe', 'Edward Raff', 'Kasra Darvish', 'Frank Ferraro', 'Cynthia Matuszek']","['cs.CV', 'cs.LG', 'cs.RO', 'stat.ML']",2020-09-01 04:16:48+00:00
http://arxiv.org/abs/2009.08868v1,Review of Machine-Learning Methods for RNA Secondary Structure Prediction,"Secondary structure plays an important role in determining the function of
non-coding RNAs. Hence, identifying RNA secondary structures is of great value
to research. Computational prediction is a mainstream approach for predicting
RNA secondary structure. Unfortunately, even though new methods have been
proposed over the past 40 years, the performance of computational prediction
methods has stagnated in the last decade. Recently, with the increasing
availability of RNA structure data, new methods based on machine-learning
technologies, especially deep learning, have alleviated the issue. In this
review, we provide a comprehensive overview of RNA secondary structure
prediction methods based on machine-learning technologies and a tabularized
summary of the most important methods in this field. The current pending issues
in the field of RNA secondary structure prediction and future trends are also
discussed.","['Qi Zhao', 'Zheng Zhao', 'Xiaoya Fan', 'Zhengwei Yuan', 'Qian Mao', 'Yudong Yao']","['q-bio.BM', 'cs.LG', 'stat.ML', 'I.2.0 General']",2020-09-01 03:17:15+00:00
http://arxiv.org/abs/2009.01047v2,Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake Claim Classification,"The rampant integration of social media in our every day lives and culture
has given rise to fast and easier access to the flow of information than ever
in human history. However, the inherently unsupervised nature of social media
platforms has also made it easier to spread false information and fake news.
Furthermore, the high volume and velocity of information flow in such platforms
make manual supervision and control of information propagation infeasible. This
paper aims to address this issue by proposing a novel deep learning approach
for automated detection of false short-text claims on social media. We first
introduce Sentimental LIAR, which extends the LIAR dataset of short claims by
adding features based on sentiment and emotion analysis of claims. Furthermore,
we propose a novel deep learning architecture based on the BERT-Base language
model for classification of claims as genuine or fake. Our results demonstrate
that the proposed architecture trained on Sentimental LIAR can achieve an
accuracy of 70%, which is an improvement of ~30% over previously reported
results for the LIAR benchmark.","['Bibek Upadhayay', 'Vahid Behzadan']","['cs.CL', 'cs.LG', 'cs.SI', 'stat.ML']",2020-09-01 02:48:11+00:00
http://arxiv.org/abs/2009.00169v1,A Mathematical Introduction to Generative Adversarial Nets (GAN),"Generative Adversarial Nets (GAN) have received considerable attention since
the 2014 groundbreaking work by Goodfellow et al. Such attention has led to an
explosion in new ideas, techniques and applications of GANs. To better
understand GANs we need to understand the mathematical foundation behind them.
This paper attempts to provide an overview of GANs from a mathematical point of
view. Many students in mathematics may find the papers on GANs more difficulty
to fully understand because most of them are written from computer science and
engineer point of view. The aim of this paper is to give more mathematically
oriented students an introduction to GANs in a language that is more familiar
to them.",['Yang Wang'],"['cs.LG', 'cs.IT', 'math.IT', 'stat.ML', '60']",2020-09-01 01:31:47+00:00
http://arxiv.org/abs/2009.01048v2,MALCOM: Generating Malicious Comments to Attack Neural Fake News Detection Models,"In recent years, the proliferation of so-called ""fake news"" has caused much
disruptions in society and weakened the news ecosystem. Therefore, to mitigate
such problems, researchers have developed state-of-the-art models to
auto-detect fake news on social media using sophisticated data science and
machine learning techniques. In this work, then, we ask ""what if adversaries
attempt to attack such detection models?"" and investigate related issues by (i)
proposing a novel threat model against fake news detectors, in which
adversaries can post malicious comments toward news articles to mislead fake
news detectors, and (ii) developing MALCOM, an end-to-end adversarial comment
generation framework to achieve such an attack. Through a comprehensive
evaluation, we demonstrate that about 94% and 93.5% of the time on average
MALCOM can successfully mislead five of the latest neural detection models to
always output targeted real and fake news labels. Furthermore, MALCOM can also
fool black box fake news detectors to always output real news labels 90% of the
time on average. We also compare our attack model with four baselines across
two real-world datasets, not only on attack performance but also on generated
quality, coherency, transferability, and robustness.","['Thai Le', 'Suhang Wang', 'Dongwon Lee']","['cs.CL', 'cs.LG', 'stat.ML']",2020-09-01 01:26:01+00:00
http://arxiv.org/abs/2009.00162v2,Learning Nash Equilibria in Zero-Sum Stochastic Games via Entropy-Regularized Policy Approximation,"We explore the use of policy approximations to reduce the computational cost
of learning Nash equilibria in zero-sum stochastic games. We propose a new
Q-learning type algorithm that uses a sequence of entropy-regularized soft
policies to approximate the Nash policy during the Q-function updates. We prove
that under certain conditions, by updating the regularized Q-function, the
algorithm converges to a Nash equilibrium. We also demonstrate the proposed
algorithm's ability to transfer previous training experiences, enabling the
agents to adapt quickly to new environments. We provide a dynamic
hyper-parameter scheduling scheme to further expedite convergence. Empirical
results applied to a number of stochastic games verify that the proposed
algorithm converges to the Nash equilibrium, while exhibiting a major speed-up
over existing algorithms.","['Yue Guan', 'Qifan Zhang', 'Panagiotis Tsiotras']","['cs.LG', 'cs.GT', 'cs.SY', 'eess.SY', 'stat.ML']",2020-09-01 01:03:44+00:00
http://arxiv.org/abs/2009.00142v4,Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning,"Learning representations of sets of nodes in a graph is crucial for
applications ranging from node-role discovery to link prediction and molecule
classification. Graph Neural Networks (GNNs) have achieved great success in
graph representation learning. However, expressive power of GNNs is limited by
the 1-Weisfeiler-Lehman (WL) test and thus GNNs generate identical
representations for graph substructures that may in fact be very different.
More powerful GNNs, proposed recently by mimicking higher-order-WL tests, only
focus on representing entire graphs and they are computationally inefficient as
they cannot utilize sparsity of the underlying graph. Here we propose and
mathematically analyze a general class of structure-related features, termed
Distance Encoding (DE). DE assists GNNs in representing any set of nodes, while
providing strictly more expressive power than the 1-WL test. DE captures the
distance between the node set whose representation is to be learned and each
node in the graph. To capture the distance DE can apply various graph-distance
measures such as shortest path distance or generalized PageRank scores. We
propose two ways for GNNs to use DEs (1) as extra node features, and (2) as
controllers of message aggregation in GNNs. Both approaches can utilize the
sparse structure of the underlying graph, which leads to computational
efficiency and scalability. We also prove that DE can distinguish node sets
embedded in almost all regular graphs where traditional GNNs always fail. We
evaluate DE on three tasks over six real networks: structural role prediction,
link prediction, and triangle prediction. Results show that our models
outperform GNNs without DE by up-to 15\% in accuracy and AUROC. Furthermore,
our models also significantly outperform other state-of-the-art methods
especially designed for the above tasks.","['Pan Li', 'Yanbang Wang', 'Hongwei Wang', 'Jure Leskovec']","['cs.LG', 'stat.ML']",2020-08-31 23:15:40+00:00
http://arxiv.org/abs/2009.00133v1,Unsupervised and Supervised Structure Learning for Protein Contact Prediction,"Protein contacts provide key information for the understanding of protein
structure and function, and therefore contact prediction from sequences is an
important problem. Recent research shows that some correctly predicted
long-range contacts could help topology-level structure modeling. Thus, contact
prediction and contact-assisted protein folding also proves the importance of
this problem. In this thesis, I will briefly introduce the extant related work,
then show how to establish the contact prediction through unsupervised
graphical models with topology constraints. Further, I will explain how to use
the supervised deep learning methods to further boost the accuracy of contact
prediction. Finally, I will propose a scoring system called diversity score to
measure the novelty of contact predictions, as well as an algorithm that
predicts contacts with respect to the new scoring system.",['Siqi Sun'],"['q-bio.QM', 'cs.LG', 'stat.ML']",2020-08-31 22:37:16+00:00
http://arxiv.org/abs/2009.00131v1,InClass Nets: Independent Classifier Networks for Nonparametric Estimation of Conditional Independence Mixture Models and Unsupervised Classification,"We introduce a new machine-learning-based approach, which we call the
Independent Classifier networks (InClass nets) technique, for the
nonparameteric estimation of conditional independence mixture models (CIMMs).
We approach the estimation of a CIMM as a multi-class classification problem,
since dividing the dataset into different categories naturally leads to the
estimation of the mixture model. InClass nets consist of multiple independent
classifier neural networks (NNs), each of which handles one of the variates of
the CIMM. Fitting the CIMM to the data is performed by simultaneously training
the individual NNs using suitable cost functions. The ability of NNs to
approximate arbitrary functions makes our technique nonparametric. Further
leveraging the power of NNs, we allow the conditionally independent variates of
the model to be individually high-dimensional, which is the main advantage of
our technique over existing non-machine-learning-based approaches. We derive
some new results on the nonparametric identifiability of bivariate CIMMs, in
the form of a necessary and a (different) sufficient condition for a bivariate
CIMM to be identifiable. We provide a public implementation of InClass nets as
a Python package called RainDancesVI and validate our InClass nets technique
with several worked out examples. Our method also has applications in
unsupervised and semi-supervised classification problems.","['Konstantin T. Matchev', 'Prasanth Shyamsundar']","['stat.ML', 'cs.LG', 'econ.EM', 'hep-ph', 'physics.data-an', 'stat.ME']",2020-08-31 22:24:09+00:00
http://arxiv.org/abs/2009.00093v4,Online Class-Incremental Continual Learning with Adversarial Shapley Value,"As image-based deep learning becomes pervasive on every device, from cell
phones to smart watches, there is a growing need to develop methods that
continually learn from data while minimizing memory footprint and power
consumption. While memory replay techniques have shown exceptional promise for
this task of continual learning, the best method for selecting which buffered
images to replay is still an open question. In this paper, we specifically
focus on the online class-incremental setting where a model needs to learn new
classes continually from an online data stream. To this end, we contribute a
novel Adversarial Shapley value scoring method that scores memory data samples
according to their ability to preserve latent decision boundaries for
previously observed classes (to maintain learning stability and avoid
forgetting) while interfering with latent decision boundaries of current
classes being learned (to encourage plasticity and optimal learning of new
class boundaries). Overall, we observe that our proposed ASER method provides
competitive or improved performance compared to state-of-the-art replay-based
continual learning methods on a variety of datasets.","['Dongsub Shim', 'Zheda Mai', 'Jihwan Jeong', 'Scott Sanner', 'Hyunwoo Kim', 'Jongseong Jang']","['cs.LG', 'cs.CV', 'stat.ML']",2020-08-31 20:52:27+00:00
http://arxiv.org/abs/2009.00089v1,"Random Forest (RF) Kernel for Regression, Classification and Survival","Breiman's random forest (RF) can be interpreted as an implicit kernel
generator,where the ensuing proximity matrix represents the data-driven RF
kernel. Kernel perspective on the RF has been used to develop a principled
framework for theoretical investigation of its statistical properties. However,
practical utility of the links between kernels and the RF has not been widely
explored and systematically evaluated.Focus of our work is investigation of the
interplay between kernel methods and the RF. We elucidate the performance and
properties of the data driven RF kernels used by regularized linear models in a
comprehensive simulation study comprising of continuous, binary and survival
targets. We show that for continuous and survival targets, the RF kernels are
competitive to RF in higher dimensional scenarios with larger number of noisy
features. For the binary target, the RF kernel and RF exhibit comparable
performance. As the RF kernel asymptotically converges to the Laplace kernel,
we included it in our evaluation. For most simulation setups, the RF and
RFkernel outperformed the Laplace kernel. Nevertheless, in some cases the
Laplace kernel was competitive, showing its potential value for applications.
We also provide the results from real life data sets for the regression,
classification and survival to illustrate how these insights may be leveraged
in practice.Finally, we discuss further extensions of the RF kernels in the
context of interpretable prototype and landmarking classification, regression
and survival. We outline future line of research for kernels furnished by
Bayesian counterparts of the RF.","['Dai Feng', 'Richard Baumgartner']","['stat.ML', 'cs.LG']",2020-08-31 20:21:27+00:00
http://arxiv.org/abs/2009.00038v3,Uncertainty quantification for Markov Random Fields,"We present an information-based uncertainty quantification method for general
Markov Random Fields. Markov Random Fields (MRF) are structured, probabilistic
graphical models over undirected graphs, and provide a fundamental unifying
modeling tool for statistical mechanics, probabilistic machine learning, and
artificial intelligence. Typically MRFs are complex and high-dimensional with
nodes and edges (connections) built in a modular fashion from simpler,
low-dimensional probabilistic models and their local connections; in turn, this
modularity allows to incorporate available data to MRFs and efficiently
simulate them by leveraging their graph-theoretic structure. Learning graphical
models from data and/or constructing them from physical modeling and
constraints necessarily involves uncertainties inherited from data, modeling
choices, or numerical approximations. These uncertainties in the MRF can be
manifested either in the graph structure or the probability distribution
functions, and necessarily will propagate in predictions for quantities of
interest. Here we quantify such uncertainties using tight, information based
bounds on the predictions of quantities of interest; these bounds take
advantage of the graphical structure of MRFs and are capable of handling the
inherent high-dimensionality of such graphical models. We demonstrate our
methods in MRFs for medical diagnostics and statistical mechanics models. In
the latter, we develop uncertainty quantification bounds for finite size
effects and phase diagrams, which constitute two of the typical predictions
goals of statistical mechanics modeling.","['Panagiota Birmpa', 'Markos A. Katsoulakis']","['stat.ML', 'cs.IT', 'cs.LG', 'math.IT', 'math.PR', '62H22, 82B20, 94A17']",2020-08-31 18:07:24+00:00
http://arxiv.org/abs/2008.13781v1,"A Multisite, Report-Based, Centralized Infrastructure for Feedback and Monitoring of Radiology AI/ML Development and Clinical Deployment","An infrastructure for multisite, geographically-distributed creation and
collection of diverse, high-quality, curated and labeled radiology image data
is crucial for the successful automated development, deployment, monitoring and
continuous improvement of Artificial Intelligence (AI)/Machine Learning (ML)
solutions in the real world. An interactive radiology reporting approach that
integrates image viewing, dictation, natural language processing (NLP) and
creation of hyperlinks between image findings and the report, provides
localized labels during routine interpretation. These images and labels can be
captured and centralized in a cloud-based system. This method provides a
practical and efficient mechanism with which to monitor algorithm performance.
It also supplies feedback for iterative development and quality improvement of
new and existing algorithmic models. Both feedback and monitoring are achieved
without burdening the radiologist. The method addresses proposed regulatory
requirements for post-marketing surveillance and external data. Comprehensive
multi-site data collection assists in reducing bias. Resource requirements are
greatly reduced compared to dedicated retrospective expert labeling.","['Menashe Benjamin', 'Guy Engelhard', 'Alex Aisen', 'Yinon Aradi', 'Elad Benjamin']","['cs.LG', 'cs.CV', 'cs.CY', 'stat.ML']",2020-08-31 17:59:04+00:00
http://arxiv.org/abs/2008.13777v2,Low-rank matrix recovery with non-quadratic loss: projected gradient method and regularity projection oracle,"Existing results for low-rank matrix recovery largely focus on quadratic
loss, which enjoys favorable properties such as restricted strong
convexity/smoothness (RSC/RSM) and well conditioning over all low rank
matrices. However, many interesting problems involve more general,
non-quadratic losses, which do not satisfy such properties. For these problems,
standard nonconvex approaches such as rank-constrained projected gradient
descent (a.k.a. iterative hard thresholding) and Burer-Monteiro factorization
could have poor empirical performance, and there is no satisfactory theory
guaranteeing global and fast convergence for these algorithms.
  In this paper, we show that a critical component in provable low-rank
recovery with non-quadratic loss is a regularity projection oracle. This oracle
restricts iterates to low-rank matrices within an appropriate bounded set, over
which the loss function is well behaved and satisfies a set of approximate
RSC/RSM conditions. Accordingly, we analyze an (averaged) projected gradient
method equipped with such an oracle, and prove that it converges globally and
linearly. Our results apply to a wide range of non-quadratic low-rank
estimation problems including one bit matrix sensing/completion, individualized
rank aggregation, and more broadly generalized linear models with rank
constraints.","['Lijun Ding', 'Yuqian Zhang', 'Yudong Chen']","['stat.ML', 'cs.LG', 'math.OC', 'math.ST', 'stat.TH']",2020-08-31 17:56:04+00:00
http://arxiv.org/abs/2008.13773v3,Beyond variance reduction: Understanding the true impact of baselines on policy optimization,"Bandit and reinforcement learning (RL) problems can often be framed as
optimization problems where the goal is to maximize average performance while
having access only to stochastic estimates of the true gradient. Traditionally,
stochastic optimization theory predicts that learning dynamics are governed by
the curvature of the loss function and the noise of the gradient estimates. In
this paper we demonstrate that this is not the case for bandit and RL problems.
To allow our analysis to be interpreted in light of multi-step MDPs, we focus
on techniques derived from stochastic optimization principles (e.g., natural
policy gradient and EXP3) and we show that some standard assumptions from
optimization theory are violated in these problems. We present theoretical
results showing that, at least for bandit problems, curvature and noise are not
sufficient to explain the learning dynamics and that seemingly innocuous
choices like the baseline can determine whether an algorithm converges. These
theoretical findings match our empirical evaluation, which we extend to
multi-state MDPs.","['Wesley Chung', 'Valentin Thomas', 'Marlos C. Machado', 'Nicolas Le Roux']","['cs.LG', 'stat.ML']",2020-08-31 17:52:09+00:00
http://arxiv.org/abs/2008.13763v5,Anomaly Detection by Recombining Gated Unsupervised Experts,"Anomaly detection has been considered under several extents of prior
knowledge. Unsupervised methods do not require any labelled data, whereas
semi-supervised methods leverage some known anomalies. Inspired by
mixture-of-experts models and the analysis of the hidden activations of neural
networks, we introduce a novel data-driven anomaly detection method called
ARGUE. Our method is not only applicable to unsupervised and semi-supervised
environments, but also profits from prior knowledge of self-supervised
settings. We designed ARGUE as a combination of dedicated expert networks,
which specialise on parts of the input data. For its final decision, ARGUE
fuses the distributed knowledge across the expert systems using a gated
mixture-of-experts architecture. Our evaluation motivates that prior knowledge
about the normal data distribution may be as valuable as known anomalies.","['J. -P. Schulze', 'P. Sperl', 'K. Böttinger']","['cs.LG', 'stat.ML']",2020-08-31 17:35:57+00:00
http://arxiv.org/abs/2008.13735v1,Estimating Rank-One Spikes from Heavy-Tailed Noise via Self-Avoiding Walks,"We study symmetric spiked matrix models with respect to a general class of
noise distributions. Given a rank-1 deformation of a random noise matrix, whose
entries are independently distributed with zero mean and unit variance, the
goal is to estimate the rank-1 part. For the case of Gaussian noise, the top
eigenvector of the given matrix is a widely-studied estimator known to achieve
optimal statistical guarantees, e.g., in the sense of the celebrated BBP phase
transition. However, this estimator can fail completely for heavy-tailed noise.
In this work, we exhibit an estimator that works for heavy-tailed noise up to
the BBP threshold that is optimal even for Gaussian noise. We give a
non-asymptotic analysis of our estimator which relies only on the variance of
each entry remaining constant as the size of the matrix grows: higher moments
may grow arbitrarily fast or even fail to exist. Previously, it was only known
how to achieve these guarantees if higher-order moments of the noises are
bounded by a constant independent of the size of the matrix. Our estimator can
be evaluated in polynomial time by counting self-avoiding walks via a color
-coding technique. Moreover, we extend our estimator to spiked tensor models
and establish analogous results.","['Jingqiu Ding', 'Samuel B. Hopkins', 'David Steurer']","['cs.DS', 'math.ST', 'stat.ML', 'stat.TH']",2020-08-31 16:57:20+00:00
http://arxiv.org/abs/2008.13723v1,Langevin Cooling for Domain Translation,"Domain translation is the task of finding correspondence between two domains.
Several Deep Neural Network (DNN) models, e.g., CycleGAN and cross-lingual
language models, have shown remarkable successes on this task under the
unsupervised setting---the mappings between the domains are learned from two
independent sets of training data in both domains (without paired samples).
However, those methods typically do not perform well on a significant
proportion of test samples. In this paper, we hypothesize that many of such
unsuccessful samples lie at the fringe---relatively low-density areas---of data
distribution, where the DNN was not trained very well, and propose to perform
Langevin dynamics to bring such fringe samples towards high density areas. We
demonstrate qualitatively and quantitatively that our strategy, called Langevin
Cooling (L-Cool), enhances state-of-the-art methods in image translation and
language translation tasks.","['Vignesh Srinivasan', 'Klaus-Robert Müller', 'Wojciech Samek', 'Shinichi Nakajima']","['cs.LG', 'stat.ML']",2020-08-31 16:43:17+00:00
http://arxiv.org/abs/2008.13697v13,A Topological Framework for Deep Learning,"We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.","['Mustafa Hajij', 'Kyle Istvan']","['cs.LG', 'cs.CG', 'math.AT', 'stat.ML']",2020-08-31 15:56:42+00:00
http://arxiv.org/abs/2008.13690v2,Evaluation of machine learning algorithms for Health and Wellness applications: a tutorial,"Research on decision support applications in healthcare, such as those
related to diagnosis, prediction, treatment planning, etc., have seen
enormously increased interest recently. This development is thanks to the
increase in data availability as well as advances in artificial intelligence
and machine learning research. Highly promising research examples are published
daily. However, at the same time, there are some unrealistic expectations with
regards to the requirements for reliable development and objective validation
that is needed in healthcare settings. These expectations may lead to unmet
schedules and disappointments (or non-uptake) at the end-user side. It is the
aim of this tutorial to provide practical guidance on how to assess performance
reliably and efficiently and avoid common traps. Instead of giving a list of
do's and don't s, this tutorial tries to build a better understanding behind
these do's and don't s and presents both the most relevant performance
evaluation criteria as well as how to compute them. Along the way, we will
indicate common mistakes and provide references discussing various topics more
in-depth.","['Jussi Tohka', 'Mark van Gils']","['cs.LG', 'stat.ML']",2020-08-31 15:50:51+00:00
http://arxiv.org/abs/2009.09893v1,Decontextualized learning for interpretable hierarchical representations of visual patterns,"Apart from discriminative models for classification and object detection
tasks, the application of deep convolutional neural networks to basic research
utilizing natural imaging data has been somewhat limited; particularly in cases
where a set of interpretable features for downstream analysis is needed, a key
requirement for many scientific investigations. We present an algorithm and
training paradigm designed specifically to address this: decontextualized
hierarchical representation learning (DHRL). By combining a generative model
chaining procedure with a ladder network architecture and latent space
regularization for inference, DHRL address the limitations of small datasets
and encourages a disentangled set of hierarchically organized features. In
addition to providing a tractable path for analyzing complex hierarchal
patterns using variation inference, this approach is generative and can be
directly combined with empirical and theoretical approaches. To highlight the
extensibility and usefulness of DHRL, we demonstrate this method in application
to a question from evolutionary biology.","['R. Ian Etheredge', 'Manfred Schartl', 'Alex Jordan']","['cs.CV', 'cs.LG', 'q-bio.QM', 'stat.ML']",2020-08-31 14:47:55+00:00
http://arxiv.org/abs/2008.13651v3,Causal Inference in Possibly Nonlinear Factor Models,"This paper develops a general causal inference method for treatment effects
models with noisily measured confounders. The key feature is that a large set
of noisy measurements are linked with the underlying latent confounders through
an unknown, possibly nonlinear factor structure. The main building block is a
local principal subspace approximation procedure that combines $K$-nearest
neighbors matching and principal component analysis. Estimators of many causal
parameters, including average treatment effects and counterfactual
distributions, are constructed based on doubly-robust score functions.
Large-sample properties of these estimators are established, which only require
relatively mild conditions on the principal subspace approximation. The results
are illustrated with an empirical application studying the effect of political
connections on stock returns of financial firms, and a Monte Carlo experiment.
The main technical and methodological results regarding the general local
principal subspace approximation method may be of independent interest.",['Yingjie Feng'],"['econ.EM', 'stat.ME', 'stat.ML']",2020-08-31 14:39:36+00:00
http://arxiv.org/abs/2008.13646v2,Switchable Deep Beamformer,"Recent proposals of deep beamformers using deep neural networks have
attracted significant attention as computational efficient alternatives to
adaptive and compressive beamformers. Moreover, deep beamformers are versatile
in that image post-processing algorithms can be combined with the beamforming.
Unfortunately, in the current technology, a separate beamformer should be
trained and stored for each application, demanding significant scanner
resources. To address this problem, here we propose a {\em switchable} deep
beamformer that can produce various types of output such as DAS, speckle
removal, deconvolution, etc., using a single network with a simple switch. In
particular, the switch is implemented through Adaptive Instance Normalization
(AdaIN) layers, so that various output can be generated by merely changing the
AdaIN code. Experimental results using B-mode focused ultrasound confirm the
flexibility and efficacy of the proposed methods for various applications.","['Shujaat Khan', 'Jaeyoung Huh', 'Jong Chul Ye']","['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2020-08-31 14:31:03+00:00
http://arxiv.org/abs/2008.13625v1,Transfer entropy applied on EEG in depression reveals aberrated dynamics,"We applied transfer entropy analysis on samples of electroencephalogram
recorded from patients diagnosed with major depressive disorder and matched
healthy controls. This is the first graphical representation of aberrated
dynamics in terms of connectivity and the direction of information between
standard centers in MDD.","['Milena Cukic', 'Slavoljub Radenkovic', 'Miodrag Stokic', 'Danka Savic']","['q-bio.NC', 'cs.LG', 'stat.ML']",2020-08-31 14:07:20+00:00
http://arxiv.org/abs/2008.13607v3,Ranking Policy Decisions,"Policies trained via Reinforcement Learning (RL) are often needlessly
complex, making them difficult to analyse and interpret. In a run with $n$ time
steps, a policy will make $n$ decisions on actions to take; we conjecture that
only a small subset of these decisions delivers value over selecting a simple
default action. Given a trained policy, we propose a novel black-box method
based on statistical fault localisation that ranks the states of the
environment according to the importance of decisions made in those states. We
argue that among other things, the ranked list of states can help explain and
understand the policy. As the ranking method is statistical, a direct
evaluation of its quality is hard. As a proxy for quality, we use the ranking
to create new, simpler policies from the original ones by pruning decisions
identified as unimportant (that is, replacing them by default actions) and
measuring the impact on performance. Our experiments on a diverse set of
standard benchmarks demonstrate that pruned policies can perform on a level
comparable to the original policies. Conversely, we show that naive approaches
for ranking policy decisions, e.g., ranking based on the frequency of visiting
a state, do not result in high-performing pruned policies.","['Hadrien Pouget', 'Hana Chockler', 'Youcheng Sun', 'Daniel Kroening']","['cs.LG', 'stat.ML']",2020-08-31 13:54:44+00:00
http://arxiv.org/abs/2008.13600v2,$β$-Cores: Robust Large-Scale Bayesian Data Summarization in the Presence of Outliers,"Modern machine learning applications should be able to address the intrinsic
challenges arising over inference on massive real-world datasets, including
scalability and robustness to outliers. Despite the multiple benefits of
Bayesian methods (such as uncertainty-aware predictions, incorporation of
experts knowledge, and hierarchical modeling), the quality of classic Bayesian
inference depends critically on whether observations conform with the assumed
data generating model, which is impossible to guarantee in practice. In this
work, we propose a variational inference method that, in a principled way, can
simultaneously scale to large datasets, and robustify the inferred posterior
with respect to the existence of outliers in the observed data. Reformulating
Bayes theorem via the $\beta$-divergence, we posit a robustified
pseudo-Bayesian posterior as the target of inference. Moreover, relying on the
recent formulations of Riemannian coresets for scalable Bayesian inference, we
propose a sparse variational approximation of the robustified posterior and an
efficient stochastic black-box algorithm to construct it. Overall our method
allows releasing cleansed data summaries that can be applied broadly in
scenarios including structured data corruption. We illustrate the applicability
of our approach in diverse simulated and real datasets, and various statistical
models, including Gaussian mean inference, logistic and neural linear
regression, demonstrating its superiority to existing Bayesian summarization
methods in the presence of outliers.","['Dionysis Manousakas', 'Cecilia Mascolo']","['cs.LG', 'cs.AI', 'stat.AP', 'stat.ML']",2020-08-31 13:47:12+00:00
http://arxiv.org/abs/2008.13539v1,Multi-View Spectral Clustering with High-Order Optimal Neighborhood Laplacian Matrix,"Multi-view spectral clustering can effectively reveal the intrinsic cluster
structure among data by performing clustering on the learned optimal embedding
across views. Though demonstrating promising performance in various
applications, most of existing methods usually linearly combine a group of
pre-specified first-order Laplacian matrices to construct the optimal Laplacian
matrix, which may result in limited representation capability and insufficient
information exploitation. Also, storing and implementing complex operations on
the $n\times n$ Laplacian matrices incurs intensive storage and computation
complexity. To address these issues, this paper first proposes a multi-view
spectral clustering algorithm that learns a high-order optimal neighborhood
Laplacian matrix, and then extends it to the late fusion version for accurate
and efficient multi-view clustering. Specifically, our proposed algorithm
generates the optimal Laplacian matrix by searching the neighborhood of the
linear combination of both the first-order and high-order base Laplacian
matrices simultaneously. By this way, the representative capacity of the
learned optimal Laplacian matrix is enhanced, which is helpful to better
utilize the hidden high-order connection information among data, leading to
improved clustering performance. We design an efficient algorithm with proved
convergence to solve the resultant optimization problem. Extensive experimental
results on nine datasets demonstrate the superiority of our algorithm against
state-of-the-art methods, which verifies the effectiveness and advantages of
the proposed algorithm.","['Weixuan Liang', 'Sihang Zhou', 'Jian Xiong', 'Xinwang Liu', 'Siwei Wang', 'En Zhu', 'Zhiping Cai', 'Xin Xu']","['cs.LG', 'stat.ML']",2020-08-31 12:28:40+00:00
http://arxiv.org/abs/2008.13485v1,ROS-Neuro Integration of Deep Convolutional Autoencoders for EEG Signal Compression in Real-time BCIs,"Typical EEG-based BCI applications require the computation of complex
functions over the noisy EEG channels to be carried out in an efficient way.
Deep learning algorithms are capable of learning flexible nonlinear functions
directly from data, and their constant processing latency is perfect for their
deployment into online BCI systems. However, it is crucial for the jitter of
the processing system to be as low as possible, in order to avoid unpredictable
behaviour that can ruin the system's overall usability. In this paper, we
present a novel encoding method, based on on deep convolutional autoencoders,
that is able to perform efficient compression of the raw EEG inputs. We deploy
our model in a ROS-Neuro node, thus making it suitable for the integration in
ROS-based BCI and robotic systems in real world scenarios. The experimental
results show that our system is capable to generate meaningful compressed
encoding preserving to original information contained in the raw input. They
also show that the ROS-Neuro node is able to produce such encodings at a steady
rate, with minimal jitter. We believe that our system can represent an
important step towards the development of an effective BCI processing pipeline
fully standardized in ROS-Neuro framework.","['Andrea Valenti', 'Michele Barsotti', 'Raffaello Brondi', 'Davide Bacciu', 'Luca Ascari']","['cs.LG', 'eess.SP', 'stat.ML']",2020-08-31 10:58:45+00:00
http://arxiv.org/abs/2008.13454v1,Complex-valued embeddings of generic proximity data,"Proximities are at the heart of almost all machine learning methods. If the
input data are given as numerical vectors of equal lengths, euclidean distance,
or a Hilbertian inner product is frequently used in modeling algorithms. In a
more generic view, objects are compared by a (symmetric) similarity or
dissimilarity measure, which may not obey particular mathematical properties.
This renders many machine learning methods invalid, leading to convergence
problems and the loss of guarantees, like generalization bounds. In many cases,
the preferred dissimilarity measure is not metric, like the earth mover
distance, or the similarity measure may not be a simple inner product in a
Hilbert space but in its generalization a Krein space. If the input data are
non-vectorial, like text sequences, proximity-based learning is used or ngram
embedding techniques can be applied. Standard embeddings lead to the desired
fixed-length vector encoding, but are costly and have substantial limitations
in preserving the original data's full information. As an information
preserving alternative, we propose a complex-valued vector embedding of
proximity data. This allows suitable machine learning algorithms to use these
fixed-length, complex-valued vectors for further processing. The complex-valued
data can serve as an input to complex-valued machine learning algorithms. In
particular, we address supervised learning and use extensions of
prototype-based learning. The proposed approach is evaluated on a variety of
standard benchmarks and shows strong performance compared to traditional
techniques in processing non-metric or non-psd proximity data.","['Maximilian Münch', 'Michiel Straat', 'Michael Biehl', 'Frank-Michael Schleif']","['cs.LG', 'stat.ML']",2020-08-31 09:40:30+00:00
http://arxiv.org/abs/2008.13443v5,On the Quality Requirements of Demand Prediction for Dynamic Public Transport,"As Public Transport (PT) becomes more dynamic and demand-responsive, it
increasingly depends on predictions of transport demand. But how accurate need
such predictions be for effective PT operation? We address this question
through an experimental case study of PT trips in Metropolitan Copenhagen,
Denmark, which we conduct independently of any specific prediction models.
First, we simulate errors in demand prediction through unbiased noise
distributions that vary considerably in shape. Using the noisy predictions, we
then simulate and optimize demand-responsive PT fleets via a linear programming
formulation and measure their performance. Our results suggest that the
optimized performance is mainly affected by the skew of the noise distribution
and the presence of infrequently large prediction errors. In particular, the
optimized performance can improve under non-Gaussian vs. Gaussian noise. We
also find that dynamic routing could reduce trip time by at least 23% vs.
static routing. This reduction is estimated at 809,000 EUR/year in terms of
Value of Travel Time Savings for the case study.","['Inon Peled', 'Kelvin Lee', 'Yu Jiang', 'Justin Dauwels', 'Francisco C. Pereira']","['stat.ML', 'cs.LG', 'eess.SP']",2020-08-31 09:05:05+00:00
http://arxiv.org/abs/2008.13429v1,Structured Graph Learning for Clustering and Semi-supervised Classification,"Graphs have become increasingly popular in modeling structures and
interactions in a wide variety of problems during the last decade. Graph-based
clustering and semi-supervised classification techniques have shown impressive
performance. This paper proposes a graph learning framework to preserve both
the local and global structure of data. Specifically, our method uses the
self-expressiveness of samples to capture the global structure and adaptive
neighbor approach to respect the local structure. Furthermore, most existing
graph-based methods conduct clustering and semi-supervised classification on
the graph learned from the original data matrix, which doesn't have explicit
cluster structure, thus they might not achieve the optimal performance. By
considering rank constraint, the achieved graph will have exactly $c$ connected
components if there are $c$ clusters or classes. As a byproduct of this, graph
learning and label inference are jointly and iteratively implemented in a
principled way. Theoretically, we show that our model is equivalent to a
combination of kernel k-means and k-means methods under certain condition.
Extensive experiments on clustering and semi-supervised classification
demonstrate that the proposed method outperforms other state-of-the-art
methods.","['Zhao Kang', 'Chong Peng', 'Qiang Cheng', 'Xinwang Liu', 'Xi Peng', 'Zenglin Xu', 'Ling Tian']","['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']",2020-08-31 08:41:20+00:00
http://arxiv.org/abs/2009.03782v1,Analysis and Prediction of Deforming 3D Shapes using Oriented Bounding Boxes and LSTM Autoencoders,"For sequences of complex 3D shapes in time we present a general approach to
detect patterns for their analysis and to predict the deformation by making use
of structural components of the complex shape. We incorporate long short-term
memory (LSTM) layers into an autoencoder to create low dimensional
representations that allow the detection of patterns in the data and
additionally detect the temporal dynamics in the deformation behavior. This is
achieved with two decoders, one for reconstruction and one for prediction of
future time steps of the sequence. In a preprocessing step the components of
the studied object are converted to oriented bounding boxes which capture the
impact of plastic deformation and allow reducing the dimensionality of the data
describing the structure. The architecture is tested on the results of 196 car
crash simulations of a model with 133 different components, where material
properties are varied. In the latent representation we can detect patterns in
the plastic deformation for the different components. The predicted bounding
boxes give an estimate of the final simulation result and their quality is
improved in comparison to different baselines.","['Sara Hahner', 'Rodrigo Iza-Teran', 'Jochen Garcke']","['cs.CV', 'cs.LG', 'stat.ML']",2020-08-31 08:07:32+00:00
http://arxiv.org/abs/2008.13374v2,Active Local Learning,"In this work we consider active local learning: given a query point $x$, and
active access to an unlabeled training set $S$, output the prediction $h(x)$ of
a near-optimal $h \in H$ using significantly fewer labels than would be needed
to actually learn $h$ fully. In particular, the number of label queries should
be independent of the complexity of $H$, and the function $h$ should be
well-defined, independent of $x$. This immediately also implies an algorithm
for distance estimation: estimating the value $opt(H)$ from many fewer labels
than needed to actually learn a near-optimal $h \in H$, by running local
learning on a few random query points and computing the average error.
  For the hypothesis class consisting of functions supported on the interval
$[0,1]$ with Lipschitz constant bounded by $L$, we present an algorithm that
makes $O(({1 / \epsilon^6}) \log(1/\epsilon))$ label queries from an unlabeled
pool of $O(({L / \epsilon^4})\log(1/\epsilon))$ samples. It estimates the
distance to the best hypothesis in the class to an additive error of $\epsilon$
for an arbitrary underlying distribution. We further generalize our algorithm
to more than one dimensions. We emphasize that the number of labels used is
independent of the complexity of the hypothesis class which depends on $L$.
Furthermore, we give an algorithm to locally estimate the values of a
near-optimal function at a few query points of interest with number of labels
independent of $L$.
  We also consider the related problem of approximating the minimum error that
can be achieved by the Nadaraya-Watson estimator under a linear diagonal
transformation with eigenvalues coming from a small range. For a
$d$-dimensional pointset of size $N$, our algorithm achieves an additive
approximation of $\epsilon$, makes $\tilde{O}({d}/{\epsilon^2})$ queries and
runs in $\tilde{O}({d^2}/{\epsilon^{d+4}}+{dN}/{\epsilon^2})$ time.","['Arturs Backurs', 'Avrim Blum', 'Neha Gupta']","['cs.LG', 'stat.ML']",2020-08-31 05:39:35+00:00
http://arxiv.org/abs/2008.13363v2,Extreme Memorization via Scale of Initialization,"We construct an experimental setup in which changing the scale of
initialization strongly impacts the implicit regularization induced by SGD,
interpolating from good generalization performance to completely memorizing the
training set while making little progress on the test set. Moreover, we find
that the extent and manner in which generalization ability is affected depends
on the activation and loss function used, with $\sin$ activation demonstrating
extreme memorization. In the case of the homogeneous ReLU activation, we show
that this behavior can be attributed to the loss function. Our empirical
investigation reveals that increasing the scale of initialization correlates
with misalignment of representations and gradients across examples in the same
class. This insight allows us to devise an alignment measure over gradients and
representations which can capture this phenomenon. We demonstrate that our
alignment measure correlates with generalization of deep models trained on
image classification tasks.","['Harsh Mehta', 'Ashok Cutkosky', 'Behnam Neyshabur']","['cs.LG', 'cs.CV', 'stat.ML']",2020-08-31 04:53:11+00:00
http://arxiv.org/abs/2008.13361v1,Multi-Scale One-Class Recurrent Neural Networks for Discrete Event Sequence Anomaly Detection,"Discrete event sequences are ubiquitous, such as an ordered event series of
process interactions in Information and Communication Technology systems.
Recent years have witnessed increasing efforts in detecting anomalies with
discrete-event sequences. However, it still remains an extremely difficult task
due to several intrinsic challenges including data imbalance issues, the
discrete property of the events, and sequential nature of the data. To address
these challenges, in this paper, we propose OC4Seq, a multi-scale one-class
recurrent neural network for detecting anomalies in discrete event sequences.
Specifically, OC4Seq integrates the anomaly detection objective with recurrent
neural networks (RNNs) to embed the discrete event sequences into latent
spaces, where anomalies can be easily detected. In addition, given that an
anomalous sequence could be caused by either individual events, subsequences of
events, or the whole sequence, we design a multi-scale RNN framework to capture
different levels of sequential patterns simultaneously. Experimental results on
three benchmark datasets show that OC4Seq consistently outperforms various
representative baselines by a large margin. Moreover, through both quantitative
and qualitative analysis, the importance of capturing multi-scale sequential
patterns for event anomaly detection is verified.","['Zhiwei Wang', 'Zhengzhang Chen', 'Jingchao Ni', 'Hui Liu', 'Haifeng Chen', 'Jiliang Tang']","['cs.LG', 'stat.ML']",2020-08-31 04:48:22+00:00
http://arxiv.org/abs/2008.13351v1,Learning Adaptive Embedding Considering Incremental Class,"Class-Incremental Learning (CIL) aims to train a reliable model with the
streaming data, which emerges unknown classes sequentially. Different from
traditional closed set learning, CIL has two main challenges: 1) Novel class
detection. The initial training data only contains incomplete classes, and
streaming test data will accept unknown classes. Therefore, the model needs to
not only accurately classify known classes, but also effectively detect unknown
classes; 2) Model expansion. After the novel classes are detected, the model
needs to be updated without re-training using entire previous data. However,
traditional CIL methods have not fully considered these two challenges, first,
they are always restricted to single novel class detection each phase and
embedding confusion caused by unknown classes. Besides, they also ignore the
catastrophic forgetting of known categories in model update. To this end, we
propose a Class-Incremental Learning without Forgetting (CILF) framework, which
aims to learn adaptive embedding for processing novel class detection and model
update in a unified framework. In detail, CILF designs to regularize
classification with decoupled prototype based loss, which can improve the
intra-class and inter-class structure significantly, and acquire a compact
embedding representation for novel class detection in result. Then, CILF
employs a learnable curriculum clustering operator to estimate the number of
semantic clusters via fine-tuning the learned network, in which curriculum
operator can adaptively learn the embedding in self-taught form. Therefore,
CILF can detect multiple novel classes and mitigate the embedding confusion
problem. Last, with the labeled streaming test data, CILF can update the
network with robust regularization to mitigate the catastrophic forgetting.
Consequently, CILF is able to iteratively perform novel class detection and
model update.","['Yang Yang', 'Zhen-Qiang Sun', 'HengShu Zhu', 'Yanjie Fu', 'Hui Xiong', 'Jian Yang']","['cs.LG', 'cs.AI', 'stat.ML']",2020-08-31 04:11:24+00:00
http://arxiv.org/abs/2008.13319v3,Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL,"Reinforcement learning (RL) in episodic, factored Markov decision processes
(FMDPs) is studied. We propose an algorithm called FMDP-BF, which leverages the
factorization structure of FMDP. The regret of FMDP-BF is shown to be
exponentially smaller than that of optimal algorithms designed for non-factored
MDPs, and improves on the best previous result for FMDPs~\citep{osband2014near}
by a factored of $\sqrt{H|\mathcal{S}_i|}$, where $|\mathcal{S}_i|$ is the
cardinality of the factored state subspace and $H$ is the planning horizon. To
show the optimality of our bounds, we also provide a lower bound for FMDP,
which indicates that our algorithm is near-optimal w.r.t. timestep $T$, horizon
$H$ and factored state-action subspace cardinality. Finally, as an application,
we study a new formulation of constrained RL, known as RL with knapsack
constraints (RLwK), and provides the first sample-efficient algorithm based on
FMDP-BF.","['Xiaoyu Chen', 'Jiachen Hu', 'Lihong Li', 'Liwei Wang']","['cs.LG', 'stat.ML']",2020-08-31 02:20:41+00:00
http://arxiv.org/abs/2008.13306v1,Relationship-aware Multivariate Sampling Strategy for Scientific Simulation Data,"With the increasing computational power of current supercomputers, the size
of data produced by scientific simulations is rapidly growing. To reduce the
storage footprint and facilitate scalable post-hoc analyses of such scientific
data sets, various data reduction/summarization methods have been proposed over
the years. Different flavors of sampling algorithms exist to sample the
high-resolution scientific data, while preserving important data properties
required for subsequent analyses. However, most of these sampling algorithms
are designed for univariate data and cater to post-hoc analyses of single
variables. In this work, we propose a multivariate sampling strategy which
preserves the original variable relationships and enables different
multivariate analyses directly on the sampled data. Our proposed strategy
utilizes principal component analysis to capture the variance of multivariate
data and can be built on top of any existing state-of-the-art sampling
algorithms for single variables. In addition, we also propose variants of
different data partitioning schemes (regular and irregular) to efficiently
model the local multivariate relationships. Using two real-world multivariate
data sets, we demonstrate the efficacy of our proposed multivariate sampling
strategy with respect to its data reduction capabilities as well as the ease of
performing efficient post-hoc multivariate analyses.","['Subhashis Hazarika', 'Ayan Biswas', 'Phillip J. Wolfram', 'Earl Lawrence', 'Nathan Urban']","['cs.LG', 'cs.GR', 'cs.HC', 'stat.ML']",2020-08-31 00:52:17+00:00
http://arxiv.org/abs/2008.13293v5,Sharp finite-sample concentration of independent variables,"We show an extension of Sanov's theorem on large deviations, controlling the
tail probabilities of i.i.d. random variables with matching concentration and
anti-concentration bounds. This result has a general scope, applies to samples
of any size, and has a short information-theoretic proof using elementary
techniques.",['Akshay Balsubramani'],"['cs.LG', 'cs.IT', 'math.IT', 'math.PR', 'stat.ML']",2020-08-30 23:05:55+00:00
http://arxiv.org/abs/2009.00700v1,Multimodal Inductive Transfer Learning for Detection of Alzheimer's Dementia and its Severity,"Alzheimer's disease is estimated to affect around 50 million people worldwide
and is rising rapidly, with a global economic burden of nearly a trillion
dollars. This calls for scalable, cost-effective, and robust methods for
detection of Alzheimer's dementia (AD). We present a novel architecture that
leverages acoustic, cognitive, and linguistic features to form a multimodal
ensemble system. It uses specialized artificial neural networks with temporal
characteristics to detect AD and its severity, which is reflected through
Mini-Mental State Exam (MMSE) scores. We first evaluate it on the ADReSS
challenge dataset, which is a subject-independent and balanced dataset matched
for age and gender to mitigate biases, and is available through DementiaBank.
Our system achieves state-of-the-art test accuracy, precision, recall, and
F1-score of 83.3% each for AD classification, and state-of-the-art test root
mean squared error (RMSE) of 4.60 for MMSE score regression. To the best of our
knowledge, the system further achieves state-of-the-art AD classification
accuracy of 88.0% when evaluated on the full benchmark DementiaBank Pitt
database. Our work highlights the applicability and transferability of
spontaneous speech to produce a robust inductive transfer learning model, and
demonstrates generalizability through a task-agnostic feature-space. The source
code is available at https://github.com/wazeerzulfikar/alzheimers-dementia","['Utkarsh Sarawgi', 'Wazeer Zulfikar', 'Nouran Soliman', 'Pattie Maes']","['eess.AS', 'cs.LG', 'cs.SD', 'stat.ML']",2020-08-30 21:47:26+00:00
http://arxiv.org/abs/2008.13265v6,A Meta-Learning Control Algorithm with Provable Finite-Time Guarantees,"In this work we provide provable regret guarantees for an online
meta-learning control algorithm in an iterative control setting, where in each
iteration the system to be controlled is a linear deterministic system that is
different and unknown, the cost for the controller in an iteration is a general
additive cost function and the control input is required to be constrained,
which if violated incurs an additional cost. We prove (i) that the algorithm
achieves a regret for the controller cost and constraint violation that are
$O(T^{3/4})$ for an episode of duration $T$ with respect to the best policy
that satisfies the control input control constraints and (ii) that the average
of the regret for the controller cost and constraint violation with respect to
the same policy vary as $O((1+\log(N)/N)T^{3/4})$ with the number of iterations
$N$, showing that the worst regret for the learning within an iteration
continuously improves with experience of more iterations.","['Deepan Muthirayan', 'Pramod Khargonekar']","['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY', 'stat.ML']",2020-08-30 20:30:40+00:00
http://arxiv.org/abs/2009.00003v1,diproperm: An R Package for the DiProPerm Test,"High-dimensional low sample size (HDLSS) data sets emerge frequently in many
biomedical applications. A common task for analyzing HDLSS data is to assign
data to the correct class using a classifier. Classifiers which use two labels
and a linear combination of features are known as binary linear classifiers.
The direction-projection-permutation (DiProPerm) test was developed for testing
the difference of two high-dimensional distributions induced by a binary linear
classifier. This paper discusses the key components of the DiProPerm test,
introduces the diproperm R package, and demonstrates the package on a
real-world data set.","['Andrew G. Allmon', 'J. S. Marron', 'Michael G. Hudgens']","['stat.CO', 'cs.LG', 'stat.ML']",2020-08-30 20:14:26+00:00
http://arxiv.org/abs/2008.13261v1,Benchmarking adversarial attacks and defenses for time-series data,"The adversarial vulnerability of deep networks has spurred the interest of
researchers worldwide. Unsurprisingly, like images, adversarial examples also
translate to time-series data as they are an inherent weakness of the model
itself rather than the modality. Several attempts have been made to defend
against these adversarial attacks, particularly for the visual modality. In
this paper, we perform detailed benchmarking of well-proven adversarial defense
methodologies on time-series data. We restrict ourselves to the $L_{\infty}$
threat model. We also explore the trade-off between smoothness and clean
accuracy for regularization-based defenses to better understand the trade-offs
that they offer. Our analysis shows that the explored adversarial defenses
offer robustness against both strong white-box as well as black-box attacks.
This paves the way for future research in the direction of adversarial attacks
and defenses, particularly for time-series data.","['Shoaib Ahmed Siddiqui', 'Andreas Dengel', 'Sheraz Ahmed']","['cs.LG', 'cs.AI', 'stat.ML']",2020-08-30 20:03:35+00:00
http://arxiv.org/abs/2008.13235v1,An Objective for Hierarchical Clustering in Euclidean Space and its Connection to Bisecting K-means,"This paper explores hierarchical clustering in the case where pairs of points
have dissimilarity scores (e.g. distances) as a part of the input. The recently
introduced objective for points with dissimilarity scores results in every tree
being a 1/2 approximation if the distances form a metric. This shows the
objective does not make a significant distinction between a good and poor
hierarchical clustering in metric spaces. Motivated by this, the paper develops
a new global objective for hierarchical clustering in Euclidean space. The
objective captures the criterion that has motivated the use of divisive
clustering algorithms: that when a split happens, points in the same cluster
should be more similar than points in different clusters. Moreover, this
objective gives reasonable results on ground-truth inputs for hierarchical
clustering. The paper builds a theoretical connection between this objective
and the bisecting k-means algorithm. This paper proves that the optimal 2-means
solution results in a constant approximation for the objective. This is the
first paper to show the bisecting k-means algorithm optimizes a natural global
objective over the entire tree.","['Benjamin Moseley', 'Yuyan Wang']","['cs.LG', 'stat.ML']",2020-08-30 18:17:46+00:00
http://arxiv.org/abs/2008.13225v1,SOLAR: Sparse Orthogonal Learned and Random Embeddings,"Dense embedding models are commonly deployed in commercial search engines,
wherein all the document vectors are pre-computed, and near-neighbor search
(NNS) is performed with the query vector to find relevant documents. However,
the bottleneck of indexing a large number of dense vectors and performing an
NNS hurts the query time and accuracy of these models. In this paper, we argue
that high-dimensional and ultra-sparse embedding is a significantly superior
alternative to dense low-dimensional embedding for both query efficiency and
accuracy. Extreme sparsity eliminates the need for NNS by replacing them with
simple lookups, while its high dimensionality ensures that the embeddings are
informative even when sparse. However, learning extremely high dimensional
embeddings leads to blow up in the model size. To make the training feasible,
we propose a partitioning algorithm that learns such high dimensional
embeddings across multiple GPUs without any communication. This is facilitated
by our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random
(SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal
by design, while the query vectors are learned and sparse. We theoretically
prove that our way of one-sided learning is equivalent to learning both query
and label embeddings. With these unique properties, we can successfully train
500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books
and multi-label classification on the three largest public datasets. We achieve
superior precision and recall compared to the respective state-of-the-art
baselines for each of the tasks with up to 10 times faster speed.","['Tharun Medini', 'Beidi Chen', 'Anshumali Shrivastava']","['cs.LG', 'cs.AI', 'cs.DC', 'cs.IR', 'stat.ML']",2020-08-30 17:35:35+00:00
http://arxiv.org/abs/2008.13221v1,Human-in-the-Loop Methods for Data-Driven and Reinforcement Learning Systems,"Recent successes combine reinforcement learning algorithms and deep neural
networks, despite reinforcement learning not being widely applied to robotics
and real world scenarios. This can be attributed to the fact that current
state-of-the-art, end-to-end reinforcement learning approaches still require
thousands or millions of data samples to converge to a satisfactory policy and
are subject to catastrophic failures during training. Conversely, in real world
scenarios and after just a few data samples, humans are able to either provide
demonstrations of the task, intervene to prevent catastrophic actions, or
simply evaluate if the policy is performing correctly. This research
investigates how to integrate these human interaction modalities to the
reinforcement learning loop, increasing sample efficiency and enabling
real-time reinforcement learning in robotics and real world scenarios. This
novel theoretical foundation is called Cycle-of-Learning, a reference to how
different human interaction modalities, namely, task demonstration,
intervention, and evaluation, are cycled and combined to reinforcement learning
algorithms. Results presented in this work show that the reward signal that is
learned based upon human interaction accelerates the rate of learning of
reinforcement learning algorithms and that learning from a combination of human
demonstrations and interventions is faster and more sample efficient when
compared to traditional supervised learning algorithms. Finally,
Cycle-of-Learning develops an effective transition between policies learned
using human demonstrations and interventions to reinforcement learning. The
theoretical foundation developed by this research opens new research paths to
human-agent teaming scenarios where autonomous agents are able to learn from
human teammates and adapt to mission performance metrics in real-time and in
real world scenarios.",['Vinicius G. Goecks'],"['cs.LG', 'cs.AI', 'cs.HC', 'cs.RO', 'stat.ML', 'I.2.6; I.2.9; I.5.2; H.1.2']",2020-08-30 17:28:18+00:00
http://arxiv.org/abs/2008.13210v2,Multiway $p$-spectral graph cuts on Grassmann manifolds,"Nonlinear reformulations of the spectral clustering method have gained a lot
of recent attention due to their increased numerical benefits and their solid
mathematical background. We present a novel direct multiway spectral clustering
algorithm in the $p$-norm, for $p \in (1, 2]$. The problem of computing
multiple eigenvectors of the graph $p$-Laplacian, a nonlinear generalization of
the standard graph Laplacian, is recasted as an unconstrained minimization
problem on a Grassmann manifold. The value of $p$ is reduced in a
pseudocontinuous manner, promoting sparser solution vectors that correspond to
optimal graph cuts as $p$ approaches one. Monitoring the monotonic decrease of
the balanced graph cuts guarantees that we obtain the best available solution
from the $p$-levels considered. We demonstrate the effectiveness and accuracy
of our algorithm in various artificial test-cases. Our numerical examples and
comparative results with various state-of-the-art clustering methods indicate
that the proposed method obtains high quality clusters both in terms of
balanced graph cut metrics and in terms of the accuracy of the labelling
assignment. Furthermore, we conduct studies for the classification of facial
images and handwritten characters to demonstrate the applicability in
real-world datasets.","['Dimosthenis Pasadakis', 'Christie Louis Alappat', 'Olaf Schenk', 'Gerhard Wellein']","['cs.LG', 'stat.ML', '68R10 (Primary), 90C27 (Secondary)', 'G.2.1; G.2.2']",2020-08-30 16:25:04+00:00
http://arxiv.org/abs/2009.08957v1,Personalized TV Recommendation: Fusing User Behavior and Preferences,"In this paper, we propose a two-stage ranking approach for recommending
linear TV programs. The proposed approach first leverages user viewing patterns
regarding time and TV channels to identify potential candidates for
recommendation and then further leverages user preferences to rank these
candidates given textual information about programs. To evaluate the method, we
conduct empirical studies on a real-world TV dataset, the results of which
demonstrate the superior performance of our model in terms of both
recommendation accuracy and time efficiency.","['Sheng-Chieh Lin', 'Ting-Wei Lin', 'Jing-Kai Lou', 'Ming-Feng Tsai', 'Chuan-Ju Wang']","['cs.IR', 'cs.LG', 'stat.ML']",2020-08-30 16:05:53+00:00
http://arxiv.org/abs/2008.13162v1,MementoML: Performance of selected machine learning algorithm configurations on OpenML100 datasets,"Finding optimal hyperparameters for the machine learning algorithm can often
significantly improve its performance. But how to choose them in a
time-efficient way? In this paper we present the protocol of generating
benchmark data describing the performance of different ML algorithms with
different hyperparameter configurations. Data collected in this way is used to
study the factors influencing the algorithm's performance.
  This collection was prepared for the purposes of the study presented in the
EPP study. We tested algorithms performance on dense grid of hyperparameters.
Tested datasets and hyperparameters were chosen before any algorithm has run
and were not changed. This is a different approach than the one usually used in
hyperparameter tuning, where the selection of candidate hyperparameters depends
on the results obtained previously. However, such selection allows for
systematic analysis of performance sensitivity from individual hyperparameters.
  This resulted in a comprehensive dataset of such benchmarks that we would
like to share. We hope, that computed and collected result may be helpful for
other researchers. This paper describes the way data was collected. Here you
can find benchmarks of 7 popular machine learning algorithms on 39 OpenML
datasets.
  The detailed data forming this benchmark are available at:
https://www.kaggle.com/mi2datalab/mementoml.","['Wojciech Kretowicz', 'Przemysław Biecek']","['cs.LG', 'stat.ML']",2020-08-30 13:13:52+00:00
http://arxiv.org/abs/2008.13128v1,Optimal Quantization for Batch Normalization in Neural Network Deployments and Beyond,"Quantized Neural Networks (QNNs) use low bit-width fixed-point numbers for
representing weight parameters and activations, and are often used in
real-world applications due to their saving of computation resources and
reproducibility of results.
  Batch Normalization (BN) poses a challenge for QNNs for requiring floating
points in reciprocal operations, and previous QNNs either require computing BN
at high precision or revise BN to some variants in heuristic ways.
  In this work, we propose a novel method to quantize BN by converting an
affine transformation of two floating points to a fixed-point operation with
shared quantized scale, which is friendly for hardware acceleration and model
deployment.
  We confirm that our method maintains same outputs through rigorous
theoretical analysis and numerical analysis. Accuracy and efficiency of our
quantization method are verified by experiments at layer level on CIFAR and
ImageNet datasets.
  We also believe that our method is potentially useful in other problems
involving quantization.","['Dachao Lin', 'Peiqin Sun', 'Guangzeng Xie', 'Shuchang Zhou', 'Zhihua Zhang']","['cs.LG', 'stat.ML']",2020-08-30 09:33:29+00:00
http://arxiv.org/abs/2008.13122v1,Adversarial Learning for Counterfactual Fairness,"In recent years, fairness has become an important topic in the machine
learning research community. In particular, counterfactual fairness aims at
building prediction models which ensure fairness at the most individual level.
Rather than globally considering equity over the entire population, the idea is
to imagine what any individual would look like with a variation of a given
attribute of interest, such as a different gender or race for instance.
Existing approaches rely on Variational Auto-encoding of individuals, using
Maximum Mean Discrepancy (MMD) penalization to limit the statistical dependence
of inferred representations with their corresponding sensitive attributes. This
enables the simulation of counterfactual samples used for training the target
fair model, the goal being to produce similar outcomes for every alternate
version of any individual. In this work, we propose to rely on an adversarial
neural learning approach, that enables more powerful inference than with MMD
penalties, and is particularly better fitted for the continuous setting, where
values of sensitive attributes cannot be exhaustively enumerated. Experiments
show significant improvements in term of counterfactual fairness for both the
discrete and the continuous settings.","['Vincent Grari', 'Sylvain Lamprier', 'Marcin Detyniecki']","['cs.LG', 'cs.AI', 'cs.CY', 'stat.ML']",2020-08-30 09:06:03+00:00
http://arxiv.org/abs/2008.13114v1,A Novel Multiple Ensemble Learning Models Based on Different Datasets for Software Defect Prediction,"Software testing is one of the important ways to ensure the quality of
software. It is found that testing cost more than 50% of overall project cost.
Effective and efficient software testing utilizes the minimum resources of
software. Therefore, it is important to construct the procedure which is not
only able to perform the efficient testing but also minimizes the utilization
of project resources. The goal of software testing is to find maximum defects
in the software system. More the defects found in the software ensure more
efficiency is the software testing Different techniques have been proposed to
detect the defects in software and to utilize the resources and achieve good
results. As world is continuously moving toward data driven approach for making
important decision. Therefore, in this research paper we performed the machine
learning analysis on the publicly available datasets and tried to achieve the
maximum accuracy. The major focus of the paper is to apply different machine
learning techniques on the datasets and find out which technique produce
efficient result. Particularly, we proposed an ensemble learning models and
perform comparative analysis among KNN, Decision tree, SVM and Na\""ive Bayes on
different datasets and it is demonstrated that performance of Ensemble method
is more than other methods in term of accuracy, precision, recall and F1-score.
The classification accuracy of ensemble model trained on CM1 is 98.56%,
classification accuracy of ensemble model trained on KM2 is 98.18% similarly,
the classification accuracy of ensemble learning model trained on PC1 is
99.27%. This reveals that Ensemble is more efficient method for making the
defect prediction as compared other techniques.","['Ali Nawaz', 'Attique Ur Rehman', 'Muhammad Abbas']","['cs.LG', 'cs.SE', 'stat.ML']",2020-08-30 08:01:39+00:00
http://arxiv.org/abs/2008.13099v4,Pairwise Learning for Name Disambiguation in Large-Scale Heterogeneous Academic Networks,"Name disambiguation aims to identify unique authors with the same name.
Existing name disambiguation methods always exploit author attributes to
enhance disambiguation results. However, some discriminative author attributes
(e.g., email and affiliation) may change because of graduation or job-hopping,
which will result in the separation of the same author's papers in digital
libraries. Although these attributes may change, an author's co-authors and
research topics do not change frequently with time, which means that papers
within a period have similar text and relation information in the academic
network. Inspired by this idea, we introduce Multi-view Attention-based
Pairwise Recurrent Neural Network (MA-PairRNN) to solve the name disambiguation
problem. We divided papers into small blocks based on discriminative author
attributes and blocks of the same author will be merged according to pairwise
classification results of MA-PairRNN. MA-PairRNN combines heterogeneous graph
embedding learning and pairwise similarity learning into a framework. In
addition to attribute and structure information, MA-PairRNN also exploits
semantic information by meta-path and generates node representation in an
inductive way, which is scalable to large graphs. Furthermore, a semantic-level
attention mechanism is adopted to fuse multiple meta-path based
representations. A Pseudo-Siamese network consisting of two RNNs takes two
paper sequences in publication time order as input and outputs their
similarity. Results on two real-world datasets demonstrate that our framework
has a significant and consistent improvement of performance on the name
disambiguation task. It was also demonstrated that MA-PairRNN can perform well
with a small amount of training data and have better generalization ability
across different research areas.","['Qingyun Sun', 'Hao Peng', 'Jianxin Li', 'Senzhang Wang', 'Xiangyu Dong', 'Liangxuan Zhao', 'Philip S. Yu', 'Lifang He']","['cs.DL', 'cs.LG', 'cs.SI', 'stat.ML']",2020-08-30 06:08:20+00:00
http://arxiv.org/abs/2009.00236v2,A Survey of Deep Active Learning,"Active learning (AL) attempts to maximize the performance gain of the model
by marking the fewest samples. Deep learning (DL) is greedy for data and
requires a large amount of data supply to optimize massive parameters, so that
the model learns how to extract high-quality features. In recent years, due to
the rapid development of internet technology, we are in an era of information
torrents and we have massive amounts of data. In this way, DL has aroused
strong interest of researchers and has been rapidly developed. Compared with
DL, researchers have relatively low interest in AL. This is mainly because
before the rise of DL, traditional machine learning requires relatively few
labeled samples. Therefore, early AL is difficult to reflect the value it
deserves. Although DL has made breakthroughs in various fields, most of this
success is due to the publicity of the large number of existing annotation
datasets. However, the acquisition of a large number of high-quality annotated
datasets consumes a lot of manpower, which is not allowed in some fields that
require high expertise, especially in the fields of speech recognition,
information extraction, medical images, etc. Therefore, AL has gradually
received due attention. A natural idea is whether AL can be used to reduce the
cost of sample annotations, while retaining the powerful learning capabilities
of DL. Therefore, deep active learning (DAL) has emerged. Although the related
research has been quite abundant, it lacks a comprehensive survey of DAL. This
article is to fill this gap, we provide a formal classification method for the
existing work, and a comprehensive and systematic overview. In addition, we
also analyzed and summarized the development of DAL from the perspective of
application. Finally, we discussed the confusion and problems in DAL, and gave
some possible development directions for DAL.","['Pengzhen Ren', 'Yun Xiao', 'Xiaojun Chang', 'Po-Yao Huang', 'Zhihui Li', 'Brij B. Gupta', 'Xiaojiang Chen', 'Xin Wang']","['cs.LG', 'stat.ML']",2020-08-30 04:28:31+00:00
http://arxiv.org/abs/2008.13072v1,Adversarial Privacy Preserving Graph Embedding against Inference Attack,"Recently, the surge in popularity of Internet of Things (IoT), mobile
devices, social media, etc. has opened up a large source for graph data. Graph
embedding has been proved extremely useful to learn low-dimensional feature
representations from graph structured data. These feature representations can
be used for a variety of prediction tasks from node classification to link
prediction. However, existing graph embedding methods do not consider users'
privacy to prevent inference attacks. That is, adversaries can infer users'
sensitive information by analyzing node representations learned from graph
embedding algorithms. In this paper, we propose Adversarial Privacy Graph
Embedding (APGE), a graph adversarial training framework that integrates the
disentangling and purging mechanisms to remove users' private information from
learned node representations. The proposed method preserves the structural
information and utility attributes of a graph while concealing users' private
attributes from inference attacks. Extensive experiments on real-world graph
datasets demonstrate the superior performance of APGE compared to the
state-of-the-arts. Our source code can be found at
https://github.com/uJ62JHD/Privacy-Preserving-Social-Network-Embedding.","['Kaiyang Li', 'Guangchun Luo', 'Yang Ye', 'Wei Li', 'Shihao Ji', 'Zhipeng Cai']","['cs.LG', 'cs.CR', 'stat.ML']",2020-08-30 00:06:49+00:00
http://arxiv.org/abs/2008.13066v2,Computer Model Calibration with Time Series Data using Deep Learning and Quantile Regression,"Computer models play a key role in many scientific and engineering problems.
One major source of uncertainty in computer model experiment is input parameter
uncertainty. Computer model calibration is a formal statistical procedure to
infer input parameters by combining information from model runs and
observational data. The existing standard calibration framework suffers from
inferential issues when the model output and observational data are
high-dimensional dependent data such as large time series due to the difficulty
in building an emulator and the non-identifiability between effects from input
parameters and data-model discrepancy. To overcome these challenges we propose
a new calibration framework based on a deep neural network (DNN) with
long-short term memory layers that directly emulates the inverse relationship
between the model output and input parameters. Adopting the 'learning with
noise' idea we train our DNN model to filter out the effects from data model
discrepancy on input parameter inference. We also formulate a new way to
construct interval predictions for DNN using quantile regression to quantify
the uncertainty in input parameter estimates. Through a simulation study and
real data application with WRF-hydro model we show that our approach can yield
accurate point estimates and well calibrated interval estimates for input
parameters.","['Saumya Bhatnagar', 'Won Chang', 'Seonjin Kim Jiali Wang']","['stat.ML', 'cs.LG', 'stat.ME']",2020-08-29 22:18:41+00:00
http://arxiv.org/abs/2008.13065v1,Unsupervised MRI Reconstruction with Generative Adversarial Networks,"Deep learning-based image reconstruction methods have achieved promising
results across multiple MRI applications. However, most approaches require
large-scale fully-sampled ground truth data for supervised training. Acquiring
fully-sampled data is often either difficult or impossible, particularly for
dynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a
deep learning framework for MRI reconstruction without any fully-sampled data
using generative adversarial networks. We test the proposed method in two
scenarios: retrospectively undersampled fast spin echo knee exams and
prospectively undersampled abdominal DCE. The method recovers more anatomical
structure compared to conventional methods.","['Elizabeth K. Cole', 'John M. Pauly', 'Shreyas S. Vasanawala', 'Frank Ong']","['eess.IV', 'cs.LG', 'stat.ML']",2020-08-29 22:00:49+00:00
http://arxiv.org/abs/2008.13064v3,Towards Demystifying Dimensions of Source Code Embeddings,"Source code representations are key in applying machine learning techniques
for processing and analyzing programs. A popular approach in representing
source code is neural source code embeddings that represents programs with
high-dimensional vectors computed by training deep neural networks on a large
volume of programs. Although successful, there is little known about the
contents of these vectors and their characteristics. In this paper, we present
our preliminary results towards better understanding the contents of code2vec
neural source code embeddings. In particular, in a small case study, we use the
code2vec embeddings to create binary SVM classifiers and compare their
performance with the handcrafted features. Our results suggest that the
handcrafted features can perform very close to the highly-dimensional code2vec
embeddings, and the information gains are more evenly distributed in the
code2vec embeddings compared to the handcrafted features. We also find that the
code2vec embeddings are more resilient to the removal of dimensions with low
information gains than the handcrafted features. We hope our results serve a
stepping stone toward principled analysis and evaluation of these code
representations.","['Md Rafiqul Islam Rabin', 'Arjun Mukherjee', 'Omprakash Gnawali', 'Mohammad Amin Alipour']","['cs.LG', 'cs.PL', 'cs.SE', 'stat.ML']",2020-08-29 21:59:11+00:00
http://arxiv.org/abs/2008.13044v1,Reinforcement Learning with Feedback-modulated TD-STDP,"Spiking neuron networks have been used successfully to solve simple
reinforcement learning tasks with continuous action set applying learning rules
based on spike-timing-dependent plasticity (STDP). However, most of these
models cannot be applied to reinforcement learning tasks with discrete action
set since they assume that the selected action is a deterministic function of
firing rate of neurons, which is continuous. In this paper, we propose a new
STDP-based learning rule for spiking neuron networks which contains feedback
modulation. We show that the STDP-based learning rule can be used to solve
reinforcement learning tasks with discrete action set at a speed similar to
standard reinforcement learning algorithms when applied to the CartPole and
LunarLander tasks. Moreover, we demonstrate that the agent is unable to solve
these tasks if feedback modulation is omitted from the learning rule. We
conclude that feedback modulation allows better credit assignment when only the
units contributing to the executed action and TD error participate in learning.","['Stephen Chung', 'Robert Kozma']","['cs.LG', 'cs.AI', 'stat.ML', 'I.2.8']",2020-08-29 20:08:59+00:00
http://arxiv.org/abs/2009.01185v1,Exact Recovery of Community Detection in k-Community Gaussian Mixture Model,"We study the community detection problem on a Gaussian mixture model, in
which vertices are divided into $k\geq 2$ distinct communities. The major
difference in our model is that the intensities for Gaussian perturbations are
different for different entries in the observation matrix, and we do not assume
that every community has the same number of vertices. We explicitly find the
threshold for the exact recovery of the maximum likelihood estimation.
Applications include the community detection on hypergraphs.",['Zhongyang Li'],"['cs.SI', 'cs.LG', 'math.PR', 'stat.ML']",2020-08-29 19:27:20+00:00
http://arxiv.org/abs/2008.13038v1,Loss convergence in a causal Bayesian neural network of retail firm performance,"We extend the empirical results from the structural equation model (SEM)
published in the paper Assortment Planning for Retail Buying, Retail Store
Operations, and Firm Performance [1] by implementing the directed acyclic graph
as a causal Bayesian neural network. Neural network convergence is shown to
improve with the removal of the node with the weakest SEM path when variational
inference is provided by perturbing weights with Flipout layers, while results
from perturbing weights at the output with the Vadam optimizer are
inconclusive.",['F. Trevor Rogers'],"['stat.ML', 'cs.LG', 'I.5.1']",2020-08-29 19:16:43+00:00
http://arxiv.org/abs/2008.12997v2,Improving Resistance to Adversarial Deformations by Regularizing Gradients,"Improving the resistance of deep neural networks against adversarial attacks
is important for deploying models to realistic applications. However, most
defense methods are designed to defend against intensity perturbations and
ignore location perturbations, which should be equally important for deep model
security. In this paper, we focus on adversarial deformations, a typical class
of location perturbations, and propose a flow gradient regularization to
improve the resistance of models. Theoretically, we prove that, compared with
input gradient regularization, regularizing flow gradients is able to get a
tighter bound. Over multiple datasets, architectures, and adversarial
deformations, our empirical results indicate that models trained with flow
gradients can acquire a better resistance than trained with input gradients
with a large margin, and also better than adversarial training. Moreover,
compared with directly training with adversarial deformations, our method can
achieve better results in unseen attacks, and combining these two methods can
improve the resistance further.","['Pengfei Xia', 'Bin Li']","['cs.LG', 'cs.AI', 'stat.ML']",2020-08-29 15:28:23+00:00
http://arxiv.org/abs/2008.12987v1,AI-based Modeling and Data-driven Evaluation for Smart Manufacturing Processes,"Smart Manufacturing refers to optimization techniques that are implemented in
production operations by utilizing advanced analytics approaches. With the
widespread increase in deploying Industrial Internet of Things (IIoT) sensors
in manufacturing processes, there is a progressive need for optimal and
effective approaches to data management. Embracing Machine Learning and
Artificial Intelligence to take advantage of manufacturing data can lead to
efficient and intelligent automation. In this paper, we conduct a comprehensive
analysis based on Evolutionary Computing and Deep Learning algorithms toward
making semiconductor manufacturing smart. We propose a dynamic algorithm for
gaining useful insights about semiconductor manufacturing processes and to
address various challenges. We elaborate on the utilization of a Genetic
Algorithm and Neural Network to propose an intelligent feature selection
algorithm. Our objective is to provide an advanced solution for controlling
manufacturing processes and to gain perspective on various dimensions that
enable manufacturers to access effective predictive technologies.","['Mohammadhossein Ghahramani', 'Yan Qiao', 'MengChu Zhou', 'Adrian OHagan', 'James Sweeney']","['cs.LG', 'stat.ML']",2020-08-29 14:57:53+00:00
http://arxiv.org/abs/2008.12967v1,Unpaired Deep Learning for Accelerated MRI using Optimal Transport Driven CycleGAN,"Recently, deep learning approaches for accelerated MRI have been extensively
studied thanks to their high performance reconstruction in spite of
significantly reduced runtime complexity. These neural networks are usually
trained in a supervised manner, so matched pairs of subsampled and fully
sampled k-space data are required. Unfortunately, it is often difficult to
acquire matched fully sampled k-space data, since the acquisition of fully
sampled k-space data requires long scan time and often leads to the change of
the acquisition protocol. Therefore, unpaired deep learning without matched
label data has become a very important research topic. In this paper, we
propose an unpaired deep learning approach using a optimal transport driven
cycle-consistent generative adversarial network (OT-cycleGAN) that employs a
single pair of generator and discriminator. The proposed OT-cycleGAN
architecture is rigorously derived from a dual formulation of the optimal
transport formulation using a specially designed penalized least squares cost.
The experimental results show that our method can reconstruct high resolution
MR images from accelerated k- space data from both single and multiple coil
acquisition, without requiring matched reference data.","['Gyutaek Oh', 'Byeongsu Sim', 'Hyungjin Chung', 'Leonard Sunwoo', 'Jong Chul Ye']","['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2020-08-29 12:02:49+00:00
http://arxiv.org/abs/2008.12952v2,"Efficient Robustness Certificates for Discrete Data: Sparsity-Aware Randomized Smoothing for Graphs, Images and More","Existing techniques for certifying the robustness of models for discrete data
either work only for a small class of models or are general at the expense of
efficiency or tightness. Moreover, they do not account for sparsity in the
input which, as our findings show, is often essential for obtaining non-trivial
guarantees. We propose a model-agnostic certificate based on the randomized
smoothing framework which subsumes earlier work and is tight, efficient, and
sparsity-aware. Its computational complexity does not depend on the number of
discrete categories or the dimension of the input (e.g. the graph size), making
it highly scalable. We show the effectiveness of our approach on a wide variety
of models, datasets, and tasks -- specifically highlighting its use for Graph
Neural Networks. So far, obtaining provable guarantees for GNNs has been
difficult due to the discrete and non-i.i.d. nature of graph data. Our method
can certify any GNN and handles perturbations to both the graph structure and
the node attributes.","['Aleksandar Bojchevski', 'Johannes Gasteiger', 'Stephan Günnemann']","['cs.LG', 'cs.CR', 'cs.SI', 'stat.ML']",2020-08-29 10:09:02+00:00
http://arxiv.org/abs/2008.12925v1,GRAFFL: Gradient-free Federated Learning of a Bayesian Generative Model,"Federated learning platforms are gaining popularity. One of the major
benefits is to mitigate the privacy risks as the learning of algorithms can be
achieved without collecting or sharing data. While federated learning (i.e.,
many based on stochastic gradient algorithms) has shown great promise, there
are still many challenging problems in protecting privacy, especially during
the process of gradients update and exchange. This paper presents the first
gradient-free federated learning framework called GRAFFL for learning a
Bayesian generative model based on approximate Bayesian computation. Unlike
conventional federated learning algorithms based on gradients, our framework
does not require to disassemble a model (i.e., to linear components) or to
perturb data (or encryption of data for aggregation) to preserve privacy.
Instead, this framework uses implicit information derived from each
participating institution to learn posterior distributions of parameters. The
implicit information is summary statistics derived from SuffiAE that is a
neural network developed in this study to create compressed and linearly
separable representations thereby protecting sensitive information from
leakage. As a sufficient dimensionality reduction technique, this is proved to
provide sufficient summary statistics. We propose the GRAFFL-based Bayesian
Gaussian mixture model to serve as a proof-of-concept of the framework. Using
several datasets, we demonstrated the feasibility and usefulness of our model
in terms of privacy protection and prediction performance (i.e., close to an
ideal setting). The trained model as a quasi-global model can generate
informative samples involving information from other institutions and enhances
data analysis of each institution.","['Seok-Ju Hahn', 'Junghye Lee']","['cs.LG', 'stat.ML']",2020-08-29 07:19:44+00:00
http://arxiv.org/abs/2008.12922v1,Modulating Scalable Gaussian Processes for Expressive Statistical Learning,"For a learning task, Gaussian process (GP) is interested in learning the
statistical relationship between inputs and outputs, since it offers not only
the prediction mean but also the associated variability. The vanilla GP however
struggles to learn complicated distribution with the property of, e.g.,
heteroscedastic noise, multi-modality and non-stationarity, from massive data
due to the Gaussian marginal and the cubic complexity. To this end, this
article studies new scalable GP paradigms including the non-stationary
heteroscedastic GP, the mixture of GPs and the latent GP, which introduce
additional latent variables to modulate the outputs or inputs in order to learn
richer, non-Gaussian statistical representation. We further resort to different
variational inference strategies to arrive at analytical or tighter evidence
lower bounds (ELBOs) of the marginal likelihood for efficient and effective
model training. Extensive numerical experiments against state-of-the-art GP and
neural network (NN) counterparts on various tasks verify the superiority of
these scalable modulated GPs, especially the scalable latent GP, for learning
diverse data distributions.","['Haitao Liu', 'Yew-Soon Ong', 'Xiaomo Jiang', 'Xiaofang Wang']","['stat.ML', 'cs.LG']",2020-08-29 06:41:45+00:00
http://arxiv.org/abs/2008.12916v2,Random Surfing Revisited: Generalizing PageRank's Teleportation Model,"We revisit the Random Surfer model, focusing on its--often
overlooked--Teleportation component, and we introduce NCDawareRank; a novel
ranking framework designed to exploit network meta-information as well as
aspects of its higher-order structural organization in a way that preserves the
mathematical structure and the attractive computational characteristics of
PageRank. A rigorous theoretical exploration of the proposed model reveals a
wealth of mathematical properties that entail tangible benefits in terms of
robustness, computability, as well as modeling flexibility and expressiveness.
A set of experiments on real-work networks verify the theoretically predicted
properties of NCDawareRank, and showcase its effectiveness as a network
centrality measure.",['Athanasios N. Nikolakopoulos'],"['cs.SI', 'cs.IR', 'stat.ML']",2020-08-29 05:45:05+00:00
http://arxiv.org/abs/2008.12886v1,Shannon Entropy Rate of Hidden Markov Processes,"Hidden Markov chains are widely applied statistical models of stochastic
processes, from fundamental physics and chemistry to finance, health, and
artificial intelligence. The hidden Markov processes they generate are
notoriously complicated, however, even if the chain is finite state: no finite
expression for their Shannon entropy rate exists, as the set of their
predictive features is generically infinite. As such, to date one cannot make
general statements about how random they are nor how structured. Here, we
address the first part of this challenge by showing how to efficiently and
accurately calculate their entropy rates. We also show how this method gives
the minimal set of infinite predictive features. A sequel addresses the
challenge's second part on structure.","['Alexandra M. Jurgens', 'James P. Crutchfield']","['nlin.CD', 'cond-mat.stat-mech', 'cs.IT', 'math.DS', 'math.IT', 'stat.ML']",2020-08-29 00:48:17+00:00
http://arxiv.org/abs/2008.12882v1,Estimation in Tensor Ising Models,"The $p$-tensor Ising model is a one-parameter discrete exponential family for
modeling dependent binary data, where the sufficient statistic is a
multi-linear form of degree $p \geq 2$. This is a natural generalization of the
matrix Ising model, that provides a convenient mathematical framework for
capturing higher-order dependencies in complex relational data. In this paper,
we consider the problem of estimating the natural parameter of the $p$-tensor
Ising model given a single sample from the distribution on $N$ nodes. Our
estimate is based on the maximum pseudo-likelihood (MPL) method, which provides
a computationally efficient algorithm for estimating the parameter that avoids
computing the intractable partition function. We derive general conditions
under which the MPL estimate is $\sqrt N$-consistent, that is, it converges to
the true parameter at rate $1/\sqrt N$. In particular, we show the $\sqrt
N$-consistency of the MPL estimate in the $p$-spin Sherrington-Kirkpatrick (SK)
model, spin systems on general $p$-uniform hypergraphs, and Ising models on the
hypergraph stochastic block model (HSBM). In fact, for the HSBM we pin down the
exact location of the phase transition threshold, which is determined by the
positivity of a certain mean-field variational problem, such that above this
threshold the MPL estimate is $\sqrt N$-consistent, while below the threshold
no estimator is consistent. Finally, we derive the precise fluctuations of the
MPL estimate in the special case of the $p$-tensor Curie-Weiss model. An
interesting consequence of our results is that the MPL estimate in the
Curie-Weiss model saturates the Cramer-Rao lower bound at all points above the
estimation threshold, that is, the MPL estimate incurs no loss in asymptotic
efficiency, even though it is obtained by minimizing only an approximation of
the true likelihood function for computational tractability.","['Somabha Mukherjee', 'Jaesung Son', 'Bhaswar B. Bhattacharya']","['math.ST', 'math.PR', 'stat.ME', 'stat.ML', 'stat.TH']",2020-08-29 00:06:58+00:00
http://arxiv.org/abs/2008.12857v2,Locally induced Gaussian processes for large-scale simulation experiments,"Gaussian processes (GPs) serve as flexible surrogates for complex surfaces,
but buckle under the cubic cost of matrix decompositions with big training data
sizes. Geospatial and machine learning communities suggest pseudo-inputs, or
inducing points, as one strategy to obtain an approximation easing that
computational burden. However, we show how placement of inducing points and
their multitude can be thwarted by pathologies, especially in large-scale
dynamic response surface modeling tasks. As remedy, we suggest porting the
inducing point idea, which is usually applied globally, over to a more local
context where selection is both easier and faster. In this way, our proposed
methodology hybridizes global inducing point and data subset-based local GP
approximation. A cascade of strategies for planning the selection of local
inducing points is provided, and comparisons are drawn to related methodology
with emphasis on computer surrogate modeling applications. We show that local
inducing points extend their global and data-subset component parts on the
accuracy--computational efficiency frontier. Illustrative examples are provided
on benchmark data and a large-scale real-simulation satellite drag
interpolation problem.","['D. Austin Cole', 'Ryan Christianson', 'Robert B. Gramacy']","['stat.ME', 'stat.CO', 'stat.ML']",2020-08-28 21:37:46+00:00
http://arxiv.org/abs/2009.00437v6,NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size,"Neural architecture search (NAS) has attracted a lot of attention and has
been illustrated to bring tangible benefits in a large number of applications
in the past few years. Architecture topology and architecture size have been
regarded as two of the most important aspects for the performance of deep
learning models and the community has spawned lots of searching algorithms for
both aspects of the neural architectures. However, the performance gain from
these searching algorithms is achieved under different search spaces and
training setups. This makes the overall performance of the algorithms to some
extent incomparable and the improvement from a sub-module of the searching
model unclear. In this paper, we propose NATS-Bench, a unified benchmark on
searching for both topology and size, for (almost) any up-to-date NAS
algorithm. NATS-Bench includes the search space of 15,625 neural cell
candidates for architecture topology and 32,768 for architecture size on three
datasets. We analyze the validity of our benchmark in terms of various criteria
and performance comparison of all candidates in the search space. We also show
the versatility of NATS-Bench by benchmarking 13 recent state-of-the-art NAS
algorithms on it. All logs and diagnostic information trained using the same
setup for each candidate are provided. This facilitates a much larger community
of researchers to focus on developing better NAS algorithms in a more
comparable and computationally cost friendly environment. All codes are
publicly available at: https://xuanyidong.com/assets/projects/NATS-Bench.","['Xuanyi Dong', 'Lu Liu', 'Katarzyna Musial', 'Bogdan Gabrys']","['cs.LG', 'stat.ML']",2020-08-28 21:34:56+00:00
http://arxiv.org/abs/2008.12833v4,Pay Attention to Evolution: Time Series Forecasting with Deep Graph-Evolution Learning,"Time-series forecasting is one of the most active research topics in
artificial intelligence. Applications in real-world time series should consider
two factors for achieving reliable predictions: modeling dynamic dependencies
among multiple variables and adjusting the model's intrinsic hyperparameters. A
still open gap in that literature is that statistical and ensemble learning
approaches systematically present lower predictive performance than deep
learning methods. They generally disregard the data sequence aspect entangled
with multivariate data represented in more than one time series. Conversely,
this work presents a novel neural network architecture for time-series
forecasting that combines the power of graph evolution with deep recurrent
learning on distinct data distributions; we named our method Recurrent Graph
Evolution Neural Network (ReGENN). The idea is to infer multiple multivariate
relationships between co-occurring time-series by assuming that the temporal
data depends not only on inner variables and intra-temporal relationships
(i.e., observations from itself) but also on outer variables and inter-temporal
relationships (i.e., observations from other-selves). An extensive set of
experiments was conducted comparing ReGENN with dozens of ensemble methods and
classical statistical ones, showing sound improvement of up to 64.87% over the
competing algorithms. Furthermore, we present an analysis of the intermediate
weights arising from ReGENN, showing that by looking at inter and
intra-temporal relationships simultaneously, time-series forecasting is majorly
improved if paying attention to how multiple multivariate data synchronously
evolve.","['Gabriel Spadon', 'Shenda Hong', 'Bruno Brandoli', 'Stan Matwin', 'Jose F. Rodrigues-Jr', 'Jimeng Sun']","['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML', '37M10, 68T07, 68T05, 68T37, 82C32', 'I.2; I.5; I.2.4; I.2.6; I.5.1']",2020-08-28 20:10:07+00:00
http://arxiv.org/abs/2008.12829v2,A Rigorous Machine Learning Analysis Pipeline for Biomedical Binary Classification: Application in Pancreatic Cancer Nested Case-control Studies with Implications for Bias Assessments,"Machine learning (ML) offers a collection of powerful approaches for
detecting and modeling associations, often applied to data having a large
number of features and/or complex associations. Currently, there are many tools
to facilitate implementing custom ML analyses (e.g. scikit-learn). Interest is
also increasing in automated ML packages, which can make it easier for
non-experts to apply ML and have the potential to improve model performance. ML
permeates most subfields of biomedical research with varying levels of rigor
and correct usage. Tremendous opportunities offered by ML are frequently offset
by the challenge of assembling comprehensive analysis pipelines, and the ease
of ML misuse. In this work we have laid out and assembled a complete, rigorous
ML analysis pipeline focused on binary classification (i.e. case/control
prediction), and applied this pipeline to both simulated and real world data.
At a high level, this 'automated' but customizable pipeline includes a)
exploratory analysis, b) data cleaning and transformation, c) feature
selection, d) model training with 9 established ML algorithms, each with
hyperparameter optimization, and e) thorough evaluation, including appropriate
metrics, statistical analyses, and novel visualizations. This pipeline
organizes the many subtle complexities of ML pipeline assembly to illustrate
best practices to avoid bias and ensure reproducibility. Additionally, this
pipeline is the first to compare established ML algorithms to 'ExSTraCS', a
rule-based ML algorithm with the unique capability of interpretably modeling
heterogeneous patterns of association. While designed to be widely applicable
we apply this pipeline to an epidemiological investigation of established and
newly identified risk factors for pancreatic cancer to evaluate how different
sources of bias might be handled by ML algorithms.","['Ryan J. Urbanowicz', 'Pranshu Suri', 'Yuhan Cui', 'Jason H. Moore', 'Karen Ruth', 'Rachael Stolzenberg-Solomon', 'Shannon M. Lynch']","['cs.LG', 'stat.ML']",2020-08-28 19:58:05+00:00
