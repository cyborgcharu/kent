id,title,abstract,authors,categories,date
http://arxiv.org/abs/2411.08034v1,Scaling Properties of Diffusion Models for Perceptual Tasks,"In this paper, we argue that iterative computation with diffusion models
offers a powerful paradigm for not only generation but also visual perception
tasks. We unify tasks such as depth estimation, optical flow, and segmentation
under image-to-image translation, and show how diffusion models benefit from
scaling training and test-time compute for these perception tasks. Through a
careful analysis of these scaling behaviors, we present various techniques to
efficiently train diffusion models for visual perception tasks. Our models
achieve improved or comparable performance to state-of-the-art methods using
significantly less data and compute. To use our code and models, see
https://scaling-diffusion-perception.github.io .","['Rahul Ravishankar', 'Zeeshan Patel', 'Jathushan Rajasegaran', 'Jitendra Malik']","['cs.CV', 'cs.AI']",2024-11-12 18:59:35+00:00
http://arxiv.org/abs/2411.08033v1,GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation,"While 3D content generation has advanced significantly, existing methods
still face challenges with input formats, latent space design, and output
representations. This paper introduces a novel 3D generation framework that
addresses these challenges, offering scalable, high-quality 3D generation with
an interactive Point Cloud-structured Latent space. Our framework employs a
Variational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)
renderings as input, using a unique latent space design that preserves 3D shape
information, and incorporates a cascaded latent diffusion model for improved
shape-texture disentanglement. The proposed method, GaussianAnything, supports
multi-modal conditional 3D generation, allowing for point cloud, caption, and
single/multi-view image inputs. Notably, the newly proposed latent space
naturally enables geometry-texture disentanglement, thus allowing 3D-aware
editing. Experimental results demonstrate the effectiveness of our approach on
multiple datasets, outperforming existing methods in both text- and
image-conditioned 3D generation.","['Yushi Lan', 'Shangchen Zhou', 'Zhaoyang Lyu', 'Fangzhou Hong', 'Shuai Yang', 'Bo Dai', 'Xingang Pan', 'Chen Change Loy']","['cs.CV', 'cs.AI', 'cs.GR']",2024-11-12 18:59:32+00:00
http://arxiv.org/abs/2411.08028v1,Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data,"In real-world NLP applications, Large Language Models (LLMs) offer promising
solutions due to their extensive training on vast datasets. However, the large
size and high computation demands of LLMs limit their practicality in many
applications, especially when further fine-tuning is required. To address these
limitations, smaller models are typically preferred for deployment. However,
their training is hindered by the scarcity of labeled data. In contrast,
unlabeled data is often readily which can be leveraged by using LLMs to
generate pseudo-labels for training smaller models. This enables the smaller
models (student) to acquire knowledge from LLMs(teacher) while reducing
computational costs. This process introduces challenges, such as potential
noisy pseudo-labels. Selecting high-quality and informative data is therefore
critical to enhance model performance while improving the efficiency of data
utilization. To address this, we propose LLKD that enables Learning with Less
computational resources and less data for Knowledge Distillation from LLMs.
LLKD is an adaptive sample selection method that incorporates signals from both
the teacher and student. Specifically, it prioritizes samples where the teacher
demonstrates high confidence in its labeling, indicating reliable labels, and
where the student exhibits a high information need, identifying challenging
samples that require further learning. Our comprehensive experiments show that
LLKD achieves superior performance across various datasets with higher data
efficiency.","['Juanhui Li', 'Sreyashi Nag', 'Hui Liu', 'Xianfeng Tang', 'Sheikh Sarwar', 'Limeng Cui', 'Hansu Gu', 'Suhang Wang', 'Qi He', 'Jiliang Tang']",['cs.AI'],2024-11-12 18:57:59+00:00
http://arxiv.org/abs/2411.08027v1,LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models,"Physical reasoning is an important skill needed for robotic agents when
operating in the real world. However, solving such reasoning problems often
involves hypothesizing and reflecting over complex multi-body interactions
under the effect of a multitude of physical forces and thus learning all such
interactions poses a significant hurdle for state-of-the-art machine learning
frameworks, including large language models (LLMs). To study this problem, we
propose a new physical reasoning task and a dataset, dubbed TraySim. Our task
involves predicting the dynamics of several objects on a tray that is given an
external impact -- the domino effect of the ensued object interactions and
their dynamics thus offering a challenging yet controlled setup, with the goal
of reasoning being to infer the stability of the objects after the impact. To
solve this complex physical reasoning task, we present LLMPhy, a zero-shot
black-box optimization framework that leverages the physics knowledge and
program synthesis abilities of LLMs, and synergizes these abilities with the
world models built into modern physics engines. Specifically, LLMPhy uses an
LLM to generate code to iteratively estimate the physical hyperparameters of
the system (friction, damping, layout, etc.) via an implicit
analysis-by-synthesis approach using a (non-differentiable) simulator in the
loop and uses the inferred parameters to imagine the dynamics of the scene
towards solving the reasoning task. To show the effectiveness of LLMPhy, we
present experiments on our TraySim dataset to predict the steady-state poses of
the objects. Our results show that the combination of the LLM and the physics
engine leads to state-of-the-art zero-shot physical reasoning performance,
while demonstrating superior convergence against standard black-box
optimization methods and better estimation of the physical parameters.","['Anoop Cherian', 'Radu Corcodel', 'Siddarth Jain', 'Diego Romeres']","['cs.LG', 'cs.AI', 'cs.CV', 'cs.RO']",2024-11-12 18:56:58+00:00
http://arxiv.org/abs/2411.08024v1,Leonardo vindicated: Pythagorean trees for minimal reconstruction of the natural branching structures,"Trees continue to fascinate with their natural beauty and as engineering
masterpieces optimal with respect to several independent criteria. Pythagorean
tree is a well-known fractal design that realistically mimics the natural tree
branching structures. We study various types of Pythagorean-like fractal trees
with different shapes of the base, branching angles and relaxed scales in an
attempt to identify and explain which variants are the closest match to the
branching structures commonly observed in the natural world. Pursuing
simultaneously the realism and minimalism of the fractal tree model, we have
developed a flexibly parameterised and fast algorithm to grow and visually
examine deep Pythagorean-inspired fractal trees with the capability to orderly
over- or underestimate the Leonardo da Vinci's tree branching rule as well as
control various imbalances and branching angles. We tested the realism of the
generated fractal tree images by means of the classification accuracy of
detecting natural tree with the transfer-trained deep Convolutional Neural
Networks (CNNs). Having empirically established the parameters of the fractal
trees that maximize the CNN's natural tree class classification accuracy we
have translated them back to the scales and angles of branches and came to the
interesting conclusions that support the da Vinci branching rule and golden
ratio based scaling for both the shape of the branch and imbalance between the
child branches, and claim the flexibly parameterized fractal trees can be used
to generate artificial examples to train robust detectors of different species
of trees.","['Dymitr Ruta', 'Corrado Mio', 'Ernesto Damiani']","['cs.AI', 'cs.LG', '68U05, 68T45, 92C80, 28A80', 'I.3.5; I.2.10; I.4.8; I.5.1; J.2']",2024-11-12 18:54:55+00:00
http://arxiv.org/abs/2411.08019v1,Language Models as Causal Effect Generators,"We present a framework for large language model (LLM) based data generation
with controllable causal structure. In particular, we define a procedure for
turning any language model and any directed acyclic graph (DAG) into a
sequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM
is a causal model with user-defined structure and LLM-defined structural
equations. We characterize how an SD-SCM allows sampling from observational,
interventional, and counterfactual distributions according to the desired
causal structure. We then leverage this procedure to propose a new type of
benchmark for causal inference methods, generating individual-level
counterfactual data without needing to manually specify functional
relationships between variables. We create an example benchmark consisting of
thousands of datasets, and test a suite of popular estimation methods on these
datasets for average, conditional average, and individual treatment effect
estimation, both with and without hidden confounding. Apart from generating
data, the same procedure also allows us to test for the presence of a causal
effect that might be encoded in an LLM. This procedure can underpin auditing
LLMs for misinformation, discrimination, or otherwise undesirable behavior. We
believe SD-SCMs can serve as a useful tool in any application that would
benefit from sequential data with controllable causal structure.","['Lucius E. J. Bynum', 'Kyunghyun Cho']","['cs.CL', 'cs.AI', 'cs.LG', 'stat.AP', 'stat.ME', 'stat.ML']",2024-11-12 18:50:35+00:00
http://arxiv.org/abs/2411.08017v1,Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings,"Large-scale 3D generative models require substantial computational resources
yet often fall short in capturing fine details and complex geometries at high
resolutions. We attribute this limitation to the inefficiency of current
representations, which lack the compactness required to model the generative
models effectively. To address this, we introduce a novel approach called
Wavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,
compact latent encodings. Specifically, we compress a $256^3$ signed distance
field into a $12^3 \times 4$ latent grid, achieving an impressive 2427x
compression ratio with minimal loss of detail. This high level of compression
allows our method to efficiently train large-scale generative networks without
increasing the inference time. Our models, both conditional and unconditional,
contain approximately one billion parameters and successfully generate
high-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid
inference, producing shapes within two to four seconds depending on the
condition, despite the model's scale. We demonstrate state-of-the-art
performance across multiple datasets, with significant improvements in
generation quality, diversity, and computational efficiency. We open-source our
code and, to the best of our knowledge, release the largest pretrained 3D
generative models across different modalities.","['Aditya Sanghi', 'Aliasghar Khani', 'Pradyumna Reddy', 'Arianna Rampini', 'Derek Cheung', 'Kamal Rahimi Malekshan', 'Kanika Madan', 'Hooman Shayani']","['cs.CV', 'cs.AI', 'cs.LG']",2024-11-12 18:49:06+00:00
http://arxiv.org/abs/2411.08013v1,Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech,"Speech impairments in Parkinson's disease (PD) provide significant early
indicators for diagnosis. While models for speech-based PD detection have shown
strong performance, their interpretability remains underexplored. This study
systematically evaluates several explainability methods to identify PD-specific
speech features, aiming to support the development of accurate, interpretable
models for clinical decision-making in PD diagnosis and monitoring. Our
methodology involves (i) obtaining attributions and saliency maps using
mainstream interpretability techniques, (ii) quantitatively evaluating the
faithfulness of these maps and their combinations obtained via union and
intersection through a range of established metrics, and (iii) assessing the
information conveyed by the saliency maps for PD detection from an auxiliary
classifier. Our results reveal that, while explanations are aligned with the
classifier, they often fail to provide valuable information for domain experts.","['Eleonora Mancini', 'Francesco Paissan', 'Paolo Torroni', 'Cem Subakan', 'Mirco Ravanelli']","['cs.SD', 'cs.AI', 'cs.LG', 'eess.AS']",2024-11-12 18:43:27+00:00
http://arxiv.org/abs/2411.08010v1,ExpressivityArena: Can LLMs Express Information Implicitly?,"While Large Language Models (LLMs) have demonstrated remarkable performance
in certain dimensions, their ability to express implicit language cues that
human use for effective communication remains unclear. This paper presents
ExpressivityArena, a Python library for measuring the implicit communication
abilities of LLMs. We provide a comprehensive framework to evaluate
expressivity of arbitrary LLMs and explore its practical implications. To this
end, we refine the definition and measurements of ``expressivity,'' and use our
framework in a set of small experiments. These experiments test LLMs in
creative and logical tasks such as poetry, coding, and emotion-based responses.
They are then evaluated by an automated grader, through ExpressivityArena,
which we verify to be the most pragmatic for testing expressivity. Building on
these experiments, we deepen our understanding of the expressivity of LLMs by
assessing their ability to remain expressive in conversations. Our findings
indicate that LLMs are capable of generating and understanding expressive
content, however, with some limitations. These insights will inform the future
development and deployment of expressive LLMs. We provide the code for
ExpressivityArena alongside our paper.","['Joshua Tint', 'Som Sagar', 'Aditya Taparia', 'Kelly Raines', 'Bimsara Pathiraja', 'Caleb Liu', 'Ransalu Senanayake']","['cs.CL', 'cs.AI', 'I.2.7']",2024-11-12 18:35:28+00:00
http://arxiv.org/abs/2411.08003v1,Can adversarial attacks by large language models be attributed?,"Attributing outputs from Large Language Models (LLMs) in adversarial
settings-such as cyberattacks and disinformation-presents significant
challenges that are likely to grow in importance. We investigate this
attribution problem using formal language theory, specifically language
identification in the limit as introduced by Gold and extended by Angluin. By
modeling LLM outputs as formal languages, we analyze whether finite text
samples can uniquely pinpoint the originating model. Our results show that due
to the non-identifiability of certain language classes, under some mild
assumptions about overlapping outputs from fine-tuned models it is
theoretically impossible to attribute outputs to specific LLMs with certainty.
This holds also when accounting for expressivity limitations of Transformer
architectures. Even with direct model access or comprehensive monitoring,
significant computational hurdles impede attribution efforts. These findings
highlight an urgent need for proactive measures to mitigate risks posed by
adversarial LLM use as their influence continues to expand.","['Manuel Cebrian', 'Jan Arne Telle']","['cs.AI', 'cs.CL', 'cs.CY', 'cs.FL']",2024-11-12 18:28:57+00:00
http://arxiv.org/abs/2411.07990v1,Derivational Morphology Reveals Analogical Generalization in Large Language Models,"What mechanisms underlie linguistic generalization in large language models
(LLMs)? This question has attracted considerable attention, with most studies
analyzing the extent to which the language skills of LLMs resemble rules. As of
yet, it is not known whether linguistic generalization in LLMs could equally
well be explained as the result of analogical processes, which can be
formalized as similarity operations on stored exemplars. A key shortcoming of
prior research is its focus on linguistic phenomena with a high degree of
regularity, for which rule-based and analogical approaches make the same
predictions. Here, we instead examine derivational morphology, specifically
English adjective nominalization, which displays notable variability. We
introduce a new method for investigating linguistic generalization in LLMs:
focusing on GPT-J, we fit cognitive models that instantiate rule-based and
analogical learning to the LLM training data and compare their predictions on a
set of nonce adjectives with those of the LLM, allowing us to draw direct
conclusions regarding underlying mechanisms. As expected, rule-based and
analogical models explain the predictions of GPT-J equally well for adjectives
with regular nominalization patterns. However, for adjectives with variable
nominalization patterns, the analogical model provides a much better match.
Furthermore, GPT-J's behavior is sensitive to the individual word frequencies,
even for regular forms, a behavior that is consistent with an analogical
account of regular forms but not a rule-based one. These findings refute the
hypothesis that GPT-J's linguistic generalization on adjective nominalization
involves rules, suggesting similarity operations on stored exemplars as the
underlying mechanism. Overall, our study suggests that analogical processes
play a bigger role in the linguistic generalization of LLMs than previously
thought.","['Valentin Hofmann', 'Leonie Weissweiler', 'David Mortensen', 'Hinrich Schütze', 'Janet Pierrehumbert']","['cs.CL', 'cs.AI', 'cs.LG']",2024-11-12 18:15:19+00:00
http://arxiv.org/abs/2411.07983v1,Gini Coefficient as a Unified Metric for Evaluating Many-versus-Many Similarity in Vector Spaces,"We demonstrate that Gini coefficients can be used as unified metrics to
evaluate many-versus-many (all-to-all) similarity in vector spaces. Our
analysis of various image datasets shows that images with the highest Gini
coefficients tend to be the most similar to one another, while images with the
lowest Gini coefficients are the least similar. We also show that this
relationship holds true for vectorized text embeddings from various corpuses,
highlighting the consistency of our method and its broad applicability across
different types of data. Additionally, we demonstrate that selecting machine
learning training samples that closely match the distribution of the testing
dataset is far more important than ensuring data diversity. Selection of
exemplary and iconic training samples with higher Gini coefficients leads to
significantly better model performance compared to simply having a diverse
training set with lower Gini coefficients. Thus, Gini coefficients can serve as
effective criteria for selecting machine learning training samples, with our
selection method outperforming random sampling methods in very sparse
information settings.",['Ben Fauber'],['cs.AI'],2024-11-12 18:08:45+00:00
http://arxiv.org/abs/2411.07979v1,"Exact, Tractable Gauss-Newton Optimization in Deep Reversible Architectures Reveal Poor Generalization","Second-order optimization has been shown to accelerate the training of deep
neural networks in many applications, often yielding faster progress per
iteration on the training loss compared to first-order optimizers.However, the
generalization properties of second-order methods are still being debated.
Theoretical investigations have proved difficult to carry out outside the
tractable settings of heavily simplified model classes -- thus, the relevance
of existing theories to practical deep learning applications remains unclear.
Similarly, empirical studies in large-scale models and real datasets are
significantly confounded by the necessity to approximate second-order updates
in practice. It is often unclear whether the observed generalization behaviour
arises specifically from the second-order nature of the parameter updates, or
instead reflects the specific structured (e.g.\ Kronecker) approximations used
or any damping-based interpolation towards first-order updates. Here, we show
for the first time that exact Gauss-Newton (GN) updates take on a tractable
form in a class of deep reversible architectures that are sufficiently
expressive to be meaningfully applied to common benchmark datasets. We exploit
this novel setting to study the training and generalization properties of the
GN optimizer. We find that exact GN generalizes poorly. In the mini-batch
training setting, this manifests as rapidly saturating progress even on the
\emph{training} loss, with parameter updates found to overfit each
mini-batchatch without producing the features that would support generalization
to other mini-batches. We show that our experiments run in the ``lazy'' regime,
in which the neural tangent kernel (NTK) changes very little during the course
of training. This behaviour is associated with having no significant changes in
neural representations, explaining the lack of generalization.","['Davide Buffelli', 'Jamie McGowan', 'Wangkun Xu', 'Alexandru Cioba', 'Da-shan Shiu', 'Guillaume Hennequin', 'Alberto Bernacchia']","['cs.LG', 'cs.AI']",2024-11-12 17:58:40+00:00
http://arxiv.org/abs/2411.07978v1,Doubly Robust Regression Discontinuity Designs,"This study introduces a doubly robust (DR) estimator for regression
discontinuity (RD) designs. In RD designs, treatment effects are estimated in a
quasi-experimental setting where treatment assignment depends on whether a
running variable surpasses a predefined cutoff. A common approach in RD
estimation is to apply nonparametric regression methods, such as local linear
regression. In such an approach, the validity relies heavily on the consistency
of nonparametric estimators and is limited by the nonparametric convergence
rate, thereby preventing $\sqrt{n}$-consistency. To address these issues, we
propose the DR-RD estimator, which combines two distinct estimators for the
conditional expected outcomes. If either of these estimators is consistent, the
treatment effect estimator remains consistent. Furthermore, due to the
debiasing effect, our proposed estimator achieves $\sqrt{n}$-consistency if
both regression estimators satisfy certain mild conditions, which also
simplifies statistical inference.",['Masahiro Kato'],"['econ.EM', 'cs.LG', 'math.ST', 'stat.ME', 'stat.ML', 'stat.TH']",2024-11-12 17:58:34+00:00
http://arxiv.org/abs/2411.07976v1,DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring,"Coronary artery disease (CAD), one of the most common cause of mortality in
the world. Coronary artery calcium (CAC) scoring using computed tomography (CT)
is key for risk assessment to prevent coronary disease. Previous studies on
risk assessment and calcification detection in CT scans primarily use
approaches based on UNET architecture, frequently implemented on pre-built
models. However, these models are limited by the availability of annotated CT
scans containing CAC and suffering from imbalanced dataset, decreasing
performance of CAC segmentation and scoring. In this study, we extend this
approach by incorporating the self-supervised learning (SSL) technique of DINO
(self-distillation with no labels) to eliminate limitations of scarce annotated
data in CT scans. The DINO model's ability to train without requiring CAC area
annotations enhances its robustness in generating distinct features. The DINO
model is trained on to focus specifically on calcified areas by using labels,
aiming to generate features that effectively capture and highlight key
characteristics. The label-guided DINO (DINO-LG) enhances classification by
distinguishing CT slices that contain calcification from those that do not,
performing 57% better than the standard DINO model in this task. CAC scoring
and segmentation tasks are performed by a basic U-NET architecture, fed
specifically with CT slices containing calcified areas as identified by the
DINO-LG model. This targeted identification performed by DINO-LG model improves
CAC segmentation performance by approximately 10% and significant increase in
CAC scoring accuracy.","['Mahmut S. Gokmen', 'Cody Bumgardner', 'Caner Ozcan']","['eess.IV', 'cs.AI', 'cs.CV']",2024-11-12 17:55:39+00:00
http://arxiv.org/abs/2411.07975v1,JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation,"We present JanusFlow, a powerful framework that unifies image understanding
and generation in a single model. JanusFlow introduces a minimalist
architecture that integrates autoregressive language models with rectified
flow, a state-of-the-art method in generative modeling. Our key finding
demonstrates that rectified flow can be straightforwardly trained within the
large language model framework, eliminating the need for complex architectural
modifications. To further improve the performance of our unified model, we
adopt two key strategies: (i) decoupling the understanding and generation
encoders, and (ii) aligning their representations during unified training.
Extensive experiments show that JanusFlow achieves comparable or superior
performance to specialized models in their respective domains, while
significantly outperforming existing unified approaches across standard
benchmarks. This work represents a step toward more efficient and versatile
vision-language models.","['Yiyang Ma', 'Xingchao Liu', 'Xiaokang Chen', 'Wen Liu', 'Chengyue Wu', 'Zhiyu Wu', 'Zizheng Pan', 'Zhenda Xie', 'Haowei Zhang', 'Xingkai yu', 'Liang Zhao', 'Yisong Wang', 'Jiaying Liu', 'Chong Ruan']","['cs.CV', 'cs.AI', 'cs.CL']",2024-11-12 17:55:10+00:00
http://arxiv.org/abs/2411.07971v1,Optimal Control of Mechanical Ventilators with Learned Respiratory Dynamics,"Deciding on appropriate mechanical ventilator management strategies
significantly impacts the health outcomes for patients with respiratory
diseases. Acute Respiratory Distress Syndrome (ARDS) is one such disease that
requires careful ventilator operation to be effectively treated. In this work,
we frame the management of ventilators for patients with ARDS as a sequential
decision making problem using the Markov decision process framework. We
implement and compare controllers based on clinical guidelines contained in the
ARDSnet protocol, optimal control theory, and learned latent dynamics
represented as neural networks. The Pulse Physiology Engine's respiratory
dynamics simulator is used to establish a repeatable benchmark, gather
simulated data, and quantitatively compare these controllers. We score
performance in terms of measured improvement in established ARDS health markers
(pertaining to improved respiratory rate, oxygenation, and vital signs). Our
results demonstrate that techniques leveraging neural networks and optimal
control can automatically discover effective ventilation management strategies
without access to explicit ventilator management procedures or guidelines (such
as those defined in the ARDSnet protocol).","['Isaac Ronald Ward', 'Dylan M. Asmar', 'Mansur Arief', 'Jana Krystofova Mike', 'Mykel J. Kochenderfer']","['eess.SY', 'cs.LG', 'cs.SY']",2024-11-12 17:51:45+00:00
http://arxiv.org/abs/2411.07964v1,Sleep Staging from Airflow Signals Using Fourier Approximations of Persistence Curves,"Sleep staging is a challenging task, typically manually performed by sleep
technologists based on electroencephalogram and other biosignals of patients
taken during overnight sleep studies. Recent work aims to leverage automated
algorithms to perform sleep staging not based on electroencephalogram signals,
but rather based on the airflow signals of subjects. Prior work uses ideas from
topological data analysis (TDA), specifically Hermite function expansions of
persistence curves (HEPC) to featurize airflow signals. However, finite order
HEPC captures only partial information. In this work, we propose Fourier
approximations of persistence curves (FAPC), and use this technique to perform
sleep staging based on airflow signals. We analyze performance using an XGBoost
model on 1155 pediatric sleep studies taken from the Nationwide Children's
Hospital Sleep DataBank (NCHSDB), and find that FAPC methods provide
complimentary information to HEPC methods alone, leading to a 4.9% increase in
performance over baseline methods.","['Shashank Manjunath', 'Hau-Tieng Wu', 'Aarti Sathyanarayana']",['cs.LG'],2024-11-12 17:41:16+00:00
http://arxiv.org/abs/2411.07959v1,On the Convergence of Continual Federated Learning Using Incrementally Aggregated Gradients,"The holy grail of machine learning is to enable Continual Federated Learning
(CFL) to enhance the efficiency, privacy, and scalability of AI systems while
learning from streaming data. The primary challenge of a CFL system is to
overcome global catastrophic forgetting, wherein the accuracy of the global
model trained on new tasks declines on the old tasks. In this work, we propose
Continual Federated Learning with Aggregated Gradients (C-FLAG), a novel
replay-memory based federated strategy consisting of edge-based gradient
updates on memory and aggregated gradients on the current data. We provide
convergence analysis of the C-FLAG approach which addresses forgetting and bias
while converging at a rate of $O(1/\sqrt{T})$ over $T$ communication rounds. We
formulate an optimization sub-problem that minimizes catastrophic forgetting,
translating CFL into an iterative algorithm with adaptive learning rates that
ensure seamless learning across tasks. We empirically show that C-FLAG
outperforms several state-of-the-art baselines on both task and
class-incremental settings with respect to metrics such as accuracy and
forgetting.","['Satish Kumar Keshri', 'Nazreen Shah', 'Ranjitha Prasad']","['cs.LG', 'cs.DC']",2024-11-12 17:36:20+00:00
http://arxiv.org/abs/2411.07957v1,Tukey g-and-h neural network regression for non-Gaussian data,"This paper addresses non-Gaussian regression with neural networks via the use
of the Tukey g-and-h distribution.The Tukey g-and-h transform is a flexible
parametric transform with two parameters $g$ and $h$ which, when applied to a
standard normal random variable, introduces both skewness and kurtosis,
resulting in a distribution commonly called the Tukey g-and-h distribution.
Specific values of $g$ and $h$ produce good approximations to other families of
distributions, such as the Cauchy and student-t distributions. The flexibility
of the Tukey g-and-h distribution has driven its popularity in the statistical
community, in applied sciences and finance. In this work we consider the
training of a neural network to predict the parameters of a Tukey g-and-h
distribution in a regression framework via the minimization of the
corresponding negative log-likelihood, despite the latter having no closed-form
expression. We demonstrate the efficiency of our procedure in simulated
examples and apply our method to a real-world dataset of global crop yield for
several types of crops. Finally, we show how we can carry out a goodness-of-fit
analysis between the predicted distributions and the test data. A Pytorch
implementation is made available on Github and as a Pypi package.","['Arthur P. Guillaumin', 'Natalia Efremova']","['stat.ML', 'cs.LG']",2024-11-12 17:34:38+00:00
http://arxiv.org/abs/2411.07955v1,"How To Discover Short, Shorter, and the Shortest Proofs of Unsatisfiability: A Branch-and-Bound Approach for Resolution Proof Length Minimization","Modern software for propositional satisfiability problems gives a powerful
automated reasoning toolkit, capable of outputting not only a
satisfiable/unsatisfiable signal but also a justification of unsatisfiability
in the form of resolution proof (or a more expressive proof), which is commonly
used for verification purposes. Empirically, modern SAT solvers produce
relatively short proofs, however, there are no inherent guarantees that these
proofs cannot be significantly reduced. This paper proposes a novel
branch-and-bound algorithm for finding the shortest resolution proofs; to this
end, we introduce a layer list representation of proofs that groups clauses by
their level of indirection. As we show, this representation breaks all
permutational symmetries, thereby improving upon the state-of-the-art
symmetry-breaking and informing the design of a novel workflow for proof
minimization. In addition to that, we design pruning procedures that reason on
proof length lower bound, clause subsumption, and dominance. Our experiments
suggest that the proofs from state-of-the-art solvers could be shortened by
30-60% on the instances from SAT Competition 2002 and by 25-50% on small
synthetic formulas. When treated as an algorithm for finding the shortest
proof, our approach solves twice as many instances as the previous work based
on SAT solving and reduces the time to optimality by orders of magnitude for
the instances solved by both approaches.","['Konstantin Sidorov', 'Koos van der Linden', 'Gonçalo Homem de Almeida Correia', 'Mathijs de Weerdt', 'Emir Demirović']","['cs.AI', 'I.2.8']",2024-11-12 17:31:35+00:00
http://arxiv.org/abs/2411.07954v1,Learning Memory Mechanisms for Decision Making through Demonstrations,"In Partially Observable Markov Decision Processes, integrating an agent's
history into memory poses a significant challenge for decision-making.
Traditional imitation learning, relying on observation-action pairs for expert
demonstrations, fails to capture the expert's memory mechanisms used in
decision-making. To capture memory processes as demonstrations, we introduce
the concept of \textbf{memory dependency pairs} $(p, q)$ indicating that events
at time $p$ are recalled for decision-making at time $q$. We introduce
\textbf{AttentionTuner} to leverage memory dependency pairs in Transformers and
find significant improvements across several tasks compared to standard
Transformers when evaluated on Memory Gym and the Long-term Memory Benchmark.
Code is available at https://github.com/WilliamYue37/AttentionTuner .","['William Yue', 'Bo Liu', 'Peter Stone']","['cs.LG', 'cs.RO']",2024-11-12 17:30:31+00:00
http://arxiv.org/abs/2411.07942v1,Towards Low-bit Communication for Tensor Parallel LLM Inference,"Tensor parallelism provides an effective way to increase server large
language model (LLM) inference efficiency despite adding an additional
communication cost. However, as server LLMs continue to scale in size, they
will need to be distributed across more devices, magnifying the communication
cost. One way to approach this problem is with quantization, but current
methods for LLMs tend to avoid quantizing the features that tensor parallelism
needs to communicate. Taking advantage of consistent outliers in communicated
features, we introduce a quantization method that reduces communicated values
on average from 16 bits to 4.2 bits while preserving nearly all of the original
performance. For instance, our method maintains around 98.0% and 99.5% of Gemma
2 27B's and Llama 2 13B's original performance, respectively, averaged across
all tasks we evaluated on.","['Harry Dong', 'Tyler Johnson', 'Minsik Cho', 'Emad Soroush']","['cs.AI', 'cs.LG']",2024-11-12 17:11:46+00:00
http://arxiv.org/abs/2411.07941v1,DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks,"Computed tomography (CT) provides highly detailed three-dimensional (3D)
medical images but is costly, time-consuming, and often inaccessible in
intraoperative settings (Organization et al. 2011). Recent advancements have
explored reconstructing 3D chest volumes from sparse 2D X-rays, such as
single-view or orthogonal double-view images. However, current models tend to
process 2D images in a planar manner, prioritizing visual realism over
structural accuracy. In this work, we introduce DuoLift Generative Adversarial
Networks (DuoLift-GAN), a novel architecture with dual branches that
independently elevate 2D images and their features into 3D representations.
These 3D outputs are merged into a unified 3D feature map and decoded into a
complete 3D chest volume, enabling richer 3D information capture. We also
present a masked loss function that directs reconstruction towards critical
anatomical regions, improving structural accuracy and visual quality. This
paper demonstrates that DuoLift-GAN significantly enhances reconstruction
accuracy while achieving superior visual realism compared to existing methods.","['Zhaoxi Zhang', 'Yueliang Ying']","['eess.IV', 'cs.AI', 'cs.CV']",2024-11-12 17:11:18+00:00
http://arxiv.org/abs/2411.07940v1,Automatic dataset shift identification to support root cause analysis of AI performance drift,"Shifts in data distribution can substantially harm the performance of
clinical AI models. Hence, various methods have been developed to detect the
presence of such shifts at deployment time. However, root causes of dataset
shifts are varied, and the choice of shift mitigation strategies is highly
dependent on the precise type of shift encountered at test time. As such,
detecting test-time dataset shift is not sufficient: precisely identifying
which type of shift has occurred is critical. In this work, we propose the
first unsupervised dataset shift identification framework, effectively
distinguishing between prevalence shift (caused by a change in the label
distribution), covariate shift (caused by a change in input characteristics)
and mixed shifts (simultaneous prevalence and covariate shifts). We discuss the
importance of self-supervised encoders for detecting subtle covariate shifts
and propose a novel shift detector leveraging both self-supervised encoders and
task model outputs for improved shift detection. We report promising results
for the proposed shift identification framework across three different imaging
modalities (chest radiography, digital mammography, and retinal fundus images)
on five types of real-world dataset shifts, using four large publicly available
datasets.","['Mélanie Roschewitz', 'Raghav Mehta', 'Charles Jones', 'Ben Glocker']","['cs.AI', 'cs.CV']",2024-11-12 17:09:20+00:00
http://arxiv.org/abs/2411.07934v1,Doubly Mild Generalization for Offline Reinforcement Learning,"Offline Reinforcement Learning (RL) suffers from the extrapolation error and
value overestimation. From a generalization perspective, this issue can be
attributed to the over-generalization of value functions or policies towards
out-of-distribution (OOD) actions. Significant efforts have been devoted to
mitigating such generalization, and recent in-sample learning approaches have
further succeeded in entirely eschewing it. Nevertheless, we show that mild
generalization beyond the dataset can be trusted and leveraged to improve
performance under certain conditions. To appropriately exploit generalization
in offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild
action generalization and (ii) mild generalization propagation. The former
refers to selecting actions in a close neighborhood of the dataset to maximize
the Q values. Even so, the potential erroneous generalization can still be
propagated, accumulated, and exacerbated by bootstrapping. In light of this,
the latter concept is introduced to mitigate the generalization propagation
without impeding the propagation of RL learning signals. Theoretically, DMG
guarantees better performance than the in-sample optimal policy in the oracle
generalization scenario. Even under worst-case generalization, DMG can still
control value overestimation at a certain level and lower bound the
performance. Empirically, DMG achieves state-of-the-art performance across
Gym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting
from its flexibility in both generalization aspects, DMG enjoys a seamless
transition from offline to online learning and attains strong online
fine-tuning performance.","['Yixiu Mao', 'Qi Wang', 'Yun Qu', 'Yuhang Jiang', 'Xiangyang Ji']","['cs.LG', 'cs.AI']",2024-11-12 17:04:56+00:00
http://arxiv.org/abs/2411.07933v1,Prediction of Acoustic Communication Performance for AUVs using Gaussian Process Classification,"Cooperating autonomous underwater vehicles (AUVs) often rely on acoustic
communication to coordinate their actions effectively. However, the reliability
of underwater acoustic communication decreases as the communication range
between vehicles increases. Consequently, teams of cooperating AUVs typically
make conservative assumptions about the maximum range at which they can
communicate reliably. To address this limitation, we propose a novel approach
that involves learning a map representing the probability of successful
communication based on the locations of the transmitting and receiving
vehicles. This probabilistic communication map accounts for factors such as the
range between vehicles, environmental noise, and multi-path effects at a given
location. In pursuit of this goal, we investigate the application of Gaussian
process binary classification to generate the desired communication map. We
specialize existing results to this specific binary classification problem and
explore methods to incorporate uncertainty in vehicle location into the mapping
process. Furthermore, we compare the prediction performance of the probability
communication map generated using binary classification with that of a
signal-to-noise ratio (SNR) communication map generated using Gaussian process
regression. Our approach is experimentally validated using communication and
navigation data collected during trials with a pair of Virginia Tech 690 AUVs.","['Yifei Gao', 'Harun Yetkin', 'McMahon James', 'Daniel J. Stilwell']","['cs.RO', 'cs.LG']",2024-11-12 17:04:12+00:00
http://arxiv.org/abs/2411.07889v1,A Stochastic Optimization Framework for Private and Fair Learning From Decentralized Data,"Machine learning models are often trained on sensitive data (e.g., medical
records and race/gender) that is distributed across different ""silos"" (e.g.,
hospitals). These federated learning models may then be used to make
consequential decisions, such as allocating healthcare resources. Two key
challenges emerge in this setting: (i) maintaining the privacy of each person's
data, even if other silos or an adversary with access to the central server
tries to infer this data; (ii) ensuring that decisions are fair to different
demographic groups (e.g., race/gender). In this paper, we develop a novel
algorithm for private and fair federated learning (FL). Our algorithm satisfies
inter-silo record-level differential privacy (ISRL-DP), a strong notion of
private FL requiring that silo i's sent messages satisfy record-level
differential privacy for all i. Our framework can be used to promote different
fairness notions, including demographic parity and equalized odds. We prove
that our algorithm converges under mild smoothness assumptions on the loss
function, whereas prior work required strong convexity for convergence. As a
byproduct of our analysis, we obtain the first convergence guarantee for
ISRL-DP nonconvex-strongly concave min-max FL. Experiments demonstrate the
state-of-the-art fairness-accuracy tradeoffs of our algorithm across different
privacy levels.","['Devansh Gupta', 'A. S. Poornash', 'Andrew Lowy', 'Meisam Razaviyayn']",['cs.LG'],2024-11-12 15:51:35+00:00
http://arxiv.org/abs/2411.07885v1,INTRABENCH: Interactive Radiological Benchmark,"Current interactive segmentation approaches, inspired by the success of
META's Segment Anything model, have achieved notable advancements, however,
they come with substantial limitations that hinder their practical application
in real clinical scenarios. These include unrealistic human interaction
requirements, such as slice-by-slice operations for 2D models on 3D data, a
lack of iterative refinement, and insufficient evaluation experiments. These
shortcomings prevent accurate assessment of model performance and lead to
inconsistent outcomes across studies. IntRaBench overcomes these challenges by
offering a comprehensive and reproducible framework for evaluating interactive
segmentation methods in realistic, clinically relevant scenarios. It includes
diverse datasets, target structures, and segmentation models, and provides a
flexible codebase that allows seamless integration of new models and prompting
strategies. Additionally, we introduce advanced techniques to minimize
clinician interaction, ensuring fair comparisons between 2D and 3D models. By
open-sourcing IntRaBench, we invite the research community to integrate their
models and prompting techniques, ensuring continuous and transparent evaluation
of interactive segmentation models in 3D medical imaging.","['Constantin Ulrich', 'Tassilo Wald', 'Emily Tempus', 'Maximilian Rokuss', 'Paul F. Jaeger', 'Klaus Maier-Hein']","['cs.CV', 'cs.AI', 'cs.HC', 'cs.LG']",2024-11-12 15:47:17+00:00
http://arxiv.org/abs/2411.07873v1,Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules,"Humans excel at discovering regular structures from limited samples and
applying inferred rules to novel settings. We investigate whether modern
generative models can similarly learn underlying rules from finite samples and
perform reasoning through conditional sampling. Inspired by Raven's Progressive
Matrices task, we designed GenRAVEN dataset, where each sample consists of
three rows, and one of 40 relational rules governing the object position,
number, or attributes applies to all rows. We trained generative models to
learn the data distribution, where samples are encoded as integer arrays to
focus on rule learning. We compared two generative model families: diffusion
(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their
ability to generate structurally consistent samples and perform panel
completion via unconditional and conditional sampling. We found diffusion
models excel at unconditional generation, producing more novel and consistent
samples from scratch and memorizing less, but performing less well in panel
completion, even with advanced conditional sampling methods. Conversely,
autoregressive models excel at completing missing panels in a rule-consistent
manner but generate less consistent samples unconditionally. We observe diverse
data scaling behaviors: for both model families, rule learning emerges at a
certain dataset size - around 1000s examples per rule. With more training data,
diffusion models improve both their unconditional and conditional generation
capabilities. However, for autoregressive models, while panel completion
improves with more training data, unconditional generation consistency
declines. Our findings highlight complementary capabilities and limitations of
diffusion and autoregressive models in rule learning and reasoning tasks,
suggesting avenues for further research into their mechanisms and potential for
human-like reasoning.","['Binxu Wang', 'Jiaqi Shang', 'Haim Sompolinsky']","['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE', '68T07, 68T09, 68T20, 62H30', 'I.2.6; I.2.10; I.2.7; I.5.1']",2024-11-12 15:29:50+00:00
http://arxiv.org/abs/2411.07871v1,Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease,"The rapid advancements in Large Language Models (LLMs) and Vision-Language
Models (VLMs) have shown great potential in medical diagnostics, particularly
in radiology, where datasets such as X-rays are paired with human-generated
diagnostic reports. However, a significant research gap exists in the
neuroimaging field, especially for conditions such as Alzheimer's disease, due
to the lack of comprehensive diagnostic reports that can be utilized for model
fine-tuning. This paper addresses this gap by generating synthetic diagnostic
reports using GPT-4o-mini on structured data from the OASIS-4 dataset, which
comprises 663 patients. Using the synthetic reports as ground truth for
training and validation, we then generated neurological reports directly from
the images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.
Our proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,
and METEOR score of 0.4163, revealing its potential in generating clinically
relevant and accurate diagnostic reports.","['Francesco Chiumento', 'Mingming Liu']","['cs.AI', 'eess.IV']",2024-11-12 15:28:06+00:00
http://arxiv.org/abs/2411.07870v1,Trustful LLMs: Customizing and Grounding Text Generation with Knowledge Bases and Dual Decoders,"Although people are impressed by the content generation skills of large
language models, the use of LLMs, such as ChatGPT, is limited by the domain
grounding of the content. The correctness and groundedness of the generated
content need to be based on a verified context, such as results from
Retrieval-Augmented Generation (RAG). One important issue when adapting LLMs to
a customized domain is that the generated responses are often incomplete, or
the additions are not verified and may even be hallucinated. Prior studies on
hallucination detection have focused on evaluation metrics, which are not
easily adaptable to dynamic domains and can be vulnerable to attacks like
jail-breaking. In this work, we propose 1) a post-processing algorithm that
leverages knowledge triplets in RAG context to correct hallucinations and 2) a
dual-decoder model that fuses RAG context to guide the generation process.","['Xiaofeng Zhu', 'Jaya Krishna Mandivarapu']","['cs.CL', 'cs.AI']",2024-11-12 15:26:17+00:00
http://arxiv.org/abs/2411.07863v1,CDXFormer: Boosting Remote Sensing Change Detection with Extended Long Short-Term Memory,"In complex scenes and varied conditions, effectively integrating
spatial-temporal context is crucial for accurately identifying changes.
However, current RS-CD methods lack a balanced consideration of performance and
efficiency. CNNs lack global context, Transformers have quadratic computational
complexity, and Mambas are restricted by CUDA acceleration. In this paper, we
propose CDXFormer, with a core component that is a powerful XLSTM-based feature
enhancement layer, integrating the advantages of linear computational
complexity, global context perception, and strong interpret-ability.
Specifically, we introduce a scale-specific Feature Enhancer layer,
incorporating a Cross-Temporal Global Perceptron customized for
semantic-accurate deep features, and a Cross-Temporal Spatial Refiner
customized for detail-rich shallow features. Additionally, we propose a
Cross-Scale Interactive Fusion module to progressively interact global change
representations with spatial responses. Extensive experimental results
demonstrate that CDXFormer achieves state-of-the-art performance across three
benchmark datasets, offering a compelling balance between efficiency and
accuracy. Code is available at https://github.com/xwmaxwma/rschange.","['Zhenkai Wu', 'Xiaowen Ma', 'Rongrong Lian', 'Zhentao Lin', 'Wei Zhang']","['cs.CV', 'cs.LG', 'eess.IV']",2024-11-12 15:22:14+00:00
http://arxiv.org/abs/2411.07860v1,Integrating Chaotic Evolutionary and Local Search Techniques in Decision Space for Enhanced Evolutionary Multi-Objective Optimization,"This paper presents innovative approaches to optimization problems, focusing
on both Single-Objective Multi-Modal Optimization (SOMMOP) and Multi-Objective
Optimization (MOO). In SOMMOP, we integrate chaotic evolution with niching
techniques, as well as Persistence-Based Clustering combined with Gaussian
mutation. The proposed algorithms, Chaotic Evolution with Deterministic
Crowding (CEDC) and Chaotic Evolution with Clustering Algorithm (CECA), utilize
chaotic dynamics to enhance population diversity and improve search efficiency.
For MOO, we extend these methods into a comprehensive framework that
incorporates Uncertainty-Based Selection, Adaptive Parameter Tuning, and
introduces a radius \( R \) concept in deterministic crowding, which enables
clearer and more precise separation of populations at peak points. Experimental
results demonstrate that the proposed algorithms outperform traditional
methods, achieving superior optimization accuracy and robustness across a
variety of benchmark functions.",['Xiang Meng'],['cs.NE'],2024-11-12 15:18:48+00:00
http://arxiv.org/abs/2411.07854v1,Tucano: Advancing Neural Text Generation for Portuguese,"Significant advances have been made in natural language processing in recent
years. However, our current deep learning approach to language modeling
requires substantial resources in terms of data and computation. One of the
side effects of this data-hungry paradigm is the current schism between
languages, separating those considered high-resource, where most of the
development happens and resources are available, and the low-resource ones,
which struggle to attain the same level of performance and autonomy. This study
aims to introduce a new set of resources to stimulate the future development of
neural text generation in Portuguese. In this work, we document the development
of GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting
to 200 billion tokens. Via this corpus, we trained a series of
decoder-transformers named Tucano. Our models perform equal or superior to
other Portuguese and multilingual language models of similar size in several
Portuguese benchmarks. The evaluation of our models also reveals that model
performance on many currently available benchmarks used by the Portuguese NLP
community has little to no correlation with the scaling of token ingestion
during training, highlighting the limitations of such evaluations when it comes
to the assessment of Portuguese generative language models. All derivatives of
our study are openly released on GitHub and Hugging Face. See
https://nkluge-correa.github.io/Tucano/","['Nicholas Kluge Corrêa', 'Aniket Sen', 'Sophia Falk', 'Shiza Fatimah']","['cs.CL', 'cs.AI', 'cs.LG']",2024-11-12 15:06:06+00:00
http://arxiv.org/abs/2411.07853v1,Evidential time-to-event prediction model with well-calibrated uncertainty estimation,"Time-to-event analysis, or Survival analysis, provides valuable insights into
clinical prognosis and treatment recommendations. However, this task is
typically more challenging than other regression tasks due to the censored
observations. Moreover, concerns regarding the reliability of predictions
persist among clinicians, mainly attributed to the absence of confidence
assessment, robustness, and calibration of prediction. To address those
challenges, we introduce an evidential regression model designed especially for
time-to-event prediction tasks, with which the most plausible event time, is
directly quantified by aggregated Gaussian random fuzzy numbers (GRFNs). The
GRFNs are a newly introduced family of random fuzzy subsets of the real line
that generalizes both Gaussian random variables and Gaussian possibility
distributions. Different from conventional methods that construct models based
on strict data distribution, e.g., proportional hazard function, our model only
assumes the event time is encoded in a real line GFRN without any strict
distribution assumption, therefore offering more flexibility in complex data
scenarios. Furthermore, the epistemic and aleatory uncertainty regarding the
event time is quantified within the aggregated GRFN as well. Our model can,
therefore, provide more detailed clinical decision-making guidance with two
more degrees of information. The model is fit by minimizing a generalized
negative log-likelihood function that accounts for data censoring based on
uncertainty evidence reasoning. Experimental results on simulated datasets with
varying data distributions and censoring scenarios, as well as on real-world
datasets across diverse clinical settings and tasks, demonstrate that our model
achieves both accurate and reliable performance, outperforming state-of-the-art
methods.","['Ling Huang', 'Yucheng Xing', 'Swapnil Mishra', 'Thierry Denoeux', 'Mengling Feng']",['cs.LG'],2024-11-12 15:06:04+00:00
http://arxiv.org/abs/2411.07850v1,IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems,"Adversarial examples, which are inputs deliberately perturbed with
imperceptible changes to induce model errors, have raised serious concerns for
the reliability and security of deep neural networks (DNNs). While adversarial
attacks have been extensively studied in continuous data domains such as
images, the discrete nature of text presents unique challenges. In this paper,
we propose Irony-based Adversarial Examples (IAE), a method that transforms
straightforward sentences into ironic ones to create adversarial text. This
approach exploits the rhetorical device of irony, where the intended meaning is
opposite to the literal interpretation, requiring a deeper understanding of
context to detect. The IAE method is particularly challenging due to the need
to accurately locate evaluation words, substitute them with appropriate
collocations, and expand the text with suitable ironic elements while
maintaining semantic coherence. Our research makes the following key
contributions: (1) We introduce IAE, a strategy for generating textual
adversarial examples using irony. This method does not rely on pre-existing
irony corpora, making it a versatile tool for creating adversarial text in
various NLP tasks. (2) We demonstrate that the performance of several
state-of-the-art deep learning models on sentiment analysis tasks significantly
deteriorates when subjected to IAE attacks. This finding underscores the
susceptibility of current NLP systems to adversarial manipulation through
irony. (3) We compare the impact of IAE on human judgment versus NLP systems,
revealing that humans are less susceptible to the effects of irony in text.","['Xiaoyin Yi', 'Jiacheng Huang']","['cs.CL', 'cs.AI']",2024-11-12 15:01:47+00:00
http://arxiv.org/abs/2411.07845v1,Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements,"What ethical concerns, if any, do LLM researchers have? We introduce EthiCon,
a corpus of 1,580 ethical concern statements extracted from scientific papers
published in the ACL Anthology. We extract ethical concern keywords from the
statements and show promising results in automating the concern identification
process. Through a survey, we compare the ethical concerns of the corpus to the
concerns listed by the general public and professionals in the field. Finally,
we compare our retrieved ethical concerns with existing taxonomies pointing to
gaps and future research directions.","['Antonia Karamolegkou', 'Sandrine Schiller Hansen', 'Ariadni Christopoulou', 'Filippos Stamatiou', 'Anne Lauscher', 'Anders Søgaard']","['cs.CL', 'cs.AI', 'cs.CY']",2024-11-12 14:53:12+00:00
http://arxiv.org/abs/2411.07843v1,Chain Association-based Attacking and Shielding Natural Language Processing Systems,"Association as a gift enables people do not have to mention something in
completely straightforward words and allows others to understand what they
intend to refer to. In this paper, we propose a chain association-based
adversarial attack against natural language processing systems, utilizing the
comprehension gap between humans and machines. We first generate a chain
association graph for Chinese characters based on the association paradigm for
building search space of potential adversarial examples. Then, we introduce an
discrete particle swarm optimization algorithm to search for the optimal
adversarial examples. We conduct comprehensive experiments and show that
advanced natural language processing models and applications, including large
language models, are vulnerable to our attack, while humans appear good at
understanding the perturbed text. We also explore two methods, including
adversarial training and associative graph-based recovery, to shield systems
from chain association-based attack. Since a few examples that use some
derogatory terms, this paper contains materials that may be offensive or
upsetting to some people.","['Jiacheng Huang', 'Long Chen']","['cs.CL', 'cs.AI']",2024-11-12 14:51:41+00:00
http://arxiv.org/abs/2411.07841v1,Federated Learning for Discrete Optimal Transport with Large Population under Incomplete Information,"Optimal transport is a powerful framework for the efficient allocation of
resources between sources and targets. However, traditional models often
struggle to scale effectively in the presence of large and heterogeneous
populations. In this work, we introduce a discrete optimal transport framework
designed to handle large-scale, heterogeneous target populations, characterized
by type distributions. We address two scenarios: one where the type
distribution of targets is known, and one where it is unknown. For the known
distribution, we propose a fully distributed algorithm to achieve optimal
resource allocation. In the case of unknown distribution, we develop a
federated learning-based approach that enables efficient computation of the
optimal transport scheme while preserving privacy. Case studies are provided to
evaluate the performance of our learning algorithm.","['Navpreet Kaur', 'Juntao Chen', 'Yingdong Lu']",['cs.AI'],2024-11-12 14:46:31+00:00
http://arxiv.org/abs/2411.07837v1,FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training,"With the increase in the number of parameters in large language models, the
process of pre-training and fine-tuning increasingly demands larger volumes of
GPU memory. A significant portion of this memory is typically consumed by the
optimizer state. To overcome this challenge, recent approaches such as low-rank
adaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhao
et al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have been
proposed. However, in all these algorithms, the $\textit{effective rank of the
weight updates remains low-rank}$, which can lead to a substantial loss of
information from the gradient. This loss can be critically important,
especially during the pre-training stage. In this paper, we introduce
$\texttt{FRUGAL}$ ($\textbf{F}$ull-$\textbf{R}$ank $\textbf{U}$pdates with
$\textbf{G}$r$\textbf{A}$dient sp$\textbf{L}$itting), a new memory-efficient
optimization framework. $\texttt{FRUGAL}$ leverages gradient splitting to
perform low-dimensional updates using advanced algorithms (such as Adam), while
updates along the remaining directions are executed via state-free methods like
SGD or signSGD (Bernstein et al., 2018). Our framework can be integrated with
various low-rank update selection techniques, including GaLore and BAdam. We
provide theoretical convergence guarantees for our framework when using SGDM
for low-dimensional updates and SGD for state-free updates. Additionally, our
method consistently outperforms concurrent approaches across various fixed
memory budgets, achieving state-of-the-art results in pre-training and
fine-tuning tasks while balancing memory efficiency and performance metrics.","['Philip Zmushko', 'Aleksandr Beznosikov', 'Martin Takáč', 'Samuel Horváth']",['cs.LG'],2024-11-12 14:41:07+00:00
http://arxiv.org/abs/2411.07832v1,Dynamical-VAE-based Hindsight to Learn the Causal Dynamics of Factored-POMDPs,"Learning representations of underlying environmental dynamics from partial
observations is a critical challenge in machine learning. In the context of
Partially Observable Markov Decision Processes (POMDPs), state representations
are often inferred from the history of past observations and actions. We
demonstrate that incorporating future information is essential to accurately
capture causal dynamics and enhance state representations. To address this, we
introduce a Dynamical Variational Auto-Encoder (DVAE) designed to learn causal
Markovian dynamics from offline trajectories in a POMDP. Our method employs an
extended hindsight framework that integrates past, current, and multi-step
future information within a factored-POMDP setting. Empirical results reveal
that this approach uncovers the causal graph governing hidden state transitions
more effectively than history-based and typical hindsight-based models.","['Chao Han', 'Debabrota Basu', 'Michael Mangan', 'Eleni Vasilaki', 'Aditya Gilra']","['cs.LG', 'stat.ML']",2024-11-12 14:27:45+00:00
http://arxiv.org/abs/2411.07828v1,Suite-IN: Aggregating Motion Features from Apple Suite for Robust Inertial Navigation,"With the rapid development of wearable technology, devices like smartphones,
smartwatches, and headphones equipped with IMUs have become essential for
applications such as pedestrian positioning. However, traditional pedestrian
dead reckoning (PDR) methods struggle with diverse motion patterns, while
recent data-driven approaches, though improving accuracy, often lack robustness
due to reliance on a single device.In our work, we attempt to enhance the
positioning performance using the low-cost commodity IMUs embedded in the
wearable devices. We propose a multi-device deep learning framework named
Suite-IN, aggregating motion data from Apple Suite for inertial navigation.
Motion data captured by sensors on different body parts contains both local and
global motion information, making it essential to reduce the negative effects
of localized movements and extract global motion representations from multiple
devices.","['Lan Sun', 'Songpengcheng Xia', 'Junyuan Deng', 'Jiarui Yang', 'Zengyuan Lai', 'Qi Wu', 'Ling Pei']",['cs.LG'],2024-11-12 14:23:52+00:00
http://arxiv.org/abs/2411.07826v1,Efficient Federated Finetuning of Tiny Transformers with Resource-Constrained Devices,"In recent years, Large Language Models (LLMs) through Transformer structures
have dominated many machine learning tasks, especially text processing.
However, these models require massive amounts of data for training and induce
high resource requirements, particularly in terms of the large number of
Floating Point Operations (FLOPs) and the high amounts of memory needed. To
fine-tune such a model in a parameter-efficient way, techniques like Adapter or
LoRA have been developed. However, we observe that the application of LoRA,
when used in federated learning (FL), while still being parameter-efficient, is
memory and FLOP inefficient. Based on that observation, we develop a novel
layer finetuning scheme that allows devices in cross-device FL to make use of
pretrained neural networks (NNs) while adhering to given resource constraints.
We show that our presented scheme outperforms the current state of the art when
dealing with homogeneous or heterogeneous computation and memory constraints
and is on par with LoRA regarding limited communication, thereby achieving
significantly higher accuracies in FL training.","['Kilian Pfeiffer', 'Mohamed Aboelenien Ahmed', 'Ramin Khalili', 'Jörg Henkel']","['cs.LG', 'cs.AI', 'cs.DC']",2024-11-12 14:22:16+00:00
http://arxiv.org/abs/2411.07816v1,Dual-Criterion Model Aggregation in Federated Learning: Balancing Data Quantity and Quality,"Federated learning (FL) has become one of the key methods for
privacy-preserving collaborative learning, as it enables the transfer of models
without requiring local data exchange. Within the FL framework, an aggregation
algorithm is recognized as one of the most crucial components for ensuring the
efficacy and security of the system. Existing average aggregation algorithms
typically assume that all client-trained data holds equal value or that weights
are based solely on the quantity of data contributed by each client. In
contrast, alternative approaches involve training the model locally after
aggregation to enhance adaptability. However, these approaches fundamentally
ignore the inherent heterogeneity between different clients' data and the
complexity of variations in data at the aggregation stage, which may lead to a
suboptimal global model.
  To address these issues, this study proposes a novel dual-criterion weighted
aggregation algorithm involving the quantity and quality of data from the
client node. Specifically, we quantify the data used for training and perform
multiple rounds of local model inference accuracy evaluation on a specialized
dataset to assess the data quality of each client. These two factors are
utilized as weights within the aggregation process, applied through a
dynamically weighted summation of these two factors. This approach allows the
algorithm to adaptively adjust the weights, ensuring that every client can
contribute to the global model, regardless of their data's size or initial
quality. Our experiments show that the proposed algorithm outperforms several
existing state-of-the-art aggregation approaches on both a general-purpose
open-source dataset, CIFAR-10, and a dataset specific to visual obstacle
avoidance.","['Haizhou Zhang', 'Xianjia Yu', 'Tomi Westerlund']",['cs.LG'],2024-11-12 14:09:16+00:00
http://arxiv.org/abs/2411.07806v1,Federated Low-Rank Adaptation with Differential Privacy over Wireless Networks,"Fine-tuning large pre-trained foundation models (FMs) on distributed edge
devices presents considerable computational and privacy challenges. Federated
fine-tuning (FedFT) mitigates some privacy issues by facilitating collaborative
model training without the need to share raw data. To lessen the computational
burden on resource-limited devices, combining low-rank adaptation (LoRA) with
federated learning enables parameter-efficient fine-tuning. Additionally, the
split FedFT architecture partitions an FM between edge devices and a central
server, reducing the necessity for complete model deployment on individual
devices. However, the risk of privacy eavesdropping attacks in FedFT remains a
concern, particularly in sensitive areas such as healthcare and finance. In
this paper, we propose a split FedFT framework with differential privacy (DP)
over wireless networks, where the inherent wireless channel noise in the uplink
transmission is utilized to achieve DP guarantees without adding an extra
artificial noise. We shall investigate the impact of the wireless noise on
convergence performance of the proposed framework. We will also show that by
updating only one of the low-rank matrices in the split FedFT with DP, the
proposed method can mitigate the noise amplification effect. Simulation results
will demonstrate that the proposed framework achieves higher accuracy under
strict privacy budgets compared to baseline methods.","['Tianqu Kang', 'Zixin Wang', 'Hengtao He', 'Jun Zhang', 'Shenghui Song', 'Khaled B. Letaief']","['cs.LG', 'cs.CR', 'eess.SP']",2024-11-12 14:01:08+00:00
http://arxiv.org/abs/2411.07800v1,Kernel-based retrieval models for hyperspectral image data optimized with Kernel Flows,"Kernel-based statistical methods are efficient, but their performance depends
heavily on the selection of kernel parameters. In literature, the optimization
studies on kernel-based chemometric methods is limited and often reduced to
grid searching. Previously, the authors introduced Kernel Flows (KF) to learn
kernel parameters for Kernel Partial Least-Squares (K-PLS) regression. KF is
easy to implement and helps minimize overfitting. In cases of high collinearity
between spectra and biogeophysical quantities in spectroscopy, simpler methods
like Principal Component Regression (PCR) may be more suitable. In this study,
we propose a new KF-type approach to optimize Kernel Principal Component
Regression (K-PCR) and test it alongside KF-PLS. Both methods are benchmarked
against non-linear regression techniques using two hyperspectral remote sensing
datasets.","['Zina-Sabrina Duma', 'Tuomas Sihvonen', 'Jouni Susiluoto', 'Otto Lamminpää', 'Heikki Haario', 'Satu-Pia Reinikainen']","['cs.LG', 'cs.CE', 'stat.ME']",2024-11-12 13:54:13+00:00
http://arxiv.org/abs/2411.07796v1,PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health Monitoring,"Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but
traditional methods like the Dawes-Redman system are often limited by high
inter-observer variability, leading to inconsistent interpretations and
potential misdiagnoses. This paper introduces PatchCTG, a transformer-based
model specifically designed for CTG analysis, employing patch-based
tokenisation, instance normalisation and channel-independent processing to
capture essential local and global temporal dependencies within CTG signals.
PatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over
20,000 CTG traces across diverse clinical outcomes after applying the inclusion
and exclusion criteria. With extensive hyperparameter optimisation, PatchCTG
achieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at
Youden's index threshold, demonstrating adaptability to various clinical needs.
Testing across varying temporal thresholds showed robust predictive
performance, particularly with finetuning on data closer to delivery, achieving
a sensitivity of 52% and specificity of 88% for near-delivery cases. These
findings suggest the potential of PatchCTG to enhance clinical decision-making
in antepartum care by providing a reliable, objective tool for fetal health
assessment. The source code is available at
https://github.com/jaleedkhan/PatchCTG.","['M. Jaleed Khan', 'Manu Vatish', 'Gabriel Davis Jones']","['cs.AI', 'cs.LG']",2024-11-12 13:46:58+00:00
http://arxiv.org/abs/2411.07784v1,Interaction Asymmetry: A General Principle for Learning Composable Abstractions,"Learning disentangled representations of concepts and re-composing them in
unseen ways is crucial for generalizing to out-of-domain situations. However,
the underlying properties of concepts that enable such disentanglement and
compositional generalization remain poorly understood. In this work, we propose
the principle of interaction asymmetry which states: ""Parts of the same concept
have more complex interactions than parts of different concepts"". We formalize
this via block diagonality conditions on the $(n+1)$th order derivatives of the
generator mapping concepts to observed data, where different orders of
""complexity"" correspond to different $n$. Using this formalism, we prove that
interaction asymmetry enables both disentanglement and compositional
generalization. Our results unify recent theoretical results for learning
concepts of objects, which we show are recovered as special cases with
$n\!=\!0$ or $1$. We provide results for up to $n\!=\!2$, thus extending these
prior works to more flexible generator functions, and conjecture that the same
proof strategies generalize to larger $n$. Practically, our theory suggests
that, to disentangle concepts, an autoencoder should penalize its latent
capacity and the interactions between concepts during decoding. We propose an
implementation of these criteria using a flexible Transformer-based VAE, with a
novel regularizer on the attention weights of the decoder. On synthetic image
datasets consisting of objects, we provide evidence that this model can achieve
comparable object disentanglement to existing models that use more explicit
object-centric priors.","['Jack Brady', 'Julius von Kügelgen', 'Sébastien Lachapelle', 'Simon Buchholz', 'Thomas Kipf', 'Wieland Brendel']","['cs.LG', 'cs.CV']",2024-11-12 13:33:26+00:00
http://arxiv.org/abs/2411.07781v1,RedCode: Risky Code Execution and Generation Benchmark for Code Agents,"With the rapidly increasing capabilities and adoption of code agents for
AI-assisted coding, safety concerns, such as generating or executing risky
code, have become significant barriers to the real-world deployment of these
agents. To provide comprehensive and practical evaluations on the safety of
code agents, we propose RedCode, a benchmark for risky code execution and
generation: (1) RedCode-Exec provides challenging prompts that could lead to
risky code execution, aiming to evaluate code agents' ability to recognize and
handle unsafe code. We provide a total of 4,050 risky test cases in Python and
Bash tasks with diverse input formats including code snippets and natural text.
They covers 25 types of critical vulnerabilities spanning 8 domains (e.g.,
websites, file systems). We provide Docker environments and design
corresponding evaluation metrics to assess their execution results. (2)
RedCode-Gen provides 160 prompts with function signatures and docstrings as
input to assess whether code agents will follow instructions to generate
harmful code or software. Our empirical findings, derived from evaluating three
agent frameworks based on 19 LLMs, provide insights into code agents'
vulnerabilities. For instance, evaluations on RedCode-Exec show that agents are
more likely to reject executing risky operations on the operating system, but
are less likely to reject executing technically buggy code, indicating high
risks. Risky operations described in natural text lead to a lower rejection
rate than those in code format. Additionally, evaluations on RedCode-Gen show
that more capable base models and agents with stronger overall coding
abilities, such as GPT4, tend to produce more sophisticated and effective
harmful software. Our findings highlight the need for stringent safety
evaluations for diverse code agents. Our dataset and code are available at
https://github.com/AI-secure/RedCode.","['Chengquan Guo', 'Xun Liu', 'Chulin Xie', 'Andy Zhou', 'Yi Zeng', 'Zinan Lin', 'Dawn Song', 'Bo Li']","['cs.SE', 'cs.AI']",2024-11-12 13:30:06+00:00
http://arxiv.org/abs/2411.07773v1,Likelihood as a Performance Gauge for Retrieval-Augmented Generation,"Recent work finds that retrieval-augmented generation with large language
models is prone to be influenced by the order of retrieved documents in the
context. However, the lack of in-depth analysis limits the use of this
phenomenon for prompt engineering in practice. In this study, we posit that
likelihoods serve as an effective gauge for language model performance. Through
experiments on two question-answering datasets with a variety of
state-of-the-art language models, we reveal correlations between answer
accuracy and the likelihood of the question at both the corpus level and the
instance level. In addition, we find that question likelihood can also indicate
the position of the task-relevant information in the context. Based on these
findings, we propose two methods that use question likelihood as a gauge for
selecting and constructing prompts that lead to better performance. We
demonstrate their effectiveness with experiments. In addition, our
likelihood-based methods are efficient, as they only need to compute the
likelihood of the input, requiring much fewer language model passes than
heuristic prompt engineering methods that require generating responses. Our
analysis deepens our understanding of how input prompts affect model
performance and provides a promising direction for efficient prompt
optimization.","['Tianyu Liu', 'Jirui Qi', 'Paul He', 'Arianna Bisazza', 'Mrinmaya Sachan', 'Ryan Cotterell']","['cs.CL', 'cs.AI', 'cs.LG']",2024-11-12 13:14:09+00:00
http://arxiv.org/abs/2411.07772v1,Automatic Album Sequencing,"Album sequencing is a critical part of the album production process.
Recently, a data-driven approach was proposed that sequences general
collections of independent media by extracting the narrative essence of the
items in the collections. While this approach implies an album sequencing
technique, it is not widely accessible to a less technical audience, requiring
advanced knowledge of machine learning techniques to use. To address this, we
introduce a new user-friendly web-based tool that allows a less technical
audience to upload music tracks, execute this technique in one click, and
subsequently presents the result in a clean visualization to the user. To both
increase the number of templates available to the user and address shortcomings
of previous work, we also introduce a new direct transformer-based album
sequencing method. We find that our more direct method outperforms a random
baseline but does not reach the same performance as the narrative essence
approach. Both methods are included in our web-based user interface, and this
-- alongside a full copy of our implementation -- is publicly available at
https://github.com/dylanashley/automatic-album-sequencing","['Vincent Herrmann', 'Dylan R. Ashley', 'Jürgen Schmidhuber']","['cs.LG', 'cs.AI', 'cs.CL', 'cs.MM', 'cs.SD', '68T07', 'H.5.5; I.2.6; I.5.1; J.5']",2024-11-12 13:13:20+00:00
http://arxiv.org/abs/2411.07763v1,Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows,"Real-world enterprise text-to-SQL workflows often involve complex cloud or
local data across various database systems, multiple SQL queries in various
dialects, and diverse operations from data transformation to analytics. We
introduce Spider 2.0, an evaluation framework comprising 632 real-world
text-to-SQL workflow problems derived from enterprise-level database use cases.
The databases in Spider 2.0 are sourced from real data applications, often
containing over 1,000 columns and stored in local or cloud database systems
such as BigQuery and Snowflake. We show that solving problems in Spider 2.0
frequently requires understanding and searching through database metadata,
dialect documentation, and even project-level codebases. This challenge calls
for models to interact with complex SQL workflow environments, process
extremely long contexts, perform intricate reasoning, and generate multiple SQL
queries with diverse operations, often exceeding 100 lines, which goes far
beyond traditional text-to-SQL challenges. Our evaluations indicate that based
on o1-preview, our code agent framework successfully solves only 17.0% of the
tasks, compared with 91.2% on Spider 1.0 and 73.0% on BIRD. Our results on
Spider 2.0 show that while language models have demonstrated remarkable
performance in code generation -- especially in prior text-to-SQL benchmarks --
they require significant improvement in order to achieve adequate performance
for real-world enterprise usage. Progress on Spider 2.0 represents crucial
steps towards developing intelligent, autonomous, code agents for real-world
enterprise settings. Our code, baseline models, and data are available at
https://spider2-sql.github.io.","['Fangyu Lei', 'Jixuan Chen', 'Yuxiao Ye', 'Ruisheng Cao', 'Dongchan Shin', 'Hongjin Su', 'Zhaoqing Suo', 'Hongcheng Gao', 'Wenjing Hu', 'Pengcheng Yin', 'Victor Zhong', 'Caiming Xiong', 'Ruoxi Sun', 'Qian Liu', 'Sida Wang', 'Tao Yu']","['cs.CL', 'cs.AI', 'cs.DB']",2024-11-12 12:52:17+00:00
http://arxiv.org/abs/2411.07762v1,ASER: Activation Smoothing and Error Reconstruction for Large Language Model Quantization,"Quantization stands as a pivotal technique for large language model (LLM)
serving, yet it poses significant challenges particularly in achieving
effective low-bit quantization. The limited numerical mapping makes the
quantized model produce a non-trivial error, bringing out intolerable
performance degration. This paper is anchored in the basic idea of model
compression objectives, and delves into the layer-wise error distribution of
LLMs during post-training quantization. Subsequently, we introduce ASER, an
algorithm consisting of (1) Error Reconstruction: low-rank compensation for
quantization error with LoRA-style matrices constructed by whitening SVD; (2)
Activation Smoothing: outlier extraction to gain smooth activation and better
error compensation. ASER is capable of quantizing typical LLMs to low-bit ones,
particularly preserving accuracy even in W4A8 per-channel setup. Experimental
results show that ASER is competitive among the state-of-the-art quantization
algorithms, showing potential to activation quantization, with minor overhead.","['Weibo Zhao', 'Yubin Shi', 'Xinyu Lyu', 'Wanchen Sui', 'Shen Li', 'Yong Li']","['cs.LG', 'cs.AI']",2024-11-12 12:52:04+00:00
http://arxiv.org/abs/2411.07760v1,Navigation with QPHIL: Quantizing Planner for Hierarchical Implicit Q-Learning,"Offline Reinforcement Learning (RL) has emerged as a powerful alternative to
imitation learning for behavior modeling in various domains, particularly in
complex navigation tasks. An existing challenge with Offline RL is the
signal-to-noise ratio, i.e. how to mitigate incorrect policy updates due to
errors in value estimates. Towards this, multiple works have demonstrated the
advantage of hierarchical offline RL methods, which decouples high-level path
planning from low-level path following. In this work, we present a novel
hierarchical transformer-based approach leveraging a learned quantizer of the
space. This quantization enables the training of a simpler zone-conditioned
low-level policy and simplifies planning, which is reduced to discrete
autoregressive prediction. Among other benefits, zone-level reasoning in
planning enables explicit trajectory stitching rather than implicit stitching
based on noisy value function estimates. By combining this transformer-based
planner with recent advancements in offline RL, our proposed approach achieves
state-of-the-art results in complex long-distance navigation environments.","['Alexi Canesse', 'Mathieu Petitbois', 'Ludovic Denoyer', 'Sylvain Lamprier', 'Rémy Portelas']","['cs.LG', 'cs.AI', 'cs.RO']",2024-11-12 12:49:41+00:00
http://arxiv.org/abs/2411.07759v1,Optimizing Traffic Signal Control using High-Dimensional State Representation and Efficient Deep Reinforcement Learning,"In reinforcement learning-based (RL-based) traffic signal control (TSC),
decisions on the signal timing are made based on the available information on
vehicles at a road intersection. This forms the state representation for the RL
environment which can either be high-dimensional containing several variables
or a low-dimensional vector. Current studies suggest that using high
dimensional state representations does not lead to improved performance on TSC.
However, we argue, with experimental results, that the use of high dimensional
state representations can, in fact, lead to improved TSC performance with
improvements up to 17.9% of the average waiting time. This high-dimensional
representation is obtainable using the cost-effective vehicle-to-infrastructure
(V2I) communication, encouraging its adoption for TSC. Additionally, given the
large size of the state, we identified the need to have computational efficient
models and explored model compression via pruning.","['Lawrence Francis', 'Blessed Guda', 'Ahmed Biyabani']","['eess.SY', 'cs.AI', 'cs.SY']",2024-11-12 12:37:50+00:00
http://arxiv.org/abs/2411.07753v1,Spatially Regularized Graph Attention Autoencoder Framework for Detecting Rainfall Extremes,"We introduce a novel Graph Attention Autoencoder (GAE) with spatial
regularization to address the challenge of scalable anomaly detection in
spatiotemporal rainfall data across India from 1990 to 2015. Our model
leverages a Graph Attention Network (GAT) to capture spatial dependencies and
temporal dynamics in the data, further enhanced by a spatial regularization
term ensuring geographic coherence. We construct two graph datasets employing
rainfall, pressure, and temperature attributes from the Indian Meteorological
Department and ERA5 Reanalysis on Single Levels, respectively. Our network
operates on graph representations of the data, where nodes represent geographic
locations, and edges, inferred through event synchronization, denote
significant co-occurrences of rainfall events. Through extensive experiments,
we demonstrate that our GAE effectively identifies anomalous rainfall patterns
across the Indian landscape. Our work paves the way for sophisticated
spatiotemporal anomaly detection methodologies in climate science, contributing
to better climate change preparedness and response strategies.","['Mihir Agarwal', 'Progyan Das', 'Udit Bhatia']",['cs.LG'],2024-11-12 12:24:48+00:00
http://arxiv.org/abs/2411.07751v1,SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model,"Speech enhancement plays an essential role in various applications, and the
integration of visual information has been demonstrated to bring substantial
advantages. However, the majority of current research concentrates on the
examination of facial and lip movements, which can be compromised or entirely
inaccessible in scenarios where occlusions occur or when the camera view is
distant. Whereas contextual visual cues from the surrounding environment have
been overlooked: for example, when we see a dog bark, our brain has the innate
ability to discern and filter out the barking noise. To this end, in this
paper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is
the first proposal to use rich contextual information from synchronized video
as auxiliary cues to indicate the type of noise, which eventually improves the
speech enhancement performance. Specifically, we propose the VC-S$^2$E method,
which incorporates the Conformer and Mamba modules for their complementary
strengths. Extensive experiments are conducted on public MUSIC, AVSpeech and
AudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E
over other competitive methods. We will make the source code publicly
available. Project demo page: https://AVSEPage.github.io/","['Xinyuan Qian', 'Jiaran Gao', 'Yaodan Zhang', 'Qiquan Zhang', 'Hexin Liu', 'Leibny Paola Garcia', 'Haizhou Li']","['cs.SD', 'cs.AI', 'cs.CV', 'cs.MM', 'eess.AS']",2024-11-12 12:23:41+00:00
http://arxiv.org/abs/2411.07739v1,Unlocking Legal Knowledge with Multi-Layered Embedding-Based Retrieval,"This work addresses the challenge of capturing the complexities of legal
knowledge by proposing a multi-layered embedding-based retrieval method for
legal and legislative texts. Creating embeddings not only for individual
articles but also for their components (paragraphs, clauses) and structural
groupings (books, titles, chapters, etc), we seek to capture the subtleties of
legal information through the use of dense vectors of embeddings, representing
it at varying levels of granularity. Our method meets various information needs
by allowing the Retrieval Augmented Generation system to provide accurate
responses, whether for specific segments or entire sections, tailored to the
user's query. We explore the concepts of aboutness, semantic chunking, and
inherent hierarchy within legal texts, arguing that this method enhances the
legal information retrieval. Despite the focus being on Brazil's legislative
methods and the Brazilian Constitution, which follow a civil law tradition, our
findings should in principle be applicable across different legal systems,
including those adhering to common law traditions. Furthermore, the principles
of the proposed method extend beyond the legal domain, offering valuable
insights for organizing and retrieving information in any field characterized
by information encoded in hierarchical text.",['João Alberto de Oliveira Lima'],"['cs.AI', 'cs.IR', 'I.2.7']",2024-11-12 12:03:57+00:00
http://arxiv.org/abs/2411.07729v1,Exploring the loss landscape of regularized neural networks via convex duality,"We discuss several aspects of the loss landscape of regularized neural
networks: the structure of stationary points, connectivity of optimal
solutions, path with nonincreasing loss to arbitrary global optimum, and the
nonuniqueness of optimal solutions, by casting the problem into an equivalent
convex problem and considering its dual. Starting from two-layer neural
networks with scalar output, we first characterize the solution set of the
convex problem using its dual and further characterize all stationary points.
With the characterization, we show that the topology of the global optima goes
through a phase transition as the width of the network changes, and construct
counterexamples where the problem may have a continuum of optimal solutions.
Finally, we show that the solution set characterization and connectivity
results can be extended to different architectures, including two-layer
vector-valued neural networks and parallel three-layer neural networks.","['Sungyoon Kim', 'Aaron Mishkin', 'Mert Pilanci']",['cs.LG'],2024-11-12 11:41:38+00:00
http://arxiv.org/abs/2411.07728v1,No-Reference Point Cloud Quality Assessment via Graph Convolutional Network,"Three-dimensional (3D) point cloud, as an emerging visual media format, is
increasingly favored by consumers as it can provide more realistic visual
information than two-dimensional (2D) data. Similar to 2D plane images and
videos, point clouds inevitably suffer from quality degradation and information
loss through multimedia communication systems. Therefore, automatic point cloud
quality assessment (PCQA) is of critical importance. In this work, we propose a
novel no-reference PCQA method by using a graph convolutional network (GCN) to
characterize the mutual dependencies of multi-view 2D projected image contents.
The proposed GCN-based PCQA (GC-PCQA) method contains three modules, i.e.,
multi-view projection, graph construction, and GCN-based quality prediction.
First, multi-view projection is performed on the test point cloud to obtain a
set of horizontally and vertically projected images. Then, a
perception-consistent graph is constructed based on the spatial relations among
different projected images. Finally, reasoning on the constructed graph is
performed by GCN to characterize the mutual dependencies and interactions
between different projected images, and aggregate feature information of
multi-view projected images for final quality prediction. Experimental results
on two publicly available benchmark databases show that our proposed GC-PCQA
can achieve superior performance than state-of-the-art quality assessment
metrics. The code will be available at: https://github.com/chenwuwq/GC-PCQA.","['Wu Chen', 'Qiuping Jiang', 'Wei Zhou', 'Feng Shao', 'Guangtao Zhai', 'Weisi Lin']","['cs.CV', 'cs.AI', 'eess.IV']",2024-11-12 11:39:05+00:00
http://arxiv.org/abs/2411.07724v1,Convergence Rate Analysis of LION,"The LION (evoLved sIgn mOmeNtum) optimizer for deep neural network training
was found by Google via program search, with the simple sign update yet showing
impressive performance in training large scale networks. Although previous
studies have investigated its convergence properties, a comprehensive analysis,
especially the convergence rate, is still desirable. Recognizing that LION can
be regarded as solving a specific constrained problem, this paper focuses on
demonstrating its convergence to the Karush-Kuhn-Tucker (KKT) point at the rate
of $\cal O(\sqrt{d}K^{-1/4})$ measured by gradient $\ell_1$ norm, where $d$ is
the problem dimension and $K$ is the number of iteration steps. Step further,
we remove the constraint and establish that LION converges to the critical
point of the general unconstrained problem at the same rate. This rate not only
delivers the currently optimal dependence on the problem dimension $d$ but also
tightly matches the theoretical lower bound for nonconvex stochastic
optimization algorithms, which is typically measured using the gradient
$\ell_2$ norm, with respect to the number of iterations $K$. Through extensive
experiments, we not only demonstrate that LION achieves lower loss and higher
performance compared to standard SGD, but also empirically confirm that the
gradient $\ell_1/\ell_2$ norm ratio aligns with $\Theta(\sqrt{d})$, thus
proving that our convergence rate matches the theoretical lower bound with
respect to $d$ in the empirical sense.","['Yiming Dong', 'Huan Li', 'Zhouchen Lin']","['cs.LG', 'math.OC']",2024-11-12 11:30:53+00:00
http://arxiv.org/abs/2411.07722v1,Is Cognition consistent with Perception? Assessing and Mitigating Multimodal Knowledge Conflicts in Document Understanding,"Multimodal large language models (MLLMs) have shown impressive capabilities
in document understanding, a rapidly growing research area with significant
industrial demand in recent years. As a multimodal task, document understanding
requires models to possess both perceptual and cognitive abilities. However,
current MLLMs often face conflicts between perception and cognition. Taking a
document VQA task (cognition) as an example, an MLLM might generate answers
that do not match the corresponding visual content identified by its OCR
(perception). This conflict suggests that the MLLM might struggle to establish
an intrinsic connection between the information it ""sees"" and what it
""understands."" Such conflicts challenge the intuitive notion that cognition is
consistent with perception, hindering the performance and explainability of
MLLMs. In this paper, we define the conflicts between cognition and perception
as Cognition and Perception (C&P) knowledge conflicts, a form of multimodal
knowledge conflicts, and systematically assess them with a focus on document
understanding. Our analysis reveals that even GPT-4o, a leading MLLM, achieves
only 68.6% C&P consistency. To mitigate the C&P knowledge conflicts, we propose
a novel method called Multimodal Knowledge Consistency Fine-tuning. This method
first ensures task-specific consistency and then connects the cognitive and
perceptual knowledge. Our method significantly reduces C&P knowledge conflicts
across all tested MLLMs and enhances their performance in both cognitive and
perceptual tasks in most scenarios.","['Zirui Shao', 'Chuwei Luo', 'Zhaoqing Zhu', 'Hangdi Xing', 'Zhi Yu', 'Qi Zheng', 'Jiajun Bu']",['cs.AI'],2024-11-12 11:28:50+00:00
http://arxiv.org/abs/2411.07719v1,EMPERROR: A Flexible Generative Perception Error Model for Probing Self-Driving Planners,"To handle the complexities of real-world traffic, learning planners for
self-driving from data is a promising direction. While recent approaches have
shown great progress, they typically assume a setting in which the ground-truth
world state is available as input. However, when deployed, planning needs to be
robust to the long-tail of errors incurred by a noisy perception system, which
is often neglected in evaluation. To address this, previous work has proposed
drawing adversarial samples from a perception error model (PEM) mimicking the
noise characteristics of a target object detector. However, these methods use
simple PEMs that fail to accurately capture all failure modes of detection. In
this paper, we present EMPERROR, a novel transformer-based generative PEM,
apply it to stress-test an imitation learning (IL)-based planner and show that
it imitates modern detectors more faithfully than previous work. Furthermore,
it is able to produce realistic noisy inputs that increase the planner's
collision rate by up to 85%, demonstrating its utility as a valuable tool for a
more complete evaluation of self-driving planners.","['Niklas Hanselmann', 'Simon Doll', 'Marius Cordts', 'Hendrik P. A. Lensch', 'Andreas Geiger']","['cs.RO', 'cs.CV', 'cs.LG']",2024-11-12 11:24:18+00:00
http://arxiv.org/abs/2411.07715v1,Training Data for Large Language Model,"In 2022, with the release of ChatGPT, large-scale language models gained
widespread attention. ChatGPT not only surpassed previous models in terms of
parameters and the scale of its pretraining corpus but also achieved
revolutionary performance improvements through fine-tuning on a vast amount of
high-quality, human-annotated data. This progress has led enterprises and
research institutions to recognize that building smarter and more powerful
models relies on rich and high-quality datasets. Consequently, the construction
and optimization of datasets have become a critical focus in the field of
artificial intelligence. This paper summarizes the current state of pretraining
and fine-tuning data for training large-scale language models, covering aspects
such as data scale, collection methods, data types and characteristics,
processing workflows, and provides an overview of available open-source
datasets.","['Yiming Ju', 'Huanhuan Ma']",['cs.AI'],2024-11-12 11:09:58+00:00
http://arxiv.org/abs/2411.07711v1,OWLed: Outlier-weighed Layerwise Pruning for Efficient Autonomous Driving Framework,"The integration of Large Language Models (LLMs) into autonomous driving
systems offers promising enhancements in environmental understanding and
decision-making. However, the substantial computational demands of deploying
LLMs locally on vehicles render this approach unfeasible for real-world
automotive applications. To address this challenge, we introduce OWLed, the
Outlier-Weighed Layerwise Pruning for Efficient Autonomous Driving Framework
that leverages outlier-weighted layerwise sparsity for model compression. Our
method assigns non-uniform sparsity ratios to different layers based on the
distribution of outlier features, significantly reducing the model size without
the need for fine-tuning. To ensure the compressed model adapts well to
autonomous driving tasks, we incorporate driving environment data into both the
calibration and pruning processes. Our empirical studies reveal that the
encoder component is more sensitive to pruning than the LLM, highlighting its
critical role in the system. Experimental results demonstrate that OWLed
outperforms existing methods in perception, action prediction, and language
understanding while substantially lowering computational requirements. These
findings underscore the potential of combining advanced pruning techniques with
LLMs to develop efficient and robust autonomous driving systems capable of
handling complex scenarios. Code will be made publicly available.","['Jiaxi Li', 'Lu Yin', 'Xilu Wang']","['cs.LG', 'cs.RO']",2024-11-12 10:55:30+00:00
http://arxiv.org/abs/2411.07700v1,Test Where Decisions Matter: Importance-driven Testing for Deep Reinforcement Learning,"In many Deep Reinforcement Learning (RL) problems, decisions in a trained
policy vary in significance for the expected safety and performance of the
policy. Since RL policies are very complex, testing efforts should concentrate
on states in which the agent's decisions have the highest impact on the
expected outcome. In this paper, we propose a novel model-based method to
rigorously compute a ranking of state importance across the entire state space.
We then focus our testing efforts on the highest-ranked states. In this paper,
we focus on testing for safety. However, the proposed methods can be easily
adapted to test for performance. In each iteration, our testing framework
computes optimistic and pessimistic safety estimates. These estimates provide
lower and upper bounds on the expected outcomes of the policy execution across
all modeled states in the state space. Our approach divides the state space
into safe and unsafe regions upon convergence, providing clear insights into
the policy's weaknesses. Two important properties characterize our approach.
(1) Optimal Test-Case Selection: At any time in the testing process, our
approach evaluates the policy in the states that are most critical for safety.
(2) Guaranteed Safety: Our approach can provide formal verification guarantees
over the entire state space by sampling only a fraction of the policy. Any
safety properties assured by the pessimistic estimate are formally proven to
hold for the policy. We provide a detailed evaluation of our framework on
several examples, showing that our method discovers unsafe policy behavior with
low testing effort.","['Stefan Pranger', 'Hana Chockler', 'Martin Tappler', 'Bettina Könighofer']",['cs.LG'],2024-11-12 10:26:44+00:00
http://arxiv.org/abs/2411.07691v1,New Emerged Security and Privacy of Pre-trained Model: a Survey and Outlook,"Thanks to the explosive growth of data and the development of computational
resources, it is possible to build pre-trained models that can achieve
outstanding performance on various tasks, such as neural language processing,
computer vision, and more. Despite their powerful capabilities, pre-trained
models have also sparked attention to the emerging security challenges
associated with their real-world applications. Security and privacy issues,
such as leaking privacy information and generating harmful responses, have
seriously undermined users' confidence in these powerful models. Concerns are
growing as model performance improves dramatically. Researchers are eager to
explore the unique security and privacy issues that have emerged, their
distinguishing factors, and how to defend against them. However, the current
literature lacks a clear taxonomy of emerging attacks and defenses for
pre-trained models, which hinders a high-level and comprehensive understanding
of these questions. To fill the gap, we conduct a systematical survey on the
security risks of pre-trained models, proposing a taxonomy of attack and
defense methods based on the accessibility of pre-trained models' input and
weights in various security test scenarios. This taxonomy categorizes attacks
and defenses into No-Change, Input-Change, and Model-Change approaches. With
the taxonomy analysis, we capture the unique security and privacy issues of
pre-trained models, categorizing and summarizing existing security issues based
on their characteristics. In addition, we offer a timely and comprehensive
review of each category's strengths and limitations. Our survey concludes by
highlighting potential new research opportunities in the security and privacy
of pre-trained models.","['Meng Yang', 'Tianqing Zhu', 'Chi Liu', 'WanLei Zhou', 'Shui Yu', 'Philip S. Yu']",['cs.AI'],2024-11-12 10:15:33+00:00
http://arxiv.org/abs/2411.07690v1,World Models: The Safety Perspective,"With the proliferation of the Large Language Model (LLM), the concept of
World Models (WM) has recently attracted a great deal of attention in the AI
research community, especially in the context of AI agents. It is arguably
evolving into an essential foundation for building AI agent systems. A WM is
intended to help the agent predict the future evolution of environmental states
or help the agent fill in missing information so that it can plan its actions
and behave safely. The safety property of WM plays a key role in their
effective use in critical applications. In this work, we review and analyze the
impacts of the current state-of-the-art in WM technology from the point of view
of trustworthiness and safety based on a comprehensive survey and the fields of
application envisaged. We provide an in-depth analysis of state-of-the-art WMs
and derive technical research challenges and their impact in order to call on
the research community to collaborate on improving the safety and
trustworthiness of WM.","['Zifan Zeng', 'Chongzhe Zhang', 'Feng Liu', 'Joseph Sifakis', 'Qunli Zhang', 'Shiming Liu', 'Peng Wang']",['cs.AI'],2024-11-12 10:15:11+00:00
http://arxiv.org/abs/2411.07688v1,Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG,"Ultra High Resolution (UHR) remote sensing imagery (RSI) (e.g. 100,000
$\times$ 100,000 pixels or more) poses a significant challenge for current
Remote Sensing Multimodal Large Language Models (RSMLLMs). If choose to resize
the UHR image to standard input image size, the extensive spatial and
contextual information that UHR images contain will be neglected. Otherwise,
the original size of these images often exceeds the token limits of standard
RSMLLMs, making it difficult to process the entire image and capture long-range
dependencies to answer the query based on the abundant visual context. In this
paper, we introduce ImageRAG for RS, a training-free framework to address the
complexities of analyzing UHR remote sensing imagery. By transforming UHR
remote sensing image analysis task to image's long context selection task, we
design an innovative image contextual retrieval mechanism based on the
Retrieval-Augmented Generation (RAG) technique, denoted as ImageRAG. ImageRAG's
core innovation lies in its ability to selectively retrieve and focus on the
most relevant portions of the UHR image as visual contexts that pertain to a
given query. Fast path and slow path are proposed in this framework to handle
this task efficiently and effectively. ImageRAG allows RSMLLMs to manage
extensive context and spatial information from UHR RSI, ensuring the analysis
is both accurate and efficient.","['Zilun Zhang', 'Haozhan Shen', 'Tiancheng Zhao', 'Yuhao Wang', 'Bin Chen', 'Yuxiang Cai', 'Yongheng Shang', 'Jianwei Yin']","['cs.CV', 'cs.AI']",2024-11-12 10:12:12+00:00
http://arxiv.org/abs/2411.07686v1,Data-Driven Graph Switching for Cyber-Resilient Control in Microgrids,"Distributed microgrids are conventionally dependent on communication networks
to achieve secondary control objectives. This dependence makes them vulnerable
to stealth data integrity attacks (DIAs) where adversaries may perform
manipulations via infected transmitters and repeaters to jeopardize stability.
This paper presents a physics-guided, supervised Artificial Neural Network
(ANN)-based framework that identifies communication-level cyberattacks in
microgrids by analyzing whether incoming measurements will cause abnormal
behavior of the secondary control layer. If abnormalities are detected, an
iteration through possible spanning tree graph topologies that can be used to
fulfill secondary control objectives is done. Then, a communication network
topology that would not create secondary control abnormalities is identified
and enforced for maximum stability. By altering the communication graph
topology, the framework eliminates the dependence of the secondary control
layer on inputs from compromised cyber devices helping it achieve resilience
without instability. Several case studies are provided showcasing the
robustness of the framework against False Data Injections and repeater-level
Man-in-the-Middle attacks. To understand practical feasibility, robustness is
also verified against larger microgrid sizes and in the presence of varying
noise levels. Our findings indicate that performance can be affected when
attempting scalability in the presence of noise. However, the framework
operates robustly in low-noise settings.","['Suman Rath', 'Subham Sahoo']","['eess.SY', 'cs.AI', 'cs.SY']",2024-11-12 09:58:21+00:00
http://arxiv.org/abs/2411.07685v1,Fast Disentangled Slim Tensor Learning for Multi-view Clustering,"Tensor-based multi-view clustering has recently received significant
attention due to its exceptional ability to explore cross-view high-order
correlations. However, most existing methods still encounter some limitations.
(1) Most of them explore the correlations among different affinity matrices,
making them unscalable to large-scale data. (2) Although some methods address
it by introducing bipartite graphs, they may result in sub-optimal solutions
caused by an unstable anchor selection process. (3) They generally ignore the
negative impact of latent semantic-unrelated information in each view. To
tackle these issues, we propose a new approach termed fast Disentangled Slim
Tensor Learning (DSTL) for multi-view clustering . Instead of focusing on the
multi-view graph structures, DSTL directly explores the high-order correlations
among multi-view latent semantic representations based on matrix factorization.
To alleviate the negative influence of feature redundancy, inspired by robust
PCA, DSTL disentangles the latent low-dimensional representation into a
semantic-unrelated part and a semantic-related part for each view.
Subsequently, two slim tensors are constructed with tensor-based
regularization. To further enhance the quality of feature disentanglement, the
semantic-related representations are aligned across views through a consensus
alignment indicator. Our proposed model is computationally efficient and can be
solved effectively. Extensive experiments demonstrate the superiority and
efficiency of DSTL over state-of-the-art approaches. The code of DSTL is
available at https://github.com/dengxu-nju/DSTL.","['Deng Xu', 'Chao Zhang', 'Zechao Li', 'Chunlin Chen', 'Huaxiong Li']","['cs.CV', 'cs.AI']",2024-11-12 09:57:53+00:00
http://arxiv.org/abs/2411.07684v1,AI enhanced diagnosis of Peyronies disease a novel approach using Computer Vision,"This study presents an innovative AI-driven tool for diagnosing Peyronie's
Disease (PD), a condition that affects between 0.3% and 13.1% of men worldwide.
Our method uses key point detection on both images and videos to measure penile
curvature angles, utilizing advanced computer vision techniques. This tool has
demonstrated high accuracy in identifying anatomical landmarks, validated
against conventional goniometer measurements. Traditional PD diagnosis often
involves subjective and invasive methods, which can lead to patient discomfort
and inaccuracies. Our approach offers a precise, reliable, and non-invasive
diagnostic tool to address these drawbacks. The model distinguishes between PD
and normal anatomical changes with a sensitivity of 96.7% and a specificity of
100%. This advancement represents a significant improvement in urological
diagnostics, greatly enhancing the efficacy and convenience of PD assessment
for healthcare providers and patients.","['Yudara Kularathne', 'Janitha Prathapa', 'Prarththanan Sothyrajah', 'Salomi Arasaratnam', 'Sithira Ambepitiya', 'Thanveer Ahamed', 'Dinuka Wijesundara']","['eess.IV', 'cs.AI', 'cs.CV']",2024-11-12 09:56:42+00:00
http://arxiv.org/abs/2411.07681v1,What Do Learning Dynamics Reveal About Generalization in LLM Reasoning?,"Despite the remarkable capabilities of modern large language models (LLMs),
the mechanisms behind their problem-solving abilities remain elusive. In this
work, we aim to better understand how the learning dynamics of LLM finetuning
shapes downstream generalization. Our analysis focuses on reasoning tasks,
whose problem structure allows us to distinguish between memorization (the
exact replication of reasoning steps from the training data) and performance
(the correctness of the final solution). We find that a model's generalization
behavior can be effectively characterized by a training metric we call
pre-memorization train accuracy: the accuracy of model samples on training
queries before they begin to copy the exact reasoning steps from the training
set. On the dataset level, this metric is able to reliably predict test
accuracy, achieving $R^2$ of around or exceeding 0.9 across various models
(Llama3 8, Gemma2 9B), datasets (GSM8k, MATH), and training configurations. On
a per-example level, this metric is also indicative of whether individual model
predictions are robust to perturbations in the training query. By connecting a
model's learning behavior to its generalization, pre-memorization train
accuracy can guide targeted improvements to training strategies. We focus on
data curation as an example, and show that prioritizing examples with low
pre-memorization accuracy leads to 1.5-2x improvements in data efficiency
compared to i.i.d. data scaling, and outperforms other standard data curation
techniques.","['Katie Kang', 'Amrith Setlur', 'Dibya Ghosh', 'Jacob Steinhardt', 'Claire Tomlin', 'Sergey Levine', 'Aviral Kumar']",['cs.LG'],2024-11-12 09:52:40+00:00
http://arxiv.org/abs/2411.07679v1,Safe Exploitative Play with Untrusted Type Beliefs,"The combination of the Bayesian game and learning has a rich history, with
the idea of controlling a single agent in a system composed of multiple agents
with unknown behaviors given a set of types, each specifying a possible
behavior for the other agents. The idea is to plan an agent's own actions with
respect to those types which it believes are most likely to maximize the
payoff. However, the type beliefs are often learned from past actions and
likely to be incorrect. With this perspective in mind, we consider an agent in
a game with type predictions of other components, and investigate the impact of
incorrect beliefs to the agent's payoff. In particular, we formally define a
tradeoff between risk and opportunity by comparing the payoff obtained against
the optimal payoff, which is represented by a gap caused by trusting or
distrusting the learned beliefs. Our main results characterize the tradeoff by
establishing upper and lower bounds on the Pareto front for both normal-form
and stochastic Bayesian games, with numerical results provided.","['Tongxin Li', 'Tinashe Handina', 'Shaolei Ren', 'Adam Wierman']","['cs.LG', 'cs.GT']",2024-11-12 09:49:16+00:00
http://arxiv.org/abs/2411.07672v1,Rethinking Structure Learning For Graph Neural Networks,"To improve the performance of Graph Neural Networks (GNNs), Graph Structure
Learning (GSL) has been extensively applied to reconstruct or refine original
graph structures, effectively addressing issues like heterophily,
over-squashing, and noisy structures. While GSL is generally thought to improve
GNN performance, it often leads to longer training times and more
hyperparameter tuning. Besides, the distinctions among current GSL methods
remain ambiguous from the perspective of GNN training, and there is a lack of
theoretical analysis to quantify their effectiveness. Recent studies further
suggest that, under fair comparisons with the same hyperparameter tuning, GSL
does not consistently outperform baseline GNNs. This motivates us to ask a
critical question: is GSL really useful for GNNs? To address this question,
this paper makes two key contributions. First, we propose a new GSL framework,
which includes three steps: GSL base (the representation used for GSL)
construction, new structure construction, and view fusion, to better understand
the effectiveness of GSL in GNNs. Second, after graph convolution, we analyze
the differences in mutual information (MI) between node representations derived
from the original topology and those from the newly constructed topology.
Surprisingly, our empirical observations and theoretical analysis show that no
matter which type of graph structure construction methods are used, after
feeding the same GSL bases to the newly constructed graph, there is no MI gain
compared to the original GSL bases. To fairly reassess the effectiveness of
GSL, we conduct ablation experiments and find that it is the pretrained GSL
bases that enhance GNN performance, and in most cases, GSL cannot improve GNN
performance. This finding encourages us to rethink the essential components in
GNNs, such as self-training and structural encoding, in GNN design rather than
GSL.","['Yilun Zheng', 'Zhuofan Zhang', 'Ziming Wang', 'Xiang Li', 'Sitao Luan', 'Xiaojiang Peng', 'Lihui Chen']",['cs.LG'],2024-11-12 09:39:22+00:00
http://arxiv.org/abs/2411.07663v1,Is Graph Convolution Always Beneficial For Every Feature?,"Graph Neural Networks (GNNs) have demonstrated strong capabilities in
processing structured data. While traditional GNNs typically treat each feature
dimension equally during graph convolution, we raise an important question: Is
the graph convolution operation equally beneficial for each feature? If not,
the convolution operation on certain feature dimensions can possibly lead to
harmful effects, even worse than the convolution-free models. In prior studies,
to assess the impacts of graph convolution on features, people proposed metrics
based on feature homophily to measure feature consistency with the graph
topology. However, these metrics have shown unsatisfactory alignment with GNN
performance and have not been effectively employed to guide feature selection
in GNNs. To address these limitations, we introduce a novel metric, Topological
Feature Informativeness (TFI), to distinguish between GNN-favored and
GNN-disfavored features, where its effectiveness is validated through both
theoretical analysis and empirical observations. Based on TFI, we propose a
simple yet effective Graph Feature Selection (GFS) method, which processes
GNN-favored and GNN-disfavored features separately, using GNNs and non-GNN
models. Compared to original GNNs, GFS significantly improves the extraction of
useful topological information from each feature with comparable computational
costs. Extensive experiments show that after applying GFS to 8 baseline and
state-of-the-art (SOTA) GNN architectures across 10 datasets, 83.75% of the
GFS-augmented cases show significant performance boosts. Furthermore, our
proposed TFI metric outperforms other feature selection methods. These results
validate the effectiveness of both GFS and TFI. Additionally, we demonstrate
that GFS's improvements are robust to hyperparameter tuning, highlighting its
potential as a universal method for enhancing various GNN architectures.","['Yilun Zheng', 'Xiang Li', 'Sitao Luan', 'Xiaojiang Peng', 'Lihui Chen']","['cs.LG', 'cs.SI']",2024-11-12 09:28:55+00:00
http://arxiv.org/abs/2411.07654v1,Spike Talk in Power Electronic Grids -- Leveraging Post Moore's Computing Laws,"Emerging distributed generation demands highly reliable and resilient
coordinating control in microgrids. To improve on these aspects, spiking neural
network is leveraged, as a grid-edge intelligence tool to establish a talkative
infrastructure, Spike Talk, expediting coordination in next-generation
microgrids without the need of communication at all. This paper unravels the
physics behind Spike Talk from the perspective of its distributed
infrastructure, which aims to address the Von Neumann Bottleneck. Relying on
inferring information via power flows in tie lines, Spike Talk allows adaptive
and flexible control and coordination itself, and features in synaptic
plasticity facilitating online and local training functionality. Preliminary
case studies are demonstrated with results, while more extensive validations
are to be included as future scopes of work.","['Yubo Song', 'Subham Sahoo']","['cs.ET', 'cs.AI', 'cs.NE', 'cs.SY', 'eess.SY']",2024-11-12 09:06:16+00:00
http://arxiv.org/abs/2411.07651v1,Quasi-Bayes empirical Bayes: a sequential approach to the Poisson compound decision problem,"The Poisson compound decision problem is a classical problem in statistics,
for which parametric and nonparametric empirical Bayes methodologies are
available to estimate the Poisson's means in static or batch domains. In this
paper, we consider the Poisson compound decision problem in a streaming or
online domain. By relying on a quasi-Bayesian approach, often referred to as
Newton's algorithm, we obtain sequential Poisson's mean estimates that are of
easy evaluation, computationally efficient and with a constant computational
cost as data increase, which is desirable for streaming data. Large sample
asymptotic properties of the proposed estimates are investigated, also
providing frequentist guarantees in terms of a regret analysis. We validate
empirically our methodology, both on synthetic and real data, comparing against
the most popular alternatives.","['Stefano Favaro', 'Sandra Fortini']","['stat.ME', 'stat.ML']",2024-11-12 09:04:16+00:00
http://arxiv.org/abs/2411.07650v1,"Understanding Audiovisual Deepfake Detection: Techniques, Challenges, Human Factors and Perceptual Insights","Deep Learning has been successfully applied in diverse fields, and its impact
on deepfake detection is no exception. Deepfakes are fake yet realistic
synthetic content that can be used deceitfully for political impersonation,
phishing, slandering, or spreading misinformation. Despite extensive research
on unimodal deepfake detection, identifying complex deepfakes through joint
analysis of audio and visual streams remains relatively unexplored. To fill
this gap, this survey first provides an overview of audiovisual deepfake
generation techniques, applications, and their consequences, and then provides
a comprehensive review of state-of-the-art methods that combine audio and
visual modalities to enhance detection accuracy, summarizing and critically
analyzing their strengths and limitations. Furthermore, we discuss existing
open source datasets for a deeper understanding, which can contribute to the
research community and provide necessary information to beginners who want to
analyze deep learning-based audiovisual methods for video forensics. By
bridging the gap between unimodal and multimodal approaches, this paper aims to
improve the effectiveness of deepfake detection strategies and guide future
research in cybersecurity and media integrity.","['Ammarah Hashmi', 'Sahibzada Adil Shahzad', 'Chia-Wen Lin', 'Yu Tsao', 'Hsin-Min Wang']","['cs.CV', 'cs.AI', 'cs.LG', 'cs.MM', 'cs.SD', 'eess.IV']",2024-11-12 09:02:11+00:00
http://arxiv.org/abs/2411.07643v1,xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell Lung Cancer,"Understanding how deep learning models predict oncology patient risk can
provide critical insights into disease progression, support clinical
decision-making, and pave the way for trustworthy and data-driven precision
medicine. Building on recent advances in the spatial modeling of the tumor
microenvironment using graph neural networks, we present an explainable cell
graph (xCG) approach for survival prediction. We validate our model on a public
cohort of imaging mass cytometry (IMC) data for 416 cases of lung
adenocarcinoma. We explain survival predictions in terms of known phenotypes on
the cell level by computing risk attributions over cell graphs, for which we
propose an efficient grid-based layer-wise relevance propagation (LRP) method.
Our ablation studies highlight the importance of incorporating the cancer stage
and model ensembling to improve the quality of risk estimates. Our xCG method,
together with the IMC data, is made publicly available to support further
research.","['Marvin Sextro', 'Gabriel Dernbach', 'Kai Standvoss', 'Simon Schallenberg', 'Frederick Klauschen', 'Klaus-Robert Müller', 'Maximilian Alber', 'Lukas Ruff']","['cs.CV', 'cs.LG']",2024-11-12 08:53:49+00:00
http://arxiv.org/abs/2411.07641v1,Top-$nσ$: Not All Logits Are You Need,"Large language models (LLMs) typically employ greedy decoding or
low-temperature sampling for reasoning tasks, reflecting a perceived trade-off
between diversity and accuracy. We challenge this convention by introducing
top-$n\sigma$, a novel sampling method that operates directly on pre-softmax
logits by leveraging a statistical threshold. Our key insight is that logits
naturally separate into a Gaussian-distributed noisy region and a distinct
informative region, enabling efficient token filtering without complex
probability manipulations. Unlike existing methods (e.g., top-$p$, min-$p$)
that inadvertently include more noise tokens at higher temperatures,
top-$n\sigma$ maintains a stable sampling space regardless of temperature
scaling. We also provide a theoretical analysis of top-$n\sigma$ to better
understand its behavior. The extensive experimental results across four
reasoning-focused datasets demonstrate that our method not only outperforms
existing sampling approaches but also surpasses greedy decoding, while
maintaining consistent performance even at high temperatures.","['Chenxia Tang', 'Jianchun Liu', 'Hongli Xu', 'Liusheng Huang']",['cs.LG'],2024-11-12 08:46:43+00:00
http://arxiv.org/abs/2411.07634v1,Exploring Multi-Agent Reinforcement Learning for Unrelated Parallel Machine Scheduling,"Scheduling problems pose significant challenges in resource, industry, and
operational management. This paper addresses the Unrelated Parallel Machine
Scheduling Problem (UPMS) with setup times and resources using a Multi-Agent
Reinforcement Learning (MARL) approach. The study introduces the Reinforcement
Learning environment and conducts empirical analyses, comparing MARL with
Single-Agent algorithms. The experiments employ various deep neural network
policies for single- and Multi-Agent approaches. Results demonstrate the
efficacy of the Maskable extension of the Proximal Policy Optimization (PPO)
algorithm in Single-Agent scenarios and the Multi-Agent PPO algorithm in
Multi-Agent setups. While Single-Agent algorithms perform adequately in reduced
scenarios, Multi-Agent approaches reveal challenges in cooperative learning but
a scalable capacity. This research contributes insights into applying MARL
techniques to scheduling optimization, emphasizing the need for algorithmic
sophistication balanced with scalability for intelligent scheduling solutions.","['Maria Zampella', 'Urtzi Otamendi', 'Xabier Belaunzaran', 'Arkaitz Artetxe', 'Igor G. Olaizola', 'Giuseppe Longo', 'Basilio Sierra']","['cs.AI', 'cs.LG', 'cs.MA', 'cs.NE', 'I.2.1; I.2.11; I.2.8']",2024-11-12 08:27:27+00:00
http://arxiv.org/abs/2411.07618v1,Direct Preference Optimization Using Sparse Feature-Level Constraints,"The alignment of large language models (LLMs) with human preferences remains
a key challenge. While post-training techniques like Reinforcement Learning
from Human Feedback (RLHF) and Direct Preference Optimization (DPO) have
achieved notable success, they often introduce computational inefficiencies and
training instability. In this paper, we propose Feature-level constrained
Preference Optimization (FPO), a novel method designed to simplify the
alignment process while ensuring stability. FPO leverages pre-trained Sparse
Autoencoders (SAEs) and introduces feature-level constraints, allowing for
efficient, sparsity-enforced alignment. Our approach enjoys efficiency by using
sparse features activated in a well-trained sparse autoencoder and the quality
of sequential KL divergence by using the feature-level offline reference.
Experimental results on benchmark datasets demonstrate that FPO achieves a
5.08% absolute improvement in win rate with much lower computational cost
compared to state-of-the-art baselines, making it a promising solution for
efficient and controllable LLM alignments.","['Qingyu Yin', 'Chak Tou Leong', 'Hongbo Zhang', 'Minjun Zhu', 'Hanqi Yan', 'Qiang Zhang', 'Yulan He', 'Wenjie Li', 'Jun Wang', 'Yue Zhang', 'Linyi Yang']","['cs.AI', 'cs.CL']",2024-11-12 07:54:13+00:00
http://arxiv.org/abs/2411.07611v1,Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation,"Clinical rationales play a pivotal role in accurate disease diagnosis;
however, many models predominantly use discriminative methods and overlook the
importance of generating supportive rationales. Rationale distillation is a
process that transfers knowledge from large language models (LLMs) to smaller
language models (SLMs), thereby enhancing the latter's ability to break down
complex tasks. Despite its benefits, rationale distillation alone is inadequate
for addressing domain knowledge limitations in tasks requiring specialized
expertise, such as disease diagnosis. Effectively embedding domain knowledge in
SLMs poses a significant challenge. While current LLMs are primarily geared
toward processing textual data, multimodal LLMs that incorporate time series
data, especially electronic health records (EHRs), are still evolving. To
tackle these limitations, we introduce ClinRaGen, an SLM optimized for
multimodal rationale generation in disease diagnosis. ClinRaGen incorporates a
unique knowledge-augmented attention mechanism to merge domain knowledge with
time series EHR data, utilizing a stepwise rationale distillation strategy to
produce both textual and time series-based clinical rationales. Our evaluations
show that ClinRaGen markedly improves the SLM's capability to interpret
multimodal EHR data and generate accurate clinical rationales, supporting more
reliable disease diagnosis, advancing LLM applications in healthcare, and
narrowing the performance divide between LLMs and SLMs.","['Shuai Niu', 'Jing Ma', 'Liang Bai', 'Zhihua Wang', 'Yida Xu', 'Yunya Song', 'Xian Yang']","['cs.CL', 'cs.AI', 'I.2.7']",2024-11-12 07:34:56+00:00
http://arxiv.org/abs/2411.07607v1,CJST: CTC Compressor based Joint Speech and Text Training for Decoder-Only ASR,"CTC compressor can be an effective approach to integrate audio encoders to
decoder-only models, which has gained growing interest for different speech
applications. In this work, we propose a novel CTC compressor based joint
speech and text training (CJST) framework for decoder-only ASR. CJST matches
speech and text modalities from both directions by exploring a simple modality
adaptor and several features of the CTC compressor, including sequence
compression, on-the-fly forced peaky alignment and CTC class embeddings.
Experimental results on the Librispeech and TED-LIUM2 corpora show that the
proposed CJST achieves an effective text injection without the need of duration
handling, leading to the best performance for both in-domain and cross-domain
scenarios. We also provide a comprehensive study on CTC compressor, covering
various compression modes, edge case handling and behavior under both clean and
noisy data conditions, which reveals the most robust setting to use CTC
compressor for decoder-only models.","['Wei Zhou', 'Junteng Jia', 'Leda Sari', 'Jay Mahadeokar', 'Ozlem Kalinli']","['eess.AS', 'cs.LG', 'cs.SD']",2024-11-12 07:30:29+00:00
http://arxiv.org/abs/2411.07606v1,Optimizing Service Function Chain Mapping in Network Function Virtualization through Simultaneous NF Decomposition and VNF Placement,"Network function virtualization enables network operators to implement new
services through a process called service function chain mapping. The concept
of Service Function Chain (SFC) is introduced to provide complex services,
which is an ordered set of Network Functions (NF). The network functions of an
SFC can be decomposed in several ways into some Virtual Network Functions
(VNF). Additionally, the decomposed NFs can be placed (mapped) as VNFs on
different machines on the underlying physical infrastructure. Selecting good
decompositions and good placements among the possible options greatly affects
both costs and service quality metrics. Previous research has addressed NF
decomposition and VNF placement as separate problems. However, in this paper,
we address both NF decomposition and VNF placement simultaneously as a single
problem. Since finding an optimal solution is NP-hard, we have employed
heuristic algorithms to solve the problem. Specifically, we have introduced a
multiobjective decomposition and mapping VNFs (MODMVNF) method based on the
non-dominated sorting genetic multi-objective algorithm (NSGAII) to solve the
problem. The goal is to find near-optimal decomposition and mapping on the
physical network at the same time to minimize the mapping cost and
communication latency of SFC. The comparison of the results of the proposed
method with the results obtained by solving ILP formulation of the problem as
well as the results obtained from the multi-objective particle swarm algorithm
shows the efficiency and effectiveness of the proposed method in terms of cost
and communication latency.","['Asghar Asgharian-Sardroud', 'Mohammad Hossein Izanlou', 'Amin Jabbari', 'Sepehr Mahmoodian Hamedani']","['cs.NI', 'cs.AI', '90C29, 68M10', 'C.2.1; C.2.4; I.2.8']",2024-11-12 07:26:51+00:00
http://arxiv.org/abs/2411.07602v1,Circuit Complexity Bounds for RoPE-based Transformer Architecture,"Characterizing the express power of the Transformer architecture is critical
to understanding its capacity limits and scaling law. Recent works provide the
circuit complexity bounds to Transformer-like architecture. On the other hand,
Rotary Position Embedding ($\mathsf{RoPE}$) has emerged as a crucial technique
in modern large language models, offering superior performance in capturing
positional information compared to traditional position embeddings, which shows
great potential in application prospects, particularly for the long context
scenario. Empirical evidence also suggests that $\mathsf{RoPE}$-based
Transformer architectures demonstrate greater generalization capabilities
compared to conventional Transformer models. In this work, we establish a
tighter circuit complexity bound for Transformers with $\mathsf{RoPE}$
attention. Our key contribution is that we show that unless $\mathsf{TC}^0 =
\mathsf{NC}^1$, a $\mathsf{RoPE}$-based Transformer with
$\mathrm{poly}(n)$-precision, $O(1)$ layers, hidden dimension $d \leq O(n)$
cannot solve the arithmetic problem or the Boolean formula value problem. This
result significantly demonstrates the fundamental limitation of the
expressivity of the $\mathsf{RoPE}$-based Transformer architecture, although it
achieves giant empirical success. Our theoretical framework not only
establishes tighter complexity bounds but also may instruct further work on the
$\mathsf{RoPE}$-based Transformer.","['Bo Chen', 'Xiaoyu Li', 'Yingyu Liang', 'Jiangxuan Long', 'Zhenmei Shi', 'Zhao Song']","['cs.LG', 'cs.AI', 'cs.CC', 'cs.CL']",2024-11-12 07:24:41+00:00
http://arxiv.org/abs/2411.07601v1,SegQC: a segmentation network-based framework for multi-metric segmentation quality control and segmentation error detection in volumetric medical images,"Quality control of structures segmentation in volumetric medical images is
important for identifying segmentation errors in clinical practice and for
facilitating model development. This paper introduces SegQC, a novel framework
for segmentation quality estimation and segmentation error detection. SegQC
computes an estimate measure of the quality of a segmentation in volumetric
scans and in their individual slices and identifies possible segmentation error
regions within a slice. The key components include: 1. SegQC-Net, a deep
network that inputs a scan and its segmentation mask and outputs segmentation
error probabilities for each voxel in the scan; 2. three new segmentation
quality metrics, two overlap metrics and a structure size metric, computed from
the segmentation error probabilities; 3. a new method for detecting possible
segmentation errors in scan slices computed from the segmentation error
probabilities. We introduce a new evaluation scheme to measure segmentation
error discrepancies based on an expert radiologist corrections of automatically
produced segmentations that yields smaller observer variability and is closer
to actual segmentation errors. We demonstrate SegQC on three fetal structures
in 198 fetal MRI scans: fetal brain, fetal body and the placenta. To assess the
benefits of SegQC, we compare it to the unsupervised Test Time Augmentation
(TTA)-based quality estimation. Our studies indicate that SegQC outperforms
TTA-based quality estimation in terms of Pearson correlation and MAE for fetal
body and fetal brain structures segmentation. Our segmentation error detection
method achieved recall and precision rates of 0.77 and 0.48 for fetal body, and
0.74 and 0.55 for fetal brain segmentation error detection respectively. SegQC
enhances segmentation metrics estimation for whole scans and individual slices,
as well as provides error regions detection.","['Bella Specktor-Fadida', 'Liat Ben-Sira', 'Dafna Ben-Bashat', 'Leo Joskowicz']","['eess.IV', 'cs.CV', 'cs.LG', '68T45']",2024-11-12 07:24:06+00:00
http://arxiv.org/abs/2411.07600v1,Decision Feedback In-Context Symbol Detection over Block-Fading Channels,"Pre-trained Transformers, through in-context learning (ICL), have
demonstrated exceptional capabilities to adapt to new tasks using example
prompts \textit{without model update}. Transformer-based wireless receivers,
where prompts consist of the pilot data in the form of transmitted and received
signal pairs, have shown high estimation accuracy when pilot data are abundant.
However, pilot information is often costly and limited in practice. In this
work, we propose the \underline{DE}cision \underline{F}eedback
\underline{IN}-Cont\underline{E}xt \underline{D}etection (DEFINED) solution as
a new wireless receiver design, which bypasses channel estimation and directly
performs symbol detection using the (sometimes extremely) limited pilot data.
The key innovation in DEFINED is the proposed decision feedback mechanism in
ICL, where we sequentially incorporate the detected symbols into the prompts to
improve the detections for subsequent symbols. Extensive experiments across a
broad range of wireless communication settings demonstrate that DEFINED
achieves significant performance improvements, in some cases only needing a
single pilot pair.","['Li Fan', 'Jing Yang', 'Cong Shen']","['cs.IT', 'cs.LG', 'eess.SP', 'math.IT', 'stat.ML']",2024-11-12 07:20:48+00:00
http://arxiv.org/abs/2411.07598v1,Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations,"Many open-ended conversations (e.g., tutoring lessons or business meetings)
revolve around pre-defined reference materials, like worksheets or meeting
bullets. To provide a framework for studying such conversation structure, we
introduce Problem-Oriented Segmentation & Retrieval (POSR), the task of jointly
breaking down conversations into segments and linking each segment to the
relevant reference item. As a case study, we apply POSR to education where
effectively structuring lessons around problems is critical yet difficult. We
present LessonLink, the first dataset of real-world tutoring lessons, featuring
3,500 segments, spanning 24,300 minutes of instruction and linked to 116 SAT
math problems. We define and evaluate several joint and independent approaches
for POSR, including segmentation (e.g., TextTiling), retrieval (e.g., ColBERT),
and large language models (LLMs) methods. Our results highlight that modeling
POSR as one joint task is essential: POSR methods outperform independent
segmentation and retrieval pipelines by up to +76% on joint metrics and surpass
traditional segmentation methods by up to +78% on segmentation metrics. We
demonstrate POSR's practical impact on downstream education applications,
deriving new insights on the language and time use in real-world lesson
structures.","['Rose E. Wang', 'Pawan Wirawarn', 'Kenny Lam', 'Omar Khattab', 'Dorottya Demszky']","['cs.CL', 'cs.AI']",2024-11-12 07:16:51+00:00
http://arxiv.org/abs/2411.07595v1,Entropy Controllable Direct Preference Optimization,"In the post-training of large language models (LLMs), Reinforcement Learning
from Human Feedback (RLHF) is an effective approach to achieve generation
aligned with human preferences. Direct Preference Optimization (DPO) allows for
policy training with a simple binary cross-entropy loss without a reward model.
The objective of DPO is regularized by reverse KL divergence that encourages
mode-seeking fitting to the reference policy. Nonetheless, we indicate that
minimizing reverse KL divergence could fail to capture a mode of the reference
distribution, which may hurt the policy's performance. Based on this
observation, we propose a simple modification to DPO, H-DPO, which allows for
control over the entropy of the resulting policy, enhancing the distribution's
sharpness and thereby enabling mode-seeking fitting more effectively. In our
experiments, we show that H-DPO outperformed DPO across various tasks,
demonstrating superior results in pass@$k$ evaluations for mathematical tasks.
Moreover, H-DPO is simple to implement, requiring only minor modifications to
the loss calculation of DPO, which makes it highly practical and promising for
wide-ranging applications in the training of LLMs.","['Motoki Omura', 'Yasuhiro Fujita', 'Toshiki Kataoka']","['cs.LG', 'cs.AI', 'cs.CL']",2024-11-12 07:09:44+00:00
http://arxiv.org/abs/2411.07591v1,Overcoming the Curse of Dimensionality in Reinforcement Learning Through Approximate Factorization,"Reinforcement Learning (RL) algorithms are known to suffer from the curse of
dimensionality, which refers to the fact that large-scale problems often lead
to exponentially high sample complexity. A common solution is to use deep
neural networks for function approximation; however, such approaches typically
lack theoretical guarantees. To provably address the curse of dimensionality,
we observe that many real-world problems exhibit task-specific model structures
that, when properly leveraged, can improve the sample efficiency of RL.
Building on this insight, we propose overcoming the curse of dimensionality by
approximately factorizing the original Markov decision processes (MDPs) into
smaller, independently evolving MDPs. This factorization enables the
development of sample-efficient RL algorithms in both model-based and
model-free settings, with the latter involving a variant of variance-reduced
Q-learning. We provide improved sample complexity guarantees for both proposed
algorithms. Notably, by leveraging model structure through the approximate
factorization of the MDP, the dependence of sample complexity on the size of
the state-action space can be exponentially reduced. Numerically, we
demonstrate the practicality of our proposed methods through experiments on
both synthetic MDP tasks and a wind farm-equipped storage control problem.","['Chenbei Lu', 'Laixi Shi', 'Zaiwei Chen', 'Chenye Wu', 'Adam Wierman']",['cs.LG'],2024-11-12 07:08:00+00:00
http://arxiv.org/abs/2411.07589v1,Overhead-free User-side Recommender Systems,"Traditionally, recommendation algorithms have been designed for service
developers. But recently, a new paradigm called user-side recommender systems
has been proposed. User-side recommender systems are built and used by end
users, in sharp contrast to traditional provider-side recommender systems. Even
if the official recommender system offered by the provider is not fair, end
users can create and enjoy their own user-side recommender systems by
themselves. Although the concept of user-side recommender systems is
attractive, the problem is they require tremendous communication costs between
the user and the official system. Even the most efficient user-side recommender
systems require about 5 times more costs than provider-side recommender
systems. Such high costs hinder the adoption of user-side recommender systems.
In this paper, we propose overhead-free user-side recommender systems,
RecCycle, which realizes user-side recommender systems without any
communication overhead. The main idea of RecCycle is to recycle past
recommendation results offered by the provider's recommender systems. The
ingredients of RecCycle can be retrieved ``for free,'' and it greatly reduces
the cost of user-side recommendations. In the experiments, we confirm that
RecCycle performs as well as state-of-the-art user-side recommendation
algorithms while RecCycle reduces costs significantly.",['Ryoma Sato'],"['cs.IR', 'cs.AI', 'cs.DB', 'cs.DL']",2024-11-12 06:58:03+00:00
http://arxiv.org/abs/2411.07586v1,A Comprehensive Survey of AI-Driven Advancements and Techniques in Automated Program Repair and Code Generation,"Bug fixing and code generation have been core research topics in software
development for many years. The recent explosive growth in Large Language
Models has completely transformed these spaces, putting in reach incredibly
powerful tools for both. In this survey, 27 recent papers have been reviewed
and split into two groups: one dedicated to Automated Program Repair (APR) and
LLM integration and the other to code generation using LLMs. The first group
consists of new methods for bug detection and repair, which include locating
semantic errors, security vulnerabilities, and runtime failure bugs. The place
of LLMs in reducing manual debugging efforts is emphasized in this work by APR
toward context-aware fixes, with innovations that boost accuracy and efficiency
in automatic debugging. The second group dwells on code generation, providing
an overview of both general-purpose LLMs fine-tuned for programming and
task-specific models. It also presents methods to improve code generation, such
as identifier-aware training, fine-tuning at the instruction level, and
incorporating semantic code structures. This survey work contrasts the
methodologies in APR and code generation to identify trends such as using LLMs,
feedback loops to enable iterative code improvement and open-source models. It
also discusses the challenges of achieving functional correctness and security
and outlines future directions for research in LLM-based software development.","['Avinash Anand', 'Akshit Gupta', 'Nishchay Yadav', 'Shaurya Bajaj']",['cs.AI'],2024-11-12 06:47:54+00:00
http://arxiv.org/abs/2411.07585v1,Reinforcement Learning Framework for Quantitative Trading,"The inherent volatility and dynamic fluctuations within the financial stock
market underscore the necessity for investors to employ a comprehensive and
reliable approach that integrates risk management strategies, market trends,
and the movement trends of individual securities. By evaluating specific data,
investors can make more informed decisions. However, the current body of
literature lacks substantial evidence supporting the practical efficacy of
reinforcement learning (RL) agents, as many models have only demonstrated
success in back testing using historical data. This highlights the urgent need
for a more advanced methodology capable of addressing these challenges. There
is a significant disconnect in the effective utilization of financial
indicators to better understand the potential market trends of individual
securities. The disclosure of successful trading strategies is often restricted
within financial markets, resulting in a scarcity of widely documented and
published strategies leveraging RL. Furthermore, current research frequently
overlooks the identification of financial indicators correlated with various
market trends and their potential advantages.
  This research endeavors to address these complexities by enhancing the
ability of RL agents to effectively differentiate between positive and negative
buy/sell actions using financial indicators. While we do not address all
concerns, this paper provides deeper insights and commentary on the utilization
of technical indicators and their benefits within reinforcement learning. This
work establishes a foundational framework for further exploration and
investigation of more complex scenarios.","['Alhassan S. Yasin', 'Prabdeep S. Gill']","['q-fin.TR', 'cs.AI', 'q-fin.CP']",2024-11-12 06:44:28+00:00
http://arxiv.org/abs/2411.07574v1,Disentangling Tabular Data towards Better One-Class Anomaly Detection,"Tabular anomaly detection under the one-class classification setting poses a
significant challenge, as it involves accurately conceptualizing ""normal""
derived exclusively from a single category to discern anomalies from normal
data variations. Capturing the intrinsic correlation among attributes within
normal samples presents one promising method for learning the concept. To do
so, the most recent effort relies on a learnable mask strategy with a
reconstruction task. However, this wisdom may suffer from the risk of producing
uniform masks, i.e., essentially nothing is masked, leading to less effective
correlation learning. To address this issue, we presume that attributes related
to others in normal samples can be divided into two non-overlapping and
correlated subsets, defined as CorrSets, to capture the intrinsic correlation
effectively. Accordingly, we introduce an innovative method that disentangles
CorrSets from normal tabular data. To our knowledge, this is a pioneering
effort to apply the concept of disentanglement for one-class anomaly detection
on tabular data. Extensive experiments on 20 tabular datasets show that our
method substantially outperforms the state-of-the-art methods and leads to an
average performance improvement of 6.1% on AUC-PR and 2.1% on AUC-ROC.","['Jianan Ye', 'Zhaorui Tan', 'Yijie Hu', 'Xi Yang', 'Guangliang Cheng', 'Kaizhu Huang']","['cs.LG', 'cs.AI']",2024-11-12 06:24:11+00:00
http://arxiv.org/abs/2411.07567v1,Uncertainty-Aware Test-Time Adaptation for Inverse Consistent Diffeomorphic Lung Image Registration,"Diffeomorphic deformable image registration ensures smooth invertible
transformations across inspiratory and expiratory chest CT scans. Yet, in
practice, deep learning-based diffeomorphic methods struggle to capture large
deformations between inspiratory and expiratory volumes, and therefore lack
inverse consistency. Existing methods also fail to account for model
uncertainty, which can be useful for improving performance. We propose an
uncertainty-aware test-time adaptation framework for inverse consistent
diffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to
estimate spatial uncertainty that is used to improve model performance. We
train and evaluate our method for inspiratory-to-expiratory CT registration on
a large cohort of 675 subjects from the COPDGene study, achieving a higher Dice
similarity coefficient (DSC) between the lung boundaries (0.966) compared to
both VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates
consistent improvements in the inverse registration direction as well with an
overall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956).
Paired t-tests indicate statistically significant improvements.","['Muhammad F. A. Chaudhary', 'Stephanie M. Aguilera', 'Arie Nakhmani', 'Joseph M. Reinhardt', 'Surya P. Bhatt', 'Sandeep Bodduluri']","['eess.IV', 'cs.CV', 'cs.LG']",2024-11-12 05:59:21+00:00
http://arxiv.org/abs/2411.07563v1,Improving Grapheme-to-Phoneme Conversion through In-Context Knowledge Retrieval with Large Language Models,"Grapheme-to-phoneme (G2P) conversion is a crucial step in Text-to-Speech
(TTS) systems, responsible for mapping grapheme to corresponding phonetic
representations. However, it faces ambiguities problems where the same grapheme
can represent multiple phonemes depending on contexts, posing a challenge for
G2P conversion. Inspired by the remarkable success of Large Language Models
(LLMs) in handling context-aware scenarios, contextual G2P conversion systems
with LLMs' in-context knowledge retrieval (ICKR) capabilities are proposed to
promote disambiguation capability. The efficacy of incorporating ICKR into G2P
conversion systems is demonstrated thoroughly on the Librig2p dataset. In
particular, the best contextual G2P conversion system using ICKR outperforms
the baseline with weighted average phoneme error rate (PER) reductions of 2.0%
absolute (28.9% relative). Using GPT-4 in the ICKR system can increase of 3.5%
absolute (3.8% relative) on the Librig2p dataset.","['Dongrui Han', 'Mingyu Cui', 'Jiawen Kang', 'Xixin Wu', 'Xunying Liu', 'Helen Meng']",['cs.AI'],2024-11-12 05:38:43+00:00
http://arxiv.org/abs/2411.07560v1,EUR/USD Exchange Rate Forecasting incorporating Text Mining Based on Pre-trained Language Models and Deep Learning Methods,"This study introduces a novel approach for EUR/USD exchange rate forecasting
that integrates deep learning, textual analysis, and particle swarm
optimization (PSO). By incorporating online news and analysis texts as
qualitative data, the proposed PSO-LSTM model demonstrates superior performance
compared to traditional econometric and machine learning models. The research
employs advanced text mining techniques, including sentiment analysis using the
RoBERTa-Large model and topic modeling with LDA. Empirical findings underscore
the significant advantage of incorporating textual data, with the PSO-LSTM
model outperforming benchmark models such as SVM, SVR, ARIMA, and GARCH.
Ablation experiments reveal the contribution of each textual data category to
the overall forecasting performance. The study highlights the transformative
potential of artificial intelligence in finance and paves the way for future
research in real-time forecasting and the integration of alternative data
sources.","['Xiangyu Shi', 'Hongcheng Ding', 'Salaar Faroog', 'Deshinta Arrova Dewi', 'Shamsul Nahar Abdullah', 'Bahiah A Malek']","['cs.CE', 'cs.AI']",2024-11-12 05:28:52+00:00
