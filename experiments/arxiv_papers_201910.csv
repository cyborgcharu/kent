id,title,abstract,authors,categories,date
http://arxiv.org/abs/1911.04362v1,To Populate is To Regulate,"We examine the effects of instantiating Lewis signaling games within a
population of speaker and listener agents with the aim of producing a set of
general and robust representations of unstructured pixel data. Preliminary
experiments suggest that the set of representations associated with languages
generated within a population outperform those generated between a single
speaker-listener pair on this objective, making a case for the adoption of
population-based approaches in emergent communication studies. Furthermore,
post-hoc analysis reveals that population-based learning induces a number of
novel factors to the conventional emergent communication setup, inviting a wide
range of future research questions regarding communication dynamics and the
flow of information within them.",['Nicole Fitzgerald'],"['cs.LG', 'cs.CL', 'stat.ML']",2019-11-06 23:51:45+00:00
http://arxiv.org/abs/1911.02682v1,Physics-Guided Architecture (PGA) of Neural Networks for Quantifying Uncertainty in Lake Temperature Modeling,"To simultaneously address the rising need of expressing uncertainties in deep
learning models along with producing model outputs which are consistent with
the known scientific knowledge, we propose a novel physics-guided architecture
(PGA) of neural networks in the context of lake temperature modeling where the
physical constraints are hard coded in the neural network architecture. This
allows us to integrate such models with state of the art uncertainty estimation
approaches such as Monte Carlo (MC) Dropout without sacrificing the physical
consistency of our results. We demonstrate the effectiveness of our approach in
ensuring better generalizability as well as physical consistency in MC
estimates over data collected from Lake Mendota in Wisconsin and Falling Creek
Reservoir in Virginia, even with limited training data. We further show that
our MC estimates correctly match the distribution of ground-truth observations,
thus making the PGA paradigm amenable to physically grounded uncertainty
quantification.","['Arka Daw', 'R. Quinn Thomas', 'Cayelan C. Carey', 'Jordan S. Read', 'Alison P. Appling', 'Anuj Karpatne']","['cs.LG', 'physics.comp-ph', 'stat.ML']",2019-11-06 23:47:14+00:00
http://arxiv.org/abs/1911.02681v3,Generalized Transformation-based Gradient,"The reparameterization trick has become one of the most useful tools in the
field of variational inference. However, the reparameterization trick is based
on the standardization transformation which restricts the scope of application
of this method to distributions that have tractable inverse cumulative
distribution functions or are expressible as deterministic transformations of
such distributions. In this paper, we generalized the reparameterization trick
by allowing a general transformation. We discover that the proposed model is a
special case of control variate indicating that the proposed model can combine
the advantages of CV and generalized reparameterization.","['Anbang Wu', 'Shuangxi Chen', 'Chunming Wu']","['cs.LG', 'math.OC', 'stat.ML']",2019-11-06 23:40:12+00:00
http://arxiv.org/abs/1911.02673v2,Towards the Use of Neural Networks for Influenza Prediction at Multiple Spatial Resolutions,"We introduce the use of a Gated Recurrent Unit (GRU) for influenza prediction
at the state- and city-level in the US, and experiment with the inclusion of
real-time flu-related Internet search data. We find that a GRU has lower
prediction error than current state-of-the-art methods for data-driven
influenza prediction at time horizons of over two weeks. In contrast with other
machine learning approaches, the inclusion of real-time Internet search data
does not improve GRU predictions.","['Emily L. Aiken', 'Andre T. Nguyen', 'Mauricio Santillana']","['cs.LG', 'cs.CY', 'stat.AP', 'stat.ML']",2019-11-06 23:14:53+00:00
http://arxiv.org/abs/1911.02660v1,What Do We Really Need? Degenerating U-Net on Retinal Vessel Segmentation,"Retinal vessel segmentation is an essential step for fundus image analysis.
With the recent advances of deep learning technologies, many convolutional
neural networks have been applied in this field, including the successful
U-Net. In this work, we firstly modify the U-Net with functional blocks aiming
to pursue higher performance. The absence of the expected performance boost
then lead us to dig into the opposite direction of shrinking the U-Net and
exploring the extreme conditions such that its segmentation performance is
maintained. Experiment series to simplify the network structure, reduce the
network size and restrict the training conditions are designed. Results show
that for retinal vessel segmentation on DRIVE database, U-Net does not
degenerate until surprisingly acute conditions: one level, one filter in
convolutional layers, and one training sample. This experimental discovery is
both counter-intuitive and worthwhile. Not only are the extremes of the U-Net
explored on a well-studied application, but also one intriguing warning is
raised for the research methodology which seeks for marginal performance
enhancement regardless of the resource cost.","['Weilin Fu', 'Katharina Breininger', 'Zhaoya Pan', 'Andreas Maier']","['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2019-11-06 22:49:55+00:00
http://arxiv.org/abs/1911.02656v1,Invariance and identifiability issues for word embeddings,"Word embeddings are commonly obtained as optimizers of a criterion function
$f$ of a text corpus, but assessed on word-task performance using a different
evaluation function $g$ of the test data. We contend that a possible source of
disparity in performance on tasks is the incompatibility between classes of
transformations that leave $f$ and $g$ invariant. In particular, word
embeddings defined by $f$ are not unique; they are defined only up to a class
of transformations to which $f$ is invariant, and this class is larger than the
class to which $g$ is invariant. One implication of this is that the apparent
superiority of one word embedding over another, as measured by word task
performance, may largely be a consequence of the arbitrary elements selected
from the respective solution sets. We provide a formal treatment of the above
identifiability issue, present some numerical examples, and discuss possible
resolutions.","['Rachel Carrington', 'Karthik Bharath', 'Simon Preston']","['stat.ML', 'cs.CL', 'cs.LG', 'stat.CO']",2019-11-06 22:41:04+00:00
http://arxiv.org/abs/1911.04336v1,Fair Meta-Learning: Learning How to Learn Fairly,"Data sets for fairness relevant tasks can lack examples or be biased
according to a specific label in a sensitive attribute. We demonstrate the
usefulness of weight based meta-learning approaches in such situations. For
models that can be trained through gradient descent, we demonstrate that there
are some parameter configurations that allow models to be optimized from a few
number of gradient steps and with minimal data which are both fair and
accurate. To learn such weight sets, we adapt the popular MAML algorithm to
Fair-MAML by the inclusion of a fairness regularization term. In practice,
Fair-MAML allows practitioners to train fair machine learning models from only
a few examples when data from related tasks is available. We empirically
exhibit the value of this technique by comparing to relevant baselines.","['Dylan Slack', 'Sorelle Friedler', 'Emile Givental']","['cs.LG', 'stat.ML']",2019-11-06 21:43:53+00:00
http://arxiv.org/abs/1911.02624v1,Data Generation for Neural Programming by Example,"Programming by example is the problem of synthesizing a program from a small
set of input / output pairs. Recent works applying machine learning methods to
this task show promise, but are typically reliant on generating synthetic
examples for training. A particular challenge lies in generating meaningful
sets of inputs and outputs, which well-characterize a given program and
accurately demonstrate its behavior. Where examples used for testing are
generated by the same method as training data then the performance of a model
may be partly reliant on this similarity. In this paper we introduce a novel
approach using an SMT solver to synthesize inputs which cover a diverse set of
behaviors for a given program. We carry out a case study comparing this method
to existing synthetic data generation procedures in the literature, and find
that data generated using our approach improves both the discriminatory power
of example sets and the ability of trained machine learning models to
generalize to unfamiliar data.","['Judith Clymo', 'Haik Manukian', 'Nathanaël Fijalkow', 'Adrià Gascón', 'Brooks Paige']","['cs.LG', 'cs.NE', 'cs.PL', 'stat.ML']",2019-11-06 20:57:03+00:00
http://arxiv.org/abs/1911.02623v1,Map Enhanced Route Travel Time Prediction using Deep Neural Networks,"Travel time estimation is a fundamental problem in transportation science
with extensive literature. The study of these techniques has intensified due to
availability of many publicly available large trip datasets. Recently developed
deep learning based models have improved the generality and performance and
have focused on estimating times for individual sub-trajectories and
aggregating them to predict the travel time of the entire trajectory. However,
these techniques ignore the road network information. In this work, we propose
and study techniques for incorporating road networks along with historical
trips' data into travel time prediction. We incorporate both node embeddings as
well as road distance into the existing model. Experiments on large real-world
benchmark datasets suggest improved performance, especially when the train data
is small. As expected, the proposed method performs better than the baseline
when there is a larger difference between road distance and Vincenty distance
between start and end points.","['Soumi Das', 'Rajath Nandan Kalava', 'Kolli Kiran Kumar', 'Akhil Kandregula', 'Kalpam Suhaas', 'Sourangshu Bhattacharya', 'Niloy Ganguly']","['cs.LG', 'stat.ML']",2019-11-06 20:52:02+00:00
http://arxiv.org/abs/1911.02613v1,Hyper-SAGNN: a self-attention based graph neural network for hypergraphs,"Graph representation learning for hypergraphs can be used to extract patterns
among higher-order interactions that are critically important in many real
world problems. Current approaches designed for hypergraphs, however, are
unable to handle different types of hypergraphs and are typically not generic
for various learning tasks. Indeed, models that can predict variable-sized
heterogeneous hyperedges have not been available. Here we develop a new
self-attention based graph neural network called Hyper-SAGNN applicable to
homogeneous and heterogeneous hypergraphs with variable hyperedge sizes. We
perform extensive evaluations on multiple datasets, including four benchmark
network datasets and two single-cell Hi-C datasets in genomics. We demonstrate
that Hyper-SAGNN significantly outperforms the state-of-the-art methods on
traditional tasks while also achieving great performance on a new task called
outsider identification. Hyper-SAGNN will be useful for graph representation
learning to uncover complex higher-order interactions in different
applications.","['Ruochi Zhang', 'Yuesong Zou', 'Jian Ma']","['cs.LG', 'stat.ML']",2019-11-06 20:10:24+00:00
http://arxiv.org/abs/1911.02590v1,Optimizing Millions of Hyperparameters by Implicit Differentiation,"We propose an algorithm for inexpensive gradient-based hyperparameter
optimization that combines the implicit function theorem (IFT) with efficient
inverse Hessian approximations. We present results about the relationship
between the IFT and differentiating through optimization, motivating our
algorithm. We use the proposed approach to train modern network architectures
with millions of weights and millions of hyper-parameters. For example, we
learn a data-augmentation network - where every weight is a hyperparameter
tuned for validation performance - outputting augmented training examples.
Jointly tuning weights and hyperparameters with our approach is only a few
times more costly in memory and compute than standard training.","['Jonathan Lorraine', 'Paul Vicol', 'David Duvenaud']","['cs.LG', 'stat.ML']",2019-11-06 19:04:16+00:00
http://arxiv.org/abs/1911.02549v2,MLPerf Inference Benchmark,"Machine-learning (ML) hardware and software system demand is burgeoning.
Driven by ML applications, the number of different ML inference systems has
exploded. Over 100 organizations are building ML inference chips, and the
systems that incorporate existing models span at least three orders of
magnitude in power consumption and five orders of magnitude in performance;
they range from embedded devices to data-center solutions. Fueling the hardware
are a dozen or more software frameworks and libraries. The myriad combinations
of ML hardware and ML software make assessing ML-system performance in an
architecture-neutral, representative, and reproducible manner challenging.
There is a clear need for industry-wide standard ML benchmarking and evaluation
criteria. MLPerf Inference answers that call. In this paper, we present our
benchmarking method for evaluating ML inference systems. Driven by more than 30
organizations as well as more than 200 ML engineers and practitioners, MLPerf
prescribes a set of rules and best practices to ensure comparability across
systems with wildly differing architectures. The first call for submissions
garnered more than 600 reproducible inference-performance measurements from 14
organizations, representing over 30 systems that showcase a wide range of
capabilities. The submissions attest to the benchmark's flexibility and
adaptability.","['Vijay Janapa Reddi', 'Christine Cheng', 'David Kanter', 'Peter Mattson', 'Guenther Schmuelling', 'Carole-Jean Wu', 'Brian Anderson', 'Maximilien Breughe', 'Mark Charlebois', 'William Chou', 'Ramesh Chukka', 'Cody Coleman', 'Sam Davis', 'Pan Deng', 'Greg Diamos', 'Jared Duke', 'Dave Fick', 'J. Scott Gardner', 'Itay Hubara', 'Sachin Idgunji', 'Thomas B. Jablin', 'Jeff Jiao', 'Tom St. John', 'Pankaj Kanwar', 'David Lee', 'Jeffery Liao', 'Anton Lokhmotov', 'Francisco Massa', 'Peng Meng', 'Paulius Micikevicius', 'Colin Osborne', 'Gennady Pekhimenko', 'Arun Tejusve Raghunath Rajan', 'Dilip Sequeira', 'Ashish Sirasao', 'Fei Sun', 'Hanlin Tang', 'Michael Thomson', 'Frank Wei', 'Ephrem Wu', 'Lingjie Xu', 'Koichi Yamada', 'Bing Yu', 'George Yuan', 'Aaron Zhong', 'Peizhao Zhang', 'Yuchen Zhou']","['cs.LG', 'cs.PF', 'stat.ML']",2019-11-06 18:43:10+00:00
http://arxiv.org/abs/1911.02536v2,Unsupervised Hierarchy Matching with Optimal Transport over Hyperbolic Spaces,"This paper focuses on the problem of unsupervised alignment of hierarchical
data such as ontologies or lexical databases. This is a problem that appears
across areas, from natural language processing to bioinformatics, and is
typically solved by appeal to outside knowledge bases and label-textual
similarity. In contrast, we approach the problem from a purely geometric
perspective: given only a vector-space representation of the items in the two
hierarchies, we seek to infer correspondences across them. Our work derives
from and interweaves hyperbolic-space representations for hierarchical data, on
one hand, and unsupervised word-alignment methods, on the other. We first
provide a set of negative results showing how and why Euclidean methods fail in
this hyperbolic setting. We then propose a novel approach based on optimal
transport over hyperbolic spaces, and show that it outperforms standard
embedding alignment techniques in various experiments on cross-lingual WordNet
alignment and ontology matching tasks.","['David Alvarez-Melis', 'Youssef Mroueh', 'Tommi S. Jaakkola']","['cs.LG', 'stat.ML']",2019-11-06 18:20:35+00:00
http://arxiv.org/abs/1911.02522v1,"Auptimizer -- an Extensible, Open-Source Framework for Hyperparameter Tuning","Tuning machine learning models at scale, especially finding the right
hyperparameter values, can be difficult and time-consuming. In addition to the
computational effort required, this process also requires some ancillary
efforts including engineering tasks (e.g., job scheduling) as well as more
mundane tasks (e.g., keeping track of the various parameters and associated
results). We present Auptimizer, a general Hyperparameter Optimization (HPO)
framework to help data scientists speed up model tuning and bookkeeping. With
Auptimizer, users can use all available computing resources in distributed
settings for model training. The user-friendly system design simplifies
creating, controlling, and tracking of a typical machine learning project. The
design also allows researchers to integrate new HPO algorithms. To demonstrate
its flexibility, we show how Auptimizer integrates a few major HPO techniques
(from random search to neural architecture search). The code is available at
https://github.com/LGE-ARC-AdvancedAI/auptimizer.","['Jiayi Liu', 'Samarth Tripathi', 'Unmesh Kurup', 'Mohak Shah']","['cs.LG', 'stat.ML']",2019-11-06 18:00:31+00:00
http://arxiv.org/abs/1911.02516v1,DC-S3GD: Delay-Compensated Stale-Synchronous SGD for Large-Scale Decentralized Neural Network Training,"Data parallelism has become the de facto standard for training Deep Neural
Network on multiple processing units. In this work we propose DC-S3GD, a
decentralized (without Parameter Server) stale-synchronous version of the
Delay-Compensated Asynchronous Stochastic Gradient Descent (DC-ASGD) algorithm.
In our approach, we allow for the overlap of computation and communication, and
compensate the inherent error with a first-order correction of the gradients.
We prove the effectiveness of our approach by training Convolutional Neural
Network with large batches and achieving state-of-the-art results.",['Alessandro Rigazzi'],"['cs.LG', 'cs.DC', 'stat.ML']",2019-11-06 17:54:56+00:00
http://arxiv.org/abs/1911.02508v2,Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods,"As machine learning black boxes are increasingly being deployed in domains
such as healthcare and criminal justice, there is growing emphasis on building
tools and techniques for explaining these black boxes in an interpretable
manner. Such explanations are being leveraged by domain experts to diagnose
systematic errors and underlying biases of black boxes. In this paper, we
demonstrate that post hoc explanations techniques that rely on input
perturbations, such as LIME and SHAP, are not reliable. Specifically, we
propose a novel scaffolding technique that effectively hides the biases of any
given classifier by allowing an adversarial entity to craft an arbitrary
desired explanation. Our approach can be used to scaffold any biased classifier
in such a way that its predictions on the input data distribution still remain
biased, but the post hoc explanations of the scaffolded classifier look
innocuous. Using extensive evaluation with multiple real-world datasets
(including COMPAS), we demonstrate how extremely biased (racist) classifiers
crafted by our framework can easily fool popular explanation techniques such as
LIME and SHAP into generating innocuous explanations which do not reflect the
underlying biases.","['Dylan Slack', 'Sophie Hilgard', 'Emily Jia', 'Sameer Singh', 'Himabindu Lakkaraju']","['cs.LG', 'cs.AI', 'stat.ML']",2019-11-06 17:52:20+00:00
http://arxiv.org/abs/1911.03362v2,"Domain, Translationese and Noise in Synthetic Data for Neural Machine Translation","The quality of neural machine translation can be improved by leveraging
additional monolingual resources to create synthetic training data. Source-side
monolingual data can be (forward-)translated into the target language for
self-training; target-side monolingual data can be back-translated. It has been
widely reported that back-translation delivers superior results, but could this
be due to artefacts in the test sets? We perform a case study using
French-English news translation task and separate test sets based on their
original languages. We show that forward translation delivers superior gains in
terms of BLEU on sentences that were originally in the source language,
complementing previous studies which show large improvements with
back-translation on sentences that were originally in the target language. To
better understand when and why forward and back-translation are effective, we
study the role of domains, translationese, and noise. While translationese
effects are well known to influence MT evaluation, we also find evidence that
news data from different languages shows subtle domain differences, which is
another explanation for varying performance on different portions of the test
set. We perform additional low-resource experiments which demonstrate that
forward translation is more sensitive to the quality of the initial translation
system than back-translation, and tends to perform worse in low-resource
settings.","['Nikolay Bogoychev', 'Rico Sennrich']","['cs.CL', 'cs.LG', 'stat.ML']",2019-11-06 17:30:57+00:00
http://arxiv.org/abs/1911.03224v3,"Assessing the Frontier: Active Learning, Model Accuracy, and Multi-objective Materials Discovery and Optimization","Discovering novel materials can be greatly accelerated by iterative machine
learning-informed proposal of candidates---active learning. However, standard
\emph{global-scope error} metrics for model quality are not predictive of
discovery performance, and can be misleading. We introduce the notion of
\emph{Pareto shell-scope error} to help judge the suitability of a model for
proposing material candidates. Further, through synthetic cases and a
thermoelectric dataset, we probe the relation between acquisition function
fidelity and active learning performance. Results suggest novel diagnostic
tools, as well as new insights for acquisition function design.","['Zachary del Rosario', 'Matthias Rupp', 'Yoolhee Kim', 'Erin Antono', 'Julia Ling']","['stat.ML', 'cs.LG', 'stat.ME']",2019-11-06 17:24:35+00:00
http://arxiv.org/abs/1911.02497v2,A Programmable Approach to Neural Network Compression,"Deep neural networks (DNNs) frequently contain far more weights, represented
at a higher precision, than are required for the specific task which they are
trained to perform. Consequently, they can often be compressed using techniques
such as weight pruning and quantization that reduce both the model size and
inference time without appreciable loss in accuracy. However, finding the best
compression strategy and corresponding target sparsity for a given DNN,
hardware platform, and optimization objective currently requires expensive,
frequently manual, trial-and-error experimentation. In this paper, we introduce
a programmable system for model compression called Condensa. Users
programmatically compose simple operators, in Python, to build more complex and
practically interesting compression strategies. Given a strategy and
user-provided objective (such as minimization of running time), Condensa uses a
novel Bayesian optimization-based algorithm to automatically infer desirable
sparsities. Our experiments on four real-world DNNs demonstrate memory
footprint and hardware runtime throughput improvements of 188x and 2.59x,
respectively, using at most ten samples per search. We have released a
reference implementation of Condensa at https://github.com/NVlabs/condensa.","['Vinu Joseph', 'Saurav Muralidharan', 'Animesh Garg', 'Michael Garland', 'Ganesh Gopalakrishnan']","['cs.LG', 'cs.CV', 'stat.ML']",2019-11-06 17:14:32+00:00
http://arxiv.org/abs/1911.02490v2,OpenML-Python: an extensible Python API for OpenML,"OpenML is an online platform for open science collaboration in machine
learning, used to share datasets and results of machine learning experiments.
In this paper we introduce OpenML-Python, a client API for Python, opening up
the OpenML platform for a wide range of Python-based tools. It provides easy
access to all datasets, tasks and experiments on OpenML from within Python. It
also provides functionality to conduct machine learning experiments, upload the
results to OpenML, and reproduce results which are stored on OpenML.
Furthermore, it comes with a scikit-learn plugin and a plugin mechanism to
easily integrate other machine learning libraries written in Python into the
OpenML ecosystem. Source code and documentation is available at
https://github.com/openml/openml-python/.","['Matthias Feurer', 'Jan N. van Rijn', 'Arlind Kadra', 'Pieter Gijsbers', 'Neeratyoy Mallik', 'Sahithya Ravi', 'Andreas Müller', 'Joaquin Vanschoren', 'Frank Hutter']","['cs.LG', 'stat.ML']",2019-11-06 16:59:30+00:00
http://arxiv.org/abs/1911.03959v4,Multi-Armed Bandits with Correlated Arms,"We consider a multi-armed bandit framework where the rewards obtained by
pulling different arms are correlated. We develop a unified approach to
leverage these reward correlations and present fundamental generalizations of
classic bandit algorithms to the correlated setting. We present a unified proof
technique to analyze the proposed algorithms. Rigorous analysis of C-UCB (the
correlated bandit version of Upper-confidence-bound) reveals that the algorithm
ends up pulling certain sub-optimal arms, termed as non-competitive, only O(1)
times, as opposed to the O(log T) pulls required by classic bandit algorithms
such as UCB, TS etc. We present regret-lower bound and show that when arms are
correlated through a latent random source, our algorithms obtain order-optimal
regret. We validate the proposed algorithms via experiments on the MovieLens
and Goodreads datasets, and show significant improvement over classical bandit
algorithms.","['Samarth Gupta', 'Shreyas Chaudhari', 'Gauri Joshi', 'Osman Yağan']","['stat.ML', 'cs.LG']",2019-11-06 16:56:46+00:00
http://arxiv.org/abs/1911.02471v1,Designing Evaluations of Machine Learning Models for Subjective Inference: The Case of Sentence Toxicity,"Machine Learning (ML) is increasingly applied in real-life scenarios, raising
concerns about bias in automatic decision making. We focus on bias as a notion
of opinion exclusion, that stems from the direct application of traditional ML
pipelines to infer subjective properties. We argue that such ML systems should
be evaluated with subjectivity and bias in mind. Considering the lack of
evaluation standards yet to create evaluation benchmarks, we propose an initial
list of specifications to define prior to creating evaluation datasets, in
order to later accurately evaluate the biases. With the example of a sentence
toxicity inference system, we illustrate how the specifications support the
analysis of biases related to subjectivity. We highlight difficulties in
instantiating these specifications and list future work for the crowdsourcing
community to help the creation of appropriate evaluation datasets.","['Agathe Balayn', 'Alessandro Bozzon']","['cs.LG', 'cs.CL', 'stat.ML']",2019-11-06 16:38:19+00:00
http://arxiv.org/abs/1911.02469v1,Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse,"Posterior collapse in Variational Autoencoders (VAEs) arises when the
variational posterior distribution closely matches the prior for a subset of
latent variables. This paper presents a simple and intuitive explanation for
posterior collapse through the analysis of linear VAEs and their direct
correspondence with Probabilistic PCA (pPCA). We explain how posterior collapse
may occur in pPCA due to local maxima in the log marginal likelihood.
Unexpectedly, we prove that the ELBO objective for the linear VAE does not
introduce additional spurious local maxima relative to log marginal likelihood.
We show further that training a linear VAE with exact variational inference
recovers an identifiable global maximum corresponding to the principal
component directions. Empirically, we find that our linear analysis is
predictive even for high-capacity, non-linear VAEs and helps explain the
relationship between the observation noise, local maxima, and posterior
collapse in deep Gaussian VAEs.","['James Lucas', 'George Tucker', 'Roger Grosse', 'Mohammad Norouzi']","['cs.LG', 'stat.ML']",2019-11-06 16:34:04+00:00
http://arxiv.org/abs/1911.02457v5,High-dimensional Black-box Optimization Under Uncertainty,"Optimizing expensive black-box systems with limited data is an extremely
challenging problem. As a resolution, we present a new surrogate optimization
approach by addressing two gaps in prior research -- unimportant input
variables and inefficient treatment of uncertainty associated with the
black-box output. We first design a new flexible non-interpolating parsimonious
surrogate model using a partitioning-based multivariate adaptive regression
splines approach, Tree Knot MARS (TK-MARS). The proposed model is specifically
designed for optimization by capturing the structure of the function, bending
at near-optimal locations, and is capable of screening unimportant input
variables. Furthermore, we develop a novel replication approach called
\emph{Smart-Replication}, to overcome the uncertainty associated with the
black-box output. The Smart-Replication approach identifies promising input
points to replicate and avoids unnecessary evaluations of other data points.
Smart-Replication is agnostic to the choice of a surrogate and can adapt itself
to an unknown noise level. Finally to demonstrate the effectiveness of our
proposed approaches we consider different complex global optimization test
functions from the surrogate optimization literature. The results indicate that
TK-MARS outperforms original MARS within a surrogate optimization algorithm and
successfully detects important variables. The results also show that although
non-interpolating surrogates can mitigate uncertainty, replication is still
beneficial for optimizing highly complex black-box functions. The robustness
and the quality of the final optimum solution found through Smart-Replication
are competitive with that using no replications in environments with low levels
of noise and using a fixed number of replications in highly noisy environments.","['Hadis Anahideh', 'Jay Rosenberger', 'Victoria Chen']","['math.OC', 'stat.ME', 'stat.ML']",2019-11-06 16:13:36+00:00
http://arxiv.org/abs/1911.02455v1,Unfairness towards subjective opinions in Machine Learning,"Despite the high interest for Machine Learning (ML) in academia and industry,
many issues related to the application of ML to real-life problems are yet to
be addressed. Here we put forward one limitation which arises from a lack of
adaptation of ML models and datasets to specific applications. We formalise a
new notion of unfairness as exclusion of opinions. We propose ways to quantify
this unfairness, and aid understanding its causes through visualisation. These
insights into the functioning of ML-based systems hint at methods to mitigate
unfairness.","['Agathe Balayn', 'Alessandro Bozzon', 'Zoltan Szlavik']","['cs.LG', 'cs.CY', 'cs.HC', 'stat.ML']",2019-11-06 16:11:41+00:00
http://arxiv.org/abs/1911.05495v4,Correlated Feature Selection for Tweet Spam Classification,"The identification of spam messages on social networks is a very challenging
task. Social media sites like Twitter \& Facebook attracts a lot of users and
companies to advertise and attract users of personal gains. These
advertisements most of the time leads to spamming, which in return leads to
poor user experience. The purpose of this paper is to undertake the analysis of
spamming on Twitter. To classify spams efficiently, it is necessary to first
understand the features of the spam tweets as well as identify attributes of
the spammer. We extract both tweet based features and user-based features for
our analysis and observe the correlation between these features. This step is
necessary as we can reduce the training time if we combine the highly
correlated features. Our proposed approach uses a classification model based on
artificial neural networks to classify the tweets as spam or non-spam giving
the highest accuracy of 97.57\% when compared with four other standard
classifiers namely, SVM, K Nearest Neighbours, Naive Bayes, and Random Forest.",['Prakamya Mishra'],"['cs.SI', 'cs.LG', 'stat.ML']",2019-11-06 15:16:35+00:00
http://arxiv.org/abs/1911.02417v2,Energy Efficient Federated Learning Over Wireless Communication Networks,"In this paper, the problem of energy efficient transmission and computation
resource allocation for federated learning (FL) over wireless communication
networks is investigated. In the considered model, each user exploits limited
local computational resources to train a local FL model with its collected data
and, then, sends the trained FL model to a base station (BS) which aggregates
the local FL model and broadcasts it back to all of the users. Since FL
involves an exchange of a learning model between users and the BS, both
computation and communication latencies are determined by the learning accuracy
level. Meanwhile, due to the limited energy budget of the wireless users, both
local computation energy and transmission energy must be considered during the
FL process. This joint learning and communication problem is formulated as an
optimization problem whose goal is to minimize the total energy consumption of
the system under a latency constraint. To solve this problem, an iterative
algorithm is proposed where, at every step, closed-form solutions for time
allocation, bandwidth allocation, power control, computation frequency, and
learning accuracy are derived. Since the iterative algorithm requires an
initial feasible solution, we construct the completion time minimization
problem and a bisection-based algorithm is proposed to obtain the optimal
solution, which is a feasible solution to the original energy minimization
problem. Numerical results show that the proposed algorithms can reduce up to
59.5% energy consumption compared to the conventional FL method.","['Zhaohui Yang', 'Mingzhe Chen', 'Walid Saad', 'Choong Seon Hong', 'Mohammad Shikh-Bahaei']","['cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2019-11-06 14:51:49+00:00
http://arxiv.org/abs/1911.02377v5,Searching to Exploit Memorization Effect in Learning from Corrupted Labels,"Sample selection approaches are popular in robust learning from noisy labels.
However, how to properly control the selection process so that deep networks
can benefit from the memorization effect is a hard problem. In this paper,
motivated by the success of automated machine learning (AutoML), we model this
issue as a function approximation problem. Specifically, we design a
domain-specific search space based on general patterns of the memorization
effect and propose a novel Newton algorithm to solve the bi-level optimization
problem efficiently. We further provide theoretical analysis of the algorithm,
which ensures a good approximation to critical points. Experiments are
performed on benchmark data sets. Results demonstrate that the proposed method
is much better than the state-of-the-art noisy-label-learning approaches, and
also much more efficient than existing AutoML algorithms.","['Quanming Yao', 'Hansi Yang', 'Bo Han', 'Gang Niu', 'James Kwok']","['cs.LG', 'stat.ML']",2019-11-06 13:36:04+00:00
http://arxiv.org/abs/1911.03522v1,Deep Sequential Models for Suicidal Ideation from Multiple Source Data,"This article presents a novel method for predicting suicidal ideation from
Electronic Health Records (EHR) and Ecological Momentary Assessment (EMA) data
using deep sequential models. Both EHR longitudinal data and EMA question forms
are defined by asynchronous, variable length, randomly-sampled data sequences.
In our method, we model each of them with a Recurrent Neural Network (RNN), and
both sequences are aligned by concatenating the hidden state of each of them
using temporal marks. Furthermore, we incorporate attention schemes to improve
performance in long sequences and time-independent pre-trained schemes to cope
with very short sequences. Using a database of 1023 patients, our experimental
results show that the addition of EMA records boosts the system recall to
predict the suicidal ideation diagnosis from 48.13% obtained exclusively from
EHR-based state-of-the-art methods to 67.78%. Additionally, our method provides
interpretability through the t-SNE representation of the latent space. Further,
the most relevant input features are identified and interpreted medically.","['Ignacio Peis', 'Pablo M. Olmos', 'Constanza Vera-Varela', 'María Luisa Barrigón', 'Philippe Courtet', 'Enrique Baca-García', 'Antonio Artés-Rodríguez']","['cs.LG', 'stat.ML']",2019-11-06 12:55:28+00:00
http://arxiv.org/abs/1911.02347v1,Convolutional Neural Network for Multipath Detection in GNSS Receivers,"Global Navigation Satellite System (GNSS) signals are subject to different
kinds of events causing significant errors in positioning. This work explores
the application of Machine Learning (ML) methods of anomaly detection applied
to GNSS receiver signals. More specifically, our study focuses on multipath
contamination, using samples of the correlator output signal. The GPS L1 C/A
signal data is used and sourced directly from the correlator output. To extract
the important features and patterns from such data, we use deep convolutional
neural networks (CNN), which have proven to be efficient in image analysis in
particular. To take advantage of CNN, the correlator output signal is mapped as
a 2D input image and fed to the convolutional layers of a neural network. The
network automatically extracts the relevant features from the input samples and
proceeds with the multipath detection. We train the CNN using synthetic
signals. To optimize the model architecture with respect to the GNSS correlator
complexity, the evaluation of the CNN performance is done as a function of the
number of correlator output points.","['Evgenii Munin', 'Antoine Blais', 'Nicolas Couellan']","['eess.SP', 'stat.ML']",2019-11-06 12:55:02+00:00
http://arxiv.org/abs/1911.07936v4,Privacy Preserving Gaze Estimation using Synthetic Images via a Randomized Encoding Based Framework,"Eye tracking is handled as one of the key technologies for applications that
assess and evaluate human attention, behavior, and biometrics, especially using
gaze, pupillary, and blink behaviors. One of the challenges with regard to the
social acceptance of eye tracking technology is however the preserving of
sensitive and personal information. To tackle this challenge, we employ a
privacy-preserving framework based on randomized encoding to train a Support
Vector Regression model using synthetic eye images privately to estimate the
human gaze. During the computation, none of the parties learn about the data or
the result that any other party has. Furthermore, the party that trains the
model cannot reconstruct pupil, blinks or visual scanpath. The experimental
results show that our privacy-preserving framework is capable of working in
real-time, with the same accuracy as compared to non-private version and could
be extended to other eye tracking related problems.","['Efe Bozkir', 'Ali Burak Ünal', 'Mete Akgün', 'Enkelejda Kasneci', 'Nico Pfeifer']","['cs.CV', 'cs.CR', 'cs.HC', 'cs.LG', 'stat.ML']",2019-11-06 12:52:09+00:00
http://arxiv.org/abs/1911.04862v1,An End-to-end Approach for Lexical Stress Detection based on Transformer,"The dominant automatic lexical stress detection method is to split the
utterance into syllable segments using phoneme sequence and their time-aligned
boundaries. Then we extract features from syllable to use classification method
to classify the lexical stress. However, we can't get very accurate time
boundaries of each phoneme and we have to design some features in the syllable
segments to classify the lexical stress. Therefore, we propose a end-to-end
approach using sequence to sequence model of transformer to estimate lexical
stress. For this, we train transformer model using feature sequence of audio
and their phoneme sequence with lexical stress marks. During the recognition
process, the recognized phoneme sequence is restricted according to the
original standard phoneme sequence without lexical stress marks, but the
lexical stress mark of each phoneme is not limited. We train the model in
different subset of Librispeech and do lexical stress recognition in TIMIT and
L2-ARCTIC dataset. For all subsets, the end-to-end model will perform better
than the syllable segments classification method. Our method can achieve a
6.36% phoneme error rate on the TIMIT dataset, which exceeds the 7.2% error
rate in other studies.","['Yong Ruan', 'Xiangdong Wang', 'Hong Liu', 'Zhigang Ou', 'Yun Gao', 'Jianfeng Cheng', 'Yueliang Qian']","['eess.AS', 'cs.LG', 'cs.SD', 'stat.ML']",2019-11-06 11:29:37+00:00
http://arxiv.org/abs/1911.02319v6,Improving reinforcement learning algorithms: towards optimal learning rate policies,"This paper investigates to what extent one can improve reinforcement learning
algorithms. Our study is split in three parts. First, our analysis shows that
the classical asymptotic convergence rate $O(1/\sqrt{N})$ is pessimistic and
can be replaced by $O((\log(N)/N)^{\beta})$ with $\frac{1}{2}\leq \beta \leq 1$
and $N$ the number of iterations. Second, we propose a dynamic optimal policy
for the choice of the learning rate $(\gamma_k)_{k\geq 0}$ used in stochastic
approximation (SA). We decompose our policy into two interacting levels: the
inner and the outer level. In the inner level, we present the
\nameref{Alg:v_4_s} algorithm (for ""PAst Sign Search"") which, based on a
predefined sequence $(\gamma^o_k)_{k\geq 0}$, constructs a new sequence
$(\gamma^i_k)_{k\geq 0}$ whose error decreases faster. In the outer level, we
propose an optimal methodology for the selection of the predefined sequence
$(\gamma^o_k)_{k\geq 0}$. Third, we show empirically that our selection
methodology of the learning rate outperforms significantly standard algorithms
used in reinforcement learning (RL) in the three following applications: the
estimation of a drift, the optimal placement of limit orders and the optimal
execution of large number of shares.","['Othmane Mounjid', 'Charles-Albert Lehalle']","['cs.LG', 'math.OC', 'stat.ML']",2019-11-06 11:17:53+00:00
http://arxiv.org/abs/1911.05466v2,Attentive Geo-Social Group Recommendation,"Social activities play an important role in people's daily life since they
interact. For recommendations based on social activities, it is vital to have
not only the activity information but also individuals' social relations.
Thanks to the geo-social networks and widespread use of location-aware mobile
devices, massive geo-social data is now readily available for exploitation by
the recommendation system. In this paper, a novel group recommendation method,
called attentive geo-social group recommendation, is proposed to recommend the
target user with both activity locations and a group of users that may join the
activities. We present an attention mechanism to model the influence of the
target user $u_T$ in candidate user groups that satisfy the social constraints.
It helps to retrieve the optimal user group and activity topic candidates, as
well as explains the group decision-making process. Once the user group and
topics are retrieved, a novel efficient spatial query algorithm SPA-DF is
employed to determine the activity location under the constraints of the given
user group and activity topic candidates. The proposed method is evaluated in
real-world datasets and the experimental results show that the proposed model
significantly outperforms baseline methods.","['Fei Yu', 'Feiyi Fan', 'Shouxu Jiang', 'Kaiping Zheng']","['cs.SI', 'cs.LG', 'stat.ML', '68U35', 'H.3.3']",2019-11-06 11:13:27+00:00
http://arxiv.org/abs/1911.02306v1,Linear Support Vector Regression with Linear Constraints,"This paper studies the addition of linear constraints to the Support Vector
Regression (SVR) when the kernel is linear. Adding those constraints into the
problem allows to add prior knowledge on the estimator obtained, such as
finding probability vector or monotone data. We propose a generalization of the
Sequential Minimal Optimization (SMO) algorithm for solving the optimization
problem with linear constraints and prove its convergence. Then, practical
performances of this estimator are shown on simulated and real datasets with
different settings: non negative regression, regression onto the simplex for
biomedical data and isotonic regression for weather forecast.","['Quentin Klopfenstein', 'Samuel Vaiter']","['math.OC', 'stat.ML']",2019-11-06 10:57:29+00:00
http://arxiv.org/abs/1911.02256v1,A Divergence Minimization Perspective on Imitation Learning Methods,"In many settings, it is desirable to learn decision-making and control
policies through learning or bootstrapping from expert demonstrations. The most
common approaches under this Imitation Learning (IL) framework are Behavioural
Cloning (BC), and Inverse Reinforcement Learning (IRL). Recent methods for IRL
have demonstrated the capacity to learn effective policies with access to a
very limited set of demonstrations, a scenario in which BC methods often fail.
Unfortunately, due to multiple factors of variation, directly comparing these
methods does not provide adequate intuition for understanding this difference
in performance. In this work, we present a unified probabilistic perspective on
IL algorithms based on divergence minimization. We present $f$-MAX, an
$f$-divergence generalization of AIRL [Fu et al., 2018], a state-of-the-art IRL
method. $f$-MAX enables us to relate prior IRL methods such as GAIL [Ho &
Ermon, 2016] and AIRL [Fu et al., 2018], and understand their algorithmic
properties. Through the lens of divergence minimization we tease apart the
differences between BC and successful IRL approaches, and empirically evaluate
these nuances on simulated high-dimensional continuous control domains. Our
findings conclusively identify that IRL's state-marginal matching objective
contributes most to its superior performance. Lastly, we apply our new
understanding of IL methods to the problem of state-marginal matching, where we
demonstrate that in simulated arm pushing environments we can teach agents a
diverse range of behaviours using simply hand-specified state distributions and
no reward functions or expert demonstrations. For datasets and reproducing
results please refer to
https://github.com/KamyarGh/rl_swiss/blob/master/reproducing/fmax_paper.md .","['Seyed Kamyar Seyed Ghasemipour', 'Richard Zemel', 'Shixiang Gu']","['cs.LG', 'stat.ML']",2019-11-06 08:50:50+00:00
http://arxiv.org/abs/1911.02254v2,Secure Federated Submodel Learning,"Federated learning was proposed with an intriguing vision of achieving
collaborative machine learning among numerous clients without uploading their
private data to a cloud server. However, the conventional framework requires
each client to leverage the full model for learning, which can be prohibitively
inefficient for resource-constrained clients and large-scale deep learning
tasks. We thus propose a new framework, called federated submodel learning,
where clients download only the needed parts of the full model, namely
submodels, and then upload the submodel updates. Nevertheless, the ""position""
of a client's truly required submodel corresponds to her private data, and its
disclosure to the cloud server during interactions inevitably breaks the tenet
of federated learning. To integrate efficiency and privacy, we have designed a
secure federated submodel learning scheme coupled with a private set union
protocol as a cornerstone. Our secure scheme features the properties of
randomized response, secure aggregation, and Bloom filter, and endows each
client with a customized plausible deniability, in terms of local differential
privacy, against the position of her desired submodel, thus protecting her
private data. We further instantiated our scheme with the e-commerce
recommendation scenario in Alibaba, implemented a prototype system, and
extensively evaluated its performance over 30-day Taobao user data. The
analysis and evaluation results demonstrate the feasibility and scalability of
our scheme from model accuracy and convergency, practical communication,
computation, and storage overheads, as well as manifest its remarkable
advantages over the conventional federated learning framework.","['Chaoyue Niu', 'Fan Wu', 'Shaojie Tang', 'Lifeng Hua', 'Rongfei Jia', 'Chengfei Lv', 'Zhihua Wu', 'Guihai Chen']","['cs.LG', 'cs.CR', 'cs.DC', 'stat.ML']",2019-11-06 08:49:23+00:00
http://arxiv.org/abs/1911.02247v2,Unsupervised Opinion Summarization as Copycat-Review Generation,"Opinion summarization is the task of automatically creating summaries that
reflect subjective information expressed in multiple documents, such as product
reviews. While the majority of previous work has focused on the extractive
setting, i.e., selecting fragments from input reviews to produce a summary, we
let the model generate novel sentences and hence produce abstractive summaries.
Recent progress in summarization has seen the development of supervised models
which rely on large quantities of document-summary pairs. Since such training
data is expensive to acquire, we instead consider the unsupervised setting, in
other words, we do not use any summaries in training. We define a generative
model for a review collection which capitalizes on the intuition that when
generating a new review given a set of other reviews of a product, we should be
able to control the ""amount of novelty"" going into the new review or,
equivalently, vary the extent to which it deviates from the input. At test
time, when generating summaries, we force the novelty to be minimal, and
produce a text reflecting consensus opinions. We capture this intuition by
defining a hierarchical variational autoencoder model. Both individual reviews
and the products they correspond to are associated with stochastic latent
codes, and the review generator (""decoder"") has direct access to the text of
input reviews through the pointer-generator mechanism. Experiments on Amazon
and Yelp datasets, show that setting at test time the review's latent code to
its mean, allows the model to produce fluent and coherent summaries reflecting
common opinions.","['Arthur Bražinskas', 'Mirella Lapata', 'Ivan Titov']","['cs.CL', 'cs.IR', 'cs.LG', 'stat.ML']",2019-11-06 08:20:13+00:00
http://arxiv.org/abs/1911.06455v2,Graph Transformer Networks,"Graph neural networks (GNNs) have been widely used in representation learning
on graphs and achieved state-of-the-art performance in tasks such as node
classification and link prediction. However, most existing GNNs are designed to
learn node representations on the fixed and homogeneous graphs. The limitations
especially become problematic when learning representations on a misspecified
graph or a heterogeneous graph that consists of various types of nodes and
edges. In this paper, we propose Graph Transformer Networks (GTNs) that are
capable of generating new graph structures, which involve identifying useful
connections between unconnected nodes on the original graph, while learning
effective node representation on the new graphs in an end-to-end fashion. Graph
Transformer layer, a core layer of GTNs, learns a soft selection of edge types
and composite relations for generating useful multi-hop connections so-called
meta-paths. Our experiments show that GTNs learn new graph structures, based on
data and tasks without domain knowledge, and yield powerful node representation
via convolution on the new graphs. Without domain-specific graph preprocessing,
GTNs achieved the best performance in all three benchmark node classification
tasks against the state-of-the-art methods that require pre-defined meta-paths
from domain knowledge.","['Seongjun Yun', 'Minbyul Jeong', 'Raehyun Kim', 'Jaewoo Kang', 'Hyunwoo J. Kim']","['cs.LG', 'cs.SI', 'stat.ML']",2019-11-06 06:40:05+00:00
http://arxiv.org/abs/1911.02212v3,The gradient complexity of linear regression,"We investigate the computational complexity of several basic linear algebra
primitives, including largest eigenvector computation and linear regression, in
the computational model that allows access to the data via a matrix-vector
product oracle. We show that for polynomial accuracy, $\Theta(d)$ calls to the
oracle are necessary and sufficient even for a randomized algorithm.
  Our lower bound is based on a reduction to estimating the least eigenvalue of
a random Wishart matrix. This simple distribution enables a concise proof,
leveraging a few key properties of the random Wishart ensemble.","['Mark Braverman', 'Elad Hazan', 'Max Simchowitz', 'Blake Woodworth']","['cs.LG', 'cs.DS', 'math.OC', 'stat.ML']",2019-11-06 05:45:05+00:00
http://arxiv.org/abs/1911.02210v2,Machine Learning using the Variational Predictive Information Bottleneck with a Validation Set,"Zellner (1988) modeled statistical inference in terms of information
processing and postulated the Information Conservation Principle (ICP) between
the input and output of the information processing block, showing that this
yielded Bayesian inference as the optimum information processing rule.
Recently, Alemi (2019) reviewed Zellner's work in the context of machine
learning and showed that the ICP could be seen as a special case of a more
general optimum information processing criterion, namely the Predictive
Information Bottleneck Objective. However, Alemi modeled the model training
step in machine learning as using training and test data sets only, and did not
account for the use of a validation data set during training. The present note
is an attempt to extend Alemi's information processing formulation of machine
learning, and the predictive information bottleneck objective for model
training, to the widely-used scenario where training utilizes not only a
training but also a validation data set.",['Sayandev Mukherjee'],"['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",2019-11-06 05:31:59+00:00
http://arxiv.org/abs/1911.02182v2,Finding Strength in Weakness: Learning to Separate Sounds with Weak Supervision,"While there has been much recent progress using deep learning techniques to
separate speech and music audio signals, these systems typically require large
collections of isolated sources during the training process. When extending
audio source separation algorithms to more general domains such as
environmental monitoring, it may not be possible to obtain isolated signals for
training. Here, we propose objective functions and network architectures that
enable training a source separation system with weak labels. In this scenario,
weak labels are defined in contrast with strong time-frequency (TF) labels such
as those obtained from isolated sources, and refer either to frame-level weak
labels where one only has access to the time periods when different sources are
active in an audio mixture, or to clip-level weak labels that only indicate the
presence or absence of sounds in an entire audio clip. We train a separator
that estimates a TF mask for each type of sound event, using a sound event
classifier as an assessor of the separator's performance to bridge the gap
between the TF-level separation and the ground truth weak labels only available
at the frame or clip level. Our objective function requires the classifier
applied to a separated source to assign high probability to the class
corresponding to that source and low probability to all other classes. The
objective function also enforces that the separated sources sum up to the
mixture. We benchmark the performance of our algorithm using synthetic mixtures
of overlapping events created from a database of sounds recorded in urban
environments. Compared to training a network using isolated sources, our model
achieves somewhat lower but still significant SI-SDR improvement, even in
scenarios with significant sound event overlap.","['Fatemeh Pishdadian', 'Gordon Wichern', 'Jonathan Le Roux']","['cs.SD', 'cs.LG', 'eess.AS', 'stat.ML']",2019-11-06 03:36:55+00:00
http://arxiv.org/abs/1911.02175v1,Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems,"This manuscript contributes a general and practical framework for casting a
Markov process model of a system at equilibrium as a structural causal model,
and carrying out counterfactual inference. Markov processes mathematically
describe the mechanisms in the system, and predict the system's equilibrium
behavior upon intervention, but do not support counterfactual inference. In
contrast, structural causal models support counterfactual inference, but do not
identify the mechanisms. This manuscript leverages the benefits of both
approaches. We define the structural causal models in terms of the parameters
and the equilibrium dynamics of the Markov process models, and counterfactual
inference flows from these settings. The proposed approach alleviates the
identifiability drawback of the structural causal models, in that the
counterfactual inference is consistent with the counterfactual trajectories
simulated from the Markov process model. We showcase the benefits of this
framework in case studies of complex biomolecular systems with nonlinear
dynamics. We illustrate that, in presence of Markov process model
misspecification, counterfactual inference leverages prior data, and therefore
estimates the outcome of an intervention more accurately than a direct
simulation.","['Robert Osazuwa Ness', 'Kaushal Paneri', 'Olga Vitek']","['stat.ML', 'cs.LG', 'q-bio.MN', 'stat.AP']",2019-11-06 03:01:45+00:00
http://arxiv.org/abs/1911.02171v4,Minimax Nonparametric Two-sample Test under Smoothing,"We consider the problem of comparing probability densities between two
groups. A new probabilistic tensor product smoothing spline framework is
developed to model the joint density of two variables. Under such a framework,
the probability density comparison is equivalent to testing the
presence/absence of interactions. We propose a penalized likelihood ratio test
for such interaction testing and show that the test statistic is asymptotically
chi-square distributed under the null hypothesis. Furthermore, we derive a
sharp minimax testing rate based on the Bernstein width for nonparametric
two-sample tests and show that our proposed test statistics is minimax optimal.
In addition, a data-adaptive tuning criterion is developed to choose the
penalty parameter. Simulations and real applications demonstrate that the
proposed test outperforms the conventional approaches under various scenarios.","['Xin Xing', 'Zuofeng Shang', 'Pang Du', 'Ping Ma', 'Wenxuan Zhong', 'Jun S. Liu']","['stat.ME', 'math.ST', 'stat.AP', 'stat.ML', 'stat.TH']",2019-11-06 02:40:35+00:00
http://arxiv.org/abs/1911.02161v2,Exact Partitioning of High-order Models with a Novel Convex Tensor Cone Relaxation,"In this paper we propose an algorithm for exact partitioning of high-order
models. We define a general class of $m$-degree Homogeneous Polynomial Models,
which subsumes several examples motivated from prior literature. Exact
partitioning can be formulated as a tensor optimization problem. We relax this
high-order combinatorial problem to a convex conic form problem. To this end,
we carefully define the Carath\'eodory symmetric tensor cone, and show its
convexity, and the convexity of its dual cone. This allows us to construct a
primal-dual certificate to show that the solution of the convex relaxation is
correct (equal to the unobserved true group assignment) and to analyze the
statistical upper bound of exact partitioning.","['Chuyang Ke', 'Jean Honorio']","['cs.LG', 'stat.ML']",2019-11-06 01:52:05+00:00
http://arxiv.org/abs/1911.02156v2,Safe Linear Thompson Sampling with Side Information,"The design and performance analysis of bandit algorithms in the presence of
stage-wise safety or reliability constraints has recently garnered significant
interest. In this work, we consider the linear stochastic bandit problem under
additional \textit{linear safety constraints} that need to be satisfied at each
round. We provide a new safe algorithm based on linear Thompson Sampling (TS)
for this problem and show a frequentist regret of order $\mathcal{O}
(d^{3/2}\log^{1/2}d \cdot T^{1/2}\log^{3/2}T)$, which remarkably matches the
results provided by (Abeille et al., 2017) for the standard linear TS algorithm
in the absence of safety constraints. We compare the performance of our
algorithm with UCB-based safe algorithms and highlight how the inherently
randomized nature of TS leads to a superior performance in expanding the set of
safe actions the algorithm has access to at each round.","['Ahmadreza Moradipari', 'Sanae Amani', 'Mahnoosh Alizadeh', 'Christos Thrampoulidis']","['cs.LG', 'stat.ML']",2019-11-06 00:59:20+00:00
http://arxiv.org/abs/1911.02155v1,Spatially regularized active diffusion learning for high-dimensional images,"An active learning algorithm for the classification of high-dimensional
images is proposed in which spatially-regularized nonlinear diffusion geometry
is used to characterize cluster cores. The proposed method samples from
estimated cluster cores in order to generate a small but potent set of training
labels which propagate to the remainder of the dataset via the underlying
diffusion process. By spatially regularizing the rich, high-dimensional
spectral information of the image to efficiently estimate the most significant
and influential points in the data, our approach avoids redundancy in the
training dataset. This allows it to produce high-accuracy labelings with a very
small number of training labels. The proposed algorithm admits an efficient
numerical implementation that scales essentially linearly in the number of data
points under a suitable data model and enjoys state-of-the-art performance on
real hyperspectral images.",['James M. Murphy'],"['cs.LG', 'cs.CV', 'stat.ME', 'stat.ML']",2019-11-06 00:58:24+00:00
http://arxiv.org/abs/1911.05663v1,A coupled autoencoder approach for multi-modal analysis of cell types,"Recent developments in high throughput profiling of individual neurons have
spurred data driven exploration of the idea that there exist natural groupings
of neurons referred to as cell types. The promise of this idea is that the
immense complexity of brain circuits can be reduced, and effectively studied by
means of interactions between cell types. While clustering of neuron
populations based on a particular data modality can be used to define cell
types, such definitions are often inconsistent across different
characterization modalities. We pose this issue of cross-modal alignment as an
optimization problem and develop an approach based on coupled training of
autoencoders as a framework for such analyses. We apply this framework to a
Patch-seq dataset consisting of transcriptomic and electrophysiological
profiles for the same set of neurons to study consistency of representations
across modalities, and evaluate cross-modal data prediction ability. We explore
the problem where only a subset of neurons is characterized with more than one
modality, and demonstrate that representations learned by coupled autoencoders
can be used to identify types sampled only by a single modality.","['Rohan Gala', 'Nathan Gouwens', 'Zizhen Yao', 'Agata Budzillo', 'Osnat Penn', 'Bosiljka Tasic', 'Gabe Murphy', 'Hongkui Zeng', 'Uygar Sümbül']","['q-bio.NC', 'cs.LG', 'stat.ML']",2019-11-06 00:58:02+00:00
http://arxiv.org/abs/1911.02151v3,Information-Theoretic Generalization Bounds for SGLD via Data-Dependent Estimates,"In this work, we improve upon the stepwise analysis of noisy iterative
learning algorithms initiated by Pensia, Jog, and Loh (2018) and recently
extended by Bu, Zou, and Veeravalli (2019). Our main contributions are
significantly improved mutual information bounds for Stochastic Gradient
Langevin Dynamics via data-dependent estimates. Our approach is based on the
variational characterization of mutual information and the use of
data-dependent priors that forecast the mini-batch gradient based on a subset
of the training samples. Our approach is broadly applicable within the
information-theoretic framework of Russo and Zou (2015) and Xu and Raginsky
(2017). Our bound can be tied to a measure of flatness of the empirical risk
surface. As compared with other bounds that depend on the squared norms of
gradients, empirical investigations show that the terms in our bounds are
orders of magnitude smaller.","['Jeffrey Negrea', 'Mahdi Haghifam', 'Gintare Karolina Dziugaite', 'Ashish Khisti', 'Daniel M. Roy']","['stat.ML', 'cs.IT', 'cs.LG', 'math.IT']",2019-11-06 00:28:33+00:00
http://arxiv.org/abs/1911.04240v1,Physics-guided Design and Learning of Neural Networks for Predicting Drag Force on Particle Suspensions in Moving Fluids,"Physics-based simulations are often used to model and understand complex
physical systems and processes in domains like fluid dynamics. Such
simulations, although used frequently, have many limitations which could arise
either due to the inability to accurately model a physical process owing to
incomplete knowledge about certain facets of the process or due to the
underlying process being too complex to accurately encode into a simulation
model. In such situations, it is often useful to rely on machine learning
methods to fill in the gap by learning a model of the complex physical process
directly from simulation data. However, as data generation through simulations
is costly, we need to develop models, being cognizant of data paucity issues.
In such scenarios it is often helpful if the rich physical knowledge of the
application domain is incorporated in the architectural design of machine
learning models. Further, we can also use information from physics-based
simulations to guide the learning process using aggregate supervision to
favorably constrain the learning process. In this paper, we propose PhyDNN, a
deep learning model using physics-guided structural priors and physics-guided
aggregate supervision for modeling the drag forces acting on each particle in a
Computational Fluid Dynamics-Discrete Element Method(CFD-DEM). We conduct
extensive experiments in the context of drag force prediction and showcase the
usefulness of including physics knowledge in our deep learning formulation both
in the design and through learning process. Our proposed PhyDNN model has been
compared to several state-of-the-art models and achieves a significant
performance improvement of 8.46% on average across all baseline models. The
source code has been made available and the dataset used is detailed in [1, 2].","['Nikhil Muralidhar', 'Jie Bu', 'Ze Cao', 'Long He', 'Naren Ramakrishnan', 'Danesh Tafti', 'Anuj Karpatne']","['cs.LG', 'physics.comp-ph', 'stat.ML', '68T99, 76T20']",2019-11-06 00:05:37+00:00
http://arxiv.org/abs/1911.02140v3,Fully Parameterized Quantile Function for Distributional Reinforcement Learning,"Distributional Reinforcement Learning (RL) differs from traditional RL in
that, rather than the expectation of total returns, it estimates distributions
and has achieved state-of-the-art performance on Atari Games. The key challenge
in practical distributional RL algorithms lies in how to parameterize estimated
distributions so as to better approximate the true continuous distribution.
Existing distributional RL algorithms parameterize either the probability side
or the return value side of the distribution function, leaving the other side
uniformly fixed as in C51, QR-DQN or randomly sampled as in IQN. In this paper,
we propose fully parameterized quantile function that parameterizes both the
quantile fraction axis (i.e., the x-axis) and the value axis (i.e., y-axis) for
distributional RL. Our algorithm contains a fraction proposal network that
generates a discrete set of quantile fractions and a quantile value network
that gives corresponding quantile values. The two networks are jointly trained
to find the best approximation of the true distribution. Experiments on 55
Atari Games show that our algorithm significantly outperforms existing
distributional RL algorithms and creates a new record for the Atari Learning
Environment for non-distributed agents.","['Derek Yang', 'Li Zhao', 'Zichuan Lin', 'Tao Qin', 'Jiang Bian', 'Tieyan Liu']","['cs.LG', 'cs.AI', 'stat.ML']",2019-11-05 23:38:57+00:00
http://arxiv.org/abs/1911.02121v2,GAN-enhanced Conditional Echocardiogram Generation,"Echocardiography (echo) is a common means of evaluating cardiac conditions.
Due to the label scarcity, semi-supervised paradigms in automated echo analysis
are getting traction. One of the most sought-after problems in echo is the
segmentation of cardiac structures (e.g. chambers). Accordingly, we propose an
echocardiogram generation approach using generative adversarial networks with a
conditional patch-based discriminator. In this work, we validate the
feasibility of GAN-enhanced echo generation with different conditions
(segmentation masks), namely, the left ventricle, ventricular myocardium, and
atrium. Results show that the proposed adversarial algorithm can generate
high-quality echo frames whose cardiac structures match the given segmentation
masks. This method is expected to facilitate the training of other machine
learning models in a semi-supervised fashion as suggested in similar
researches.","['Amir H. Abdi', 'Teresa Tsang', 'Purang Abolmaesumi']","['eess.IV', 'cs.LG', 'stat.ML']",2019-11-05 22:49:25+00:00
http://arxiv.org/abs/1911.02109v3,Deep least-squares methods: an unsupervised learning-based numerical method for solving elliptic PDEs,"This paper studies an unsupervised deep learning-based numerical approach for
solving partial differential equations (PDEs). The approach makes use of the
deep neural network to approximate solutions of PDEs through the compositional
construction and employs least-squares functionals as loss functions to
determine parameters of the deep neural network. There are various
least-squares functionals for a partial differential equation. This paper
focuses on the so-called first-order system least-squares (FOSLS) functional
studied in [3], which is based on a first-order system of scalar second-order
elliptic PDEs. Numerical results for second-order elliptic PDEs in one
dimension are presented.","['Zhiqiang Cai', 'Jingshuang Chen', 'Min Liu', 'Xinyu Liu']","['cs.LG', 'cs.NA', 'math.NA', 'physics.comp-ph', 'stat.ML', '35Q68']",2019-11-05 22:24:06+00:00
http://arxiv.org/abs/1911.02106v2,Designing over uncertain outcomes with stochastic sampling Bayesian optimization,"Optimization is becoming increasingly common in scientific and engineering
domains. Oftentimes, these problems involve various levels of stochasticity or
uncertainty in generating proposed solutions. Therefore, optimization in these
scenarios must consider this stochasticity to properly guide the design of
future experiments. Here, we adapt Bayesian optimization to handle uncertain
outcomes, proposing a new framework called stochastic sampling Bayesian
optimization (SSBO). We show that the bounds on expected regret for an upper
confidence bound search in SSBO resemble those of earlier Bayesian optimization
approaches, with added penalties due to the stochastic generation of inputs.
Additionally, we adapt existing batch optimization techniques to properly limit
the myopic decision making that can arise when selecting multiple instances
before feedback. Finally, we show that SSBO techniques properly optimize a set
of standard optimization problems as well as an applied problem inspired by
bioengineering.","['Peter D. Tonner', 'Daniel V. Samarov', 'A. Gilad Kusne']","['stat.ML', 'cs.LG']",2019-11-05 22:21:07+00:00
http://arxiv.org/abs/1911.02098v3,A Scalable Multilabel Classification to Deploy Deep Learning Architectures For Edge Devices,"Convolution Neural Networks (CNN) have performed well in many applications
such as object detection, pattern recognition, video surveillance and so on.
CNN carryout feature extraction on labelled data to perform classification.
Multi-label classification assigns more than one label to a particular data
sample in a data set. In multi-label classification, properties of a data point
that are considered to be mutually exclusive are classified. However, existing
multi-label classification requires some form of data pre-processing that
involves image training data cropping or image tiling. The computation and
memory requirement of these multi-label CNN models makes their deployment on
edge devices challenging. In this paper, we propose a methodology that solves
this problem by extending the capability of existing multi-label classification
and provide models with lower latency that requires smaller memory size when
deployed on edge devices. We make use of a single CNN model designed with
multiple loss layers and multiple accuracy layers. This methodology is tested
on state-of-the-art deep learning algorithms such as AlexNet, GoogleNet and
SqueezeNet using the Stanford Cars Dataset and deployed on Raspberry Pi3. From
the results the proposed methodology achieves comparable accuracy with 1.8x
less MACC operation, 0.97x reduction in latency and 0.5x, 0.84x and 0.97x
reduction in size for the generated AlexNet, GoogleNet and SqueezeNet CNN
models respectively when compared to conventional ways of achieving multi-label
classification like hard-coding multi-label instances into single labels. The
methodology also yields CNN models that achieve 50\% less MACC operations, 50%
reduction in latency and size of generated versions of AlexNet, GoogleNet and
SqueezeNet respectively when compared to conventional ways using 2 different
single-labelled models to achieve multi-label classification.","['Tolulope A. Odetola', 'Ogheneuriri Oderhohwo', 'Syed Rafay Hasan']","['cs.LG', 'stat.ML']",2019-11-05 21:45:36+00:00
http://arxiv.org/abs/1911.06182v1,MML: Maximal Multiverse Learning for Robust Fine-Tuning of Language Models,"Recent state-of-the-art language models utilize a two-phase training
procedure comprised of (i) unsupervised pre-training on unlabeled text, and
(ii) fine-tuning for a specific supervised task. More recently, many studies
have been focused on trying to improve these models by enhancing the
pre-training phase, either via better choice of hyperparameters or by
leveraging an improved formulation. However, the pre-training phase is
computationally expensive and often done on private datasets. In this work, we
present a method that leverages BERT's fine-tuning phase to its fullest, by
applying an extensive number of parallel classifier heads, which are enforced
to be orthogonal, while adaptively eliminating the weaker heads during
training. Our method allows the model to converge to an optimal number of
parallel classifiers, depending on the given dataset at hand.
  We conduct an extensive inter- and intra-dataset evaluations, showing that
our method improves the robustness of BERT, sometimes leading to a +9\% gain in
accuracy. These results highlight the importance of a proper fine-tuning
procedure, especially for relatively smaller-sized datasets. Our code is
attached as supplementary and our models will be made completely public.","['Itzik Malkiel', 'Lior Wolf']","['cs.CL', 'cs.LG', 'stat.ML']",2019-11-05 21:21:40+00:00
http://arxiv.org/abs/1911.02088v3,An Alternative Probabilistic Interpretation of the Huber Loss,"The Huber loss is a robust loss function used for a wide range of regression
tasks. To utilize the Huber loss, a parameter that controls the transitions
from a quadratic function to an absolute value function needs to be selected.
We believe the standard probabilistic interpretation that relates the Huber
loss to the Huber density fails to provide adequate intuition for identifying
the transition point. As a result, a hyper-parameter search is often necessary
to determine an appropriate value. In this work, we propose an alternative
probabilistic interpretation of the Huber loss, which relates minimizing the
loss to minimizing an upper-bound on the Kullback-Leibler divergence between
Laplace distributions, where one distribution represents the noise in the
ground-truth and the other represents the noise in the prediction. In addition,
we show that the parameters of the Laplace distributions are directly related
to the transition point of the Huber loss. We demonstrate, through a toy
problem, that the optimal transition point of the Huber loss is closely related
to the distribution of the noise in the ground-truth data. As a result, our
interpretation provides an intuitive way to identify well-suited
hyper-parameters by approximating the amount of noise in the data, which we
demonstrate through a case study and experimentation on the Faster R-CNN and
RetinaNet object detectors.",['Gregory P. Meyer'],"['stat.ML', 'cs.CV', 'cs.LG']",2019-11-05 21:15:19+00:00
http://arxiv.org/abs/1911.02079v1,Post-Training 4-bit Quantization on Embedding Tables,"Continuous representations have been widely adopted in recommender systems
where a large number of entities are represented using embedding vectors. As
the cardinality of the entities increases, the embedding components can easily
contain millions of parameters and become the bottleneck in both storage and
inference due to large memory consumption. This work focuses on post-training
4-bit quantization on the continuous embeddings. We propose row-wise uniform
quantization with greedy search and codebook-based quantization that
consistently outperforms state-of-the-art quantization approaches on reducing
accuracy degradation. We deploy our uniform quantization technique on a
production model in Facebook and demonstrate that it can reduce the model size
to only 13.89% of the single-precision version while the model quality stays
neutral.","['Hui Guan', 'Andrey Malevich', 'Jiyan Yang', 'Jongsoo Park', 'Hector Yuen']","['cs.LG', 'cs.IR', 'stat.ML']",2019-11-05 20:43:51+00:00
http://arxiv.org/abs/1911.02074v1,Computational Separations between Sampling and Optimization,"Two commonly arising computational tasks in Bayesian learning are
Optimization (Maximum A Posteriori estimation) and Sampling (from the posterior
distribution). In the convex case these two problems are efficiently reducible
to each other. Recent work (Ma et al. 2019) shows that in the non-convex case,
sampling can sometimes be provably faster. We present a simpler and stronger
separation. We then compare sampling and optimization in more detail and show
that they are provably incomparable: there are families of continuous functions
for which optimization is easy but sampling is NP-hard, and vice versa.
Further, we show function families that exhibit a sharp phase transition in the
computational complexity of sampling, as one varies the natural temperature
parameter. Our results draw on a connection to analogous separations in the
discrete setting which are well-studied.",['Kunal Talwar'],"['cs.LG', 'stat.ML']",2019-11-05 20:29:20+00:00
http://arxiv.org/abs/1911.02069v1,Hierarchical Mixtures of Generators for Adversarial Learning,"Generative adversarial networks (GANs) are deep neural networks that allow us
to sample from an arbitrary probability distribution without explicitly
estimating the distribution. There is a generator that takes a latent vector as
input and transforms it into a valid sample from the distribution. There is
also a discriminator that is trained to discriminate such fake samples from
true samples of the distribution; at the same time, the generator is trained to
generate fakes that the discriminator cannot tell apart from the true samples.
Instead of learning a global generator, a recent approach involves training
multiple generators each responsible from one part of the distribution. In this
work, we review such approaches and propose the hierarchical mixture of
generators, inspired from the hierarchical mixture of experts model, that
learns a tree structure implementing a hierarchical clustering with soft splits
in the decision nodes and local generators in the leaves. Since the generators
are combined softly, the whole model is continuous and can be trained using
gradient-based optimization, just like the original GAN model. Our experiments
on five image data sets, namely, MNIST, FashionMNIST, UTZap50K, Oxford Flowers,
and CelebA, show that our proposed model generates samples of high quality and
diversity in terms of popular GAN evaluation metrics. The learned hierarchical
structure also leads to knowledge extraction.","['Alper Ahmetoğlu', 'Ethem Alpaydın']","['cs.LG', 'stat.ML']",2019-11-05 20:13:31+00:00
http://arxiv.org/abs/1911.02067v2,Robo-advising: Learning Investors' Risk Preferences via Portfolio Choices,"We introduce a reinforcement learning framework for retail robo-advising. The
robo-advisor does not know the investor's risk preference, but learns it over
time by observing her portfolio choices in different market environments. We
develop an exploration-exploitation algorithm which trades off costly
solicitations of portfolio choices by the investor with autonomous trading
decisions based on stale estimates of investor's risk aversion. We show that
the algorithm's value function converges to the optimal value function of an
omniscient robo-advisor over a number of periods that is polynomial in the
state and action space. By correcting for the investor's mistakes, the
robo-advisor may outperform a stand-alone investor, regardless of the
investor's opportunity cost for making portfolio decisions.","['Humoud Alsabah', 'Agostino Capponi', 'Octavio Ruiz Lacedelli', 'Matt Stern']","['q-fin.PM', 'cs.LG', 'stat.ML', '68T01', 'I.2.6']",2019-11-05 20:08:43+00:00
http://arxiv.org/abs/1911.02053v2,Alleviating Label Switching with Optimal Transport,"Label switching is a phenomenon arising in mixture model posterior inference
that prevents one from meaningfully assessing posterior statistics using
standard Monte Carlo procedures. This issue arises due to invariance of the
posterior under actions of a group; for example, permuting the ordering of
mixture components has no effect on the likelihood. We propose a resolution to
label switching that leverages machinery from optimal transport. Our algorithm
efficiently computes posterior statistics in the quotient space of the symmetry
group. We give conditions under which there is a meaningful solution to label
switching and demonstrate advantages over alternative approaches on simulated
and real data.","['Pierre Monteiller', 'Sebastian Claici', 'Edward Chien', 'Farzaneh Mirzazadeh', 'Justin Solomon', 'Mikhail Yurochkin']","['cs.LG', 'stat.ML']",2019-11-05 19:40:27+00:00
http://arxiv.org/abs/1911.02052v1,A Method to Model Conditional Distributions with Normalizing Flows,"In this work, we investigate the use of normalizing flows to model
conditional distributions. In particular, we use our proposed method to analyze
inverse problems with invertible neural networks by maximizing the posterior
likelihood. Our method uses only a single loss and is easy to train. This is an
improvement on the previous method that solves similar inverse problems with
invertible neural networks but which involves a combination of several loss
terms with ad-hoc weighting. In addition, our method provides a natural
framework to incorporate conditioning in normalizing flows, and therefore, we
can train an invertible network to perform conditional generation. We analyze
our method and perform a careful comparison with previous approaches. Simple
experiments show the effectiveness of our method, and more comprehensive
experimental evaluations are undergoing.","['Zhisheng Xiao', 'Qing Yan', 'Yali Amit']","['cs.LG', 'cs.CV', 'stat.ML']",2019-11-05 19:37:37+00:00
http://arxiv.org/abs/1911.02048v1,Guided Layer-wise Learning for Deep Models using Side Information,"Training of deep models for classification tasks is hindered by local minima
problems and vanishing gradients, while unsupervised layer-wise pretraining
does not exploit information from class labels. Here, we propose a new
regularization technique, called diversifying regularization (DR), which
applies a penalty on hidden units at any layer if they obtain similar features
for different types of data. For generative models, DR is defined as divergence
over the variational posteriori distributions and included in the maximum
likelihood estimation as a prior. Thus, DR includes class label information for
greedy pretraining of deep belief networks which result in a better weight
initialization for fine-tuning methods. On the other hand, for discriminative
training of deep neural networks, DR is defined as a distance over the features
and included in the learning objective. With our experimental tests, we show
that DR can help the backpropagation to cope with vanishing gradient problems
and to provide faster convergence and smaller generalization errors.","['Pavel Sulimov', 'Elena Sukmanova', 'Roman Chereshnev', 'Attila Kertesz-Farkas']","['cs.LG', 'stat.ML']",2019-11-05 19:27:16+00:00
http://arxiv.org/abs/1911.02042v5,GRACE: Generating Concise and Informative Contrastive Sample to Explain Neural Network Model's Prediction,"Despite the recent development in the topic of explainable AI/ML for image
and text data, the majority of current solutions are not suitable to explain
the prediction of neural network models when the datasets are tabular and their
features are in high-dimensional vectorized formats. To mitigate this
limitation, therefore, we borrow two notable ideas (i.e., ""explanation by
intervention"" from causality and ""explanation are contrastive"" from philosophy)
and propose a novel solution, named as GRACE, that better explains neural
network models' predictions for tabular datasets. In particular, given a
model's prediction as label X, GRACE intervenes and generates a
minimally-modified contrastive sample to be classified as Y, with an intuitive
textual explanation, answering the question of ""Why X rather than Y?"" We carry
out comprehensive experiments using eleven public datasets of different scales
and domains (e.g., # of features ranges from 5 to 216) and compare GRACE with
competing baselines on different measures: fidelity, conciseness, info-gain,
and influence. The user-studies show that our generated explanation is not only
more intuitive and easy-to-understand but also facilitates end-users to make as
much as 60% more accurate post-explanation decisions than that of Lime.","['Thai Le', 'Suhang Wang', 'Dongwon Lee']","['cs.LG', 'cs.AI', 'stat.ML']",2019-11-05 19:06:29+00:00
http://arxiv.org/abs/1911.02035v1,Efficiently Learning Structured Distributions from Untrusted Batches,"We study the problem, introduced by Qiao and Valiant, of learning from
untrusted batches. Here, we assume $m$ users, all of whom have samples from
some underlying distribution $p$ over $1, \ldots, n$. Each user sends a batch
of $k$ i.i.d. samples from this distribution; however an $\epsilon$-fraction of
users are untrustworthy and can send adversarially chosen responses. The goal
is then to learn $p$ in total variation distance. When $k = 1$ this is the
standard robust univariate density estimation setting and it is well-understood
that $\Omega (\epsilon)$ error is unavoidable. Suprisingly, Qiao and Valiant
gave an estimator which improves upon this rate when $k$ is large.
Unfortunately, their algorithms run in time exponential in either $n$ or $k$.
  We first give a sequence of polynomial time algorithms whose estimation error
approaches the information-theoretically optimal bound for this problem. Our
approach is based on recent algorithms derived from the sum-of-squares
hierarchy, in the context of high-dimensional robust estimation. We show that
algorithms for learning from untrusted batches can also be cast in this
framework, but by working with a more complicated set of test functions.
  It turns out this abstraction is quite powerful and can be generalized to
incorporate additional problem specific constraints. Our second and main result
is to show that this technology can be leveraged to build in prior knowledge
about the shape of the distribution. Crucially, this allows us to reduce the
sample complexity of learning from untrusted batches to polylogarithmic in $n$
for most natural classes of distributions, which is important in many
applications. To do so, we demonstrate that these sum-of-squares algorithms for
robust mean estimation can be made to handle complex combinatorial constraints
(e.g. those arising from VC theory), which may be of independent technical
interest.","['Sitan Chen', 'Jerry Li', 'Ankur Moitra']","['cs.DS', 'cs.LG', 'stat.ML']",2019-11-05 19:01:46+00:00
http://arxiv.org/abs/1911.02029v6,Selective machine learning of doubly robust functionals,"While model selection is a well-studied topic in parametric and nonparametric
regression or density estimation, selection of possibly high-dimensional
nuisance parameters in semiparametric problems is far less developed. In this
paper, we propose a selective machine learning framework for making inferences
about a finite-dimensional functional defined on a semiparametric model, when
the latter admits a doubly robust estimating function and several candidate
machine learning algorithms are available for estimating the nuisance
parameters. We introduce a new selection criterion aimed at bias reduction in
estimating the functional of interest based on a novel definition of
pseudo-risk inspired by the double robustness property. Intuitively, the
proposed criterion selects a pair of learners with the smallest pseudo-risk, so
that the estimated functional is least sensitive to perturbations of a nuisance
parameter. We establish an oracle property for a multi-fold cross-validation
version of the new selection criterion which states that our empirical
criterion performs nearly as well as an oracle with a priori knowledge of the
pseudo-risk for each pair of candidate learners. Finally, we apply the approach
to model selection of a semiparametric estimator of average treatment effect
given an ensemble of candidate machine learners to account for confounding in
an observational study which we illustrate in simulations and a data
application.","['Yifan Cui', 'Eric Tchetgen Tchetgen']","['stat.ME', 'math.ST', 'stat.ML', 'stat.TH']",2019-11-05 19:00:03+00:00
http://arxiv.org/abs/1911.01944v1,Dynamic Time Warp Convolutional Networks,"Where dealing with temporal sequences it is fair to assume that the same kind
of deformations that motivated the development of the Dynamic Time Warp
algorithm could be relevant also in the calculation of the dot product
(""convolution"") in a 1-D convolution layer. In this work a method is proposed
for aligning the convolution filter and the input where they are locally out of
phase utilising an algorithm similar to the Dynamic Time Warp. The proposed
method enables embedding a non-parametric warping of temporal sequences for
increasing similarity directly in deep networks and can expand on the
generalisation capabilities and the capacity of standard 1-D convolution layer
where local sequential deformations are present in the input. Experimental
results demonstrate the proposed method exceeds or matches the standard 1-D
convolution layer in terms of the maximum accuracy achieved on a number of time
series classification tasks. In addition the impact of different
hyperparameters settings is investigated given different datasets and the
results support the conclusions of previous work done in relation to the choice
of DTW parameter values. The proposed layer can be freely integrated with other
typical layers to compose deep artificial neural networks of an arbitrary
architecture that are trained using standard stochastic gradient descent.",['Yaniv Shulman'],"['cs.LG', 'stat.ML']",2019-11-05 17:08:02+00:00
http://arxiv.org/abs/1911.02014v1,Scribble-based Hierarchical Weakly Supervised Learning for Brain Tumor Segmentation,"The recent state-of-the-art deep learning methods have significantly improved
brain tumor segmentation. However, fully supervised training requires a large
amount of manually labeled masks, which is highly time-consuming and needs
domain expertise. Weakly supervised learning with scribbles provides a good
trade-off between model accuracy and the effort of manual labeling. However,
for segmenting the hierarchical brain tumor structures, manually labeling
scribbles for each substructure could still be demanding. In this paper, we use
only two kinds of weak labels, i.e., scribbles on whole tumor and healthy brain
tissue, and global labels for the presence of each substructure, to train a
deep learning model to segment all the sub-regions. Specifically, we train two
networks in two phases: first, we only use whole tumor scribbles to train a
whole tumor (WT) segmentation network, which roughly recovers the WT mask of
training data; then we cluster the WT region with the guide of global labels.
The rough substructure segmentation from clustering is used as weak labels to
train the second network. The dense CRF loss is used to refine the weakly
supervised segmentation. We evaluate our approach on the BraTS2017 dataset and
achieve competitive WT dice score as well as comparable scores on substructure
segmentation compared to an upper bound when trained with fully annotated
masks.","['Zhanghexuan Ji', 'Yan Shen', 'Chunwei Ma', 'Mingchen Gao']","['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2019-11-05 16:56:35+00:00
http://arxiv.org/abs/1911.01933v1,Training Neural Machine Translation (NMT) Models using Tensor Train Decomposition on TensorFlow (T3F),"We implement a Tensor Train layer in the TensorFlow Neural Machine
Translation (NMT) model using the t3f library. We perform training runs on the
IWSLT English-Vietnamese '15 and WMT German-English '16 datasets with learning
rates $\in \{0.0004,0.0008,0.0012\}$, maximum ranks $\in \{2,4,8,16\}$ and a
range of core dimensions. We compare against a target BLEU test score of 24.0,
obtained by our benchmark run. For the IWSLT English-Vietnamese training, we
obtain BLEU test/dev scores of 24.0/21.9 and 24.2/21.9 using core dimensions
$(2, 2, 256) \times (2, 2, 512)$ with learning rate 0.0012 and rank
distributions $(1,4,4,1)$ and $(1,4,16,1)$ respectively. These runs use 113\%
and 397\% of the flops of the benchmark run respectively. We find that, of the
parameters surveyed, a higher learning rate and more `rectangular' core
dimensions generally produce higher BLEU scores. For the WMT German-English
dataset, we obtain BLEU scores of 24.0/23.8 using core dimensions $(4, 4, 128)
\times (4, 4, 256)$ with learning rate 0.0012 and rank distribution
$(1,2,2,1)$. We discuss the potential for future optimization and application
of Tensor Train decomposition to other NMT models.","['Amelia Drew', 'Alexander Heinecke']","['cs.LG', 'cs.CL', 'stat.ML']",2019-11-05 16:48:30+00:00
http://arxiv.org/abs/1911.01931v6,Online matrix factorization for Markovian data and applications to Network Dictionary Learning,"Online Matrix Factorization (OMF) is a fundamental tool for dictionary
learning problems, giving an approximate representation of complex data sets in
terms of a reduced number of extracted features. Convergence guarantees for
most of the OMF algorithms in the literature assume independence between data
matrices, and the case of dependent data streams remains largely unexplored. In
this paper, we show that a non-convex generalization of the well-known OMF
algorithm for i.i.d. stream of data in \citep{mairal2010online} converges
almost surely to the set of critical points of the expected loss function, even
when the data matrices are functions of some underlying Markov chain satisfying
a mild mixing condition. This allows one to extract features more efficiently
from dependent data streams, as there is no need to subsample the data sequence
to approximately satisfy the independence assumption. As the main application,
by combining online non-negative matrix factorization and a recent MCMC
algorithm for sampling motifs from networks, we propose a novel framework of
Network Dictionary Learning, which extracts ``network dictionary patches' from
a given network in an online manner that encodes main features of the network.
We demonstrate this technique and its application to network denoising problems
on real-world network data.","['Hanbaek Lyu', 'Deanna Needell', 'Laura Balzano']","['cs.LG', 'cs.DS', 'math.OC', 'math.PR', 'stat.ML']",2019-11-05 16:47:28+00:00
http://arxiv.org/abs/1911.01929v2,GP-ALPS: Automatic Latent Process Selection for Multi-Output Gaussian Process Models,"A simple and widely adopted approach to extend Gaussian processes (GPs) to
multiple outputs is to model each output as a linear combination of a
collection of shared, unobserved latent GPs. An issue with this approach is
choosing the number of latent processes and their kernels. These choices are
typically done manually, which can be time consuming and prone to human biases.
We propose Gaussian Process Automatic Latent Process Selection (GP-ALPS), which
automatically chooses the latent processes by turning off those that do not
meaningfully contribute to explaining the data. We develop a variational
inference scheme, assess the quality of the variational posterior by comparing
it against the gold standard MCMC, and demonstrate the suitability of GP-ALPS
in a set of preliminary experiments.","['Pavel Berkovich', 'Eric Perim', 'Wessel Bruinsma']","['stat.ML', 'cs.LG', 'stat.ME']",2019-11-05 16:46:37+00:00
http://arxiv.org/abs/1911.01919v1,Neural Network Based Parameter Estimation Method for the Pareto/NBD Model,"Whether stochastic or parametric, the Pareto/NBD model can only be utilized
for an in-sample prediction rather than an out-of-sample prediction. This
research thus provides a neural network based extension of the Pareto/NBD model
to estimate the out-of-sample parameters, which overrides the estimation burden
and the application dilemma of the Pareto/NBD approach. The empirical results
indicate that the Pareto/NBD model and neural network algorithms have similar
predictability for identifying inactive customers. Even with a strong trend
fitting on the customer count of each repeat purchase point, the Pareto/NBD
model underestimates repeat purchases at both the individual and aggregate
levels. Nonetheless, when embedding the likelihood function of the Pareto/NBD
model into the loss function, the proposed parameter estimation method shows
extraordinary predictability on repeat purchases at these two levels.
Furthermore, the proposed neural network based method is highly efficient and
resource-friendly and can be deployed in cloud computing to handle with big
data analysis.",['Shao-Ming Xie'],"['stat.AP', 'stat.ML']",2019-11-05 16:27:41+00:00
http://arxiv.org/abs/1911.01916v4,Practical Compositional Fairness: Understanding Fairness in Multi-Component Recommender Systems,"How can we build recommender systems to take into account fairness?
Real-world recommender systems are often composed of multiple models, built by
multiple teams. However, most research on fairness focuses on improving
fairness in a single model. Further, recent research on classification fairness
has shown that combining multiple ""fair"" classifiers can still result in an
""unfair"" classification system. This presents a significant challenge: how do
we understand and improve fairness in recommender systems composed of multiple
components?
  In this paper, we study the compositionality of recommender fairness. We
consider two recently proposed fairness ranking metrics: equality of exposure
and pairwise ranking accuracy. While we show that fairness in recommendation is
not guaranteed to compose, we provide theory for a set of conditions under
which fairness of individual models does compose. We then present an analytical
framework for both understanding whether a real system's signals can achieve
compositional fairness, and improving which component would have the greatest
impact on the fairness of the overall system. In addition to the theoretical
results, we find on multiple datasets -- including a large-scale real-world
recommender system -- that the overall system's end-to-end fairness is largely
achievable by improving fairness in individual components.","['Xuezhi Wang', 'Nithum Thain', 'Anu Sinha', 'Flavien Prost', 'Ed H. Chi', 'Jilin Chen', 'Alex Beutel']","['cs.LG', 'stat.ML']",2019-11-05 16:22:25+00:00
http://arxiv.org/abs/1911.01915v1,Scalable Variational Gaussian Processes for Crowdsourcing: Glitch Detection in LIGO,"In the last years, crowdsourcing is transforming the way classification
training sets are obtained. Instead of relying on a single expert annotator,
crowdsourcing shares the labelling effort among a large number of
collaborators. For instance, this is being applied to the data acquired by the
laureate Laser Interferometer Gravitational Waves Observatory (LIGO), in order
to detect glitches which might hinder the identification of true
gravitational-waves. The crowdsourcing scenario poses new challenging
difficulties, as it deals with different opinions from a heterogeneous group of
annotators with unknown degrees of expertise. Probabilistic methods, such as
Gaussian Processes (GP), have proven successful in modeling this setting.
However, GPs do not scale well to large data sets, which hampers their broad
adoption in real practice (in particular at LIGO). This has led to the recent
introduction of deep learning based crowdsourcing methods, which have become
the state-of-the-art. However, the accurate uncertainty quantification of GPs
has been partially sacrificed. This is an important aspect for astrophysicists
in LIGO, since a glitch detection system should provide very accurate
probability distributions of its predictions. In this work, we leverage the
most popular sparse GP approximation to develop a novel GP based crowdsourcing
method that factorizes into mini-batches. This makes it able to cope with
previously-prohibitive data sets. The approach, which we refer to as Scalable
Variational Gaussian Processes for Crowdsourcing (SVGPCR), brings back GP-based
methods to the state-of-the-art, and excels at uncertainty quantification.
SVGPCR is shown to outperform deep learning based methods and previous
probabilistic approaches when applied to the LIGO data. Moreover, its behavior
and main properties are carefully analyzed in a controlled experiment based on
the MNIST data set.","['Pablo Morales-Álvarez', 'Pablo Ruiz', 'Scott Coughlin', 'Rafael Molina', 'Aggelos K. Katsaggelos']","['cs.LG', 'cs.CV', 'gr-qc', 'stat.ML']",2019-11-05 16:20:38+00:00
http://arxiv.org/abs/1911.01914v1,A Comparative Analysis of XGBoost,"XGBoost is a scalable ensemble technique based on gradient boosting that has
demonstrated to be a reliable and efficient machine learning challenge solver.
This work proposes a practical analysis of how this novel technique works in
terms of training speed, generalization performance and parameter setup. In
addition, a comprehensive comparison between XGBoost, random forests and
gradient boosting has been performed using carefully tuned models as well as
using the default settings. The results of this comparison may indicate that
XGBoost is not necessarily the best choice under all circumstances. Finally an
extensive analysis of XGBoost parametrization tuning process is carried out.","['Candice Bentéjac', 'Anna Csörgő', 'Gonzalo Martínez-Muñoz']","['cs.LG', 'stat.ML']",2019-11-05 16:18:29+00:00
http://arxiv.org/abs/1911.01894v1,"A Rule for Gradient Estimator Selection, with an Application to Variational Inference","Stochastic gradient descent (SGD) is the workhorse of modern machine
learning. Sometimes, there are many different potential gradient estimators
that can be used. When so, choosing the one with the best tradeoff between cost
and variance is important. This paper analyzes the convergence rates of SGD as
a function of time, rather than iterations. This results in a simple rule to
select the estimator that leads to the best optimization convergence guarantee.
This choice is the same for different variants of SGD, and with different
assumptions about the objective (e.g. convexity or smoothness). Inspired by
this principle, we propose a technique to automatically select an estimator
when a finite pool of estimators is given. Then, we extend to infinite pools of
estimators, where each one is indexed by control variate weights. This is
enabled by a reduction to a mixed-integer quadratic program. Empirically,
automatically choosing an estimator performs comparably to the best estimator
chosen with hindsight.","['Tomas Geffner', 'Justin Domke']","['cs.LG', 'stat.ML', '68T99']",2019-11-05 15:57:19+00:00
http://arxiv.org/abs/1911.01877v1,Out of distribution detection for intra-operative functional imaging,"Multispectral optical imaging is becoming a key tool in the operating room.
Recent research has shown that machine learning algorithms can be used to
convert pixel-wise reflectance measurements to tissue parameters, such as
oxygenation. However, the accuracy of these algorithms can only be guaranteed
if the spectra acquired during surgery match the ones seen during training. It
is therefore of great interest to detect so-called out of distribution (OoD)
spectra to prevent the algorithm from presenting spurious results. In this
paper we present an information theory based approach to OoD detection based on
the widely applicable information criterion (WAIC). Our work builds upon recent
methodology related to invertible neural networks (INN). Specifically, we make
use of an ensemble of INNs as we need their tractable Jacobians in order to
compute the WAIC. Comprehensive experiments with in silico, and in vivo
multispectral imaging data indicate that our approach is well-suited for OoD
detection. Our method could thus be an important step towards reliable
functional imaging in the operating room.","['Tim J. Adler', 'Leonardo Ayala', 'Lynton Ardizzone', 'Hannes G. Kenngott', 'Anant Vemuri', 'Beat P. Müller-Stich', 'Carsten Rother', 'Ullrich Köthe', 'Lena Maier-Hein']","['eess.IV', 'cs.LG', 'physics.med-ph', 'stat.ML']",2019-11-05 15:31:29+00:00
http://arxiv.org/abs/1911.01872v1,Interpretability Study on Deep Learning for Jet Physics at the Large Hadron Collider,"Using deep neural networks for identifying physics objects at the Large
Hadron Collider (LHC) has become a powerful alternative approach in recent
years. After successful training of deep neural networks, examining the trained
networks not only helps us understand the behaviour of neural networks, but
also helps improve the performance of deep learning models through proper
interpretation. We take jet tagging problem at the LHC as an example, using
recursive neural networks as a starting point, aim at a thorough understanding
of the behaviour of the physics-oriented DNNs and the information encoded in
the embedding space. We make a comparative study on a series of different jet
tagging tasks dominated by different underlying physics. Interesting
observations on the latent space are obtained.",['Taoli Cheng'],"['hep-ph', 'cs.LG', 'hep-ex', 'stat.ML']",2019-11-05 15:27:30+00:00
http://arxiv.org/abs/1911.01861v2,Biconditional Generative Adversarial Networks for Multiview Learning with Missing Views,"In this paper, we present a conditional GAN with two generators and a common
discriminator for multiview learning problems where observations have two
views, but one of them may be missing for some of the training samples. This is
for example the case for multilingual collections where documents are not
available in all languages. Some studies tackled this problem by assuming the
existence of view generation functions to approximately complete the missing
views; for example Machine Translation to translate documents into the missing
languages. These functions generally require an external resource to be set and
their quality has a direct impact on the performance of the learned multiview
classifier over the completed training set. Our proposed approach addresses
this problem by jointly learning the missing views and the multiview classifier
using a tripartite game with two generators and a discriminator. Each of the
generators is associated to one of the views and tries to fool the
discriminator by generating the other missing view conditionally on the
corresponding observed view. The discriminator then tries to identify if for an
observation, one of its views is completed by one of the generators or if both
views are completed along with its class. Our results on a subset of Reuters
RCV1/RCV2 collections show that the discriminator achieves significant
classification performance; and that the generators learn the missing views
with high quality without the need of any consequent external resource.","['Anastasiia Doinychko', 'Massih-Reza Amini']","['cs.LG', 'stat.ML']",2019-11-05 15:20:06+00:00
http://arxiv.org/abs/1911.01812v1,Enhancing the Privacy of Federated Learning with Sketching,"In response to growing concerns about user privacy, federated learning has
emerged as a promising tool to train statistical models over networks of
devices while keeping data localized. Federated learning methods run training
tasks directly on user devices and do not share the raw user data with third
parties. However, current methods still share model updates, which may contain
private information (e.g., one's weight and height), during the training
process. Existing efforts that aim to improve the privacy of federated learning
make compromises in one or more of the following key areas: performance
(particularly communication cost), accuracy, or privacy. To better optimize
these trade-offs, we propose that \textit{sketching algorithms} have a unique
advantage in that they can provide both privacy and performance benefits while
maintaining accuracy. We evaluate the feasibility of sketching-based federated
learning with a prototype on three representative learning models. Our initial
findings show that it is possible to provide strong privacy guarantees for
federated learning without sacrificing performance or accuracy. Our work
highlights that there exists a fundamental connection between privacy and
communication in distributed settings, and suggests important open problems
surrounding the theoretical understanding, methodology, and system design of
practical, private federated learning.","['Zaoxing Liu', 'Tian Li', 'Virginia Smith', 'Vyas Sekar']","['cs.LG', 'cs.CR', 'cs.NI', 'stat.ML']",2019-11-05 14:38:18+00:00
http://arxiv.org/abs/1911.01738v2,Weakly Supervised Fine Tuning Approach for Brain Tumor Segmentation Problem,"Segmentation of tumors in brain MRI images is a challenging task, where most
recent methods demand large volumes of data with pixel-level annotations, which
are generally costly to obtain. In contrast, image-level annotations, where
only the presence of lesion is marked, are generally cheap, generated in far
larger volumes compared to pixel-level labels, and contain less labeling noise.
In the context of brain tumor segmentation, both pixel-level and image-level
annotations are commonly available; thus, a natural question arises whether a
segmentation procedure could take advantage of both. In the present work we: 1)
propose a learning-based framework that allows simultaneous usage of both
pixel- and image-level annotations in MRI images to learn a segmentation model
for brain tumor; 2) study the influence of comparative amounts of pixel- and
image-level annotations on the quality of brain tumor segmentation; 3) compare
our approach to the traditional fully-supervised approach and show that the
performance of our method in terms of segmentation quality may be competitive.","['Sergey Pavlov', 'Alexey Artemov', 'Maksim Sharaev', 'Alexander Bernstein', 'Evgeny Burnaev']","['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2019-11-05 12:14:40+00:00
http://arxiv.org/abs/1911.01731v3,GraphAIR: Graph Representation Learning with Neighborhood Aggregation and Interaction,"Graph representation learning is of paramount importance for a variety of
graph analytical tasks, ranging from node classification to community
detection. Recently, graph convolutional networks (GCNs) have been successfully
applied for graph representation learning. These GCNs generate node
representation by aggregating features from the neighborhoods, which follows
the ""neighborhood aggregation"" scheme. In spite of having achieved promising
performance on various tasks, existing GCN-based models have difficulty in well
capturing complicated non-linearity of graph data. In this paper, we first
theoretically prove that coefficients of the neighborhood interacting terms are
relatively small in current models, which explains why GCNs barely outperforms
linear models. Then, in order to better capture the complicated non-linearity
of graph data, we present a novel GraphAIR framework which models the
neighborhood interaction in addition to neighborhood aggregation. Comprehensive
experiments conducted on benchmark tasks including node classification and link
prediction using public datasets demonstrate the effectiveness of the proposed
method.","['Fenyu Hu', 'Yanqiao Zhu', 'Shu Wu', 'Weiran Huang', 'Liang Wang', 'Tieniu Tan']","['cs.LG', 'stat.ML']",2019-11-05 11:47:58+00:00
http://arxiv.org/abs/1911.01705v1,A GMM based algorithm to generate point-cloud and its application to neuroimaging,"Recent years have witnessed the emergence of 3D medical imaging techniques
with the development of 3D sensors and technology. Due to the presence of noise
in image acquisition, registration researchers focused on an alternative way to
represent medical images. An alternative way to analyze medical imaging is by
understanding the 3D shapes represented in terms of point-cloud. Though in the
medical imaging community, 3D point-cloud processing is not a ``go-to'' choice,
it is a ``natural'' way to capture 3D shapes. However, as the number of samples
for medical images are small, researchers have used pre-trained models to
fine-tune on medical images. Furthermore, due to different modality in medical
images, standard generative models can not be used to generate new samples of
medical images. In this work, we use the advantage of point-cloud
representation of 3D structures of medical images and propose a Gaussian
mixture model-based generation scheme. Our proposed method is robust to
outliers. Experimental validation has been performed to show that the proposed
scheme can generate new 3D structures using interpolation techniques, i.e.,
given two 3D structures represented as point-clouds, we can generate
point-clouds in between. We have also generated new point-clouds for subjects
with and without dementia and show that the generated samples are indeed
closely matched to the respective training samples from the same class.","['Liu Yang', 'Rudrasis Chakraborty']","['cs.LG', 'eess.IV', 'stat.ML']",2019-11-05 10:54:53+00:00
http://arxiv.org/abs/1911.03443v1,"An ""augmentation-free"" rotation invariant classification scheme on point-cloud and its application to neuroimaging","Recent years have witnessed the emergence and increasing popularity of 3D
medical imaging techniques with the development of 3D sensors and technology.
However, achieving geometric invariance in the processing of 3D medical images
is computationally expensive but nonetheless essential due to the presence of
possible errors caused by rigid registration techniques. An alternative way to
analyze medical imaging is by understanding the 3D shapes represented in terms
of point-cloud. Though in the medical imaging community, 3D point-cloud
processing is not a ""go-to"" choice, it is a canonical way to preserve rotation
invariance. Unfortunately, due to the presence of discrete topology, one can
not use the standard convolution operator on point-cloud. To the best of our
knowledge, the existing ways to do ""convolution"" can not preserve the rotation
invariance without explicit data augmentation. Therefore, we propose a rotation
invariant convolution operator by inducing topology from hypersphere.
Experimental validation has been performed on publicly available OASIS dataset
in terms of classification accuracy between subjects with (without) dementia,
demonstrating the usefulness of our proposed method in terms of model
complexity, classification accuracy, and last but most important invariance to
rotations.","['Liu Yang', 'Rudrasis Chakraborty']","['eess.IV', 'cs.CV', 'cs.LG', 'stat.ML']",2019-11-05 10:45:56+00:00
http://arxiv.org/abs/1911.01702v2,DocParser: Hierarchical Structure Parsing of Document Renderings,"Translating renderings (e. g. PDFs, scans) into hierarchical document
structures is extensively demanded in the daily routines of many real-world
applications. However, a holistic, principled approach to inferring the
complete hierarchical structure of documents is missing. As a remedy, we
developed ""DocParser"": an end-to-end system for parsing the complete document
structure - including all text elements, nested figures, tables, and table cell
structures. Our second contribution is to provide a dataset for evaluating
hierarchical document structure parsing. Our third contribution is to propose a
scalable learning framework for settings where domain-specific data are scarce,
which we address by a novel approach to weak supervision that significantly
improves the document structure parsing performance. Our experiments confirm
the effectiveness of our proposed weak supervision: Compared to the baseline
without weak supervision, it improves the mean average precision for detecting
document entities by 39.1 % and improves the F1 score of classifying
hierarchical relations by 35.8 %.","['Johannes Rausch', 'Octavio Martinez', 'Fabian Bissig', 'Ce Zhang', 'Stefan Feuerriegel']","['cs.LG', 'cs.CL', 'cs.CV', 'stat.ML']",2019-11-05 10:42:08+00:00
http://arxiv.org/abs/1911.01700v1,Deep Hedging: Learning to Simulate Equity Option Markets,"We construct realistic equity option market simulators based on generative
adversarial networks (GANs). We consider recurrent and temporal convolutional
architectures, and assess the impact of state compression. Option market
simulators are highly relevant because they allow us to extend the limited
real-world data sets available for the training and evaluation of option
trading strategies. We show that network-based generators outperform classical
methods on a range of benchmark metrics, and adversarial training achieves the
best performance. Our work demonstrates for the first time that GANs can be
successfully applied to the task of generating multivariate financial time
series.","['Magnus Wiese', 'Lianjun Bai', 'Ben Wood', 'Hans Buehler']","['q-fin.CP', 'cs.LG', 'q-fin.MF', 'q-fin.ST', 'stat.ML']",2019-11-05 10:23:39+00:00
http://arxiv.org/abs/1911.01695v2,Towards Optimal and Efficient Best Arm Identification in Linear Bandits,"We give a new algorithm for best arm identification in linearly parameterised
bandits in the fixed confidence setting. The algorithm generalises the
well-known LUCB algorithm of Kalyanakrishnan et al. (2012) by playing an arm
which minimises a suitable notion of geometric overlap of the statistical
confidence set for the unknown parameter, and is fully adaptive and
computationally efficient as compared to several state-of-the methods. We
theoretically analyse the sample complexity of the algorithm for problems with
two and three arms, showing optimality in many cases. Numerical results
indicate favourable performance over other algorithms with which we compare.","['Mohammadi Zaki', 'Avinash Mohan', 'Aditya Gopalan']","['cs.LG', 'math.OC', 'stat.ML']",2019-11-05 10:11:49+00:00
http://arxiv.org/abs/1911.01694v1,Bounds for the Number of Tests in Non-Adaptive Randomized Algorithms for Group Testing,"We study the group testing problem with non-adaptive randomized algorithms.
Several models have been discussed in the literature to determine how to
randomly choose the tests. For a model ${\cal M}$, let $m_{\cal M}(n,d)$ be the
minimum number of tests required to detect at most $d$ defectives within $n$
items, with success probability at least $1-\delta$, for some constant
$\delta$. In this paper, we study the measures $$c_{\cal M}(d)=\lim_{n\to
\infty} \frac{m_{\cal M}(n,d)}{\ln n} \mbox{ and } c_{\cal M}=\lim_{d\to
\infty} \frac{c_{\cal M}(d)}{d}.$$
  In the literature, the analyses of such models only give upper bounds for
$c_{\cal M}(d)$ and $c_{\cal M}$, and for some of them, the bounds are not
tight. We give new analyses that yield tight bounds for $c_{\cal M}(d)$ and
$c_{\cal M}$ for all the known models~${\cal M}$.","['Nader H. Bshouty', 'George Haddad', 'Catherine A. Haddad-Zaknoon']","['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2019-11-05 10:09:28+00:00
http://arxiv.org/abs/1911.04227v3,Cumulo: A Dataset for Learning Cloud Classes,"One of the greatest sources of uncertainty in future climate projections
comes from limitations in modelling clouds and in understanding how different
cloud types interact with the climate system. A key first step in reducing this
uncertainty is to accurately classify cloud types at high spatial and temporal
resolution. In this paper, we introduce Cumulo, a benchmark dataset for
training and evaluating global cloud classification models. It consists of one
year of 1km resolution MODIS hyperspectral imagery merged with pixel-width
'tracks' of CloudSat cloud labels. Bringing these complementary datasets
together is a crucial first step, enabling the Machine-Learning community to
develop innovative new techniques which could greatly benefit the Climate
community. To showcase Cumulo, we provide baseline performance analysis using
an invertible flow generative model (IResNet), which further allows us to
discover new sub-classes for a given cloud class by exploring the latent space.
To compare methods, we introduce a set of evaluation criteria, to identify
models that are not only accurate, but also physically-realistic. CUMULO can be
download from
https://www.dropbox.com/sh/i3s9q2v2jjyk2it/AACxXnXfMF5wuIqLXqH4NJOra?dl=0 .","['Valentina Zantedeschi', 'Fabrizio Falasca', 'Alyson Douglas', 'Richard Strange', 'Matt J. Kusner', 'Duncan Watson-Parris']","['physics.ao-ph', 'cs.CV', 'cs.LG', 'stat.ML']",2019-11-05 09:36:16+00:00
http://arxiv.org/abs/1911.01679v2,Apprenticeship Learning via Frank-Wolfe,"We consider the applications of the Frank-Wolfe (FW) algorithm for
Apprenticeship Learning (AL). In this setting, we are given a Markov Decision
Process (MDP) without an explicit reward function. Instead, we observe an
expert that acts according to some policy, and the goal is to find a policy
whose feature expectations are closest to those of the expert policy. We
formulate this problem as finding the projection of the feature expectations of
the expert on the feature expectations polytope -- the convex hull of the
feature expectations of all the deterministic policies in the MDP. We show that
this formulation is equivalent to the AL objective and that solving this
problem using the FW algorithm is equivalent well-known Projection method of
Abbeel and Ng (2004). This insight allows us to analyze AL with tools from
convex optimization literature and derive tighter convergence bounds on AL.
Specifically, we show that a variation of the FW method that is based on taking
""away steps"" achieves a linear rate of convergence when applied to AL and that
a stochastic version of the FW algorithm can be used to avoid precise
estimation of feature expectations. We also experimentally show that this
version outperforms the FW baseline. To the best of our knowledge, this is the
first work that shows linear convergence rates for AL.","['Tom Zahavy', 'Alon Cohen', 'Haim Kaplan', 'Yishay Mansour']","['cs.LG', 'stat.ML']",2019-11-05 09:26:06+00:00
http://arxiv.org/abs/1911.01658v1,Joint Ranking SVM and Binary Relevance with Robust Low-Rank Learning for Multi-Label Classification,"Multi-label classification studies the task where each example belongs to
multiple labels simultaneously. As a representative method, Ranking Support
Vector Machine (Rank-SVM) aims to minimize the Ranking Loss and can also
mitigate the negative influence of the class-imbalance issue. However, due to
its stacking-style way for thresholding, it may suffer error accumulation and
thus reduces the final classification performance. Binary Relevance (BR) is
another typical method, which aims to minimize the Hamming Loss and only needs
one-step learning. Nevertheless, it might have the class-imbalance issue and
does not take into account label correlations. To address the above issues, we
propose a novel multi-label classification model, which joints Ranking support
vector machine and Binary Relevance with robust Low-rank learning (RBRL). RBRL
inherits the ranking loss minimization advantages of Rank-SVM, and thus
overcomes the disadvantages of BR suffering the class-imbalance issue and
ignoring the label correlations. Meanwhile, it utilizes the hamming loss
minimization and one-step learning advantages of BR, and thus tackles the
disadvantages of Rank-SVM including another thresholding learning step.
Besides, a low-rank constraint is utilized to further exploit high-order label
correlations under the assumption of low dimensional label space. Furthermore,
to achieve nonlinear multi-label classifiers, we derive the kernelization RBRL.
Two accelerated proximal gradient methods (APG) are used to solve the
optimization problems efficiently. Extensive comparative experiments with
several state-of-the-art methods illustrate a highly competitive or superior
performance of our method RBRL.","['Guoqiang Wu', 'Ruobing Zheng', 'Yingjie Tian', 'Dalian Liu']","['cs.LG', 'stat.ML']",2019-11-05 07:50:36+00:00
http://arxiv.org/abs/1911.01654v1,Detecting Point Outliers Using Prune-based Outlier Factor (PLOF),"Outlier detection (also known as anomaly detection or deviation detection) is
a process of detecting data points in which their patterns deviate
significantly from others. It is common to have outliers in industry
applications, which could be generated by different causes such as human error,
fraudulent activities, or system failure. Recently, density-based methods have
shown promising results, particularly among which Local Outlier Factor (LOF) is
arguably dominating. However, one of the major drawbacks of LOF is that it is
computationally expensive. Motivated by the mentioned problem, this research
presents a novel pruning-based procedure in which the execution time of LOF is
reduced while the performance is maintained. A novel Prune-based Local Outlier
Factor (PLOF) approach is proposed, in which prior to employing LOF,
outlierness of each data instance is measured. Next, based on a threshold, data
instances that require further investigation are separated and LOF score is
only computed for these points. Extensive experiments have been conducted and
results are promising. Comparison experiments with the original LOF and two
state-of-the-art variants of LOF have shown that PLOF produces higher accuracy
and precision while reducing execution time.","['Kasra Babaei', 'ZhiYuan Chen', 'Tomas Maul']","['cs.LG', 'stat.ML']",2019-11-05 07:42:42+00:00
http://arxiv.org/abs/1911.01649v1,Study of Constrained Network Structures for WGANs on Numeric Data Generation,"Some recent studies have suggested using GANs for numeric data generation
such as to generate data for completing the imbalanced numeric data.
Considering the significant difference between the dimensions of the numeric
data and images, as well as the strong correlations between features of numeric
data, the conventional GANs normally face an overfitting problem, consequently
leads to an ill-conditioning problem in generating numeric and structured data.
This paper studies the constrained network structures between generator G and
discriminator D in WGAN, designs several structures including isomorphic,
mirror and self-symmetric structures. We evaluates the performances of the
constrained WGANs in data augmentations, taking the non-constrained GANs and
WGANs as the baselines. Experiments prove the constrained structures have been
improved in 17/20 groups of experiments. In twenty experiments on four UCI
Machine Learning Repository datasets, Australian Credit Approval data, German
Credit data, Pima Indians Diabetes data and SPECT heart data facing five
conventional classifiers. Especially, Isomorphic WGAN is the best in 15/20
experiments. Finally, we theoretically proves that the effectiveness of
constrained structures by the directed graphic model (DGM) analysis.","['Wei Wang', 'Chuang Wang', 'Tao Cui', 'Yue Li']","['cs.LG', 'stat.ML']",2019-11-05 07:27:46+00:00
http://arxiv.org/abs/1911.01641v3,New Potential-Based Bounds for Prediction with Expert Advice,"This work addresses the classic machine learning problem of online prediction
with expert advice. We consider the finite-horizon version of this zero-sum,
two-person game. Using verification arguments from optimal control theory, we
view the task of finding better lower and upper bounds on the value of the game
(regret) as the problem of finding better sub- and supersolutions of certain
partial differential equations (PDEs). These sub- and supersolutions serve as
the potentials for player and adversary strategies, which lead to the
corresponding bounds. To get explicit bounds, we use closed-form solutions of
specific PDEs. Our bounds hold for any given number of experts and horizon; in
certain regimes (which we identify) they improve upon the previous state of the
art. For two and three experts, our bounds provide the optimal leading order
term.","['Vladimir A. Kobzar', 'Robert V. Kohn', 'Zhilei Wang']","['cs.LG', 'cs.GT', 'math.AP', 'math.OC', 'stat.ML', '35Q93, 35Q68, 49L20, 68W27, 91A05, 93C20', 'I.2.8']",2019-11-05 06:43:21+00:00
http://arxiv.org/abs/1911.02010v2,A Fourier Analytical Approach to Estimation of Smooth Functions in Gaussian Shift Model,"Let $\mathbf{x}_j = \mathbf{\theta} + \mathbf{\epsilon}_j$, $j=1,\dots,n$ be
i.i.d. copies of a Gaussian random vector
$\mathbf{x}\sim\mathcal{N}(\mathbf{\theta},\mathbf{\Sigma})$ with unknown mean
$\mathbf{\theta} \in \mathbb{R}^d$ and unknown covariance matrix
$\mathbf{\Sigma}\in \mathbb{R}^{d\times d}$. The goal of this article is to
study the estimation of $f(\mathbf{\theta})$ where $f$ is a given smooth
function of which smoothness is characterized by a Besov-type norm. The problem
of interest resides in the high dimensional regime where the intrinsic
dimension can grow with the sample size $n$. Inspired by the classical work of
A. N. Kolmogorov on unbiased estimation and Littlewood-Paley theory, we develop
a new estimator based on a Fourier analytical approach that achieves effective
bias reduction. Asymptotic normality and efficiency are proved when the
smoothness index of $f$ is above certain threshold which was discovered
recently by Koltchinskii et. al. (2018) for a H\""{o}lder type class. Numerical
simulations are presented to validate our analysis. The simplicity of
implementation and its superiority over the plug-in approach indicate the new
estimator can be applied to a broad range of real world applications.","['Fan Zhou', 'Ping Li']","['math.ST', 'cs.IT', 'math.IT', 'stat.ML', 'stat.TH']",2019-11-05 03:16:24+00:00
http://arxiv.org/abs/1911.01559v3,A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models,"Despite their tremendous success in a range of domains, deep learning systems
are inherently susceptible to two types of manipulations: adversarial inputs --
maliciously crafted samples that deceive target deep neural network (DNN)
models, and poisoned models -- adversely forged DNNs that misbehave on
pre-defined inputs. While prior work has intensively studied the two attack
vectors in parallel, there is still a lack of understanding about their
fundamental connections: what are the dynamic interactions between the two
attack vectors? what are the implications of such interactions for optimizing
existing attacks? what are the potential countermeasures against the enhanced
attacks? Answering these key questions is crucial for assessing and mitigating
the holistic vulnerabilities of DNNs deployed in realistic settings.
  Here we take a solid step towards this goal by conducting the first
systematic study of the two attack vectors within a unified framework.
Specifically, (i) we develop a new attack model that jointly optimizes
adversarial inputs and poisoned models; (ii) with both analytical and empirical
evidence, we reveal that there exist intriguing ""mutual reinforcement"" effects
between the two attack vectors -- leveraging one vector significantly amplifies
the effectiveness of the other; (iii) we demonstrate that such effects enable a
large design spectrum for the adversary to enhance the existing attacks that
exploit both vectors (e.g., backdoor attacks), such as maximizing the attack
evasiveness with respect to various detection methods; (iv) finally, we discuss
potential countermeasures against such optimized attacks and their technical
challenges, pointing to several promising research directions.","['Ren Pang', 'Hua Shen', 'Xinyang Zhang', 'Shouling Ji', 'Yevgeniy Vorobeychik', 'Xiapu Luo', 'Alex Liu', 'Ting Wang']","['cs.LG', 'cs.CR', 'stat.ML']",2019-11-05 01:32:57+00:00
http://arxiv.org/abs/1911.01545v5,Compositional Generalization with Tree Stack Memory Units,"We study compositional generalization, viz., the problem of zero-shot
generalization to novel compositions of concepts in a domain. Standard neural
networks fail to a large extent on compositional learning. We propose Tree
Stack Memory Units (Tree-SMU) to enable strong compositional generalization.
Tree-SMU is a recursive neural network with Stack Memory Units (\SMU s), a
novel memory augmented neural network whose memory has a differentiable stack
structure. Each SMU in the tree architecture learns to read from its stack and
to write to it by combining the stacks and states of its children through
gating. The stack helps capture long-range dependencies in the problem domain,
thereby enabling compositional generalization. Additionally, the stack also
preserves the ordering of each node's descendants, thereby retaining locality
on the tree. We demonstrate strong empirical results on two mathematical
reasoning benchmarks. We use four compositionality tests to assess the
generalization performance of Tree-SMU and show that it enables accurate
compositional generalization compared to strong baselines such as Transformers
and Tree-LSTMs.","['Forough Arabshahi', 'Zhichu Lu', 'Pranay Mundra', 'Sameer Singh', 'Animashree Anandkumar']","['cs.LG', 'cs.NE', 'stat.ML']",2019-11-05 00:27:03+00:00
http://arxiv.org/abs/1911.01544v3,The generalization error of max-margin linear classifiers: Benign overfitting and high dimensional asymptotics in the overparametrized regime,"Modern machine learning classifiers often exhibit vanishing classification
error on the training set. They achieve this by learning nonlinear
representations of the inputs that maps the data into linearly separable
classes.
  Motivated by these phenomena, we revisit high-dimensional maximum margin
classification for linearly separable data. We consider a stylized setting in
which data $(y_i,{\boldsymbol x}_i)$, $i\le n$ are i.i.d. with ${\boldsymbol
x}_i\sim\mathsf{N}({\boldsymbol 0},{\boldsymbol \Sigma})$ a $p$-dimensional
Gaussian feature vector, and $y_i \in\{+1,-1\}$ a label whose distribution
depends on a linear combination of the covariates $\langle {\boldsymbol
\theta}_*,{\boldsymbol x}_i \rangle$. While the Gaussian model might appear
extremely simplistic, universality arguments can be used to show that the
results derived in this setting also apply to the output of certain nonlinear
featurization maps.
  We consider the proportional asymptotics $n,p\to\infty$ with $p/n\to \psi$,
and derive exact expressions for the limiting generalization error. We use this
theory to derive two results of independent interest: $(i)$ Sufficient
conditions on $({\boldsymbol \Sigma},{\boldsymbol \theta}_*)$ for `benign
overfitting' that parallel previously derived conditions in the case of linear
regression; $(ii)$ An asymptotically exact expression for the generalization
error when max-margin classification is used in conjunction with feature
vectors produced by random one-layer neural networks.","['Andrea Montanari', 'Feng Ruan', 'Youngtak Sohn', 'Jun Yan']","['math.ST', 'stat.ML', 'stat.TH']",2019-11-05 00:15:27+00:00
http://arxiv.org/abs/1911.01535v1,Scalable Deep Generative Relational Models with High-Order Node Dependence,"We propose a probabilistic framework for modelling and exploring the latent
structure of relational data. Given feature information for the nodes in a
network, the scalable deep generative relational model (SDREM) builds a deep
network architecture that can approximate potential nonlinear mappings between
nodes' feature information and the nodes' latent representations. Our
contribution is two-fold: (1) We incorporate high-order neighbourhood structure
information to generate the latent representations at each node, which vary
smoothly over the network. (2) Due to the Dirichlet random variable structure
of the latent representations, we introduce a novel data augmentation trick
which permits efficient Gibbs sampling. The SDREM can be used for large sparse
networks as its computational cost scales with the number of positive links. We
demonstrate its competitive performance through improved link prediction
performance on a range of real-world datasets.","['Xuhui Fan', 'Bin Li', 'Scott Anthony Sisson', 'Caoyuan Li', 'Ling Chen']","['stat.ML', 'cs.LG']",2019-11-04 23:36:09+00:00
