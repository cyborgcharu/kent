id,title,abstract,authors,categories,date
http://arxiv.org/abs/1807.05464v3,Tractable Querying and Learning in Hybrid Domains via Sum-Product Networks,"Probabilistic representations, such as Bayesian and Markov networks, are
fundamental to much of statistical machine learning. Thus, learning
probabilistic representations directly from data is a deep challenge, the main
computational bottleneck being inference that is intractable. Tractable
learning is a powerful new paradigm that attempts to learn distributions that
support efficient probabilistic querying. By leveraging local structure,
representations such as sum-product networks (SPNs) can capture high tree-width
models with many hidden layers, essentially a deep architecture, while still
admitting a range of probabilistic queries to be computable in time polynomial
in the network size. The leaf nodes in SPNs, from which more intricate mixtures
are formed, are tractable univariate distributions, and so the literature has
focused on Bernoulli and Gaussian random variables. This is clearly a
restriction for handling mixed discrete-continuous data, especially if the
continuous features are generated from non-parametric and non-Gaussian
distribution families. In this work, we present a framework that systematically
integrates SPN structure learning with weighted model integration, a recently
introduced computational abstraction for performing inference in hybrid
domains, by means of piecewise polynomial approximations of density functions
of arbitrary shape. Our framework is instantiated by exploiting the notion of
propositional abstractions, thus minimally interfering with the SPN structure
learning module, and supports a powerful query interface for conditioning on
interval constraints. Our empirical results show that our approach is
effective, and allows a study of the trade off between the granularity of the
learned model and its predictive power.","['Andreas Bueff', 'Stefanie Speichert', 'Vaishak Belle']","['cs.LG', 'cs.AI', 'stat.ML']",2018-07-14 23:25:16+00:00
http://arxiv.org/abs/1807.05459v1,Multi-time-horizon Solar Forecasting Using Recurrent Neural Network,"The non-stationarity characteristic of the solar power renders traditional
point forecasting methods to be less useful due to large prediction errors.
This results in increased uncertainties in the grid operation, thereby
negatively affecting the reliability and increased cost of operation. This
research paper proposes a unified architecture for multi-time-horizon
predictions for short and long-term solar forecasting using Recurrent Neural
Networks (RNN). The paper describes an end-to-end pipeline to implement the
architecture along with the methods to test and validate the performance of the
prediction model. The results demonstrate that the proposed method based on the
unified architecture is effective for multi-horizon solar forecasting and
achieves a lower root-mean-squared prediction error compared to the previous
best-performing methods which use one model for each time-horizon. The proposed
method enables multi-horizon forecasts with real-time inputs, which have a high
potential for practical applications in the evolving smart grid.","['Sakshi Mishra', 'Praveen Palanisamy']","['cs.LG', 'eess.SP', 'stat.ML']",2018-07-14 22:12:25+00:00
http://arxiv.org/abs/1807.05411v4,A Unified Framework for Sparse Relaxed Regularized Regression: SR3,"Regularized regression problems are ubiquitous in statistical modeling,
signal processing, and machine learning. Sparse regression in particular has
been instrumental in scientific model discovery, including compressed sensing
applications, variable selection, and high-dimensional analysis. We propose a
broad framework for sparse relaxed regularized regression, called SR3. The key
idea is to solve a relaxation of the regularized problem, which has three
advantages over the state-of-the-art: (1) solutions of the relaxed problem are
superior with respect to errors, false positives, and conditioning, (2)
relaxation allows extremely fast algorithms for both convex and nonconvex
formulations, and (3) the methods apply to composite regularizers such as total
variation (TV) and its nonconvex variants. We demonstrate the advantages of SR3
(computational efficiency, higher accuracy, faster convergence rates, greater
flexibility) across a range of regularized regression problems with synthetic
and real data, including applications in compressed sensing, LASSO, matrix
completion, TV regularization, and group sparsity. To promote reproducible
research, we also provide a companion MATLAB package that implements these
examples.","['Peng Zheng', 'Travis Askham', 'Steven L. Brunton', 'J. Nathan Kutz', 'Aleksandr Y. Aravkin']","['stat.ML', 'cs.LG', 'math.OC', '62F35, 65K10, 49M15']",2018-07-14 15:37:37+00:00
http://arxiv.org/abs/1807.05351v1,ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies,"The ML-Schema, proposed by the W3C Machine Learning Schema Community Group,
is a top-level ontology that provides a set of classes, properties, and
restrictions for representing and interchanging information on machine learning
algorithms, datasets, and experiments. It can be easily extended and
specialized and it is also mapped to other more domain-specific ontologies
developed in the area of machine learning and data mining. In this paper we
overview existing state-of-the-art machine learning interchange formats and
present the first release of ML-Schema, a canonical format resulted of more
than seven years of experience among different research institutions. We argue
that exposing semantics of machine learning algorithms, models, and experiments
through a canonical format may pave the way to better interpretability and to
realistically achieve the full interoperability of experiments regardless of
platform or adopted workflow solution.","['Gustavo Correa Publio', 'Diego Esteves', 'Agnieszka Ławrynowicz', 'Panče Panov', 'Larisa Soldatova', 'Tommaso Soru', 'Joaquin Vanschoren', 'Hamid Zafar']","['cs.LG', 'cs.DB', 'cs.IR', 'stat.ML']",2018-07-14 08:07:31+00:00
http://arxiv.org/abs/1807.05344v2,Adversarially Learned Mixture Model,"The Adversarially Learned Mixture Model (AMM) is a generative model for
unsupervised or semi-supervised data clustering. The AMM is the first
adversarially optimized method to model the conditional dependence between
inferred continuous and categorical latent variables. Experiments on the MNIST
and SVHN datasets show that the AMM allows for semantic separation of complex
data when little or no labeled data is available. The AMM achieves a
state-of-the-art unsupervised clustering error rate of 2.86% on the MNIST
dataset. A semi-supervised extension of the AMM yields competitive results on
the SVHN dataset.","['Andrew Jesson', 'Cécile Low-Kam', 'Tanya Nair', 'Florian Soudan', 'Florent Chandelier', 'Nicolas Chapados']","['stat.ML', 'cs.LG']",2018-07-14 07:17:58+00:00
http://arxiv.org/abs/1807.05343v1,Generalization in quasi-periodic environments,"By and large the behavior of stochastic gradient is regarded as a challenging
problem, and it is often presented in the framework of statistical machine
learning. This paper offers a novel view on the analysis of on-line models of
learning that arises when dealing with a generalized version of stochastic
gradient that is based on dissipative dynamics. In order to face the complex
evolution of these models, a systematic treatment is proposed which is based on
energy balance equations that are derived by means of the Caldirola-Kanai (CK)
Hamiltonian. According to these equations, learning can be regarded as an
ordering process which corresponds with the decrement of the loss function.
Finally, the main results established in this paper is that in the case of
quasi-periodic environments, where the pattern novelty is progressively limited
as time goes by, the system dynamics yields an asymptotically consistent
solution in the weight space, that is the solution maps similar patterns to the
same decision.","['Giovanni Bellettini', 'Alessandro Betti', 'Marco Gori']","['cs.LG', 'stat.ML']",2018-07-14 07:01:14+00:00
http://arxiv.org/abs/1808.01006v2,A Hybrid Variational Autoencoder for Collaborative Filtering,"In today's day and age when almost every industry has an online presence with
users interacting in online marketplaces, personalized recommendations have
become quite important. Traditionally, the problem of collaborative filtering
has been tackled using Matrix Factorization which is linear in nature. We
extend the work of [11] on using variational autoencoders (VAEs) for
collaborative filtering with implicit feedback by proposing a hybrid,
multi-modal approach. Our approach combines movie embeddings (learned from a
sibling VAE network) with user ratings from the Movielens 20M dataset and
applies it to the task of movie recommendation. We empirically show how the VAE
network is empowered by incorporating movie embeddings. We also visualize movie
and user embeddings by clustering their latent representations obtained from a
VAE.","['Kilol Gupta', 'Mukund Yelahanka Raghuprasad', 'Pankhuri Kumar']","['cs.IR', 'cs.LG', 'stat.ML']",2018-07-14 06:57:11+00:00
http://arxiv.org/abs/1807.05328v1,On the Acceleration of L-BFGS with Second-Order Information and Stochastic Batches,"This paper proposes a framework of L-BFGS based on the (approximate)
second-order information with stochastic batches, as a novel approach to the
finite-sum minimization problems. Different from the classical L-BFGS where
stochastic batches lead to instability, we use a smooth estimate for the
evaluations of the gradient differences while achieving acceleration by
well-scaling the initial Hessians. We provide theoretical analyses for both
convex and nonconvex cases. In addition, we demonstrate that within the popular
applications of least-square and cross-entropy losses, the algorithm admits a
simple implementation in the distributed environment. Numerical experiments
support the efficiency of our algorithms.","['Jie Liu', 'Yu Rong', 'Martin Takac', 'Junzhou Huang']","['cs.LG', 'math.OC', 'stat.ML']",2018-07-14 03:48:46+00:00
http://arxiv.org/abs/1807.05317v1,LeFlow: Enabling Flexible FPGA High-Level Synthesis of Tensorflow Deep Neural Networks,"Recent work has shown that Field-Programmable Gate Arrays (FPGAs) play an
important role in the acceleration of Machine Learning applications. Initial
specification of machine learning applications are often done using a
high-level Python-oriented framework such as Tensorflow, followed by a manual
translation to either C or RTL for synthesis using vendor tools. This manual
translation step is time-consuming and requires expertise that limit the
applicability of FPGAs in this important domain. In this paper, we present an
open-source tool-flow that maps numerical computation models written in
Tensorflow to synthesizable hardware. Unlike other tools, which are often
constrained by a small number of inflexible templates, our flow uses Google's
XLA compiler which emits LLVM code directly from a Tensorflow specification.
This LLVM code can then be used with a high-level synthesis tool to
automatically generate hardware. We show that our flow allows users to generate
Deep Neural Networks with very few lines of Python code.","['Daniel H. Noronha', 'Bahar Salehpour', 'Steven J. E. Wilton']","['cs.LG', 'stat.ML']",2018-07-14 01:06:13+00:00
http://arxiv.org/abs/1807.05307v5,How Do Classifiers Induce Agents To Invest Effort Strategically?,"Algorithms are often used to produce decision-making rules that classify or
evaluate individuals. When these individuals have incentives to be classified a
certain way, they may behave strategically to influence their outcomes. We
develop a model for how strategic agents can invest effort in order to change
the outcomes they receive, and we give a tight characterization of when such
agents can be incentivized to invest specified forms of effort into improving
their outcomes as opposed to ""gaming"" the classifier. We show that whenever any
""reasonable"" mechanism can do so, a simple linear mechanism suffices.","['Jon Kleinberg', 'Manish Raghavan']","['cs.LG', 'cs.CY', 'cs.DS', 'cs.GT', 'stat.ML']",2018-07-13 23:46:52+00:00
http://arxiv.org/abs/1807.05306v3,Generative Adversarial Privacy,"We present a data-driven framework called generative adversarial privacy
(GAP). Inspired by recent advancements in generative adversarial networks
(GANs), GAP allows the data holder to learn the privatization mechanism
directly from the data. Under GAP, finding the optimal privacy mechanism is
formulated as a constrained minimax game between a privatizer and an adversary.
We show that for appropriately chosen adversarial loss functions, GAP provides
privacy guarantees against strong information-theoretic adversaries. We also
evaluate GAP's performance on the GENKI face database.","['Chong Huang', 'Peter Kairouz', 'Xiao Chen', 'Lalitha Sankar', 'Ram Rajagopal']","['cs.LG', 'cs.CR', 'cs.GT', 'cs.IT', 'math.IT', 'stat.ML']",2018-07-13 23:40:33+00:00
http://arxiv.org/abs/1807.05292v1,Neural Networks Regularization Through Representation Learning,"Neural network models and deep models are one of the leading and state of the
art models in machine learning. Most successful deep neural models are the ones
with many layers which highly increases their number of parameters. Training
such models requires a large number of training samples which is not always
available. One of the fundamental issues in neural networks is overfitting
which is the issue tackled in this thesis. Such problem often occurs when the
training of large models is performed using few training samples. Many
approaches have been proposed to prevent the network from overfitting and
improve its generalization performance such as data augmentation, early
stopping, parameters sharing, unsupervised learning, dropout, batch
normalization, etc.
  In this thesis, we tackle the neural network overfitting issue from a
representation learning perspective by considering the situation where few
training samples are available which is the case of many real world
applications. We propose three contributions. The first one presented in
chapter 2 is dedicated to dealing with structured output problems to perform
multivariate regression when the output variable y contains structural
dependencies between its components. The second contribution described in
chapter 3 deals with the classification task where we propose to exploit prior
knowledge about the internal representation of the hidden layers in neural
networks. Our last contribution presented in chapter 4 showed the interest of
transfer learning in applications where only few samples are available. In this
contribution, we provide an automatic system based on such learning scheme with
an application to medical domain. In this application, the task consists in
localizing the third lumbar vertebra in a 3D CT scan. This work has been done
in collaboration with the clinic Rouen Henri Becquerel Center who provided us
with data.",['Soufiane Belharbi'],"['cs.LG', 'stat.ML']",2018-07-13 21:57:18+00:00
http://arxiv.org/abs/1807.05247v2,Channel Charting: Locating Users within the Radio Environment using Channel State Information,"We propose channel charting (CC), a novel framework in which a multi-antenna
network element learns a chart of the radio geometry in its surrounding area.
The channel chart captures the local spatial geometry of the area so that
points that are close in space will also be close in the channel chart and vice
versa. CC works in a fully unsupervised manner, i.e., learning is only based on
channel state information (CSI) that is passively collected at a single point
in space, but from multiple transmit locations in the area over time. The
method then extracts channel features that characterize large-scale fading
properties of the wireless channel. Finally, the channel charts are generated
with tools from dimensionality reduction, manifold learning, and deep neural
networks. The network element performing CC may be, for example, a
multi-antenna base-station in a cellular system and the charted area in the
served cell. Logical relationships related to the position and movement of a
transmitter, e.g., a user equipment (UE), in the cell can then be directly
deduced from comparing measured radio channel characteristics to the channel
chart. The unsupervised nature of CC enables a range of new applications in UE
localization, network planning, user scheduling, multipoint connectivity,
hand-over, cell search, user grouping, and other cognitive tasks that rely on
CSI and UE movement relative to the base-station, without the need of
information from global navigation satellite systems.","['Christoph Studer', 'Saïd Medjkouh', 'Emre Gönültaş', 'Tom Goldstein', 'Olav Tirkkonen']","['cs.IT', 'eess.SP', 'math.IT', 'stat.ML']",2018-07-13 18:56:34+00:00
http://arxiv.org/abs/1807.06446v1,Bridging the Gap Between Layout Pattern Sampling and Hotspot Detection via Batch Active Learning,"Layout hotpot detection is one of the main steps in modern VLSI design. A
typical hotspot detection flow is extremely time consuming due to the
computationally expensive mask optimization and lithographic simulation. Recent
researches try to facilitate the procedure with a reduced flow including
feature extraction, training set generation and hotspot detection, where
feature extraction methods and hotspot detection engines are deeply studied.
However, the performance of hotspot detectors relies highly on the quality of
reference layout libraries which are costly to obtain and usually predetermined
or randomly sampled in previous works. In this paper, we propose an active
learning-based layout pattern sampling and hotspot detection flow, which
simultaneously optimizes the machine learning model and the training set that
aims to achieve similar or better hotspot detection performance with much
smaller number of training instances. Experimental results show that our
proposed method can significantly reduce lithography simulation overhead while
attaining satisfactory detection accuracy on designs under both DUV and EUV
lithography technologies.","['Haoyu Yang', 'Shuhe Li', 'Cyrus Tabery', 'Bingqing Lin', 'Bei Yu']","['cs.LG', 'eess.IV', 'stat.ML']",2018-07-13 17:51:42+00:00
http://arxiv.org/abs/1807.05207v2,Parametric generation of conditional geological realizations using generative neural networks,"Deep learning techniques are increasingly being considered for geological
applications where -- much like in computer vision -- the challenges are
characterized by high-dimensional spatial data dominated by multipoint
statistics. In particular, a novel technique called generative adversarial
networks has been recently studied for geological parametrization and
synthesis, obtaining very impressive results that are at least qualitatively
competitive with previous methods. The method obtains a neural network
parametrization of the geology -- so-called a generator -- that is capable of
reproducing very complex geological patterns with dimensionality reduction of
several orders of magnitude. Subsequent works have addressed the conditioning
task, i.e. using the generator to generate realizations honoring spatial
observations (hard data). The current approaches, however, do not provide a
parametrization of the conditional generation process. In this work, we propose
a method to obtain a parametrization for direct generation of conditional
realizations. The main idea is to simply extend the existing generator network
by stacking a second inference network that learns to perform the conditioning.
This inference network is a neural network trained to sample a posterior
distribution derived using a Bayesian formulation of the conditioning task. The
resulting extended neural network thus provides the conditional
parametrization. Our method is assessed on a benchmark image of binary
channelized subsurface, obtaining very promising results for a wide variety of
conditioning configurations.","['Shing Chan', 'Ahmed H. Elsheikh']","['stat.ML', 'cs.LG', 'physics.comp-ph']",2018-07-13 17:46:00+00:00
http://arxiv.org/abs/1807.05185v1,Model Reconstruction from Model Explanations,"We show through theory and experiment that gradient-based explanations of a
model quickly reveal the model itself. Our results speak to a tension between
the desire to keep a proprietary model secret and the ability to offer model
explanations. On the theoretical side, we give an algorithm that provably
learns a two-layer ReLU network in a setting where the algorithm may query the
gradient of the model with respect to chosen inputs. The number of queries is
independent of the dimension and nearly optimal in its dependence on the model
size. Of interest not only from a learning-theoretic perspective, this result
highlights the power of gradients rather than labels as a learning primitive.
Complementing our theory, we give effective heuristics for reconstructing
models from gradient explanations that are orders of magnitude more
query-efficient than reconstruction attacks relying on prediction interfaces.","['Smitha Milli', 'Ludwig Schmidt', 'Anca D. Dragan', 'Moritz Hardt']","['stat.ML', 'cs.LG']",2018-07-13 17:15:00+00:00
http://arxiv.org/abs/1807.05836v3,Forecasting market states,"We propose a novel methodology to define, analyze and forecast market states.
In our approach market states are identified by a reference sparse precision
matrix and a vector of expectation values. In our procedure, each multivariate
observation is associated with a given market state accordingly to a
minimization of a penalized Mahalanobis distance. The procedure is made
computationally very efficient and can be used with a large number of assets.
We demonstrate that this procedure is successful at clustering different states
of the markets in an unsupervised manner. In particular, we describe an
experiment with one hundred log-returns and two states in which the methodology
automatically associates states prevalently to pre- and post- crisis periods
with one state gathering periods with average positive returns and the other
state periods with average negative returns, therefore discovering
spontaneously the common classification of `bull' and `bear' markets. In
another experiment, with again one hundred log-returns and two states, we
demonstrate that this procedure can be efficiently used to forecast off-sample
future market states with significant prediction accuracy. This methodology
opens the way to a range of applications in risk management and trading
strategies in the context where the correlation structure plays a central role.","['Pier Francesco Procacci', 'Tomaso Aste']","['q-fin.ST', 'cs.LG', 'stat.ML']",2018-07-13 16:43:39+00:00
http://arxiv.org/abs/1807.05118v1,Tune: A Research Platform for Distributed Model Selection and Training,"Modern machine learning algorithms are increasingly computationally
demanding, requiring specialized hardware and distributed computation to
achieve high performance in a reasonable time frame. Many hyperparameter search
algorithms have been proposed for improving the efficiency of model selection,
however their adaptation to the distributed compute environment is often
ad-hoc. We propose Tune, a unified framework for model selection and training
that provides a narrow-waist interface between training scripts and search
algorithms. We show that this interface meets the requirements for a broad
range of hyperparameter search algorithms, allows straightforward scaling of
search to large clusters, and simplifies algorithm implementation. We
demonstrate the implementation of several state-of-the-art hyperparameter
search algorithms in Tune. Tune is available at
http://ray.readthedocs.io/en/latest/tune.html.","['Richard Liaw', 'Eric Liang', 'Robert Nishihara', 'Philipp Moritz', 'Joseph E. Gonzalez', 'Ion Stoica']","['cs.LG', 'cs.DC', 'stat.ML']",2018-07-13 15:00:17+00:00
http://arxiv.org/abs/1807.05087v1,Learning Graph Representations by Dendrograms,"Hierarchical graph clustering is a common technique to reveal the multi-scale
structure of complex networks. We propose a novel metric for assessing the
quality of a hierarchical clustering. This metric reflects the ability to
reconstruct the graph from the dendrogram, which encodes the hierarchy. The
optimal representation of the graph defines a class of reducible linkages
leading to regular dendrograms by greedy agglomerative clustering.","['Thomas Bonald', 'Bertrand Charpentier']","['cs.SI', 'cs.LG', 'stat.ML']",2018-07-13 13:51:52+00:00
http://arxiv.org/abs/1807.09586v3,Perturb and Combine to Identify Influential Spreaders in Real-World Networks,"Some of the most effective influential spreader detection algorithms are
unstable to small perturbations of the network structure. Inspired by bagging
in Machine Learning, we propose the first Perturb and Combine (P&C) procedure
for networks. It (1) creates many perturbed versions of a given graph, (2)
applies a node scoring function separately to each graph, and (3) combines the
results. Experiments conducted on real-world networks of various sizes with the
k-core, generalized k-core, and PageRank algorithms reveal that P&C brings
substantial improvements. Moreover, this performance boost can be obtained at
almost no extra cost through parallelization. Finally, a bias-variance analysis
suggests that P&C works mainly by reducing bias, and that therefore, it should
be capable of improving the performance of all vertex scoring functions,
including stable ones.","['Antoine J. -P. Tixier', 'Maria-Evgenia G. Rossi', 'Fragkiskos D. Malliaros', 'Jesse Read', 'Michalis Vazirgiannis']","['cs.SI', 'cs.LG', 'stat.ML']",2018-07-13 13:43:15+00:00
http://arxiv.org/abs/1807.05031v6,On the Relation Between the Sharpest Directions of DNN Loss and the SGD Step Length,"Stochastic Gradient Descent (SGD) based training of neural networks with a
large learning rate or a small batch-size typically ends in well-generalizing,
flat regions of the weight space, as indicated by small eigenvalues of the
Hessian of the training loss. However, the curvature along the SGD trajectory
is poorly understood. An empirical investigation shows that initially SGD
visits increasingly sharp regions, reaching a maximum sharpness determined by
both the learning rate and the batch-size of SGD. When studying the SGD
dynamics in relation to the sharpest directions in this initial phase, we find
that the SGD step is large compared to the curvature and commonly fails to
minimize the loss along the sharpest directions. Furthermore, using a reduced
learning rate along these directions can improve training speed while leading
to both sharper and better generalizing solutions compared to vanilla SGD. In
summary, our analysis of the dynamics of SGD in the subspace of the sharpest
directions shows that they influence the regions that SGD steers to (where
larger learning rate or smaller batch size result in wider regions visited),
the overall training speed, and the generalization ability of the final model.","['Stanisław Jastrzębski', 'Zachary Kenton', 'Nicolas Ballas', 'Asja Fischer', 'Yoshua Bengio', 'Amos Storkey']","['stat.ML', 'cs.LG']",2018-07-13 12:17:41+00:00
http://arxiv.org/abs/1807.05027v1,Are generative deep models for novelty detection truly better?,"Many deep models have been recently proposed for anomaly detection. This
paper presents comparison of selected generative deep models and classical
anomaly detection methods on an extensive number of non--image benchmark
datasets. We provide statistical comparison of the selected models, in many
configurations, architectures and hyperparamaters. We arrive to conclusion that
performance of the generative models is determined by the process of selection
of their hyperparameters. Specifically, performance of the deep generative
models deteriorates with decreasing amount of anomalous samples used in
hyperparameter selection. In practical scenarios of anomaly detection, none of
the deep generative models systematically outperforms the kNN.","['Vít Škvára', 'Tomáš Pevný', 'Václav Šmídl']","['cs.LG', 'stat.ML']",2018-07-13 12:05:25+00:00
http://arxiv.org/abs/1807.04950v1,Deep Learning in the Wild,"Deep learning with neural networks is applied by an increasing number of
people outside of classic research environments, due to the vast success of the
methodology on a wide range of machine perception tasks. While this interest is
fueled by beautiful success stories, practical work in deep learning on novel
tasks without existing baselines remains challenging. This paper explores the
specific challenges arising in the realm of real world tasks, based on case
studies from research \& development in conjunction with industry, and extracts
lessons learned from them. It thus fills a gap between the publication of
latest algorithmic and methodical developments, and the usually omitted
nitty-gritty of how to make them work. Specifically, we give insight into deep
learning projects on face matching, print media monitoring, industrial quality
control, music scanning, strategy game playing, and automated machine learning,
thereby providing best practices for deep learning in practice.","['Thilo Stadelmann', 'Mohammadreza Amirian', 'Ismail Arabaci', 'Marek Arnold', 'Gilbert François Duivesteijn', 'Ismail Elezi', 'Melanie Geiger', 'Stefan Lörwald', 'Benjamin Bruno Meier', 'Katharina Rombach', 'Lukas Tuggener']","['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']",2018-07-13 07:22:45+00:00
http://arxiv.org/abs/1807.04936v3,Non-Gaussian Component Analysis using Entropy Methods,"Non-Gaussian component analysis (NGCA) is a problem in multidimensional data
analysis which, since its formulation in 2006, has attracted considerable
attention in statistics and machine learning. In this problem, we have a random
variable $X$ in $n$-dimensional Euclidean space. There is an unknown subspace
$\Gamma$ of the $n$-dimensional Euclidean space such that the orthogonal
projection of $X$ onto $\Gamma$ is standard multidimensional Gaussian and the
orthogonal projection of $X$ onto $\Gamma^{\perp}$, the orthogonal complement
of $\Gamma$, is non-Gaussian, in the sense that all its one-dimensional
marginals are different from the Gaussian in a certain metric defined in terms
of moments. The NGCA problem is to approximate the non-Gaussian subspace
$\Gamma^{\perp}$ given samples of $X$.
  Vectors in $\Gamma^{\perp}$ correspond to `interesting' directions, whereas
vectors in $\Gamma$ correspond to the directions where data is very noisy. The
most interesting applications of the NGCA model is for the case when the
magnitude of the noise is comparable to that of the true signal, a setting in
which traditional noise reduction techniques such as PCA don't apply directly.
NGCA is also related to dimension reduction and to other data analysis problems
such as ICA. NGCA-like problems have been studied in statistics for a long time
using techniques such as projection pursuit.
  We give an algorithm that takes polynomial time in the dimension $n$ and has
an inverse polynomial dependence on the error parameter measuring the angle
distance between the non-Gaussian subspace and the subspace output by the
algorithm. Our algorithm is based on relative entropy as the contrast function
and fits under the projection pursuit framework. The techniques we develop for
analyzing our algorithm maybe of use for other related problems.","['Navin Goyal', 'Abhishek Shetty']","['cs.LG', 'cs.DS', 'cs.IT', 'math.IT', 'stat.ML']",2018-07-13 06:47:06+00:00
http://arxiv.org/abs/1807.04932v2,Sequential sampling of Gaussian process latent variable models,"We consider the problem of inferring a latent function in a probabilistic
model of data. When dependencies of the latent function are specified by a
Gaussian process and the data likelihood is complex, efficient computation
often involve Markov chain Monte Carlo sampling with limited applicability to
large data sets. We extend some of these techniques to scale efficiently when
the problem exhibits a sequential structure. We propose an approximation that
enables sequential sampling of both latent variables and associated parameters.
We demonstrate strong performance in growing-data settings that would otherwise
be unfeasible with naive, non-sequential sampling.","['Martin Tegner', 'Benjamin Bloem-Reddy', 'Stephen Roberts']","['stat.ML', 'cs.LG']",2018-07-13 06:38:21+00:00
http://arxiv.org/abs/1807.04919v1,TequilaGAN: How to easily identify GAN samples,"In this paper we show strategies to easily identify fake samples generated
with the Generative Adversarial Network framework. One strategy is based on the
statistical analysis and comparison of raw pixel values and features extracted
from them. The other strategy learns formal specifications from the real data
and shows that fake samples violate the specifications of the real data. We
show that fake samples produced with GANs have a universal signature that can
be used to identify fake samples. We provide results on MNIST, CIFAR10, music
and speech data.","['Rafael Valle', 'Wilson Cai', 'Anish Doshi']","['cs.LG', 'cs.CV', 'stat.ML']",2018-07-13 05:25:54+00:00
http://arxiv.org/abs/1807.04863v2,Avoiding Latent Variable Collapse With Generative Skip Models,"Variational autoencoders learn distributions of high-dimensional data. They
model data with a deep latent-variable model and then fit the model by
maximizing a lower bound of the log marginal likelihood. VAEs can capture
complex distributions, but they can also suffer from an issue known as ""latent
variable collapse,"" especially if the likelihood model is powerful.
Specifically, the lower bound involves an approximate posterior of the latent
variables; this posterior ""collapses"" when it is set equal to the prior, i.e.,
when the approximate posterior is independent of the data. While VAEs learn
good generative models, latent variable collapse prevents them from learning
useful representations. In this paper, we propose a simple new way to avoid
latent variable collapse by including skip connections in our generative model;
these connections enforce strong links between the latent variables and the
likelihood function. We study generative skip models both theoretically and
empirically. Theoretically, we prove that skip models increase the mutual
information between the observations and the inferred latent variables.
Empirically, we study images (MNIST and Omniglot) and text (Yahoo). Compared to
existing VAE architectures, we show that generative skip models maintain
similar predictive performance but lead to less collapse and provide more
meaningful representations of the data.","['Adji B. Dieng', 'Yoon Kim', 'Alexander M. Rush', 'David M. Blei']","['stat.ML', 'cs.CL', 'cs.LG']",2018-07-12 23:37:27+00:00
http://arxiv.org/abs/1807.04855v4,A feature agnostic approach for glaucoma detection in OCT volumes,"Optical coherence tomography (OCT) based measurements of retinal layer
thickness, such as the retinal nerve fibre layer (RNFL) and the ganglion cell
with inner plexiform layer (GCIPL) are commonly used for the diagnosis and
monitoring of glaucoma. Previously, machine learning techniques have utilized
segmentation-based imaging features such as the peripapillary RNFL thickness
and the cup-to-disc ratio. Here, we propose a deep learning technique that
classifies eyes as healthy or glaucomatous directly from raw, unsegmented OCT
volumes of the optic nerve head (ONH) using a 3D Convolutional Neural Network
(CNN). We compared the accuracy of this technique with various feature-based
machine learning algorithms and demonstrated the superiority of the proposed
deep learning based method.
  Logistic regression was found to be the best performing classical machine
learning technique with an AUC of 0.89. In direct comparison, the deep learning
approach achieved a substantially higher AUC of 0.94 with the additional
advantage of providing insight into which regions of an OCT volume are
important for glaucoma detection.
  Computing Class Activation Maps (CAM), we found that the CNN identified
neuroretinal rim and optic disc cupping as well as the lamina cribrosa (LC) and
its surrounding areas as the regions significantly associated with the glaucoma
classification. These regions anatomically correspond to the well established
and commonly used clinical markers for glaucoma diagnosis such as increased cup
volume, cup diameter, and neuroretinal rim thinning at the superior and
inferior segments.","['Stefan Maetschke', 'Bhavna Antony', 'Hiroshi Ishikawa', 'Gadi Wollstein', 'Joel S. Schuman', 'Rahil Garnavi']","['cs.CV', 'cs.LG', 'stat.ML']",2018-07-12 22:57:19+00:00
http://arxiv.org/abs/1807.04833v1,DP-GP-LVM: A Bayesian Non-Parametric Model for Learning Multivariate Dependency Structures,"We present a non-parametric Bayesian latent variable model capable of
learning dependency structures across dimensions in a multivariate setting. Our
approach is based on flexible Gaussian process priors for the generative
mappings and interchangeable Dirichlet process priors to learn the structure.
The introduction of the Dirichlet process as a specific structural prior allows
our model to circumvent issues associated with previous Gaussian process latent
variable models. Inference is performed by deriving an efficient variational
bound on the marginal log-likelihood on the model.","['Andrew R. Lawrence', 'Carl Henrik Ek', 'Neill D. F. Campbell']","['stat.ML', 'cs.LG']",2018-07-12 21:32:27+00:00
http://arxiv.org/abs/1807.04801v3,Practical Obstacles to Deploying Active Learning,"Active learning (AL) is a widely-used training strategy for maximizing
predictive performance subject to a fixed annotation budget. In AL one
iteratively selects training examples for annotation, often those for which the
current model is most uncertain (by some measure). The hope is that active
sampling leads to better performance than would be achieved under independent
and identically distributed (i.i.d.) random samples. While AL has shown promise
in retrospective evaluations, these studies often ignore practical obstacles to
its use. In this paper we show that while AL may provide benefits when used
with specific models and for particular domains, the benefits of current
approaches do not generalize reliably across models and tasks. This is
problematic because in practice one does not have the opportunity to explore
and compare alternative AL strategies. Moreover, AL couples the training
dataset with the model used to guide its acquisition. We find that subsequently
training a successor model with an actively-acquired dataset does not
consistently outperform training on i.i.d. sampled data. Our findings raise the
question of whether the downsides inherent to AL are worth the modest and
inconsistent performance gains it tends to afford.","['David Lowell', 'Zachary C. Lipton', 'Byron C. Wallace']","['cs.LG', 'stat.ML']",2018-07-12 19:41:20+00:00
http://arxiv.org/abs/1807.04800v1,Feature Selection for Gender Classification in TUIK Life Satisfaction Survey,"As known, attribute selection is a method that is used before the
classification of data mining. In this study, a new data set has been created
by using attributes expressing overall satisfaction in Turkey Statistical
Institute (TSI) Life Satisfaction Survey dataset. Attributes are sorted by
Ranking search method using attribute selection algorithms in a data mining
application. These selected attributes were subjected to a classification test
with Naive Bayes and Random Forest from machine learning algorithms. The
feature selection algorithms are compared according to the number of attributes
selected and the classification accuracy rates achievable with them. In this
study, which is aimed at reducing the dataset volume, the best classification
result comes up with 3 attributes selected by the Chi2 algorithm. The best
classification rate was 73% with the Random Forest classification algorithm.","['Adil Çoban', 'Ilhan Tarımer']","['cs.LG', 'stat.ML']",2018-07-12 19:38:21+00:00
http://arxiv.org/abs/1807.04778v1,Improving on Q & A Recurrent Neural Networks Using Noun-Tagging,"Often, more time is spent on finding a model that works well, rather than
tuning the model and working directly with the dataset. Our research began as
an attempt to improve upon a simple Recurrent Neural Network for answering
""simple"" first-order questions (QA-RNN), developed by Ferhan Ture and Oliver
Jojic, from Comcast Labs, using the SimpleQuestions dataset. Their baseline
model, a bidirectional, 2-layer LSTM RNN and a GRU RNN, have accuracies of 0.94
and 0.90, for entity detection and relation prediction, respectively. We fine
tuned these models by doing substantial hyper-parameter tuning, getting
resulting accuracies of 0.70 and 0.80, for entity detection and relation
prediction, respectively. An accuracy of 0.984 was obtained on entity detection
using a 1-layer LSTM, where preprocessing was done by removing all words not
part of a noun chunk from the question. 100% of the dataset was available for
relation prediction, but only 20% of the dataset, was available for entity
detection, which we believe to be much of the reason for our initial
difficulties in replicating their result, despite the fact we were able to
improve on their entity detection results.","['Erik Partridge', 'Jack Sklar', 'Omar El-lakany']","['cs.LG', 'stat.ML']",2018-07-12 18:27:42+00:00
http://arxiv.org/abs/1807.04742v2,Visual Reinforcement Learning with Imagined Goals,"For an autonomous agent to fulfill a wide range of user-specified goals at
test time, it must be able to learn broadly applicable and general-purpose
skill repertoires. Furthermore, to provide the requisite level of generality,
these skills must handle raw sensory input such as images. In this paper, we
propose an algorithm that acquires such general-purpose skills by combining
unsupervised representation learning and reinforcement learning of
goal-conditioned policies. Since the particular goals that might be required at
test-time are not known in advance, the agent performs a self-supervised
""practice"" phase where it imagines goals and attempts to achieve them. We learn
a visual representation with three distinct purposes: sampling goals for
self-supervised practice, providing a structured transformation of raw sensory
inputs, and computing a reward signal for goal reaching. We also propose a
retroactive goal relabeling scheme to further improve the sample-efficiency of
our method. Our off-policy algorithm is efficient enough to learn policies that
operate on raw image observations and goals for a real-world robotic system,
and substantially outperforms prior techniques.","['Ashvin Nair', 'Vitchyr Pong', 'Murtaza Dalal', 'Shikhar Bahl', 'Steven Lin', 'Sergey Levine']","['cs.LG', 'cs.CV', 'cs.RO', 'stat.ML']",2018-07-12 17:51:16+00:00
http://arxiv.org/abs/1807.04740v5,Negative Momentum for Improved Game Dynamics,"Games generalize the single-objective optimization paradigm by introducing
different objective functions for different players. Differentiable games often
proceed by simultaneous or alternating gradient updates. In machine learning,
games are gaining new importance through formulations like generative
adversarial networks (GANs) and actor-critic systems. However, compared to
single-objective optimization, game dynamics are more complex and less
understood. In this paper, we analyze gradient-based methods with momentum on
simple games. We prove that alternating updates are more stable than
simultaneous updates. Next, we show both theoretically and empirically that
alternating gradient updates with a negative momentum term achieves convergence
in a difficult toy adversarial problem, but also on the notoriously difficult
to train saturating GANs.","['Gauthier Gidel', 'Reyhane Askari Hemmat', 'Mohammad Pezeshki', 'Remi Lepriol', 'Gabriel Huang', 'Simon Lacoste-Julien', 'Ioannis Mitliagkas']","['cs.LG', 'stat.ML', 'I.2.6; G.1.6']",2018-07-12 17:46:56+00:00
http://arxiv.org/abs/1807.04734v1,Scalable Convolutional Dictionary Learning with Constrained Recurrent Sparse Auto-encoders,"Given a convolutional dictionary underlying a set of observed signals, can a
carefully designed auto-encoder recover the dictionary in the presence of
noise? We introduce an auto-encoder architecture, termed constrained recurrent
sparse auto-encoder (CRsAE), that answers this question in the affirmative.
Given an input signal and an approximate dictionary, the encoder finds a sparse
approximation using FISTA. The decoder reconstructs the signal by applying the
dictionary to the output of the encoder. The encoder and decoder in CRsAE
parallel the sparse-coding and dictionary update steps in optimization-based
alternating-minimization schemes for dictionary learning. As such, the
parameters of the encoder and decoder are not independent, a constraint which
we enforce for the first time. We derive the back-propagation algorithm for
CRsAE. CRsAE is a framework for blind source separation that, only knowing the
number of sources (dictionary elements), and assuming sparsely-many can
overlap, is able to separate them. We demonstrate its utility in the context of
spike sorting, a source separation problem in computational neuroscience. We
demonstrate the ability of CRsAE to recover the underlying dictionary and
characterize its sensitivity as a function of SNR.","['Bahareh Tolooshams', 'Sourav Dey', 'Demba Ba']","['cs.LG', 'stat.ML']",2018-07-12 17:18:37+00:00
http://arxiv.org/abs/1807.04723v1,The Bottleneck Simulator: A Model-based Deep Reinforcement Learning Approach,"Deep reinforcement learning has recently shown many impressive successes.
However, one major obstacle towards applying such methods to real-world
problems is their lack of data-efficiency. To this end, we propose the
Bottleneck Simulator: a model-based reinforcement learning method which
combines a learned, factorized transition model of the environment with rollout
simulations to learn an effective policy from few examples. The learned
transition model employs an abstract, discrete (bottleneck) state, which
increases sample efficiency by reducing the number of model parameters and by
exploiting structural properties of the environment. We provide a mathematical
analysis of the Bottleneck Simulator in terms of fixed points of the learned
policy, which reveals how performance is affected by four distinct sources of
error: an error related to the abstract space structure, an error related to
the transition model estimation variance, an error related to the transition
model estimation bias, and an error related to the transition model class bias.
Finally, we evaluate the Bottleneck Simulator on two natural language
processing tasks: a text adventure game and a real-world, complex dialogue
response selection task. On both tasks, the Bottleneck Simulator yields
excellent performance beating competing approaches.","['Iulian Vlad Serban', 'Chinnadhurai Sankar', 'Michael Pieper', 'Joelle Pineau', 'Yoshua Bengio']","['cs.LG', 'cs.AI', 'cs.CL', 'cs.NE', 'stat.ML', 'I.5.1; I.2.7']",2018-07-12 16:59:28+00:00
http://arxiv.org/abs/1807.04720v3,A Large-Scale Study on Regularization and Normalization in GANs,"Generative adversarial networks (GANs) are a class of deep generative models
which aim to learn a target distribution in an unsupervised fashion. While they
were successfully applied to many problems, training a GAN is a notoriously
challenging task and requires a significant number of hyperparameter tuning,
neural architecture engineering, and a non-trivial amount of ""tricks"". The
success in many practical applications coupled with the lack of a measure to
quantify the failure modes of GANs resulted in a plethora of proposed losses,
regularization and normalization schemes, as well as neural architectures. In
this work we take a sober view of the current state of GANs from a practical
perspective. We discuss and evaluate common pitfalls and reproducibility
issues, open-source our code on Github, and provide pre-trained models on
TensorFlow Hub.","['Karol Kurach', 'Mario Lucic', 'Xiaohua Zhai', 'Marcin Michalski', 'Sylvain Gelly']","['cs.LG', 'stat.ML']",2018-07-12 16:56:50+00:00
http://arxiv.org/abs/1807.04715v2,Orthogonal Matching Pursuit for Text Classification,"In text classification, the problem of overfitting arises due to the high
dimensionality, making regularization essential. Although classic regularizers
provide sparsity, they fail to return highly accurate models. On the contrary,
state-of-the-art group-lasso regularizers provide better results at the expense
of low sparsity. In this paper, we apply a greedy variable selection algorithm,
called Orthogonal Matching Pursuit, for the text classification task. We also
extend standard group OMP by introducing overlapping Group OMP to handle
overlapping groups of features. Empirical analysis verifies that both OMP and
overlapping GOMP constitute powerful regularizers, able to produce effective
and very sparse models. Code and data are available online:
https://github.com/y3nk0/OMP-for-Text-Classification .","['Konstantinos Skianis', 'Nikolaos Tziortziotis', 'Michalis Vazirgiannis']","['cs.LG', 'cs.CL', 'stat.ML']",2018-07-12 16:43:32+00:00
http://arxiv.org/abs/1807.04709v3,Inferring Multidimensional Rates of Aging from Cross-Sectional Data,"Modeling how individuals evolve over time is a fundamental problem in the
natural and social sciences. However, existing datasets are often
cross-sectional with each individual observed only once, making it impossible
to apply traditional time-series methods. Motivated by the study of human
aging, we present an interpretable latent-variable model that learns temporal
dynamics from cross-sectional data. Our model represents each individual's
features over time as a nonlinear function of a low-dimensional,
linearly-evolving latent state. We prove that when this nonlinear function is
constrained to be order-isomorphic, the model family is identifiable solely
from cross-sectional data provided the distribution of time-independent
variation is known. On the UK Biobank human health dataset, our model
reconstructs the observed data while learning interpretable rates of aging
associated with diseases, mortality, and aging risk factors.","['Emma Pierson', 'Pang Wei Koh', 'Tatsunori Hashimoto', 'Daphne Koller', 'Jure Leskovec', 'Nicholas Eriksson', 'Percy Liang']","['cs.LG', 'stat.ML']",2018-07-12 16:27:40+00:00
http://arxiv.org/abs/1807.04689v1,Explorations in Homeomorphic Variational Auto-Encoding,"The manifold hypothesis states that many kinds of high-dimensional data are
concentrated near a low-dimensional manifold. If the topology of this data
manifold is non-trivial, a continuous encoder network cannot embed it in a
one-to-one manner without creating holes of low density in the latent space.
This is at odds with the Gaussian prior assumption typically made in
Variational Auto-Encoders (VAEs), because the density of a Gaussian
concentrates near a blob-like manifold.
  In this paper we investigate the use of manifold-valued latent variables.
Specifically, we focus on the important case of continuously differentiable
symmetry groups (Lie groups), such as the group of 3D rotations
$\operatorname{SO}(3)$. We show how a VAE with $\operatorname{SO}(3)$-valued
latent variables can be constructed, by extending the reparameterization trick
to compact connected Lie groups. Our experiments show that choosing
manifold-valued latent variables that match the topology of the latent data
manifold, is crucial to preserve the topological structure and learn a
well-behaved latent space.","['Luca Falorsi', 'Pim de Haan', 'Tim R. Davidson', 'Nicola De Cao', 'Maurice Weiler', 'Patrick Forré', 'Taco S. Cohen']","['stat.ML', 'cs.LG']",2018-07-12 15:55:55+00:00
http://arxiv.org/abs/1807.04687v1,Making Efficient Use of a Domain Expert's Time in Relation Extraction,"Scarcity of labeled data is one of the most frequent problems faced in
machine learning. This is particularly true in relation extraction in text
mining, where large corpora of texts exists in many application domains, while
labeling of text data requires an expert to invest much time to read the
documents. Overall, state-of-the art models, like the convolutional neural
network used in this paper, achieve great results when trained on large enough
amounts of labeled data. However, from a practical point of view the question
arises whether this is the most efficient approach when one takes the manual
effort of the expert into account. In this paper, we report on an alternative
approach where we first construct a relation extraction model using distant
supervision, and only later make use of a domain expert to refine the results.
Distant supervision provides a mean of labeling data given known relations in a
knowledge base, but it suffers from noisy labeling. We introduce an active
learning based extension, that allows our neural network to incorporate expert
feedback and report on first results on a complex data set.","['Linara Adilova', 'Sven Giesselbach', 'Stefan Rüping']","['cs.LG', 'cs.CL', 'stat.ML']",2018-07-12 15:53:29+00:00
http://arxiv.org/abs/1807.04680v1,Unseeded low-rank graph matching by transform-based unsupervised point registration,"The problem of learning a correspondence relationship between nodes of two
networks has drawn much attention of the computer science community and
recently that of statisticians. The unseeded version of this problem, in which
we do not know any part of the true correspondence, is a long-standing
challenge. For low-rank networks, the problem can be translated into an
unsupervised point registration problem, in which two point sets generated from
the same distribution are matchable by an unknown orthonormal transformation.
Conventional methods generally lack consistency guarantee and are usually
computationally costly.
  In this paper, we propose a novel approach to this problem. Instead of
simultaneously estimating the unknown correspondence and orthonormal
transformation to match up the two point sets, we match their distributions via
minimizing our designed loss function capturing the discrepancy between their
Laplace transforms, thus avoiding the optimization over all possible
correspondences. This dramatically reduces the dimension of the optimization
problem from $\Omega(n^2)$ parameters to $O(d^2)$ parameters, where $d$ is the
fixed rank, and enables convenient theoretical analysis. In this paper, we
provide arguably the first consistency guarantee and explicit error rate for
general low-rank models. Our method provides control over the computational
complexity ranging from $\omega(n)$ (any growth rate faster than $n$) to
$O(n^2)$ while pertaining consistency. We demonstrate the effectiveness of our
method through several numerical examples.",['Yuan Zhang'],"['stat.ME', 'cs.LG', 'stat.ML']",2018-07-12 15:37:32+00:00
http://arxiv.org/abs/1807.04662v1,Scikit-Multiflow: A Multi-output Streaming Framework,"Scikit-multiflow is a multi-output/multi-label and stream data mining
framework for the Python programming language. Conceived to serve as a platform
to encourage democratization of stream learning research, it provides multiple
state of the art methods for stream learning, stream generators and evaluators.
scikit-multiflow builds upon popular open source frameworks including
scikit-learn, MOA and MEKA. Development follows the FOSS principles and quality
is enforced by complying with PEP8 guidelines and using continuous integration
and automatic testing. The source code is publicly available at
https://github.com/scikit-multiflow/scikit-multiflow.","['Jacob Montiel', 'Jesse Read', 'Albert Bifet', 'Talel Abdessalem']","['cs.LG', 'stat.ML']",2018-07-12 15:03:13+00:00
http://arxiv.org/abs/1807.05076v1,Metalearning with Hebbian Fast Weights,"We unify recent neural approaches to one-shot learning with older ideas of
associative memory in a model for metalearning. Our model learns jointly to
represent data and to bind class labels to representations in a single shot. It
builds representations via slow weights, learned across tasks through SGD,
while fast weights constructed by a Hebbian learning rule implement one-shot
binding for each new task. On the Omniglot, Mini-ImageNet, and Penn Treebank
one-shot learning benchmarks, our model achieves state-of-the-art results.","['Tsendsuren Munkhdalai', 'Adam Trischler']","['cs.NE', 'cs.AI', 'cs.LG', 'stat.ML']",2018-07-12 14:40:06+00:00
http://arxiv.org/abs/1807.04640v2,Automatically Composing Representation Transformations as a Means for Generalization,"A generally intelligent learner should generalize to more complex tasks than
it has previously encountered, but the two common paradigms in machine learning
-- either training a separate learner per task or training a single learner for
all tasks -- both have difficulty with such generalization because they do not
leverage the compositional structure of the task distribution. This paper
introduces the compositional problem graph as a broadly applicable formalism to
relate tasks of different complexity in terms of problems with shared
subproblems. We propose the compositional generalization problem for measuring
how readily old knowledge can be reused and hence built upon. As a first step
for tackling compositional generalization, we introduce the compositional
recursive learner, a domain-general framework for learning algorithmic
procedures for composing representation transformations, producing a learner
that reasons about what computation to execute by making analogies to
previously seen problems. We show on a symbolic and a high-dimensional domain
that our compositional approach can generalize to more complex problems than
the learner has previously encountered, whereas baselines that are not
explicitly compositional do not.","['Michael B. Chang', 'Abhishek Gupta', 'Sergey Levine', 'Thomas L. Griffiths']","['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']",2018-07-12 14:33:49+00:00
http://arxiv.org/abs/1807.04602v1,Rule Induction Partitioning Estimator,"RIPE is a novel deterministic and easily understandable prediction algorithm
developed for continuous and discrete ordered data. It infers a model, from a
sample, to predict and to explain a real variable $Y$ given an input variable
$X \in \mathcal X$ (features). The algorithm extracts a sparse set of
hyperrectangles $\mathbf r \subset \mathcal X$, which can be thought of as
rules of the form If-Then. This set is then turned into a partition of the
features space $\mathcal X$ of which each cell is explained as a list of rules
with satisfied their If conditions. The process of RIPE is illustrated on
simulated datasets and its efficiency compared with that of other usual
algorithms.","['Vincent Margot', 'Jean-Patrick Baudry', 'Frederic Guilloux', 'Olivier Wintenberger']","['stat.ML', 'cs.LG']",2018-07-12 13:38:05+00:00
http://arxiv.org/abs/1807.04594v1,The Incremental Proximal Method: A Probabilistic Perspective,"In this work, we highlight a connection between the incremental proximal
method and stochastic filters. We begin by showing that the proximal operators
coincide, and hence can be realized with, Bayes updates. We give the explicit
form of the updates for the linear regression problem and show that there is a
one-to-one correspondence between the proximal operator of the least-squares
regression and the Bayes update when the prior and the likelihood are Gaussian.
We then carry out this observation to a general sequential setting: We consider
the incremental proximal method, which is an algorithm for large-scale
optimization, and show that, for a linear-quadratic cost function, it can
naturally be realized by the Kalman filter. We then discuss the implications of
this idea for nonlinear optimization problems where proximal operators are in
general not realizable. In such settings, we argue that the extended Kalman
filter can provide a systematic way for the derivation of practical procedures.","['Ömer Deniz Akyildiz', 'Victor Elvira', 'Joaquin Miguez']","['stat.CO', 'math.OC', 'stat.ML']",2018-07-12 13:16:42+00:00
http://arxiv.org/abs/1807.04587v2,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures,"The backpropagation of error algorithm (BP) is impossible to implement in a
real brain. The recent success of deep networks in machine learning and AI,
however, has inspired proposals for understanding how the brain might learn
across multiple layers, and hence how it might approximate BP. As of yet, none
of these proposals have been rigorously evaluated on tasks where BP-guided deep
learning has proved critical, or in architectures more structured than simple
fully-connected networks. Here we present results on scaling up biologically
motivated models of deep learning on datasets which need deep networks with
appropriate architectures to achieve good performance. We present results on
the MNIST, CIFAR-10, and ImageNet datasets and explore variants of
target-propagation (TP) and feedback alignment (FA) algorithms, and explore
performance in both fully- and locally-connected architectures. We also
introduce weight-transport-free variants of difference target propagation (DTP)
modified to remove backpropagation from the penultimate layer. Many of these
algorithms perform well for MNIST, but for CIFAR and ImageNet we find that TP
and FA variants perform significantly worse than BP, especially for networks
composed of locally connected units, opening questions about whether new
architectures and algorithms are required to scale these approaches. Our
results and implementation details help establish baselines for biologically
motivated deep learning schemes going forward.","['Sergey Bartunov', 'Adam Santoro', 'Blake A. Richards', 'Luke Marris', 'Geoffrey E. Hinton', 'Timothy Lillicrap']","['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']",2018-07-12 12:53:50+00:00
http://arxiv.org/abs/1807.04585v2,Deep Learning for Imbalance Data Classification using Class Expert Generative Adversarial Network,"Without any specific way for imbalance data classification, artificial
intelligence algorithm cannot recognize data from minority classes easily. In
general, modifying the existing algorithm by assuming that the training data is
imbalanced, is the only way to handle imbalance data. However, for a normal
data handling, this way mostly produces a deficient result. In this research,
we propose a class expert generative adversarial network (CE-GAN) as the
solution for imbalance data classification. CE-GAN is a modification in deep
learning algorithm architecture that does not have an assumption that the
training data is imbalance data. Moreover, CE-GAN is designed to identify more
detail about the character of each class before classification step. CE-GAN has
been proved in this research to give a good performance for imbalance data
classification.","['Fanny', 'Tjeng Wawan Cenggoro']","['cs.LG', 'cs.CV', 'stat.ML']",2018-07-12 12:51:24+00:00
http://arxiv.org/abs/1807.04566v1,Decentralized Clustering on Compressed Data without Prior Knowledge of the Number of Clusters,"In sensor networks, it is not always practical to set up a fusion center.
Therefore, there is need for fully decentralized clustering algorithms.
Decentralized clustering algorithms should minimize the amount of data
exchanged between sensors in order to reduce sensor energy consumption. In this
respect, we propose one centralized and one decentralized clustering algorithm
that work on compressed data without prior knowledge of the number of clusters.
In the standard K-means clustering algorithm, the number of clusters is
estimated by repeating the algorithm several times, which dramatically
increases the amount of exchanged data, while our algorithm can estimate this
number in one run.
  The proposed clustering algorithms derive from a theoretical framework
establishing that, under asymptotic conditions, the cluster centroids are the
only fixed-point of a cost function we introduce. This cost function depends on
a weight function which we choose as the p-value of a Wald hypothesis test.
This p-value measures the plausibility that a given measurement vector belongs
to a given cluster. Experimental results show that our two algorithms are
competitive in terms of clustering performance with respect to K-means and
DB-Scan, while lowering by a factor at least $2$ the amount of data exchanged
between sensors.","['Elsa Dupraz', 'Dominique Pastor', 'François-Xavier Socheleau']","['stat.ML', 'cs.LG']",2018-07-12 12:20:05+00:00
http://arxiv.org/abs/1807.05077v2,Maximizing Invariant Data Perturbation with Stochastic Optimization,"Feature attribution methods, or saliency maps, are one of the most popular
approaches for explaining the decisions of complex machine learning models such
as deep neural networks. In this study, we propose a stochastic optimization
approach for the perturbation-based feature attribution method. While the
original optimization problem of the perturbation-based feature attribution is
difficult to solve because of the complex constraints, we propose to
reformulate the problem as the maximization of a differentiable function, which
can be solved using gradient-based algorithms. In particular, stochastic
optimization is well-suited for the proposed reformulation, and we can solve
the problem using popular algorithms such as SGD, RMSProp, and Adam. The
experiment on the image classification with VGG16 shows that the proposed
method could identify relevant parts of the images effectively.","['Kouichi Ikeno', 'Satoshi Hara']","['stat.ML', 'cs.LG']",2018-07-12 11:47:17+00:00
http://arxiv.org/abs/1807.04551v1,A Constrained Randomized Shortest-Paths Framework for Optimal Exploration,"The present work extends the randomized shortest-paths framework (RSP),
interpolating between shortest-path and random-walk routing in a network, in
three directions. First, it shows how to deal with equality constraints on a
subset of transition probabilities and develops a generic algorithm for solving
this constrained RSP problem using Lagrangian duality. Second, it derives a
surprisingly simple iterative procedure to compute the optimal, randomized,
routing policy generalizing the previously developed ""soft"" Bellman-Ford
algorithm. The resulting algorithm allows balancing exploitation and
exploration in an optimal way by interpolating between a pure random behavior
and the deterministic, optimal, policy (least-cost paths) while satisfying the
constraints. Finally, the two algorithms are applied to Markov decision
problems by considering the process as a constrained RSP on a bipartite
state-action graph. In this context, the derived ""soft"" value iteration
algorithm appears to be closely related to dynamic policy programming as well
as Kullback-Leibler and path integral control, and similar to a recently
introduced reinforcement learning exploration strategy. This shows that this
strategy is optimal in the RSP sense - it minimizes expected path cost subject
to relative entropy constraint. Simulation results on illustrative examples
show that the model behaves as expected.","['Bertrand Lebichot', 'Guillaume Guex', 'Ilkka Kivimäki', 'Marco Saerens']","['cs.LG', 'cs.AI', 'stat.ML']",2018-07-12 11:42:04+00:00
http://arxiv.org/abs/1807.04511v5,Training Neural Networks Using Features Replay,"Training a neural network using backpropagation algorithm requires passing
error gradients sequentially through the network. The backward locking prevents
us from updating network layers in parallel and fully leveraging the computing
resources. Recently, there are several works trying to decouple and parallelize
the backpropagation algorithm. However, all of them suffer from severe accuracy
loss or memory explosion when the neural network is deep. To address these
challenging issues, we propose a novel parallel-objective formulation for the
objective function of the neural network. After that, we introduce features
replay algorithm and prove that it is guaranteed to converge to critical points
for the non-convex problem under certain conditions. Finally, we apply our
method to training deep convolutional neural networks, and the experimental
results show that the proposed method achieves {faster} convergence, {lower}
memory consumption, and {better} generalization error than compared methods.","['Zhouyuan Huo', 'Bin Gu', 'Heng Huang']","['cs.LG', 'stat.ML']",2018-07-12 10:14:50+00:00
http://arxiv.org/abs/1807.04489v2,Fast yet Simple Natural-Gradient Descent for Variational Inference in Complex Models,"Bayesian inference plays an important role in advancing machine learning, but
faces computational challenges when applied to complex models such as deep
neural networks. Variational inference circumvents these challenges by
formulating Bayesian inference as an optimization problem and solving it using
gradient-based optimization. In this paper, we argue in favor of
natural-gradient approaches which, unlike their gradient-based counterparts,
can improve convergence by exploiting the information geometry of the
solutions. We show how to derive fast yet simple natural-gradient updates by
using a duality associated with exponential-family distributions. An attractive
feature of these methods is that, by using natural-gradients, they are able to
extract accurate local approximations for individual model components. We
summarize recent results for Bayesian deep learning showing the superiority of
natural-gradient approaches over their gradient counterparts.","['Mohammad Emtiyaz Khan', 'Didrik Nielsen']","['stat.ML', 'cs.IT', 'cs.LG', 'math.IT', 'stat.CO']",2018-07-12 09:15:46+00:00
http://arxiv.org/abs/1807.04457v1,Query-Efficient Hard-label Black-box Attack:An Optimization-based Approach,"We study the problem of attacking a machine learning model in the hard-label
black-box setting, where no model information is revealed except that the
attacker can make queries to probe the corresponding hard-label decisions. This
is a very challenging problem since the direct extension of state-of-the-art
white-box attacks (e.g., CW or PGD) to the hard-label black-box setting will
require minimizing a non-continuous step function, which is combinatorial and
cannot be solved by a gradient-based optimizer. The only current approach is
based on random walk on the boundary, which requires lots of queries and lacks
convergence guarantees. We propose a novel way to formulate the hard-label
black-box attack as a real-valued optimization problem which is usually
continuous and can be solved by any zeroth order optimization algorithm. For
example, using the Randomized Gradient-Free method, we are able to bound the
number of iterations needed for our algorithm to achieve stationary points. We
demonstrate that our proposed method outperforms the previous random walk
approach to attacking convolutional neural networks on MNIST, CIFAR, and
ImageNet datasets. More interestingly, we show that the proposed algorithm can
also be used to attack other discrete and non-continuous machine learning
models, such as Gradient Boosting Decision Trees (GBDT).","['Minhao Cheng', 'Thong Le', 'Pin-Yu Chen', 'Jinfeng Yi', 'Huan Zhang', 'Cho-Jui Hsieh']","['cs.LG', 'cs.AI', 'stat.ML']",2018-07-12 08:04:27+00:00
http://arxiv.org/abs/1807.04439v1,Will it Blend? Composing Value Functions in Reinforcement Learning,"An important property for lifelong-learning agents is the ability to combine
existing skills to solve unseen tasks. In general, however, it is unclear how
to compose skills in a principled way. We provide a ""recipe"" for optimal value
function composition in entropy-regularised reinforcement learning (RL) and
then extend this to the standard RL setting. Composition is demonstrated in a
video game environment, where an agent with an existing library of policies is
able to solve new tasks without the need for further learning.","['Benjamin van Niekerk', 'Steven James', 'Adam Earle', 'Benjamin Rosman']","['cs.LG', 'stat.ML']",2018-07-12 06:43:12+00:00
http://arxiv.org/abs/1807.04431v2,Statistical Inference with Local Optima,"We study the statistical properties of an estimator derived by applying a
gradient ascent method with multiple initializations to a multi-modal
likelihood function. We derive the population quantity that is the target of
this estimator and study the properties of confidence intervals (CIs)
constructed from asymptotic normality and the bootstrap approach. In
particular, we analyze the coverage deficiency due to finite number of random
initializations. We also investigate the CIs by inverting the likelihood ratio
test, the score test, and the Wald test, and we show that the resulting CIs may
be very different. We propose a two-sample test procedure even when the MLE is
intractable. In addition, we analyze the performance of the EM algorithm under
random initializations and derive the coverage of a CI with a finite number of
initializations.",['Yen-Chi Chen'],"['math.ST', 'stat.ME', 'stat.ML', 'stat.TH']",2018-07-12 06:08:33+00:00
http://arxiv.org/abs/1807.04428v2,Convergence Rate of Block-Coordinate Maximization Burer-Monteiro Method for Solving Large SDPs,"Semidefinite programming (SDP) with diagonal constraints arise in many
optimization problems, such as Max-Cut, community detection and group
synchronization. Although SDPs can be solved to arbitrary precision in
polynomial time, generic convex solvers do not scale well with the dimension of
the problem. In order to address this issue, Burer and Monteiro proposed to
reduce the dimension of the problem by appealing to a low-rank factorization
and solve the subsequent non-convex problem instead. In this paper, we present
coordinate ascent based methods to solve this non-convex problem with provable
convergence guarantees. More specifically, we prove that the block-coordinate
maximization algorithm applied to the non-convex Burer-Monteiro method globally
converges to a first-order stationary point with a sublinear rate without any
assumptions on the problem. We further show that this algorithm converges
linearly around a local maximum provided that the objective function exhibits
quadratic decay. We establish that this condition generically holds when the
rank of the factorization is sufficiently large. Furthermore, incorporating
Lanczos method to the block-coordinate maximization, we propose an algorithm
that is guaranteed to return a solution that provides $1-O(1/r)$ approximation
to the original SDP without any assumptions, where $r$ is the rank of the
factorization. This approximation ratio is known to be optimal (up to
constants) under the unique games conjecture, and we can explicitly quantify
the number of iterations to obtain such a solution.","['Murat A. Erdogdu', 'Asuman Ozdaglar', 'Pablo A. Parrilo', 'Nuri Denizcan Vanli']","['math.OC', 'cs.LG', 'stat.ML']",2018-07-12 05:18:11+00:00
http://arxiv.org/abs/1807.04427v3,Simultaneous Coherent Structure Coloring facilitates interpretable clustering of scientific data by amplifying dissimilarity,"The clustering of data into physically meaningful subsets often requires
assumptions regarding the number, size, or shape of the subgroups. Here, we
present a new method, simultaneous coherent structure coloring (sCSC), which
accomplishes the task of unsupervised clustering without a priori guidance
regarding the underlying structure of the data. sCSC performs a sequence of
binary splittings on the dataset such that the most dissimilar data points are
required to be in separate clusters. To achieve this, we obtain a set of
orthogonal coordinates along which dissimilarity in the dataset is maximized
from a generalized eigenvalue problem based on the pairwise dissimilarity
between the data points to be clustered. This sequence of bifurcations produces
a binary tree representation of the system, from which the number of clusters
in the data and their interrelationships naturally emerge. To illustrate the
effectiveness of the method in the absence of a priori assumptions, we apply it
to three exemplary problems in fluid dynamics. Then, we illustrate its capacity
for interpretability using a high-dimensional protein folding simulation
dataset. While we restrict our examples to dynamical physical systems in this
work, we anticipate straightforward translation to other fields where existing
analysis tools require ad hoc assumptions on the data structure, lack the
interpretability of the present method, or in which the underlying processes
are less accessible, such as genomics and neuroscience.","['Brooke E. Husic', 'Kristy L. Schlueter-Kuck', 'John O. Dabiri']","['stat.ML', 'cs.LG', 'physics.bio-ph', 'physics.flu-dyn', 'q-bio.QM']",2018-07-12 05:14:45+00:00
http://arxiv.org/abs/1807.09751v1,Multi-Perspective Neural Architecture for Recommendation System,"Currently, there starts a research trend to leverage neural architecture for
recommendation systems. Though several deep recommender models are proposed,
most methods are too simple to characterize users' complex preference. In this
paper, for a fine-grain analysis, users' ratings are explained from multiple
perspectives, based on which, we propose our neural architecture. Specifically,
our model employs several sequential stages to encode the user and item into
hidden representations. In one stage, the user and item are represented from
multiple perspectives and in each perspective, the representations of user and
item put attentions to each other. Last, we metric the output representations
of final stage to approach the users' rating. Extensive experiments demonstrate
that our method achieves substantial improvements against baselines.","['Han Xiao', 'Yidong Chen', 'Xiaodong Shi']","['cs.IR', 'cs.LG', 'stat.ML']",2018-07-12 05:06:39+00:00
http://arxiv.org/abs/1807.04426v2,A likelihood-ratio type test for stochastic block models with bounded degrees,"A fundamental problem in network data analysis is to test Erd\""{o}s-R\'{e}nyi
model $\mathcal{G}\left(n,\frac{a+b}{2n}\right)$ versus a bisection stochastic
block model $\mathcal{G}\left(n,\frac{a}{n},\frac{b}{n}\right)$, where $a,b>0$
are constants that represent the expected degrees of the graphs and $n$ denotes
the number of nodes. This problem serves as the foundation of many other
problems such as testing-based methods for determining the number of
communities (\cite{BS16,L16}) and community detection (\cite{MS16}). Existing
work has been focusing on growing-degree regime $a,b\to\infty$
(\cite{BS16,L16,MS16,BM17,B18,GL17a,GL17b}) while leaving the bounded-degree
regime untreated. In this paper, we propose a likelihood-ratio (LR) type
procedure based on regularization to test stochastic block models with bounded
degrees. We derive the limit distributions as power Poisson laws under both
null and alternative hypotheses, based on which the limit power of the test is
carefully analyzed. We also examine a Monte-Carlo method that partly resolves
the computational cost issue. The proposed procedures are examined by both
simulated and real-world data. The proof depends on a contiguity theory
developed by Janson \cite{J95}.","['Mingao Yuan', 'Yang Feng', 'Zuofeng Shang']","['stat.ME', 'cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2018-07-12 05:05:09+00:00
http://arxiv.org/abs/1807.04415v1,Process Discovery using Classification Tree Hidden Semi-Markov Model,"Various and ubiquitous information systems are being used in monitoring,
exchanging, and collecting information. These systems are generating massive
amount of event sequence logs that may help us understand underlying
phenomenon. By analyzing these logs, we can learn process models that describe
system procedures, predict the development of the system, or check whether the
changes are expected. In this paper, we consider a novel technique that models
these sequences of events in temporal-probabilistic manners. Specifically, we
propose a probabilistic process model that combines hidden semi-Markov model
and classification trees learning. Our experimental result shows that the
proposed approach can answer a kind of question-""what are the most frequent
sequence of system dynamics relevant to a given sequence of observable
events?"". For example, ""Given a series of medical treatments, what are the most
relevant patients' health condition pattern changes at different times?""","['Yihuang Kang', 'Vladimir Zadorozhny']","['stat.ML', 'cs.LG']",2018-07-12 04:08:44+00:00
http://arxiv.org/abs/1807.09571v1,Deep Learning Detection Networks in MIMO Decode-Forward Relay Channels,"In this paper, we consider signal detection algorithms in a multiple-input
multiple-output (MIMO) decode-forward (DF) relay channel with one source, one
relay, and one destination. The existing suboptimal near maximum likelihood
(NML) detector and the NML with two-level pair-wise error probability
(NMLw2PEP) detector achieve excellent performance with instantaneous channel
state information (CSI) of the source-relay (SR) link and with statistical CSI
of the SR link, respectively. However, the NML detectors require an
exponentially increasing complexity as the number of transmit antennas
increases. Using deep learning algorithms, NML-based detection networks
(NMLDNs) are proposed with and without the CSI of the SR link at the
destination. The NMLDNs detect signals in changing channels after a single
training using a large number of randomly distributed channels. The detection
networks require much lower detection complexity than the exhaustive search NML
detectors while exhibiting good performance. To evaluate the performance, we
introduce semidefinite relaxation detectors with polynomial complexity based on
the NML detectors. Additionally, new linear detectors based on the zero
gradient of the NML metrics are proposed. Applying various detection algorithms
at the relay (DetR) and detection algorithms at the destination (DetD), we
present some DetR-DetD methods in MIMO DF relay channels. An appropriate
DetR-DetD method can be employed according to the required error probability
and detection complexity. The complexity analysis and simulation results
validate the arguments of this paper.","['Xianglan Jin', 'Hyoung-Nam Kim']","['stat.ML', 'cs.IT', 'cs.LG', 'math.IT']",2018-07-12 02:31:37+00:00
http://arxiv.org/abs/1807.04386v1,Topic Diffusion Discovery based on Sparseness-constrained Non-negative Matrix Factorization,"Due to recent explosion of text data, researchers have been overwhelmed by
ever-increasing volume of articles produced by different research communities.
Various scholarly search websites, citation recommendation engines, and
research databases have been created to simplify the text search tasks.
However, it is still difficult for researchers to be able to identify potential
research topics without doing intensive reviews on a tremendous number of
articles published by journals, conferences, meetings, and workshops. In this
paper, we consider a novel topic diffusion discovery technique that
incorporates sparseness-constrained Non-negative Matrix Factorization with
generalized Jensen-Shannon divergence to help understand term-topic evolutions
and identify topic diffusions. Our experimental result shows that this approach
can extract more prominent topics from large article databases, visualize
relationships between terms of interest and abstract topics, and further help
researchers understand whether given terms/topics have been widely explored or
whether new topics are emerging from literature.","['Yihuang Kang', 'Keng-Pei Lin', 'I-Ling Cheng']","['cs.IR', 'cs.LG', 'stat.ML']",2018-07-12 00:31:43+00:00
http://arxiv.org/abs/1807.10574v1,"Deep Learning Hyperspectral Image Classification Using Multiple Class-based Denoising Autoencoders, Mixed Pixel Training Augmentation, and Morphological Operations","Herein, we present a system for hyperspectral image segmentation that
utilizes multiple class--based denoising autoencoders which are efficiently
trained. Moreover, we present a novel hyperspectral data augmentation method
for labelled HSI data using linear mixtures of pixels from each class, which
helps the system with edge pixels which are almost always mixed pixels.
Finally, we utilize a deep neural network and morphological hole-filling to
provide robust image classification. Results run on the Salinas dataset verify
the high performance of the proposed algorithm.","['John E. Ball', 'Pan Wei']","['cs.CV', 'cs.LG', 'stat.ML']",2018-07-11 23:49:30+00:00
http://arxiv.org/abs/1807.11573v1,State-of-the-art and gaps for deep learning on limited training data in remote sensing,"Deep learning usually requires big data, with respect to both volume and
variety. However, most remote sensing applications only have limited training
data, of which a small subset is labeled. Herein, we review three
state-of-the-art approaches in deep learning to combat this challenge. The
first topic is transfer learning, in which some aspects of one domain, e.g.,
features, are transferred to another domain. The next is unsupervised learning,
e.g., autoencoders, which operate on unlabeled data. The last is generative
adversarial networks, which can generate realistic looking data that can fool
the likes of both a deep learning network and human. The aim of this article is
to raise awareness of this dilemma, to direct the reader to existing work and
to highlight current gaps that need solving.","['John E. Ball', 'Derek T. Anderson', 'Pan Wei']","['cs.CV', 'cs.LG', 'stat.ML']",2018-07-11 23:44:50+00:00
http://arxiv.org/abs/1807.04369v2,"Differentially-Private ""Draw and Discard"" Machine Learning","In this work, we propose a novel framework for privacy-preserving
client-distributed machine learning. It is motivated by the desire to achieve
differential privacy guarantees in the local model of privacy in a way that
satisfies all systems constraints using asynchronous client-server
communication and provides attractive model learning properties. We call it
""Draw and Discard"" because it relies on random sampling of models for load
distribution (scalability), which also provides additional server-side privacy
protections and improved model quality through averaging. We present the
mechanics of client and server components of ""Draw and Discard"" and demonstrate
how the framework can be applied to learning Generalized Linear models. We then
analyze the privacy guarantees provided by our approach against several types
of adversaries and showcase experimental results that provide evidence for the
framework's viability in practical deployments.","['Vasyl Pihur', 'Aleksandra Korolova', 'Frederick Liu', 'Subhash Sankuratripati', 'Moti Yung', 'Dachuan Huang', 'Ruogu Zeng']","['cs.CR', 'cs.LG', 'stat.ML']",2018-07-11 22:28:50+00:00
http://arxiv.org/abs/1807.04320v2,Automated Vulnerability Detection in Source Code Using Deep Representation Learning,"Increasing numbers of software vulnerabilities are discovered every year
whether they are reported publicly or discovered internally in proprietary
code. These vulnerabilities can pose serious risk of exploit and result in
system compromise, information leaks, or denial of service. We leveraged the
wealth of C and C++ open-source code available to develop a large-scale
function-level vulnerability detection system using machine learning. To
supplement existing labeled vulnerability datasets, we compiled a vast dataset
of millions of open-source functions and labeled it with carefully-selected
findings from three different static analyzers that indicate potential
exploits. The labeled dataset is available at: https://osf.io/d45bw/. Using
these datasets, we developed a fast and scalable vulnerability detection tool
based on deep feature representation learning that directly interprets lexed
source code. We evaluated our tool on code from both real software packages and
the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature
representation learning on source code is a promising approach for automated
software vulnerability detection.","['Rebecca L. Russell', 'Louis Kim', 'Lei H. Hamilton', 'Tomo Lazovich', 'Jacob A. Harer', 'Onur Ozdemir', 'Paul M. Ellingwood', 'Marc W. McConley']","['cs.LG', 'cs.AI', 'cs.SE', 'stat.ML']",2018-07-11 19:29:14+00:00
http://arxiv.org/abs/1807.04307v1,Manifold regularization with GANs for semi-supervised learning,"Generative Adversarial Networks are powerful generative models that are able
to model the manifold of natural images. We leverage this property to perform
manifold regularization by approximating a variant of the Laplacian norm using
a Monte Carlo approximation that is easily computed with the GAN. When
incorporated into the semi-supervised feature-matching GAN we achieve
state-of-the-art results for GAN-based semi-supervised learning on CIFAR-10 and
SVHN benchmarks, with a method that is significantly easier to implement than
competing methods. We also find that manifold regularization improves the
quality of generated images, and is affected by the quality of the GAN used to
approximate the regularizer.","['Bruno Lecouat', 'Chuan-Sheng Foo', 'Houssam Zenati', 'Vijay Chandrasekhar']","['cs.LG', 'stat.ML']",2018-07-11 18:14:04+00:00
http://arxiv.org/abs/1807.04302v1,Structured Bayesian Gaussian process latent variable model: applications to data-driven dimensionality reduction and high-dimensional inversion,"We introduce a methodology for nonlinear inverse problems using a variational
Bayesian approach where the unknown quantity is a spatial field. A structured
Bayesian Gaussian process latent variable model is used both to construct a
low-dimensional generative model of the sample-based stochastic prior as well
as a surrogate for the forward evaluation. Its Bayesian formulation captures
epistemic uncertainty introduced by the limited number of input and output
examples, automatically selects an appropriate dimensionality for the learned
latent representation of the data, and rigorously propagates the uncertainty of
the data-driven dimensionality reduction of the stochastic space through the
forward model surrogate. The structured Gaussian process model explicitly
leverages spatial information for an informative generative prior to improve
sample efficiency while achieving computational tractability through Kronecker
product decompositions of the relevant kernel matrices. Importantly, the
Bayesian inversion is carried out by solving a variational optimization
problem, replacing traditional computationally-expensive Monte Carlo sampling.
The methodology is demonstrated on an elliptic PDE and is shown to return
well-calibrated posteriors and is tractable with latent spaces with over 100
dimensions.","['Steven Atkinson', 'Nicholas Zabaras']","['stat.ML', 'cs.LG']",2018-07-11 18:03:50+00:00
http://arxiv.org/abs/1807.04252v4,Last-Iterate Convergence: Zero-Sum Games and Constrained Min-Max Optimization,"Motivated by applications in Game Theory, Optimization, and Generative
Adversarial Networks, recent work of Daskalakis et al \cite{DISZ17} and
follow-up work of Liang and Stokes \cite{LiangS18} have established that a
variant of the widely used Gradient Descent/Ascent procedure, called
""Optimistic Gradient Descent/Ascent (OGDA)"", exhibits last-iterate convergence
to saddle points in {\em unconstrained} convex-concave min-max optimization
problems. We show that the same holds true in the more general problem of {\em
constrained} min-max optimization under a variant of the no-regret
Multiplicative-Weights-Update method called ""Optimistic Multiplicative-Weights
Update (OMWU)"". This answers an open question of Syrgkanis et al \cite{SALS15}.
  The proof of our result requires fundamentally different techniques from
those that exist in no-regret learning literature and the aforementioned
papers. We show that OMWU monotonically improves the Kullback-Leibler
divergence of the current iterate to the (appropriately normalized) min-max
solution until it enters a neighborhood of the solution. Inside that
neighborhood we show that OMWU is locally (asymptotically) stable converging to
the exact solution. We believe that our techniques will be useful in the
analysis of the last iterate of other learning algorithms.","['Constantinos Daskalakis', 'Ioannis Panageas']","['math.OC', 'cs.GT', 'stat.ML']",2018-07-11 17:20:03+00:00
http://arxiv.org/abs/1807.10573v1,LiDAR and Camera Detection Fusion in a Real Time Industrial Multi-Sensor Collision Avoidance System,"Collision avoidance is a critical task in many applications, such as ADAS
(advanced driver-assistance systems), industrial automation and robotics. In an
industrial automation setting, certain areas should be off limits to an
automated vehicle for protection of people and high-valued assets. These areas
can be quarantined by mapping (e.g., GPS) or via beacons that delineate a
no-entry area. We propose a delineation method where the industrial vehicle
utilizes a LiDAR {(Light Detection and Ranging)} and a single color camera to
detect passive beacons and model-predictive control to stop the vehicle from
entering a restricted space. The beacons are standard orange traffic cones with
a highly reflective vertical pole attached. The LiDAR can readily detect these
beacons, but suffers from false positives due to other reflective surfaces such
as worker safety vests. Herein, we put forth a method for reducing false
positive detection from the LiDAR by projecting the beacons in the camera
imagery via a deep learning method and validating the detection using a neural
network-learned projection from the camera to the LiDAR space. Experimental
data collected at Mississippi State University's Center for Advanced Vehicular
Systems (CAVS) shows the effectiveness of the proposed system in keeping the
true detection while mitigating false positives.","['Pan Wei', 'Lucas Cagle', 'Tasmia Reza', 'John Ball', 'James Gafford']","['cs.CV', 'cs.LG', 'stat.ML']",2018-07-11 16:55:09+00:00
http://arxiv.org/abs/1807.04241v2,DeepMove: Learning Place Representations through Large Scale Movement Data,"Understanding and reasoning about places and their relationships are critical
for many applications. Places are traditionally curated by a small group of
people as place gazetteers and are represented by an ID with spatial extent,
category, and other descriptions. However, a place context is described to a
large extent by movements made from/to other places. Places are linked and
related to each other by these movements. This important context is missing
from the traditional representation.
  We present DeepMove, a novel approach for learning latent representations of
places. DeepMove advances the current deep learning based place representations
by directly model movements between places. We demonstrate DeepMove's latent
representations on place categorization and clustering tasks on large place and
movement datasets with respect to important parameters. Our results show that
DeepMove outperforms state-of-the-art baselines. DeepMove's representations can
provide up to 15% higher than competing methods in matching rate of place
category and result in up to 39% higher silhouette coefficient value for place
clusters.
  DeepMove is spatial and temporal context aware. It is scalable. It
outperforms competing models using much smaller training dataset (a month or
1/12 of data). These qualities make it suitable for a broad class of real-world
applications.","['Yang Zhou', 'Yan Huang']","['cs.LG', 'stat.ML']",2018-07-11 16:47:36+00:00
http://arxiv.org/abs/1807.04239v2,Morse Code Datasets for Machine Learning,"We present an algorithm to generate synthetic datasets of tunable difficulty
on classification of Morse code symbols for supervised machine learning
problems, in particular, neural networks. The datasets are spatially
one-dimensional and have a small number of input features, leading to high
density of input information content. This makes them particularly challenging
when implementing network complexity reduction methods. We explore how network
performance is affected by deliberately adding various forms of noise and
expanding the feature set and dataset size. Finally, we establish several
metrics to indicate the difficulty of a dataset, and evaluate their merits. The
algorithm and datasets are open-source.","['Sourya Dey', 'Keith M. Chugg', 'Peter A. Beerel']","['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",2018-07-11 16:41:49+00:00
http://arxiv.org/abs/1807.04225v1,Measuring abstract reasoning in neural networks,"Whether neural networks can learn abstract reasoning or whether they merely
rely on superficial statistics is a topic of recent debate. Here, we propose a
dataset and challenge designed to probe abstract reasoning, inspired by a
well-known human IQ test. To succeed at this challenge, models must cope with
various generalisation `regimes' in which the training and test data differ in
clearly-defined ways. We show that popular models such as ResNets perform
poorly, even when the training and test sets differ only minimally, and we
present a novel architecture, with a structure designed to encourage reasoning,
that does significantly better. When we vary the way in which the test
questions and training data differ, we find that our model is notably
proficient at certain forms of generalisation, but notably weak at others. We
further show that the model's ability to generalise improves markedly if it is
trained to predict symbolic explanations for its answers. Altogether, we
introduce and explore ways to both measure and induce stronger abstract
reasoning in neural networks. Our freely-available dataset should motivate
further progress in this direction.","['David G. T. Barrett', 'Felix Hill', 'Adam Santoro', 'Ari S. Morcos', 'Timothy Lillicrap']","['cs.LG', 'stat.ML']",2018-07-11 16:14:25+00:00
http://arxiv.org/abs/1807.04222v5,Make $\ell_1$ Regularization Effective in Training Sparse CNN,"Compressed Sensing using $\ell_1$ regularization is among the most powerful
and popular sparsification technique in many applications, but why has it not
been used to obtain sparse deep learning model such as convolutional neural
network (CNN)? This paper is aimed to provide an answer to this question and to
show how to make it work. We first demonstrate that the commonly used
stochastic gradient decent (SGD) and variants training algorithm is not an
appropriate match with $\ell_1$ regularization and then replace it with a
different training algorithm based on a regularized dual averaging (RDA)
method. RDA was originally designed specifically for convex problem, but with
new theoretical insight and algorithmic modifications (using proper
initialization and adaptivity), we have made it an effective match with
$\ell_1$ regularization to achieve a state-of-the-art sparsity for CNN compared
to other weight pruning methods without compromising accuracy (achieving 95\%
sparsity for ResNet18 on CIFAR-10, for example).","['Juncai He', 'Xiaodong Jia', 'Jinchao Xu', 'Lian Zhang', 'Liang Zhao']","['cs.LG', 'stat.ML']",2018-07-11 16:06:23+00:00
http://arxiv.org/abs/1807.04193v3,Distributed Variational Representation Learning,"The problem of distributed representation learning is one in which multiple
sources of information $X_1,\ldots,X_K$ are processed separately so as to learn
as much information as possible about some ground truth $Y$. We investigate
this problem from information-theoretic grounds, through a generalization of
Tishby's centralized Information Bottleneck (IB) method to the distributed
setting. Specifically, $K$ encoders, $K \geq 2$, compress their observations
$X_1,\ldots,X_K$ separately in a manner such that, collectively, the produced
representations preserve as much information as possible about $Y$. We study
both discrete memoryless (DM) and memoryless vector Gaussian data models. For
the discrete model, we establish a single-letter characterization of the
optimal tradeoff between complexity (or rate) and relevance (or information)
for a class of memoryless sources (the observations $X_1,\ldots,X_K$ being
conditionally independent given $Y$). For the vector Gaussian model, we provide
an explicit characterization of the optimal complexity-relevance tradeoff.
Furthermore, we develop a variational bound on the complexity-relevance
tradeoff which generalizes the evidence lower bound (ELBO) to the distributed
setting. We also provide two algorithms that allow to compute this bound: i) a
Blahut-Arimoto type iterative algorithm which enables to compute optimal
complexity-relevance encoding mappings by iterating over a set of
self-consistent equations, and ii) a variational inference type algorithm in
which the encoding mappings are parametrized by neural networks and the bound
approximated by Markov sampling and optimized with stochastic gradient descent.
Numerical results on synthetic and real datasets are provided to support the
efficiency of the approaches and algorithms developed in this paper.","['Inaki Estella Aguerri', 'Abdellatif Zaidi']","['stat.ML', 'cs.LG']",2018-07-11 15:25:09+00:00
http://arxiv.org/abs/1807.04188v3,A Hardware-Software Blueprint for Flexible Deep Learning Specialization,"Specialized Deep Learning (DL) acceleration stacks, designed for a specific
set of frameworks, model architectures, operators, and data types, offer the
allure of high performance while sacrificing flexibility. Changes in
algorithms, models, operators, or numerical systems threaten the viability of
specialized hardware accelerators. We propose VTA, a programmable deep learning
architecture template designed to be extensible in the face of evolving
workloads. VTA achieves this flexibility via a parametrizable architecture,
two-level ISA, and a JIT compiler. The two-level ISA is based on (1) a task-ISA
that explicitly orchestrates concurrent compute and memory tasks and (2) a
microcode-ISA which implements a wide variety of operators with single-cycle
tensor-tensor operations. Next, we propose a runtime system equipped with a JIT
compiler for flexible code-generation and heterogeneous execution that enables
effective use of the VTA architecture. VTA is integrated and open-sourced into
Apache TVM, a state-of-the-art deep learning compilation stack that provides
flexibility for diverse models and divergent hardware backends. We propose a
flow that performs design space exploration to generate a customized hardware
architecture and software operator library that can be leveraged by mainstream
learning frameworks. We demonstrate our approach by deploying optimized deep
learning models used for object classification and style transfer on edge-class
FPGAs.","['Thierry Moreau', 'Tianqi Chen', 'Luis Vega', 'Jared Roesch', 'Eddie Yan', 'Lianmin Zheng', 'Josh Fromm', 'Ziheng Jiang', 'Luis Ceze', 'Carlos Guestrin', 'Arvind Krishnamurthy']","['cs.LG', 'cs.DC', 'stat.ML']",2018-07-11 15:19:30+00:00
http://arxiv.org/abs/1807.04183v2,Optimization over Continuous and Multi-dimensional Decisions with Observational Data,"We consider the optimization of an uncertain objective over continuous and
multi-dimensional decision spaces in problems in which we are only provided
with observational data. We propose a novel algorithmic framework that is
tractable, asymptotically consistent, and superior to comparable methods on
example problems. Our approach leverages predictive machine learning methods
and incorporates information on the uncertainty of the predicted outcomes for
the purpose of prescribing decisions. We demonstrate the efficacy of our method
on examples involving both synthetic and real data sets.","['Dimitris Bertsimas', 'Christopher McCord']","['stat.ML', 'cs.LG']",2018-07-11 15:07:12+00:00
http://arxiv.org/abs/1807.04162v3,TherML: Thermodynamics of Machine Learning,"In this work we offer a framework for reasoning about a wide class of
existing objectives in machine learning. We develop a formal correspondence
between this work and thermodynamics and discuss its implications.","['Alexander A. Alemi', 'Ian Fischer']","['cs.LG', 'cond-mat.stat-mech', 'stat.ML']",2018-07-11 14:39:17+00:00
http://arxiv.org/abs/1807.05981v1,A deep learning architecture to detect events in EEG signals during sleep,"Electroencephalography (EEG) during sleep is used by clinicians to evaluate
various neurological disorders. In sleep medicine, it is relevant to detect
macro-events (> 10s) such as sleep stages, and micro-events (<2s) such as
spindles and K-complexes. Annotations of such events require a trained sleep
expert, a time consuming and tedious process with a large inter-scorer
variability. Automatic algorithms have been developed to detect various types
of events but these are event-specific. We propose a deep learning method that
jointly predicts locations, durations and types of events in EEG time series.
It relies on a convolutional neural network that builds a feature
representation from raw EEG signals. Numerical experiments demonstrate
efficiency of this new approach on various event detection tasks compared to
current state-of-the-art, event specific, algorithms.","['Stanislas Chambon', 'Valentin Thorey', 'Pierrick J. Arnal', 'Emmanuel Mignot', 'Alexandre Gramfort']","['eess.SP', 'cs.LG', 'stat.ML']",2018-07-11 14:29:55+00:00
http://arxiv.org/abs/1807.09830v1,Iterative evaluation of LSTM cells,"In this work we present a modification in the conventional flow of
information through a LSTM network, which we consider well suited for RNNs in
general. The modification leads to a iterative scheme where the computations
performed by the LSTM cell are repeated over a constant input and cell state
values, while updating the hidden state a finite number of times. We provide
theoretical and empirical evidence to support the augmented capabilities of the
iterative scheme and show examples related to language modeling. The
modification yields an enhancement in the model performance comparable with the
original model augmented more than 3 times in terms of the total amount of
parameters.","['Leandro Palma', 'Luis Argerich']","['cs.LG', 'cs.NE', 'stat.ML']",2018-07-11 13:57:23+00:00
http://arxiv.org/abs/1807.04119v5,Exploiting statistical dependencies of time series with hierarchical correlation reconstruction,"While we are usually focused on forecasting future values of time series, it
is often valuable to additionally predict their entire probability
distributions, e.g. to evaluate risk, Monte Carlo simulations. On example of
time series of $\approx$ 30000 Dow Jones Industrial Averages, there will be
presented application of hierarchical correlation reconstruction for this
purpose: MSE estimating polynomial as joint density for (current value,
context), where context is for example a few previous values. Then substituting
the currently observed context and normalizing density to 1, we get predicted
probability distribution for the current value. In contrast to standard machine
learning approaches like neural networks, optimal polynomial coefficients here
have inexpensive direct formula, have controllable accuracy, are unique and
independently calculated, each has a specific cumulant-like interpretation, and
such approximation can asymptotically approach complete description of any real
joint distribution - providing universal tool to quantitatively describe and
exploit statistical dependencies in time series, systematically enhancing
ARMA/ARCH-like approaches, also based on different distributions than Gaussian
which turns out improper for daily log returns. There is also discussed
application for non-stationary time series like calculating linear time trend,
or adapting coefficients to local statistical behavior.",['Jarek Duda'],"['cs.LG', 'stat.ML']",2018-07-11 13:31:35+00:00
http://arxiv.org/abs/1807.04109v1,Modeling and Soft-fault Diagnosis of Underwater Thrusters with Recurrent Neural Networks,"Noncritical soft-faults and model deviations are a challenge for Fault
Detection and Diagnosis (FDD) of resident Autonomous Underwater Vehicles
(AUVs). Such systems may have a faster performance degradation due to the
permanent exposure to the marine environment, and constant monitoring of
component conditions is required to ensure their reliability. This works
presents an evaluation of Recurrent Neural Networks (RNNs) for a data-driven
fault detection and diagnosis scheme for underwater thrusters with empirical
data. The nominal behavior of the thruster was modeled using the measured
control input, voltage, rotational speed and current signals. We evaluated the
performance of fault classification using all the measured signals compared to
using the computed residuals from the nominal model as features.","['Samy Nascimento', 'Matias Valdenegro-Toro']","['cs.RO', 'cs.LG', 'stat.ML', 'I.2.6; I.2.9']",2018-07-11 12:51:22+00:00
http://arxiv.org/abs/1807.04106v1,VFunc: a Deep Generative Model for Functions,"We introduce a deep generative model for functions. Our model provides a
joint distribution p(f, z) over functions f and latent variables z which lets
us efficiently sample from the marginal p(f) and maximize a variational lower
bound on the entropy H(f). We can thus maximize objectives of the form
E_{f~p(f)}[R(f)] + c*H(f), where R(f) denotes, e.g., a data log-likelihood term
or an expected reward. Such objectives encompass Bayesian deep learning in
function space, rather than parameter space, and Bayesian deep RL with
representations of uncertainty that offer benefits over bootstrapping and
parameter noise. In this short paper we describe our model, situate it in the
context of prior work, and present proof-of-concept experiments for regression
and RL.","['Philip Bachman', 'Riashat Islam', 'Alessandro Sordoni', 'Zafarali Ahmed']","['cs.LG', 'stat.ML']",2018-07-11 12:38:30+00:00
http://arxiv.org/abs/1807.04098v1,A Recurrent Neural Network Survival Model: Predicting Web User Return Time,"The size of a website's active user base directly affects its value. Thus, it
is important to monitor and influence a user's likelihood to return to a site.
Essential to this is predicting when a user will return. Current state of the
art approaches to solve this problem come in two flavors: (1) Recurrent Neural
Network (RNN) based solutions and (2) survival analysis methods. We observe
that both techniques are severely limited when applied to this problem.
Survival models can only incorporate aggregate representations of users instead
of automatically learning a representation directly from a raw time series of
user actions. RNNs can automatically learn features, but can not be directly
trained with examples of non-returning users who have no target value for their
return time. We develop a novel RNN survival model that removes the limitations
of the state of the art methods. We demonstrate that this model can
successfully be applied to return time prediction on a large e-commerce dataset
with a superior ability to discriminate between returning and non-returning
users than either method applied in isolation.","['Georg L. Grob', 'Ângelo Cardoso', 'C. H. Bryan Liu', 'Duncan A. Little', 'Benjamin Paul Chamberlain']","['cs.LG', 'cs.CY', 'cs.IR', 'cs.NE', 'stat.ML']",2018-07-11 12:12:48+00:00
http://arxiv.org/abs/1807.04081v1,Proactive Intervention to Downtrend Employee Attrition using Artificial Intelligence Techniques,"To predict the employee attrition beforehand and to enable management to take
individualized preventive action. Using Ensemble classification modeling
techniques and Linear Regression. Model could predict over 91% accurate
employee prediction, lead-time in separation and individual reasons causing
attrition. Prior intimation of employee attrition enables manager to take
preventive actions to retain employee or to manage the business consequences of
attrition. Once deployed this will model can help in downtrend Employee
Attrition, will help manager to manage team more effectively. Model does not
cover the natural calamities, and unforeseen events occurring at an individual
level like accident, death etc.","['Aasheesh Barvey', 'Jitin Kapila', 'Kumarjit Pathak']","['stat.ML', 'cs.LG']",2018-07-11 11:38:03+00:00
http://arxiv.org/abs/1807.04073v2,A punishment voting algorithm based on super categories construction for acoustic scene classification,"In acoustic scene classification researches, audio segment is usually split
into multiple samples. Majority voting is then utilized to ensemble the results
of the samples. In this paper, we propose a punishment voting algorithm based
on the super categories construction method for acoustic scene classification.
Specifically, we propose a DenseNet-like model as the base classifier. The base
classifier is trained by the CQT spectrograms generated from the raw audio
segments. Taking advantage of the results of the base classifier, we propose a
super categories construction method using the spectral clustering. Super
classifiers corresponding to the constructed super categories are further
trained. Finally, the super classifiers are utilized to enhance the majority
voting of the base classifier by punishment voting. Experiments show that the
punishment voting obviously improves the performances on both the DCASE2017
Development dataset and the LITIS Rouen dataset.","['Weiping Zheng', 'Zhenyao Mo', 'Jiantao Yi']","['cs.SD', 'cs.LG', 'stat.ML']",2018-07-11 11:14:19+00:00
http://arxiv.org/abs/1807.04065v1,Recurrent Neural Networks with Flexible Gates using Kernel Activation Functions,"Gated recurrent neural networks have achieved remarkable results in the
analysis of sequential data. Inside these networks, gates are used to control
the flow of information, allowing to model even very long-term dependencies in
the data. In this paper, we investigate whether the original gate equation (a
linear projection followed by an element-wise sigmoid) can be improved. In
particular, we design a more flexible architecture, with a small number of
adaptable parameters, which is able to model a wider range of gating functions
than the classical one. To this end, we replace the sigmoid function in the
standard gate with a non-parametric formulation extending the recently proposed
kernel activation function (KAF), with the addition of a residual
skip-connection. A set of experiments on sequential variants of the MNIST
dataset shows that the adoption of this novel gate allows to improve accuracy
with a negligible cost in terms of computational power and with a large
speed-up in the number of training iterations.","['Simone Scardapane', 'Steven Van Vaerenbergh', 'Danilo Comminiello', 'Simone Totaro', 'Aurelio Uncini']","['cs.NE', 'cs.LG', 'stat.ML']",2018-07-11 10:54:46+00:00
http://arxiv.org/abs/1807.04056v1,Temporal Convolution Networks for Real-Time Abdominal Fetal Aorta Analysis with Ultrasound,"The automatic analysis of ultrasound sequences can substantially improve the
efficiency of clinical diagnosis. In this work we present our attempt to
automate the challenging task of measuring the vascular diameter of the fetal
abdominal aorta from ultrasound images. We propose a neural network
architecture consisting of three blocks: a convolutional layer for the
extraction of imaging features, a Convolution Gated Recurrent Unit (C-GRU) for
enforcing the temporal coherence across video frames and exploiting the
temporal redundancy of a signal, and a regularized loss function, called
\textit{CyclicLoss}, to impose our prior knowledge about the periodicity of the
observed signal. We present experimental evidence suggesting that the proposed
architecture can reach an accuracy substantially superior to previously
proposed methods, providing an average reduction of the mean squared error from
$0.31 mm^2$ (state-of-art) to $0.09 mm^2$, and a relative error reduction from
$8.1\%$ to $5.3\%$. The mean execution speed of the proposed approach of 289
frames per second makes it suitable for real time clinical use.","[""Nicolo' Savioli"", 'Silvia Visentin', 'Erich Cosmi', 'Enrico Grisan', 'Pablo Lamata', 'Giovanni Montana']","['cs.CV', 'cs.LG', 'stat.ML']",2018-07-11 10:22:38+00:00
http://arxiv.org/abs/1807.10572v1,Two-Layer Mixture Network Ensemble for Apparel Attributes Classification,"Recognizing apparel attributes has recently drawn great interest in the
computer vision community. Methods based on various deep neural networks have
been proposed for image classification, which could be applied to apparel
attributes recognition. An interesting problem raised is how to ensemble these
methods to further improve the accuracy. In this paper, we propose a two-layer
mixture framework for ensemble different networks. In the first layer of this
framework, two types of ensemble learning methods, bagging and boosting, are
separately applied. Different from traditional methods, our bagging process
makes use of the whole training set, not random subsets, to train each model in
the ensemble, where several differentiated deep networks are used to promote
model variance. To avoid the bias of small-scale samples, the second layer only
adopts bagging to mix the results obtained with bagging and boosting in the
first layer. Experimental results demonstrate that the proposed mixture
framework outperforms any individual network model or either independent
ensemble method in apparel attributes classification.","['Tianqi Han', 'Zhihui Fu', 'Hongyu Li']","['cs.CV', 'cs.LG', 'stat.ML']",2018-07-11 10:16:27+00:00
http://arxiv.org/abs/1807.04020v1,Improved SVD-based Initialization for Nonnegative Matrix Factorization using Low-Rank Correction,"Due to the iterative nature of most nonnegative matrix factorization
(\textsc{NMF}) algorithms, initialization is a key aspect as it significantly
influences both the convergence and the final solution obtained. Many
initialization schemes have been proposed for NMF, among which one of the most
popular class of methods are based on the singular value decomposition (SVD).
However, these SVD-based initializations do not satisfy a rather natural
condition, namely that the error should decrease as the rank of factorization
increases. In this paper, we propose a novel SVD-based \textsc{NMF}
initialization to specifically address this shortcoming by taking into account
the SVD factors that were discarded to obtain a nonnegative initialization.
This method, referred to as nonnegative SVD with low-rank correction
(NNSVD-LRC), allows us to significantly reduce the initial error at a
negligible additional computational cost using the low-rank structure of the
discarded SVD factors. NNSVD-LRC has two other advantages compared to previous
SVD-based initializations: (1) it provably generates sparse initial factors,
and (2) it is faster as it only requires to compute a truncated SVD of rank
$\lceil r/2 + 1 \rceil$ where $r$ is the factorization rank of the sought NMF
decomposition (as opposed to a rank-$r$ truncated SVD for other methods). We
show on several standard dense and sparse data sets that our new method
competes favorably with state-of-the-art SVD-based initializations for NMF.","['Atif Muhammad Syed', 'Sameer Qazi', 'Nicolas Gillis']","['cs.NA', 'cs.LG', 'stat.ML']",2018-07-11 09:21:31+00:00
http://arxiv.org/abs/1807.04015v8,On Catastrophic Forgetting and Mode Collapse in Generative Adversarial Networks,"In this paper, we show that Generative Adversarial Networks (GANs) suffer
from catastrophic forgetting even when they are trained to approximate a single
target distribution. We show that GAN training is a continual learning problem
in which the sequence of changing model distributions is the sequence of tasks
to the discriminator. The level of mismatch between tasks in the sequence
determines the level of forgetting. Catastrophic forgetting is interrelated to
mode collapse and can make the training of GANs non-convergent. We investigate
the landscape of the discriminator's output in different variants of GANs and
find that when a GAN converges to a good equilibrium, real training datapoints
are wide local maxima of the discriminator. We empirically show the
relationship between the sharpness of local maxima and mode collapse and
generalization in GANs. We show how catastrophic forgetting prevents the
discriminator from making real datapoints local maxima, and thus causes
non-convergence. Finally, we study methods for preventing catastrophic
forgetting in GANs.","['Hoang Thanh-Tung', 'Truyen Tran']","['cs.LG', 'stat.ML']",2018-07-11 09:08:34+00:00
http://arxiv.org/abs/1807.04010v4,Causal Discovery in the Presence of Missing Data,"Missing data are ubiquitous in many domains including healthcare. When these
data entries are not missing completely at random, the (conditional)
independence relations in the observed data may be different from those in the
complete data generated by the underlying causal process. Consequently, simply
applying existing causal discovery methods to the observed data may lead to
wrong conclusions. In this paper, we aim at developing a causal discovery
method to recover the underlying causal structure from observed data that
follow different missingness mechanisms, including missing completely at random
(MCAR), missing at random (MAR), and missing not at random (MNAR). With
missingness mechanisms represented by missingness graphs, we analyse conditions
under which additional correction is needed to derive conditional
independence/dependence relations in the complete data. Based on our analysis,
we propose the Missing Value PC (MVPC) algorithm for both continuous and binary
variables, which extends the PC algorithm to incorporate additional
corrections. Our proposed MVPC is shown in theory to give asymptotically
correct results even on data that are MAR or MNAR. Experimental results on
synthetic data show that the proposed algorithm is able to find correct causal
relations even in the general case of MNAR. Moreover, we create a neuropathic
pain diagnostic simulator for evaluating causal discovery methods. Evaluated on
such simulated neuropathic pain diagnosis records and the other two real world
applications, MVPC outperforms the other benchmark methods.","['Ruibo Tu', 'Kun Zhang', 'Paul Ackermann', 'Bo Christer Bertilson', 'Clark Glymour', 'Hedvig Kjellström', 'Cheng Zhang']","['cs.LG', 'stat.ML']",2018-07-11 09:01:29+00:00
http://arxiv.org/abs/1807.04001v1,Learning Neural Models for End-to-End Clustering,"We propose a novel end-to-end neural network architecture that, once trained,
directly outputs a probabilistic clustering of a batch of input examples in one
pass. It estimates a distribution over the number of clusters $k$, and for each
$1 \leq k \leq k_\mathrm{max}$, a distribution over the individual cluster
assignment for each data point. The network is trained in advance in a
supervised fashion on separate data to learn grouping by any perceptual
similarity criterion based on pairwise labels (same/different group). It can
then be applied to different data containing different groups. We demonstrate
promising performance on high-dimensional data like images (COIL-100) and
speech (TIMIT). We call this ``learning to cluster'' and show its conceptual
difference to deep metric learning, semi-supervise clustering and other related
approaches while having the advantage of performing learnable clustering fully
end-to-end.","['Benjamin Bruno Meier', 'Ismail Elezi', 'Mohammadreza Amirian', 'Oliver Durr', 'Thilo Stadelmann']","['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']",2018-07-11 08:45:45+00:00
http://arxiv.org/abs/1807.04639v1,Moving Objects Analytics: Survey on Future Location & Trajectory Prediction Methods,"The tremendous growth of positioning technologies and GPS enabled devices has
produced huge volumes of tracking data during the recent years. This source of
information constitutes a rich input for data analytics processes, either
offline (e.g. cluster analysis, hot motion discovery) or online (e.g.
short-term forecasting of forthcoming positions). This paper focuses on
predictive analytics for moving objects (could be pedestrians, cars, vessels,
planes, animals, etc.) and surveys the state-of-the-art in the context of
future location and trajectory prediction. We provide an extensive review of
over 50 works, also proposing a novel taxonomy of predictive algorithms over
moving objects. We also list the properties of several real datasets used in
the past for validation purposes of those works and, motivated by this, we
discuss challenges that arise in the transition from conventional to Big Data
applications.
  CCS Concepts: Information systems > Spatial-temporal systems; Information
systems > Data analytics; Information systems > Data mining; Computing
methodologies > Machine learning Additional Key Words and Phrases: mobility
data, moving object trajectories, trajectory prediction, future location
prediction.","['Harris Georgiou', 'Sophia Karagiorgou', 'Yannis Kontoulis', 'Nikos Pelekis', 'Petros Petrou', 'David Scarlatti', 'Yannis Theodoridis']","['cs.LG', 'cs.DB', 'cs.IR', 'stat.ML']",2018-07-11 08:01:38+00:00
http://arxiv.org/abs/1807.10571v1,Sparse Range-constrained Learning and Its Application for Medical Image Grading,"Sparse learning has been shown to be effective in solving many real-world
problems. Finding sparse representations is a fundamentally important topic in
many fields of science including signal processing, computer vision, genome
study and medical imaging. One important issue in applying sparse
representation is to find the basis to represent the data,especially in
computer vision and medical imaging where the data is not necessary incoherent.
In medical imaging, clinicians often grade the severity or measure the risk
score of a disease based on images. This process is referred to as medical
image grading. Manual grading of the disease severity or risk score is often
used. However, it is tedious, subjective and expensive. Sparse learning has
been used for automatic grading of medical images for different diseases. In
the grading, we usually begin with one step to find a sparse representation of
the testing image using a set of reference images or atoms from the dictionary.
Then in the second step, the selected atoms are used as references to compute
the grades of the testing images. Since the two steps are conducted
sequentially, the objective function in the first step is not necessarily
optimized for the second step. In this paper, we propose a novel sparse
range-constrained learning(SRCL)algorithm for medical image grading.Different
from most of existing sparse learning algorithms, SRCL integrates the objective
of finding a sparse representation and that of grading the image into one
function. It aims to find a sparse representation of the testing image based on
atoms that are most similar in both the data or feature representation and the
medical grading scores. We apply the new proposed SRCL to CDR computation and
cataract grading. Experimental results show that the proposed method is able to
improve the accuracy in cup-to-disc ratio computation and cataract grading.",['Jun Cheng'],"['cs.CV', 'cs.LG', 'stat.ML']",2018-07-11 06:59:45+00:00
http://arxiv.org/abs/1807.03953v1,Adaptive Learning Method of Recurrent Temporal Deep Belief Network to Analyze Time Series Data,"Deep Learning has the hierarchical network architecture to represent the
complicated features of input patterns. Such architecture is well known to
represent higher learning capability compared with some conventional models if
the best set of parameters in the optimal network structure is found. We have
been developing the adaptive learning method that can discover the optimal
network structure in Deep Belief Network (DBN). The learning method can
construct the network structure with the optimal number of hidden neurons in
each Restricted Boltzmann Machine and with the optimal number of layers in the
DBN during learning phase. The network structure of the learning method can be
self-organized according to given input patterns of big data set. In this
paper, we embed the adaptive learning method into the recurrent temporal RBM
and the self-generated layer into DBN. In order to verify the effectiveness of
our proposed method, the experimental results are higher classification
capability than the conventional methods in this paper.","['Takumi Ichimura', 'Shin Kamada']","['cs.NE', 'cs.LG', 'stat.ML']",2018-07-11 05:34:32+00:00
http://arxiv.org/abs/1807.05849v1,Neural Chinese Word Segmentation with Dictionary Knowledge,"Chinese word segmentation (CWS) is an important task for Chinese NLP.
Recently, many neural network based methods have been proposed for CWS.
However, these methods require a large number of labeled sentences for model
training, and usually cannot utilize the useful information in Chinese
dictionary. In this paper, we propose two methods to exploit the dictionary
information for CWS. The first one is based on pseudo labeled data generation,
and the second one is based on multi-task learning. The experimental results on
two benchmark datasets validate that our approach can effectively improve the
performance of Chinese word segmentation, especially when training data is
insufficient.","['Junxin Liu', 'Fangzhao Wu', 'Chuhan Wu', 'Yongfeng Huang', 'Xing Xie']","['cs.CL', 'cs.LG', 'stat.ML']",2018-07-11 04:51:41+00:00
http://arxiv.org/abs/1807.03933v1,Instance-based entropy fuzzy support vector machine for imbalanced data,"Imbalanced classification has been a major challenge for machine learning
because many standard classifiers mainly focus on balanced datasets and tend to
have biased results towards the majority class. We modify entropy fuzzy support
vector machine (EFSVM) and introduce instance-based entropy fuzzy support
vector machine (IEFSVM). Both EFSVM and IEFSVM use the entropy information of
k-nearest neighbors to determine the fuzzy membership value for each sample
which prioritizes the importance of each sample. IEFSVM considers the diversity
of entropy patterns for each sample when increasing the size of neighbors, k,
while EFSVM uses single entropy information of the fixed size of neighbors for
all samples. By varying k, we can reflect the component change of sample's
neighbors from near to far distance in the determination of fuzzy value
membership. Numerical experiments on 35 public and 12 real-world imbalanced
datasets are performed to validate IEFSVM and area under the receiver operating
characteristic curve (AUC) is used to compare its performance with other SVMs
and machine learning methods. IEFSVM shows a much higher AUC value for datasets
with high imbalance ratio, implying that IEFSVM is effective in dealing with
the class imbalance problem.","['Poongjin Cho', 'Minhyuk Lee', 'Woojin Chang']","['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",2018-07-11 02:33:57+00:00
