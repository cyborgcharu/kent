id,title,abstract,authors,categories,date
http://arxiv.org/abs/1811.04504v2,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient,"Uncertainty estimation in large deep-learning models is a computationally
challenging task, where it is difficult to form even a Gaussian approximation
to the posterior distribution. In such situations, existing methods usually
resort to a diagonal approximation of the covariance matrix despite, the fact
that these matrices are known to result in poor uncertainty estimates. To
address this issue, we propose a new stochastic, low-rank, approximate
natural-gradient (SLANG) method for variational inference in large, deep
models. Our method estimates a ""diagonal plus low-rank"" structure based solely
on back-propagated gradients of the network log-likelihood. This requires
strictly less gradient computations than methods that compute the gradient of
the whole variational objective. Empirical evaluations on standard benchmarks
confirm that SLANG enables faster and more accurate estimation of uncertainty
than mean-field methods, and performs comparably to state-of-the-art methods.","['Aaron Mishkin', 'Frederik Kunstner', 'Didrik Nielsen', 'Mark Schmidt', 'Mohammad Emtiyaz Khan']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-11 23:18:27+00:00
http://arxiv.org/abs/1811.04480v1,Semi-supervised Deep Representation Learning for Multi-View Problems,"While neural networks for learning representation of multi-view data have
been previously proposed as one of the state-of-the-art multi-view dimension
reduction techniques, how to make the representation discriminative with only a
small amount of labeled data is not well-studied. We introduce a
semi-supervised neural network model, named Multi-view Discriminative Neural
Network (MDNN), for multi-view problems. MDNN finds nonlinear view-specific
mappings by projecting samples to a common feature space using multiple coupled
deep networks. It is capable of leveraging both labeled and unlabeled data to
project multi-view data so that samples from different classes are separated
and those from the same class are clustered together. It also uses the
inter-view correlation between views to exploit the available information in
both the labeled and unlabeled data. Extensive experiments conducted on four
datasets demonstrate the effectiveness of the proposed algorithm for multi-view
semi-supervised learning.","['Vahid Noroozi', 'Sara Bahaadini', 'Lei Zheng', 'Sihong Xie', 'Weixiang Shao', 'Philip S. Yu']","['cs.LG', 'stat.ML']",2018-11-11 20:53:50+00:00
http://arxiv.org/abs/1811.04477v9,Unifying Gaussian LWF and AMP Chain Graphs to Model Interference,"An intervention may have an effect on units other than those to which it was
administered. This phenomenon is called interference and it usually goes
unmodeled. In this paper, we propose to combine Lauritzen-Wermuth-Frydenberg
and Andersson-Madigan-Perlman chain graphs to create a new class of causal
models that can represent both interference and non-interference relationships
for Gaussian distributions. Specifically, we define the new class of models,
introduce global and local and pairwise Markov properties for them, and prove
their equivalence. We also propose an algorithm for maximum likelihood
parameter estimation for the new models, and report experimental results.
Finally, we show how to compute the effects of interventions in the new models.",['Jose M. Pe√±a'],"['stat.ML', 'cs.LG']",2018-11-11 20:43:19+00:00
http://arxiv.org/abs/1811.04475v1,Managing App Install Ad Campaigns in RTB: A Q-Learning Approach,"Real time bidding (RTB) enables demand side platforms (bidders) to scale ad
campaigns across multiple publishers affiliated to an RTB ad exchange. While
driving multiple campaigns for mobile app install ads via RTB, the bidder
typically has to: (i) maintain each campaign's efficiency (i.e., meet
advertiser's target cost-per-install), (ii) be sensitive to advertiser's
budget, and (iii) make profit after payouts to the ad exchange. In this
process, there is a sense of delayed rewards for the bidder's actions; the
exchange charges the bidder right after the ad is shown, but the bidder gets to
know about resultant installs after considerable delay. This makes it
challenging for the bidder to decide beforehand the bid (and corresponding cost
charged to advertiser) for each ad display opportunity. To jointly handle the
objectives mentioned above, we propose a state space based policy which decides
the exchange bid and advertiser cost for each opportunity. The state space
captures the current efficiency, budget utilization and profit. The policy
based on this state space is trained on past decisions and outcomes via a novel
Q-learning algorithm which accounts for the delay in install notifications. In
our experiments based on data from app install campaigns managed by Yahoo's
Gemini advertising platform, the Q-learning based policy led to a significant
increase in the profit and number of efficient campaigns.","['Anit Kumar Sahu', 'Shaunak Mishra', 'Narayan Bhamidipati']","['cs.GT', 'cs.LG', 'stat.ML']",2018-11-11 20:42:09+00:00
http://arxiv.org/abs/1811.04471v1,Thompson Sampling for Pursuit-Evasion Problems,"Pursuit-evasion is a multi-agent sequential decision problem wherein a group
of agents known as pursuers coordinate their traversal of a spatial domain to
locate an agent trying to evade them. Pursuit evasion problems arise in a
number of import application domains including defense and route planning.
Learning to optimally coordinate pursuer behaviors so as to minimize time to
capture of the evader is challenging because of a large action space and sparse
noisy state information; consequently, previous approaches have relied
primarily on heuristics. We propose a variant of Thompson Sampling for
pursuit-evasion that allows for the application of existing model-based
planning algorithms. This approach is general in that it allows for an
arbitrary number of pursuers, a general spatial domain, and the integration of
auxiliary information provided by informants. In a suite of simulation
experiments, Thompson Sampling for pursuit evasion significantly reduces
time-to-capture relative to competing algorithms.","['Zhen Li', 'Nicholas J. Meyer', 'Eric B. Laber', 'Robert Brigantic']","['cs.LG', 'stat.ML']",2018-11-11 20:17:01+00:00
http://arxiv.org/abs/1811.04463v1,Machine Learning with Abstention for Automated Liver Disease Diagnosis,"This paper presents a novel approach for detection of liver abnormalities in
an automated manner using ultrasound images. For this purpose, we have
implemented a machine learning model that can not only generate labels (normal
and abnormal) for a given ultrasound image but it can also detect when its
prediction is likely to be incorrect. The proposed model abstains from
generating the label of a test example if it is not confident about its
prediction. Such behavior is commonly practiced by medical doctors who, when
given insufficient information or a difficult case, can chose to carry out
further clinical or diagnostic tests before generating a diagnosis. However,
existing machine learning models are designed in a way to always generate a
label for a given example even when the confidence of their prediction is low.
We have proposed a novel stochastic gradient based solver for the learning with
abstention paradigm and use it to make a practical, state of the art method for
liver disease classification. The proposed method has been benchmarked on a
data set of approximately 100 patients from MINAR, Multan, Pakistan and our
results show that the proposed scheme offers state of the art classification
performance.","['Kanza Hamid', 'Amina Asif', 'Wajid Abbasi', 'Durre Sabih', 'Fayyaz Minhas']","['cs.LG', 'cs.CV', 'eess.IV', 'stat.ML']",2018-11-11 19:37:40+00:00
http://arxiv.org/abs/1811.04455v2,Learning with tree-based tensor formats,"This paper is concerned with the approximation of high-dimensional functions
in a statistical learning setting, by empirical risk minimization over model
classes of functions in tree-based tensor format. These are particular classes
of rank-structured functions that can be seen as deep neural networks with a
sparse architecture related to the tree and multilinear activation functions.
For learning in a given model class, we exploit the fact that tree-based tensor
formats are multilinear models and recast the problem of risk minimization over
a nonlinear set into a succession of learning problems with linear models.
Suitable changes of representation yield numerically stable learning problems
and allow to exploit sparsity. For high-dimensional problems or when only a
small data set is available, the selection of a good model class is a critical
issue. For a given tree, the selection of the tuple of tree-based ranks that
minimize the risk is a combinatorial problem. Here, we propose a rank
adaptation strategy which provides in practice a good convergence of the risk
as a function of the model class complexity. Finding a good tree is also a
combinatorial problem, which can be related to the choice of a particular
sparse architecture for deep neural networks. Here, we propose a stochastic
algorithm for minimizing the complexity of the representation of a given
function over a class of trees with a given arity, allowing changes in the
topology of the tree. This tree optimization algorithm is then included in a
learning scheme that successively adapts the tree and the corresponding
tree-based ranks. Contrary to classical learning algorithms for nonlinear model
classes, the proposed algorithms are numerically stable, reliable, and require
only a low level expertise of the user.","['Erwan Grelier', 'Anthony Nouy', 'Mathilde Chevreuil']","['stat.ML', 'cs.LG', 'math.NA']",2018-11-11 19:03:31+00:00
http://arxiv.org/abs/1811.04451v2,Multi-Source Neural Variational Inference,"Learning from multiple sources of information is an important problem in
machine-learning research. The key challenges are learning representations and
formulating inference methods that take into account the complementarity and
redundancy of various information sources. In this paper we formulate a
variational autoencoder based multi-source learning framework in which each
encoder is conditioned on a different information source. This allows us to
relate the sources via the shared latent variables by computing divergence
measures between individual source's posterior approximations. We explore a
variety of options to learn these encoders and to integrate the beliefs they
compute into a consistent posterior approximation. We visualise learned beliefs
on a toy dataset and evaluate our methods for learning shared representations
and structured output prediction, showing trade-offs of learning separate
encoders for each information source. Furthermore, we demonstrate how conflict
detection and redundancy can increase robustness of inference in a multi-source
setting.","['Richard Kurle', 'Stephan G√ºnnemann', 'Patrick van der Smagt']","['stat.ML', 'cs.LG']",2018-11-11 18:59:21+00:00
http://arxiv.org/abs/1811.07771v2,"A Multi-Task Learning & Generation Framework: Valence-Arousal, Action Units & Primary Expressions","Over the past few years many research efforts have been devoted to the field
of affect analysis. Various approaches have been proposed for: i) discrete
emotion recognition in terms of the primary facial expressions; ii) emotion
analysis in terms of facial Action Units (AUs), assuming a fixed expression
intensity; iii) dimensional emotion analysis, in terms of valence and arousal
(VA). These approaches can only be effective, if they are developed using
large, appropriately annotated databases, showing behaviors of people
in-the-wild, i.e., in uncontrolled environments. Aff-Wild has been the first,
large-scale, in-the-wild database (including around 1,200,000 frames of 300
videos), annotated in terms of VA. In the vast majority of existing emotion
databases, their annotation is limited to either primary expressions, or
valence-arousal, or action units. In this paper, we first annotate a part
(around $234,000$ frames) of the Aff-Wild database in terms of $8$ AUs and
another part (around $288,000$ frames) in terms of the $7$ basic emotion
categories, so that parts of this database are annotated in terms of VA, as
well as AUs, or primary expressions. Then, we set up and tackle multi-task
learning for emotion recognition, as well as for facial image generation.
Multi-task learning is performed using: i) a deep neural network with shared
hidden layers, which learns emotional attributes by exploiting their
inter-dependencies; ii) a discriminator of a generative adversarial network
(GAN). On the other hand, image generation is implemented through the generator
of the GAN. For these two tasks, we carefully design loss functions that fit
the examined set-up. Experiments are presented which illustrate the good
performance of the proposed approach when applied to the new annotated parts of
the Aff-Wild database.","['Dimitrios Kollias', 'Stefanos Zafeiriou']","['cs.CV', 'cs.AI', 'cs.LG', 'stat.ML']",2018-11-11 15:40:23+00:00
http://arxiv.org/abs/1811.07691v2,Improving speech emotion recognition via Transformer-based Predictive Coding through transfer learning,"I have submitted a new version to arXiv:1910.13806. I forget to choose to
replace the old version, but submitted a new one. It's my mistake.","['Zheng Lian', 'Ya Li', 'Jianhua Tao', 'Jian Huang']","['cs.LG', 'cs.HC', 'stat.ML']",2018-11-11 15:39:13+00:00
http://arxiv.org/abs/1811.04422v1,An Optimal Control View of Adversarial Machine Learning,"I describe an optimal control view of adversarial machine learning, where the
dynamical system is the machine learner, the input are adversarial actions, and
the control costs are defined by the adversary's goals to do harm and be hard
to detect. This view encompasses many types of adversarial machine learning,
including test-item attacks, training-data poisoning, and adversarial reward
shaping. The view encourages adversarial machine learning researcher to utilize
advances in control theory and reinforcement learning.",['Xiaojin Zhu'],"['cs.LG', 'stat.ML']",2018-11-11 14:28:34+00:00
http://arxiv.org/abs/1811.04411v2,Fast Matrix Factorization with Non-Uniform Weights on Missing Data,"Matrix factorization (MF) has been widely used to discover the low-rank
structure and to predict the missing entries of data matrix. In many real-world
learning systems, the data matrix can be very high-dimensional but sparse. This
poses an imbalanced learning problem, since the scale of missing entries is
usually much larger than that of observed entries, but they cannot be ignored
due to the valuable negative signal. For efficiency concern, existing work
typically applies a uniform weight on missing entries to allow a fast learning
algorithm. However, this simplification will decrease modeling fidelity,
resulting in suboptimal performance for downstream applications.
  In this work, we weight the missing data non-uniformly, and more generically,
we allow any weighting strategy on the missing data. To address the efficiency
challenge, we propose a fast learning method, for which the time complexity is
determined by the number of observed entries in the data matrix, rather than
the matrix size. The key idea is two-fold: 1) we apply truncated SVD on the
weight matrix to get a more compact representation of the weights, and 2) we
learn MF parameters with element-wise alternating least squares (eALS) and
memorize the key intermediate variables to avoid repeating computations that
are unnecessary. We conduct extensive experiments on two recommendation
benchmarks, demonstrating the correctness, efficiency, and effectiveness of our
fast eALS method.","['Xiangnan He', 'Jinhui Tang', 'Xiaoyu Du', 'Richang Hong', 'Tongwei Ren', 'Tat-Seng Chua']","['cs.IR', 'cs.LG', 'stat.ML']",2018-11-11 13:17:42+00:00
http://arxiv.org/abs/1811.05321v1,Correction of AI systems by linear discriminants: Probabilistic foundations,"Artificial Intelligence (AI) systems sometimes make errors and will make
errors in the future, from time to time. These errors are usually unexpected,
and can lead to dramatic consequences. Intensive development of AI and its
practical applications makes the problem of errors more important. Total
re-engineering of the systems can create new errors and is not always possible
due to the resources involved. The important challenge is to develop fast
methods to correct errors without damaging existing skills. We formulated the
technical requirements to the 'ideal' correctors. Such correctors include
binary classifiers, which separate the situations with high risk of errors from
the situations where the AI systems work properly. Surprisingly, for
essentially high-dimensional data such methods are possible: simple linear
Fisher discriminant can separate the situations with errors from correctly
solved tasks even for exponentially large samples. The paper presents the
probabilistic basis for fast non-destructive correction of AI systems. A series
of new stochastic separation theorems is proven. These theorems provide new
instruments for fast non-iterative correction of errors of legacy AI systems.
The new approaches become efficient in high-dimensions, for correction of
high-dimensional systems in high-dimensional world (i.e. for processing of
essentially high-dimensional data by large systems).","['A. N. Gorban', 'A. Golubkov', 'B. Grechuk', 'E. M. Mirkes', 'I. Y. Tyukin']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-11 13:11:13+00:00
http://arxiv.org/abs/1811.04407v3,An initial attempt of combining visual selective attention with deep reinforcement learning,"Visual attention serves as a means of feature selection mechanism in the
perceptual system. Motivated by Broadbent's leaky filter model of selective
attention, we evaluate how such mechanism could be implemented and affect the
learning process of deep reinforcement learning. We visualize and analyze the
feature maps of DQN on a toy problem Catch, and propose an approach to combine
visual selective attention with deep reinforcement learning. We experiment with
optical flow-based attention and A2C on Atari games. Experiment results show
that visual selective attention could lead to improvements in terms of sample
efficiency on tested games. An intriguing relation between attention and batch
normalization is also discovered.","['Liu Yuezhang', 'Ruohan Zhang', 'Dana H. Ballard']","['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']",2018-11-11 12:22:44+00:00
http://arxiv.org/abs/1811.04393v1,Gaussian-Induced Convolution for Graphs,"Learning representation on graph plays a crucial role in numerous tasks of
pattern recognition. Different from grid-shaped images/videos, on which local
convolution kernels can be lattices, however, graphs are fully coordinate-free
on vertices and edges. In this work, we propose a Gaussian-induced convolution
(GIC) framework to conduct local convolution filtering on irregular graphs.
Specifically, an edge-induced Gaussian mixture model is designed to encode
variations of subgraph region by integrating edge information into weighted
Gaussian models, each of which implicitly characterizes one component of
subgraph variations. In order to coarsen a graph, we derive a vertex-induced
Gaussian mixture model to cluster vertices dynamically according to the
connection of edges, which is approximately equivalent to the weighted graph
cut. We conduct our multi-layer graph convolution network on several public
datasets of graph classification. The extensive experiments demonstrate that
our GIC is effective and can achieve the state-of-the-art results.","['Jiatao Jiang', 'Zhen Cui', 'Chunyan Xu', 'Jian Yang']","['cs.LG', 'stat.ML']",2018-11-11 11:21:18+00:00
http://arxiv.org/abs/1811.04383v2,Adapting multi-armed bandits policies to contextual bandits scenarios,"This work explores adaptations of successful multi-armed bandits policies to
the online contextual bandits scenario with binary rewards using binary
classification algorithms such as logistic regression as black-box oracles.
Some of these adaptations are achieved through bootstrapping or approximate
bootstrapping, while others rely on other forms of randomness, resulting in
more scalable approaches than previous works, and the ability to work with any
type of classification algorithm. In particular, the Adaptive-Greedy algorithm
shows a lot of promise, in many cases achieving better performance than upper
confidence bound and Thompson sampling strategies, at the expense of more
hyperparameters to tune.",['David Cortes'],"['cs.LG', 'stat.ML']",2018-11-11 09:56:11+00:00
http://arxiv.org/abs/1811.04380v1,ReSet: Learning Recurrent Dynamic Routing in ResNet-like Neural Networks,"Neural Network is a powerful Machine Learning tool that shows outstanding
performance in Computer Vision, Natural Language Processing, and Artificial
Intelligence. In particular, recently proposed ResNet architecture and its
modifications produce state-of-the-art results in image classification
problems. ResNet and most of the previously proposed architectures have a fixed
structure and apply the same transformation to all input images. In this work,
we develop a ResNet-based model that dynamically selects Computational Units
(CU) for each input object from a learned set of transformations. Dynamic
selection allows the network to learn a sequence of useful transformations and
apply only required units to predict the image label. We compare our model to
ResNet-38 architecture and achieve better results than the original ResNet on
CIFAR-10.1 test set. While examining the produced paths, we discovered that the
network learned different routes for images from different classes and similar
routes for similar images.","['Iurii Kemaev', 'Daniil Polykovskiy', 'Dmitry Vetrov']","['stat.ML', 'cs.LG']",2018-11-11 09:45:41+00:00
http://arxiv.org/abs/1811.04376v1,Explaining Deep Learning Models using Causal Inference,"Although deep learning models have been successfully applied to a variety of
tasks, due to the millions of parameters, they are becoming increasingly opaque
and complex. In order to establish trust for their widespread commercial use,
it is important to formalize a principled framework to reason over these
models. In this work, we use ideas from causal inference to describe a general
framework to reason over CNN models. Specifically, we build a Structural Causal
Model (SCM) as an abstraction over a specific aspect of the CNN. We also
formulate a method to quantitatively rank the filters of a convolution layer
according to their counterfactual importance. We illustrate our approach with
popular CNN architectures such as LeNet5, VGG19, and ResNet32.","['Tanmayee Narendra', 'Anush Sankaran', 'Deepak Vijaykeerthy', 'Senthil Mani']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-11 09:26:55+00:00
http://arxiv.org/abs/1811.04364v6,Survey of state-of-the-art mixed data clustering algorithms,"Mixed data comprises both numeric and categorical features, and mixed
datasets occur frequently in many domains, such as health, finance, and
marketing. Clustering is often applied to mixed datasets to find structures and
to group similar objects for further analysis. However, clustering mixed data
is challenging because it is difficult to directly apply mathematical
operations, such as summation or averaging, to the feature values of these
datasets. In this paper, we present a taxonomy for the study of mixed data
clustering algorithms by identifying five major research themes. We then
present a state-of-the-art review of the research works within each research
theme. We analyze the strengths and weaknesses of these methods with pointers
for future research directions. Lastly, we present an in-depth analysis of the
overall challenges in this field, highlight open research questions and discuss
guidelines to make progress in the field.","['Amir Ahmad', 'Shehroz S. Khan']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-11 07:27:51+00:00
http://arxiv.org/abs/1811.04351v1,Generalization Bounds for Vicinal Risk Minimization Principle,"The vicinal risk minimization (VRM) principle, first proposed by
\citet{vapnik1999nature}, is an empirical risk minimization (ERM) variant that
replaces Dirac masses with vicinal functions. Although there is strong
numerical evidence showing that VRM outperforms ERM if appropriate vicinal
functions are chosen, a comprehensive theoretical understanding of VRM is still
lacking. In this paper, we study the generalization bounds for VRM. Our results
support Vapnik's original arguments and additionally provide deeper insights
into VRM. First, we prove that the complexity of function classes convolving
with vicinal functions can be controlled by that of the original function
classes under the assumption that the function class is composed of
Lipschitz-continuous functions. Then, the resulting generalization bounds for
VRM suggest that the generalization performance of VRM is also effected by the
choice of vicinity function and the quality of function classes. These findings
can be used to examine whether the choice of vicinal function is appropriate
for the VRM-based learning setting. Finally, we provide a theoretical
explanation for existing VRM models, e.g., uniform distribution-based models,
Gaussian distribution-based models, and mixup models.","['Chao Zhang', 'Min-Hsiu Hsieh', 'Dacheng Tao']","['cs.LG', 'stat.ML']",2018-11-11 05:06:02+00:00
http://arxiv.org/abs/1811.04350v1,Towards Governing Agent's Efficacy: Action-Conditional $Œ≤$-VAE for Deep Transparent Reinforcement Learning,"We tackle the blackbox issue of deep neural networks in the settings of
reinforcement learning (RL) where neural agents learn towards maximizing reward
gains in an uncontrollable way. Such learning approach is risky when the
interacting environment includes an expanse of state space because it is then
almost impossible to foresee all unwanted outcomes and penalize them with
negative rewards beforehand. Unlike reverse analysis of learned neural features
from previous works, our proposed method \nj{tackles the blackbox issue by
encouraging} an RL policy network to learn interpretable latent features
through an implementation of a disentangled representation learning method.
Toward this end, our method allows an RL agent to understand self-efficacy by
distinguishing its influences from uncontrollable environmental factors, which
closely resembles the way humans understand their scenes. Our experimental
results show that the learned latent factors not only are interpretable, but
also enable modeling the distribution of entire visited state space with a
specific action condition. We have experimented that this characteristic of the
proposed structure can lead to ex post facto governance for desired behaviors
of RL agents.","['John Yang', 'Gyujeong Lee', 'Minsung Hyun', 'Simyung Chang', 'Nojun Kwak']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-11 04:48:15+00:00
http://arxiv.org/abs/1811.04345v1,Optimizing Taxi Carpool Policies via Reinforcement Learning and Spatio-Temporal Mining,"In this paper, we develop a reinforcement learning (RL) based system to learn
an effective policy for carpooling that maximizes transportation efficiency so
that fewer cars are required to fulfill the given amount of trip demand. For
this purpose, first, we develop a deep neural network model, called ST-NN
(Spatio-Temporal Neural Network), to predict taxi trip time from the raw GPS
trip data. Secondly, we develop a carpooling simulation environment for RL
training, with the output of ST-NN and using the NYC taxi trip dataset. In
order to maximize transportation efficiency and minimize traffic congestion, we
choose the effective distance covered by the driver on a carpool trip as the
reward. Therefore, the more effective distance a driver achieves over a trip
(i.e. to satisfy more trip demand) the higher the efficiency and the less will
be the traffic congestion. We compared the performance of RL learned policy to
a fixed policy (which always accepts carpool) as a baseline and obtained
promising results that are interpretable and demonstrate the advantage of our
RL approach. We also compare the performance of ST-NN to that of
state-of-the-art travel time estimation methods and observe that ST-NN
significantly improves the prediction performance and is more robust to
outliers.","['Ishan Jindal', 'Zhiwei Qin', 'Xuewen Chen', 'Matthew Nokleby', 'Jieping Ye']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-11 04:13:31+00:00
http://arxiv.org/abs/1811.04344v3,Discovering heterogeneous subpopulations for fine-grained analysis of opioid use and opioid use disorders,"The opioid epidemic in the United States claims over 40,000 lives per year,
and it is estimated that well over two million Americans have an opioid use
disorder. Over-prescription and misuse of prescription opioids play an
important role in the epidemic. Individuals who are prescribed opioids, and who
are diagnosed with opioid use disorder, have diverse underlying health states.
Policy interventions targeting prescription opioid use, opioid use disorder,
and overdose often fail to account for this variation. To identify latent
health states, or phenotypes, pertinent to opioid use and opioid use disorders,
we use probabilistic topic modeling with medical diagnosis histories from a
statewide population of individuals who were prescribed opioids. We demonstrate
that our learned phenotypes are predictive of future opioid use-related
outcomes. In addition, we show how the learned phenotypes can provide important
context for variability in opioid prescriptions. Understanding the
heterogeneity in individual health states and in prescription opioid use can
help identify policy interventions to address this public health crisis.","['Jen J. Gong', 'Abigail Z. Jacobs', 'Toby E. Stuart', 'Mathijs de Vaan']","['q-bio.QM', 'cs.LG', 'stat.ML']",2018-11-11 04:00:32+00:00
http://arxiv.org/abs/1811.04343v1,Langevin-gradient parallel tempering for Bayesian neural learning,"Bayesian neural learning feature a rigorous approach to estimation and
uncertainty quantification via the posterior distribution of weights that
represent knowledge of the neural network. This not only provides point
estimates of optimal set of weights but also the ability to quantify
uncertainty in decision making using the posterior distribution. Markov chain
Monte Carlo (MCMC) techniques are typically used to obtain sample-based
estimates of the posterior distribution. However, these techniques face
challenges in convergence and scalability, particularly in settings with large
datasets and network architectures. This paper address these challenges in two
ways. First, parallel tempering is used used to explore multiple modes of the
posterior distribution and implemented in multi-core computing architecture.
Second, we make within-chain sampling schemes more efficient by using Langevin
gradient information in forming Metropolis-Hastings proposal distributions. We
demonstrate the techniques using time series prediction and pattern
classification applications. The results show that the method not only improves
the computational time, but provides better prediction or decision making
capabilities when compared to related methods.","['Rohitash Chandra', 'Konark Jain', 'Ratneel V. Deo', 'Sally Cripps']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-11 03:53:54+00:00
http://arxiv.org/abs/1811.06366v2,Cluster analysis of homicide rates in the Brazilian state of Goias from 2002 to 2014,"Homicide mortality is a worldwide concern and has occupied the agenda of
researchers and public managers. In Brazil, homicide is the third leading cause
of death in the general population and the first in the 15-39 age group. In
South America, Brazil has the third highest homicide mortality, behind
Venezuela and Colombia. To measure the impacts of violence it is important to
assess health systems and criminal justice, as well as other areas. In this
paper, we analyze the spatial distribution of homicide mortality in the state
of Goias, Center-West of Brazil, since the homicide rate increased from 24.5
per 100,000 in 2002 to 42.6 per 100,000 in 2014 in this location. Moreover,
this state had the fifth position of homicides in Brazil in 2014. We considered
socio-demographic variables for the state, performed analysis about correlation
and employed three clustering algorithms: K-means, Density-based and
Hierarchical. The results indicate the homicide rates are higher in cities
neighbors of large urban centers, although these cities have the best
socioeconomic indicators.","['Samuel Bruno da Silva Sousa', 'Ronaldo de Castro Del-Fiaco', 'Lilian Berton']","['cs.CY', 'cs.LG', 'stat.ML']",2018-11-11 02:10:18+00:00
http://arxiv.org/abs/1811.07770v2,Aff-Wild2: Extending the Aff-Wild Database for Affect Recognition,"Automatic understanding of human affect using visual signals is a problem
that has attracted significant interest over the past 20 years. However, human
emotional states are quite complex. To appraise such states displayed in
real-world settings, we need expressive emotional descriptors that are capable
of capturing and describing this complexity. The circumplex model of affect,
which is described in terms of valence (i.e., how positive or negative is an
emotion) and arousal (i.e., power of the activation of the emotion), can be
used for this purpose. Recent progress in the emotion recognition domain has
been achieved through the development of deep neural architectures and the
availability of very large training databases. To this end, Aff-Wild has been
the first large-scale ""in-the-wild"" database, containing around 1,200,000
frames. In this paper, we build upon this database, extending it with 260 more
subjects and 1,413,000 new video frames. We call the union of Aff-Wild with the
additional data, Aff-Wild2. The videos are downloaded from Youtube and have
large variations in pose, age, illumination conditions, ethnicity and
profession. Both database-specific as well as cross-database experiments are
performed in this paper, by utilizing the Aff-Wild2, along with the RECOLA
database. The developed deep neural architectures are based on the joint
training of state-of-the-art convolutional and recurrent neural networks with
attention mechanism; thus exploiting both the invariant properties of
convolutional features, while modeling temporal dynamics that arise in human
behaviour via the recurrent layers. The obtained results show premise for
utilization of the extended Aff-Wild, as well as of the developed deep neural
architectures for visual analysis of human behaviour in terms of continuous
emotion dimensions.","['Dimitrios Kollias', 'Stefanos Zafeiriou']","['cs.CV', 'cs.AI', 'cs.LG', 'stat.ML']",2018-11-11 01:57:15+00:00
http://arxiv.org/abs/1811.04324v2,Diversity-Driven Extensible Hierarchical Reinforcement Learning,"Hierarchical reinforcement learning (HRL) has recently shown promising
advances on speeding up learning, improving the exploration, and discovering
intertask transferable skills. Most recent works focus on HRL with two levels,
i.e., a master policy manipulates subpolicies, which in turn manipulate
primitive actions. However, HRL with multiple levels is usually needed in many
real-world scenarios, whose ultimate goals are highly abstract, while their
actions are very primitive. Therefore, in this paper, we propose a
diversity-driven extensible HRL (DEHRL), where an extensible and scalable
framework is built and learned levelwise to realize HRL with multiple levels.
DEHRL follows a popular assumption: diverse subpolicies are useful, i.e.,
subpolicies are believed to be more useful if they are more diverse. However,
existing implementations of this diversity assumption usually have their own
drawbacks, which makes them inapplicable to HRL with multiple levels.
Consequently, we further propose a novel diversity-driven solution to achieve
this assumption in DEHRL. Experimental studies evaluate DEHRL with five
baselines from four perspectives in two domains; the results show that DEHRL
outperforms the state-of-the-art baselines in all four aspects.","['Yuhang Song', 'Jianyi Wang', 'Thomas Lukasiewicz', 'Zhenghua Xu', 'Mai Xu']","['cs.LG', 'stat.ML']",2018-11-10 23:35:34+00:00
http://arxiv.org/abs/1811.07768v1,Handwriting Recognition of Historical Documents with few labeled data,"Historical documents present many challenges for offline handwriting
recognition systems, among them, the segmentation and labeling steps. Carefully
annotated textlines are needed to train an HTR system. In some scenarios,
transcripts are only available at the paragraph level with no text-line
information. In this work, we demonstrate how to train an HTR system with few
labeled data. Specifically, we train a deep convolutional recurrent neural
network (CRNN) system on only 10% of manually labeled text-line data from a
dataset and propose an incremental training procedure that covers the rest of
the data. Performance is further increased by augmenting the training set with
specially crafted multiscale data. We also propose a model-based normalization
scheme which considers the variability in the writing scale at the recognition
phase. We apply this approach to the publicly available READ dataset. Our
system achieved the second best result during the ICDAR2017 competition.","['Edgard Chammas', 'Chafic Mokbel', 'Laurence Likforman-Sulem']","['cs.CV', 'cs.LG', 'stat.ML']",2018-11-10 23:21:12+00:00
http://arxiv.org/abs/1811.04319v3,Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text,"Understanding procedural text requires tracking entities, actions and effects
as the narrative unfolds. We focus on the challenging real-world problem of
action-graph extraction from material science papers, where language is highly
specialized and data annotation is expensive and scarce. We propose a novel
approach, Text2Quest, where procedural text is interpreted as instructions for
an interactive game. A learning agent completes the game by executing the
procedure correctly in a text-based simulated lab environment. The framework
can complement existing approaches and enables richer forms of learning
compared to static texts. We discuss potential limitations and advantages of
the approach, and release a prototype proof-of-concept, hoping to encourage
research in this direction.","['Ronen Tamari', 'Hiroyuki Shindo', 'Dafna Shahaf', 'Yuji Matsumoto']","['cs.LG', 'cs.CL', 'stat.ML']",2018-11-10 21:45:07+00:00
http://arxiv.org/abs/1811.04277v1,Anomaly Detection via Graphical Lasso,"Anomalies and outliers are common in real-world data, and they can arise from
many sources, such as sensor faults. Accordingly, anomaly detection is
important both for analyzing the anomalies themselves and for cleaning the data
for further analysis of its ambient structure. Nonetheless, a precise
definition of anomalies is important for automated detection and herein we
approach such problems from the perspective of detecting sparse latent effects
embedded in large collections of noisy data. Standard Graphical Lasso-based
techniques can identify the conditional dependency structure of a collection of
random variables based on their sample covariance matrix. However, classic
Graphical Lasso is sensitive to outliers in the sample covariance matrix. In
particular, several outliers in a sample covariance matrix can destroy the
sparsity of its inverse. Accordingly, we propose a novel optimization problem
that is similar in spirit to Robust Principal Component Analysis (RPCA) and
splits the sample covariance matrix $M$ into two parts, $M=F+S$, where $F$ is
the cleaned sample covariance whose inverse is sparse and computable by
Graphical Lasso, and $S$ contains the outliers in $M$. We accomplish this
decomposition by adding an additional $ \ell_1$ penalty to classic Graphical
Lasso, and name it ""Robust Graphical Lasso (Rglasso)"". Moreover, we propose an
Alternating Direction Method of Multipliers (ADMM) solution to the optimization
problem which scales to large numbers of unknowns. We evaluate our algorithm on
both real and synthetic datasets, obtaining interpretable results and
outperforming the standard robust Minimum Covariance Determinant (MCD) method
and Robust Principal Component Analysis (RPCA) regarding both accuracy and
speed.","['Haitao Liu', 'Randy C. Paffenroth', 'Jian Zou', 'Chong Zhou']","['stat.ML', 'cs.LG']",2018-11-10 16:15:04+00:00
http://arxiv.org/abs/1811.04251v4,Formal Limitations on the Measurement of Mutual Information,"Measuring mutual information from finite data is difficult. Recent work has
considered variational methods maximizing a lower bound. In this paper, we
prove that serious statistical limitations are inherent to any method of
measuring mutual information. More specifically, we show that any
distribution-free high-confidence lower bound on mutual information estimated
from N samples cannot be larger than O(ln N ).","['David McAllester', 'Karl Stratos']","['cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2018-11-10 13:12:27+00:00
http://arxiv.org/abs/1811.04234v1,Towards Formula Translation using Recursive Neural Networks,"While it has become common to perform automated translations on natural
language, performing translations between different representations of
mathematical formulae has thus far not been possible. We implemented the first
translator for mathematical formulae based on recursive neural networks. We
chose recursive neural networks because mathematical formulae inherently
include a structural encoding. In our implementation, we developed new
techniques and topologies for recursive tree-to-tree neural networks based on
multi-variate multi-valued Long Short-Term Memory cells. We propose a novel
approach for mini-batch training that utilizes clustering and tree traversal.
We evaluate our translator and analyze the behavior of our proposed topologies
and techniques based on a translation from generic LaTeX to the semantic LaTeX
notation. We use the semantic LaTeX notation from the Digital Library for
Mathematical Formulae and the Digital Repository for Mathematical Formulae at
the National Institute for Standards and Technology. We find that a simple
heuristics-based clustering algorithm outperforms the conventional clustering
algorithms on the task of clustering binary trees of mathematical formulae with
respect to their topology. Furthermore, we find a mask for the loss function,
which can prevent the neural network from finding a local minimum of the loss
function. Given our preliminary results, a complete translation from formula to
formula is not yet possible. However, we achieved a prediction accuracy of
47.05% for predicting symbols at the correct position and an accuracy of 92.3%
when ignoring the predicted position. Concluding, our work advances the field
of recursive neural networks by improving the training speed and quality of
training. In the future, we will work towards a complete translation allowing a
machine-interpretation of LaTeX formulae.","['Felix Petersen', 'Moritz Schubotz', 'Bela Gipp']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-10 11:20:18+00:00
http://arxiv.org/abs/1811.07769v1,Addressing the Invisible: Street Address Generation for Developing Countries with Deep Learning,"More than half of the world's roads lack adequate street addressing systems.
Lack of addresses is even more visible in daily lives of people in developing
countries. We would like to object to the assumption that having an address is
a luxury, by proposing a generative address design that maps the world in
accordance with streets. The addressing scheme is designed considering several
traditional street addressing methodologies employed in the urban development
scenarios around the world. Our algorithm applies deep learning to extract
roads from satellite images, converts the road pixel confidences into a road
network, partitions the road network to find neighborhoods, and labels the
regions, roads, and address units using graph- and proximity-based algorithms.
We present our results on a sample US city, and several developing cities,
compare travel times of users using current ad hoc and new complete addresses,
and contrast our addressing solution to current industrial and open geocoding
alternatives.","['Ilke Demir', 'Ramesh Raskar']","['cs.CV', 'cs.CY', 'cs.LG', 'stat.ML']",2018-11-10 07:34:04+00:00
http://arxiv.org/abs/1811.04151v1,Design Rule Violation Hotspot Prediction Based on Neural Network Ensembles,"Design rule check is a critical step in the physical design of integrated
circuits to ensure manufacturability. However, it can be done only after a
time-consuming detailed routing procedure, which adds drastically to the time
of design iterations. With advanced technology nodes, the outcomes of global
routing and detailed routing become less correlated, which adds to the
difficulty of predicting design rule violations from earlier stages. In this
paper, a framework based on neural network ensembles is proposed to predict
design rule violation hotspots using information from placement and global
routing. A soft voting structure and a PCA-based subset selection scheme are
developed on top of a baseline neural network from a recent work. Experimental
results show that the proposed architecture achieves significant improvement in
model performance compared to the baseline case. For half of test cases, the
performance is even better than random forest, a commonly-used ensemble
learning model.","['Wei Zeng', 'Azadeh Davoodi', 'Yu Hen Hu']","['cs.LG', 'stat.ML']",2018-11-09 22:18:26+00:00
http://arxiv.org/abs/1811.04142v2,Complex Unitary Recurrent Neural Networks using Scaled Cayley Transform,"Recurrent neural networks (RNNs) have been successfully used on a wide range
of sequential data problems. A well known difficulty in using RNNs is the
\textit{vanishing or exploding gradient} problem. Recently, there have been
several different RNN architectures that try to mitigate this issue by
maintaining an orthogonal or unitary recurrent weight matrix. One such
architecture is the scaled Cayley orthogonal recurrent neural network (scoRNN)
which parameterizes the orthogonal recurrent weight matrix through a scaled
Cayley transform. This parametrization contains a diagonal scaling matrix
consisting of positive or negative one entries that can not be optimized by
gradient descent. Thus the scaling matrix is fixed before training and a
hyperparameter is introduced to tune the matrix for each particular task. In
this paper, we develop a unitary RNN architecture based on a complex scaled
Cayley transform. Unlike the real orthogonal case, the transformation uses a
diagonal scaling matrix consisting of entries on the complex unit circle which
can be optimized using gradient descent and no longer requires the tuning of a
hyperparameter. We also provide an analysis of a potential issue of the modReLU
activiation function which is used in our work and several other unitary RNNs.
In the experiments conducted, the scaled Cayley unitary recurrent neural
network (scuRNN) achieves comparable or better results than scoRNN and other
unitary RNNs without fixing the scaling matrix.","['Kehelwala D. G. Maduranga', 'Kyle E. Helfrich', 'Qiang Ye']","['stat.ML', 'cs.LG']",2018-11-09 21:37:36+00:00
http://arxiv.org/abs/1811.04136v3,The GaussianSketch for Almost Relative Error Kernel Distance,"We introduce two versions of a new sketch for approximately embedding the
Gaussian kernel into Euclidean inner product space. These work by truncating
infinite expansions of the Gaussian kernel, and carefully invoking the
RecursiveTensorSketch [Ahle et al. SODA 2020]. After providing concentration
and approximation properties of these sketches, we use them to approximate the
kernel distance between points sets. These sketches yield almost
$(1+\varepsilon)$-relative error, but with a small additive $\alpha$ term. In
the first variants the dependence on $1/\alpha$ is poly-logarithmic, but has
higher degree of polynomial dependence on the original dimension $d$. In the
second variant, the dependence on $1/\alpha$ is still poly-logarithmic, but the
dependence on $d$ is linear.","['Jeff M. Phillips', 'Wai Ming Tai']","['cs.LG', 'cs.CG', 'stat.ML']",2018-11-09 21:12:32+00:00
http://arxiv.org/abs/1811.04133v1,Integrating Recurrence Dynamics for Speech Emotion Recognition,"We investigate the performance of features that can capture nonlinear
recurrence dynamics embedded in the speech signal for the task of Speech
Emotion Recognition (SER). Reconstruction of the phase space of each speech
frame and the computation of its respective Recurrence Plot (RP) reveals
complex structures which can be measured by performing Recurrence
Quantification Analysis (RQA). These measures are aggregated by using
statistical functionals over segment and utterance periods. We report SER
results for the proposed feature set on three databases using different
classification methods. When fusing the proposed features with traditional
feature sets, we show an improvement in unweighted accuracy of up to 5.7% and
10.7% on Speaker-Dependent (SD) and Speaker-Independent (SI) SER tasks,
respectively, over the baseline. Following a segment-based approach we
demonstrate state-of-the-art performance on IEMOCAP using a Bidirectional
Recurrent Neural Network.","['Efthymios Tzinis', 'Georgios Paraskevopoulos', 'Christos Baziotis', 'Alexandros Potamianos']","['cs.SD', 'cs.LG', 'eess.AS', 'stat.ML']",2018-11-09 21:02:52+00:00
http://arxiv.org/abs/1811.04132v1,Reasoning over RDF Knowledge Bases using Deep Learning,"Semantic Web knowledge representation standards, and in particular RDF and
OWL, often come endowed with a formal semantics which is considered to be of
fundamental importance for the field. Reasoning, i.e., the drawing of logical
inferences from knowledge expressed in such standards, is traditionally based
on logical deductive methods and algorithms which can be proven to be sound and
complete and terminating, i.e. correct in a very strong sense. For various
reasons, though, in particular, the scalability issues arising from the
ever-increasing amounts of Semantic Web data available and the inability of
deductive algorithms to deal with noise in the data, it has been argued that
alternative means of reasoning should be investigated which bear high promise
for high scalability and better robustness. From this perspective, deductive
algorithms can be considered the gold standard regarding correctness against
which alternative methods need to be tested. In this paper, we show that it is
possible to train a Deep Learning system on RDF knowledge graphs, such that it
is able to perform reasoning over new RDF knowledge graphs, with high precision
and recall compared to the deductive gold standard.","['Monireh Ebrahimi', 'Md Kamruzzaman Sarker', 'Federico Bianchi', 'Ning Xie', 'Derek Doran', 'Pascal Hitzler']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-09 21:00:46+00:00
http://arxiv.org/abs/1811.04127v2,Policy Regret in Repeated Games,"The notion of \emph{policy regret} in online learning is a well defined?
performance measure for the common scenario of adaptive adversaries, which more
traditional quantities such as external regret do not take into account. We
revisit the notion of policy regret and first show that there are online
learning settings in which policy regret and external regret are incompatible:
any sequence of play that achieves a favorable regret with respect to one
definition must do poorly with respect to the other. We then focus on the
game-theoretic setting where the adversary is a self-interested agent. In that
setting, we show that external regret and policy regret are not in conflict
and, in fact, that a wide class of algorithms can ensure a favorable regret
with respect to both definitions, so long as the adversary is also using such
an algorithm. We also show that the sequence of play of no-policy regret
algorithms converges to a \emph{policy equilibrium}, a new notion of
equilibrium that we introduce. Relating this back to external regret, we show
that coarse correlated equilibria, which no-external regret players converge
to, are a strict subset of policy equilibria. Thus, in game-theoretic settings,
every sequence of play with no external regret also admits no policy regret,
but the converse does not hold.","['Raman Arora', 'Michael Dinitz', 'Teodor V. Marinov', 'Mehryar Mohri']","['cs.LG', 'cs.GT', 'stat.ML']",2018-11-09 20:30:09+00:00
http://arxiv.org/abs/1811.04064v1,Block Belief Propagation for Parameter Learning in Markov Random Fields,"Traditional learning methods for training Markov random fields require doing
inference over all variables to compute the likelihood gradient. The iteration
complexity for those methods therefore scales with the size of the graphical
models. In this paper, we propose \emph{block belief propagation learning}
(BBPL), which uses block-coordinate updates of approximate marginals to compute
approximate gradients, removing the need to compute inference on the entire
graphical model. Thus, the iteration complexity of BBPL does not scale with the
size of the graphs. We prove that the method converges to the same solution as
that obtained by using full inference per iteration, despite these
approximations, and we empirically demonstrate its scalability improvements
over standard training methods.","['You Lu', 'Zhiyuan Liu', 'Bert Huang']","['cs.LG', 'stat.ML']",2018-11-09 18:50:52+00:00
http://arxiv.org/abs/1811.04060v1,Automated Multi-Label Classification based on ML-Plan,"Automated machine learning (AutoML) has received increasing attention in the
recent past. While the main tools for AutoML, such as Auto-WEKA, TPOT, and
auto-sklearn, mainly deal with single-label classification and regression,
there is very little work on other types of machine learning tasks. In
particular, there is almost no work on automating the engineering of machine
learning applications for multi-label classification. This paper makes two
contributions. First, it discusses the usefulness and feasibility of an AutoML
approach for multi-label classification. Second, we show how the scope of
ML-Plan, an AutoML-tool for multi-class classification, can be extended towards
multi-label classification using MEKA, which is a multi-label extension of the
well-known Java library WEKA. The resulting approach recursively refines MEKA's
multi-label classifiers, which sometimes nest another multi-label classifier,
up to the selection of a single-label base learner provided by WEKA. In our
evaluation, we find that the proposed approach yields superb results and
performs significantly better than a set of baselines.","['Marcel Wever', 'Felix Mohr', 'Eyke H√ºllermeier']","['cs.LG', 'stat.ML']",2018-11-09 18:40:35+00:00
http://arxiv.org/abs/1811.04026v1,Adversarial Uncertainty Quantification in Physics-Informed Neural Networks,"We present a deep learning framework for quantifying and propagating
uncertainty in systems governed by non-linear differential equations using
physics-informed neural networks. Specifically, we employ latent variable
models to construct probabilistic representations for the system states, and
put forth an adversarial inference procedure for training them on data, while
constraining their predictions to satisfy given physical laws expressed by
partial differential equations. Such physics-informed constraints provide a
regularization mechanism for effectively training deep generative models as
surrogates of physical systems in which the cost of data acquisition is high,
and training data-sets are typically small. This provides a flexible framework
for characterizing uncertainty in the outputs of physical systems due to
randomness in their inputs or noise in their observations that entirely
bypasses the need for repeatedly sampling expensive experiments or numerical
simulators. We demonstrate the effectiveness of our approach through a series
of examples involving uncertainty propagation in non-linear conservation laws,
and the discovery of constitutive laws for flow through porous media directly
from noisy data.","['Yibo Yang', 'Paris Perdikaris']","['stat.ML', 'cs.LG', 'physics.comp-ph', '35']",2018-11-09 17:20:31+00:00
http://arxiv.org/abs/1811.04022v1,Convolutional neural networks in phase space and inverse problems,"We study inverse problems consisting on determining medium properties using
the responses to probing waves from the machine learning point of view. Based
on the understanding of propagation of waves and their nonlinear interactions,
we construct a deep convolutional neural network in which the parameters are
used to classify and reconstruct the coefficients of nonlinear wave equations
that model the medium properties. Furthermore, for given approximation
accuracy, we obtain the depth and number of units of the network and their
quantitative dependence on the complexity of the medium.","['Gunther Uhlmann', 'Yiran Wang']","['math.AP', 'cs.LG', 'stat.ML']",2018-11-09 17:17:07+00:00
http://arxiv.org/abs/1811.05540v1,Native Language Identification using i-vector,"The task of determining a speaker's native language based only on his
speeches in a second language is known as Native Language Identification or
NLI. Due to its increasing applications in various domains of speech signal
processing, this has emerged as an important research area in recent times. In
this paper we have proposed an i-vector based approach to develop an automatic
NLI system using MFCC and GFCC features. For evaluation of our approach, we
have tested our framework on the 2016 ComParE Native language sub-challenge
dataset which has English language speakers from 11 different native language
backgrounds. Our proposed method outperforms the baseline system with an
improvement in accuracy by 21.95% for the MFCC feature based i-vector framework
and 22.81% for the GFCC feature based i-vector framework.","['Ahmed Nazim Uddin', 'Md Ashequr Rahman', 'Md. Rafidul Islam', 'Mohammad Ariful Haque']","['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS', 'stat.ML']",2018-11-09 17:12:47+00:00
http://arxiv.org/abs/1811.04017v2,A generic framework for privacy preserving deep learning,"We detail a new framework for privacy preserving deep learning and discuss
its assets. The framework puts a premium on ownership and secure processing of
data and introduces a valuable representation based on chains of commands and
tensors. This abstraction allows one to implement complex privacy preserving
constructs such as Federated Learning, Secure Multiparty Computation, and
Differential Privacy while still exposing a familiar deep learning API to the
end-user. We report early results on the Boston Housing and Pima Indian
Diabetes datasets. While the privacy features apart from Differential Privacy
do not impact the prediction accuracy, the current implementation of the
framework introduces a significant overhead in performance, which will be
addressed at a later stage of the development. We believe this work is an
important milestone introducing the first reliable, general framework for
privacy preserving deep learning.","['Theo Ryffel', 'Andrew Trask', 'Morten Dahl', 'Bobby Wagner', 'Jason Mancuso', 'Daniel Rueckert', 'Jonathan Passerat-Palmbach']","['cs.LG', 'cs.CR', 'stat.ML']",2018-11-09 17:10:47+00:00
http://arxiv.org/abs/1811.12166v3,Prediction of ESG Compliance using a Heterogeneous Information Network,"Negative screening is one method to avoid interactions with inappropriate
entities. For example, financial institutions keep investment exclusion lists
of inappropriate firms that have environmental, social, and government (ESG)
problems. They create their investment exclusion lists by gathering information
from various news sources to keep their portfolios profitable as well as green.
International organizations also maintain smart sanctions lists that are used
to prohibit trade with entities that are involved in illegal activities. In the
present paper, we focus on the prediction of investment exclusion lists in the
finance domain. We construct a vast heterogeneous information network that
covers the necessary information surrounding each firm, which is assembled
using seven professionally curated datasets and two open datasets, which
results in approximately 50 million nodes and 400 million edges in total.
Exploiting these vast datasets and motivated by how professional investigators
and journalists undertake their daily investigations, we propose a model that
can learn to predict firms that are more likely to be added to an investment
exclusion list in the near future. Our approach is tested using the negative
news investment exclusion list data of more than 35,000 firms worldwide from
January 2012 to May 2018. Comparing with the state-of-the-art methods with and
without using the network, we show that the predictive accuracy is
substantially improved when using the vast information stored in the
heterogeneous information network. This work suggests new ways to consolidate
the diffuse information contained in big data to monitor dominant firms on a
global scale for better risk management and more socially responsible
investment.","['Ryohei Hisano', 'Didier Sornette', 'Takayuki Mizuno']","['cs.SI', 'cs.LG', 'stat.ML']",2018-11-09 16:54:18+00:00
http://arxiv.org/abs/1811.04006v1,Reachability-based safe learning for optimal control problem,"In this work we seek for an approach to integrate safety in the learning
process that relies on a partly known state-space model of the system and
regards the unknown dynamics as an additive bounded disturbance. We introduce a
framework for safely learning a control strategy for a given system with an
additive disturbance. On the basis of the known part of the model, a safe set
in which the system can learn safely, the algorithm can choose optimal actions
for pursuing the target set as long as the safety-preserving condition is
satisfied. After some learning episodes, the disturbance can be updated based
on real-world data. To this end, Gaussian Process regression is conducted on
the collected disturbance samples. Since the unstable nature of the law of the
real world, for example, change of friction or conductivity with the
temperature, we expect to have the more robust solution of optimal control
problem.
  For evaluation of approach described above we choose an inverted pendulum as
a benchmark model. The proposed algorithm manages to learn a policy that does
not violate the pre-specified safety constraints. Observed performance is
improved when it was incorporated exploration set up to make sure that an
optimal policy is learned everywhere in the safe set. Finally, we outline some
promising directions for future research beyond the scope of this paper.","['Stanislav Fedorov', 'Antonio Candelieri']","['cs.LG', 'cs.SY', 'stat.ML']",2018-11-09 16:37:59+00:00
http://arxiv.org/abs/1811.06369v1,Modelling student online behaviour in a virtual learning environment,"In recent years, distance education has enjoyed a major boom. Much work at
The Open University (OU) has focused on improving retention rates in these
modules by providing timely support to students who are at risk of failing the
module. In this paper we explore methods for analysing student activity in
online virtual learning environment (VLE) -- General Unary Hypotheses Automaton
(GUHA) and Markov chain-based analysis -- and we explain how this analysis can
be relevant for module tutors and other student support staff. We show that
both methods are a valid approach to modelling student activities. An advantage
of the Markov chain-based approach is in its graphical output and in the
possibility to model time dependencies of the student activities.","['Martin Hlosta', 'Drahomira Herrmannova', 'Lucie Vachova', 'Jakub Kuzilek', 'Zdenek Zdrahal', 'Annika Wolff']","['cs.CY', 'cs.LG', 'stat.ML', 'D.4.8; H.2.8']",2018-11-09 16:31:04+00:00
http://arxiv.org/abs/1811.03963v1,Deep Compression of Sum-Product Networks on Tensor Networks,"Sum-product networks (SPNs) represent an emerging class of neural networks
with clear probabilistic semantics and superior inference speed over graphical
models. This work reveals a strikingly intimate connection between SPNs and
tensor networks, thus leading to a highly efficient representation that we call
tensor SPNs (tSPNs). For the first time, through mapping an SPN onto a tSPN and
employing novel optimization techniques, we demonstrate remarkable parameter
compression with negligible loss in accuracy.","['Ching-Yun Ko', 'Cong Chen', 'Yuke Zhang', 'Kim Batselier', 'Ngai Wong']","['cs.LG', 'stat.ML']",2018-11-09 15:16:55+00:00
http://arxiv.org/abs/1811.03962v5,A Convergence Theory for Deep Learning via Over-Parameterization,"Deep neural networks (DNNs) have demonstrated dominating performance in many
fields; since AlexNet, networks used in practice are going wider and deeper. On
the theoretical side, a long line of works has been focusing on training neural
networks with one hidden layer. The theory of multi-layer networks remains
largely unsettled.
  In this work, we prove why stochastic gradient descent (SGD) can find
$\textit{global minima}$ on the training objective of DNNs in
$\textit{polynomial time}$. We only make two assumptions: the inputs are
non-degenerate and the network is over-parameterized. The latter means the
network width is sufficiently large: $\textit{polynomial}$ in $L$, the number
of layers and in $n$, the number of samples.
  Our key technique is to derive that, in a sufficiently large neighborhood of
the random initialization, the optimization landscape is almost-convex and
semi-smooth even with ReLU activations. This implies an equivalence between
over-parameterized neural networks and neural tangent kernel (NTK) in the
finite (and polynomial) width setting.
  As concrete examples, starting from randomly initialized weights, we prove
that SGD can attain 100% training accuracy in classification tasks, or minimize
regression loss in linear convergence speed, with running time polynomial in
$n,L$. Our theory applies to the widely-used but non-smooth ReLU activation,
and to any smooth and possibly non-convex loss functions. In terms of network
architectures, our theory at least applies to fully-connected neural networks,
convolutional neural networks (CNN), and residual neural networks (ResNet).","['Zeyuan Allen-Zhu', 'Yuanzhi Li', 'Zhao Song']","['cs.LG', 'cs.DS', 'cs.NE', 'math.OC', 'stat.ML']",2018-11-09 15:16:13+00:00
http://arxiv.org/abs/1811.04803v2,Observability Properties of Colored Graphs,"A colored graph is a directed graph in which nodes or edges have been
assigned colors that are not necessarily unique. Observability problems in such
graphs consider whether an agent observing the colors of edges or nodes
traversed on a path in the graph can determine which node they are at currently
or which nodes were visited earlier in the traversal. Previous research efforts
have identified several different notions of observability as well as the
associated properties of graphs for which those observability properties hold.
This paper unifies the prior work into a common framework with several new
results about relationships between those notions and associated graph
properties. The new framework provides an intuitive way to reason about the
attainable accuracy as a function of lag and time spent observing, and
identifies simple modifications to improve the observability of a given graph.
We show that one form of the graph modification problem is in NP-Complete. The
intuition of the new framework is borne out with numerical experiments. This
work has implications for problems that can be described in terms of an agent
traversing a colored graph, including the reconstruction of hidden states in a
hidden Markov model (HMM).","['Mark Chilenski', 'George Cybenko', 'Isaac Dekine', 'Piyush Kumar', 'Gil Raz']","['cs.LG', 'math.CO', 'stat.ML']",2018-11-09 15:12:24+00:00
http://arxiv.org/abs/1811.04788v2,A Bayesian Perspective of Statistical Machine Learning for Big Data,"Statistical Machine Learning (SML) refers to a body of algorithms and methods
by which computers are allowed to discover important features of input data
sets which are often very large in size. The very task of feature discovery
from data is essentially the meaning of the keyword `learning' in SML.
Theoretical justifications for the effectiveness of the SML algorithms are
underpinned by sound principles from different disciplines, such as Computer
Science and Statistics. The theoretical underpinnings particularly justified by
statistical inference methods are together termed as statistical learning
theory.
  This paper provides a review of SML from a Bayesian decision theoretic point
of view -- where we argue that many SML techniques are closely connected to
making inference by using the so called Bayesian paradigm. We discuss many
important SML techniques such as supervised and unsupervised learning, deep
learning, online learning and Gaussian processes especially in the context of
very large data sets where these are often employed. We present a dictionary
which maps the key concepts of SML from Computer Science and Statistics. We
illustrate the SML techniques with three moderately large data sets where we
also discuss many practical implementation issues. Thus the review is
especially targeted at statisticians and computer scientists who are aspiring
to understand and apply SML for moderately large to big data sets.","['Rajiv Sambasivan', 'Sourish Das', 'Sujit K Sahu']","['cs.LG', 'stat.ME', 'stat.ML']",2018-11-09 14:26:55+00:00
http://arxiv.org/abs/1811.03909v2,Evidence Transfer for Improving Clustering Tasks Using External Categorical Evidence,"In this paper we introduce evidence transfer for clustering, a deep learning
method that can incrementally manipulate the latent representations of an
autoencoder, according to external categorical evidence, in order to improve a
clustering outcome. By evidence transfer we define the process by which the
categorical outcome of an external, auxiliary task is exploited to improve a
primary task, in this case representation learning for clustering. Our proposed
method makes no assumptions regarding the categorical evidence presented, nor
the structure of the latent space. We compare our method, against the baseline
solution by performing k-means clustering before and after its deployment.
Experiments with three different kinds of evidence show that our method
effectively manipulates the latent representations when introduced with real
corresponding evidence, while remaining robust when presented with low quality
evidence.","['Athanasios Davvetas', 'Iraklis A. Klampanos', 'Vangelis Karkaletsis']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-09 14:10:18+00:00
http://arxiv.org/abs/1811.03897v1,Deep Ensemble Bayesian Active Learning : Addressing the Mode Collapse issue in Monte Carlo dropout via Ensembles,"In image classification tasks, the ability of deep CNNs to deal with complex
image data has proven to be unrivalled. However, they require large amounts of
labeled training data to reach their full potential. In specialised domains
such as healthcare, labeled data can be difficult and expensive to obtain.
Active Learning aims to alleviate this problem, by reducing the amount of
labelled data needed for a specific task while delivering satisfactory
performance. We propose DEBAL, a new active learning strategy designed for deep
neural networks. This method improves upon the current state-of-the-art deep
Bayesian active learning method, which suffers from the mode collapse problem.
We correct for this deficiency by making use of the expressive power and
statistical properties of model ensembles. Our proposed method manages to
capture superior data uncertainty, which translates into improved
classification performance. We demonstrate empirically that our ensemble method
yields faster convergence of CNNs trained on the MNIST and CIFAR-10 datasets.","['Remus Pop', 'Patric Fulop']","['cs.LG', 'stat.ML']",2018-11-09 13:44:12+00:00
http://arxiv.org/abs/1811.03895v1,Performance Guarantees for Homomorphisms Beyond Markov Decision Processes,"Most real-world problems have huge state and/or action spaces. Therefore, a
naive application of existing tabular solution methods is not tractable on such
problems. Nonetheless, these solution methods are quite useful if an agent has
access to a relatively small state-action space homomorphism of the true
environment and near-optimal performance is guaranteed by the map. A plethora
of research is focused on the case when the homomorphism is a Markovian
representation of the underlying process. However, we show that near-optimal
performance is sometimes guaranteed even if the homomorphism is non-Markovian.
Moreover, we can aggregate significantly more states by lifting the Markovian
requirement without compromising on performance. In this work, we expand
Extreme State Aggregation (ESA) framework to joint state-action aggregations.
We also lift the policy uniformity condition for aggregation in ESA that allows
even coarser modeling of the true environment.","['Sultan Javed Majeed', 'Marcus Hutter']","['cs.LG', 'stat.ML']",2018-11-09 13:39:16+00:00
http://arxiv.org/abs/1811.03883v1,Exploiting Capacity of Sewer System Using Unsupervised Learning Algorithms Combined with Dimensionality Reduction,"Exploiting capacity of sewer system using decentralized control is a cost
effective mean of minimizing the overflow. Given the size of the real sewer
system, exploiting all the installed control structures in the sewer pipes can
be challenging. This paper presents a divide and conquer solution to implement
decentralized control measures based on unsupervised learning algorithms. A
sewer system is first divided into a number of subcatchments. A series of
natural and built factors that have the impact on sewer system performance is
then collected. Clustering algorithms are then applied to grouping
subcatchments with similar hydraulic hydrologic characteristics. Following
which, principal component analysis is performed to interpret the main features
of sub-catchment groups and identify priority control locations. Overflows
under different control scenarios are compared based on the hydraulic model.
Simulation results indicate that priority control applied to the most suitable
cluster could bring the most profitable result.","['Duo Zhang', 'Geir Lindholm', 'Nicolas Martinez', 'Harsha Ratnaweera']","['cs.LG', 'stat.ML']",2018-11-09 12:39:53+00:00
http://arxiv.org/abs/1811.06367v1,Enhancing Operation of a Sewage Pumping Station for Inter Catchment Wastewater Transfer by Using Deep Learning and Hydraulic Model,"This paper presents a novel Inter Catchment Wastewater Transfer (ICWT) method
for mitigating sewer overflow. The ICWT aims at balancing the spatial mismatch
of sewer flow and treatment capacity of Wastewater Treatment Plant (WWTP),
through collaborative operation of sewer system facilities. Using a hydraulic
model, the effectiveness of ICWT is investigated in a sewer system in Drammen,
Norway. Concerning the whole system performance, we found that the S{\o}ren
Lemmich pump station plays a vital role in the ICWT framework. To enhance the
operation of this pump station, it is imperative to construct a multi-step
ahead water level prediction model. Hence, one of the most promising artificial
intelligence techniques, Long Short Term Memory (LSTM), is employed to
undertake this task. Experiments demonstrated that LSTM is superior to Gated
Recurrent Unit (GRU), Recurrent Neural Network (RNN), Feed-forward Neural
Network (FFNN) and Support Vector Regression (SVR).","['Duo Zhang', 'Erlend Skullestad Holland', 'Geir Lindholm', 'Harsha Ratnaweera']","['cs.CY', 'cs.LG', 'stat.ML']",2018-11-09 12:28:53+00:00
http://arxiv.org/abs/1811.06368v1,DeepCSO: Forecasting of Combined Sewer Overflow at a Citywide Level using Multi-task Deep Learning,"Combined Sewer Overflow (CSO) is a major problem to be addressed by many
cities. Understanding the behavior of sewer system through proper urban
hydrological models is an effective method of enhancing sewer system
management. Conventional deterministic methods, which heavily rely on physical
principles, is inappropriate for real-time purpose due to their expensive
computation. On the other hand, data-driven methods have gained huge interests,
but most studies only focus on modeling a single component of the sewer system
and supply information at a very abstract level. In this paper, we proposed the
DeepCSO model, which aims at forecasting CSO events from multiple CSO
structures simultaneously in near real time at a citywide level. The proposed
model provided an intermediate methodology that combines the flexibility of
data-driven methods and the rich information contained in deterministic methods
while avoiding the drawbacks of these two methods. A comparison of the results
demonstrated that the deep learning based multi-task model is superior to the
traditional methods.","['Duo Zhang', 'Geir Lindholm', 'Harsha Ratnaweera']","['cs.CY', 'cs.LG', 'stat.ML']",2018-11-09 12:27:28+00:00
http://arxiv.org/abs/1811.03862v5,Targeting Solutions in Bayesian Multi-Objective Optimization: Sequential and Batch Versions,"Multi-objective optimization aims at finding trade-off solutions to
conflicting objectives. These constitute the Pareto optimal set. In the context
of expensive-to-evaluate functions, it is impossible and often non-informative
to look for the entire set. As an end-user would typically prefer a certain
part of the objective space, we modify the Bayesian multi-objective
optimization algorithm which uses Gaussian Processes to maximize the Expected
Hypervolume Improvement, to focus the search in the preferred region. The
cumulated effects of the Gaussian Processes and the targeting strategy lead to
a particularly efficient convergence to the desired part of the Pareto set. To
take advantage of parallel computing, a multi-point extension of the targeting
criterion is proposed and analyzed.","['David Gaudrie', 'Rodolphe Le Riche', 'Victor Picheny', 'Benoit Enaux', 'Vincent Herbert']","['stat.ML', 'cs.LG', 'math.OC']",2018-11-09 11:03:54+00:00
http://arxiv.org/abs/1811.03850v2,MD-GAN: Multi-Discriminator Generative Adversarial Networks for Distributed Datasets,"A recent technical breakthrough in the domain of machine learning is the
discovery and the multiple applications of Generative Adversarial Networks
(GANs). Those generative models are computationally demanding, as a GAN is
composed of two deep neural networks, and because it trains on large datasets.
A GAN is generally trained on a single server.
  In this paper, we address the problem of distributing GANs so that they are
able to train over datasets that are spread on multiple workers. MD-GAN is
exposed as the first solution for this problem: we propose a novel learning
procedure for GANs so that they fit this distributed setup. We then compare the
performance of MD-GAN to an adapted version of Federated Learning to GANs,
using the MNIST and CIFAR10 datasets. MD-GAN exhibits a reduction by a factor
of two of the learning complexity on each worker node, while providing better
performances than federated learning on both datasets. We finally discuss the
practical implications of distributing GANs.","['Corentin Hardy', 'Erwan Le Merrer', 'Bruno Sericola']","['cs.LG', 'stat.ML']",2018-11-09 10:24:35+00:00
http://arxiv.org/abs/1811.03821v3,Skeptical Deep Learning with Distribution Correction,"Recently deep neural networks have been successfully used for various
classification tasks, especially for problems with massive perfectly labeled
training data. However, it is often costly to have large-scale credible labels
in real-world applications. One solution is to make supervised learning robust
with imperfectly labeled input. In this paper, we develop a distribution
correction approach that allows deep neural networks to avoid overfitting
imperfect training data. Specifically, we treat the noisy input as samples from
an incorrect distribution, which will be automatically corrected during our
training process. We test our approach on several classification datasets with
elaborately generated noisy labels. The results show significantly higher
prediction and recovery accuracy with our approach compared to alternative
methods.","['Mingxiao An', 'Yongzhou Chen', 'Qi Liu', 'Chuanren Liu', 'Guangyi Lv', 'Fangzhao Wu', 'Jianhui Ma']","['cs.LG', 'stat.ML']",2018-11-09 09:07:06+00:00
http://arxiv.org/abs/1811.03804v4,Gradient Descent Finds Global Minima of Deep Neural Networks,"Gradient descent finds a global minimum in training deep neural networks
despite the objective function being non-convex. The current paper proves
gradient descent achieves zero training loss in polynomial time for a deep
over-parameterized neural network with residual connections (ResNet). Our
analysis relies on the particular structure of the Gram matrix induced by the
neural network architecture. This structure allows us to show the Gram matrix
is stable throughout the training process and this stability implies the global
optimality of the gradient descent algorithm. We further extend our analysis to
deep residual convolutional neural networks and obtain a similar convergence
result.","['Simon S. Du', 'Jason D. Lee', 'Haochuan Li', 'Liwei Wang', 'Xiyu Zhai']","['cs.LG', 'cs.AI', 'cs.CV', 'math.OC', 'stat.ML']",2018-11-09 07:39:59+00:00
http://arxiv.org/abs/1811.03790v1,Can We Use Speaker Recognition Technology to Attack Itself? Enhancing Mimicry Attacks Using Automatic Target Speaker Selection,"We consider technology-assisted mimicry attacks in the context of automatic
speaker verification (ASV). We use ASV itself to select targeted speakers to be
attacked by human-based mimicry. We recorded 6 naive mimics for whom we select
target celebrities from VoxCeleb1 and VoxCeleb2 corpora (7,365 potential
targets) using an i-vector system. The attacker attempts to mimic the selected
target, with the utterances subjected to ASV tests using an independently
developed x-vector system. Our main finding is negative: even if some of the
attacker scores against the target speakers were slightly increased, our mimics
did not succeed in spoofing the x-vector system. Interestingly, however, the
relative ordering of the selected targets (closest, furthest, median) are
consistent between the systems, which suggests some level of transferability
between the systems.","['Tomi Kinnunen', 'Rosa Gonz√°lez Hautam√§ki', 'Ville Vestman', 'Md Sahidullah']","['eess.AS', 'cs.CL', 'stat.ML']",2018-11-09 06:15:08+00:00
http://arxiv.org/abs/1811.04076v1,AttS2S-VC: Sequence-to-Sequence Voice Conversion with Attention and Context Preservation Mechanisms,"This paper describes a method based on a sequence-to-sequence learning
(Seq2Seq) with attention and context preservation mechanism for voice
conversion (VC) tasks. Seq2Seq has been outstanding at numerous tasks involving
sequence modeling such as speech synthesis and recognition, machine
translation, and image captioning. In contrast to current VC techniques, our
method 1) stabilizes and accelerates the training procedure by considering
guided attention and proposed context preservation losses, 2) allows not only
spectral envelopes but also fundamental frequency contours and durations of
speech to be converted, 3) requires no context information such as phoneme
labels, and 4) requires no time-aligned source and target speech data in
advance. In our experiment, the proposed VC framework can be trained in only
one day, using only one GPU of an NVIDIA Tesla K80, while the quality of the
synthesized speech is higher than that of speech converted by Gaussian mixture
model-based VC and is comparable to that of speech generated by recurrent
neural network-based text-to-speech synthesis, which can be regarded as an
upper limit on VC performance.","['Kou Tanaka', 'Hirokazu Kameoka', 'Takuhiro Kaneko', 'Nobukatsu Hojo']","['eess.AS', 'cs.LG', 'cs.SD', 'stat.ML']",2018-11-09 05:19:43+00:00
http://arxiv.org/abs/1811.03760v1,EA-LSTM: Evolutionary Attention-based LSTM for Time Series Prediction,"Time series prediction with deep learning methods, especially long short-term
memory neural networks (LSTMs), have scored significant achievements in recent
years. Despite the fact that the LSTMs can help to capture long-term
dependencies, its ability to pay different degree of attention on sub-window
feature within multiple time-steps is insufficient. To address this issue, an
evolutionary attention-based LSTM training with competitive random search is
proposed for multivariate time series prediction. By transferring shared
parameters, an evolutionary attention learning approach is introduced to the
LSTMs model. Thus, like that for biological evolution, the pattern for
importance-based attention sampling can be confirmed during temporal
relationship mining. To refrain from being trapped into partial optimization
like traditional gradient-based methods, an evolutionary computation inspired
competitive random search method is proposed, which can well configure the
parameters in the attention layer. Experimental results have illustrated that
the proposed model can achieve competetive prediction performance compared with
other baseline methods.","['Youru Li', 'Zhenfeng Zhu', 'Deqiang Kong', 'Hua Han', 'Yao Zhao']","['cs.LG', 'cs.NE', 'stat.ML']",2018-11-09 03:42:36+00:00
http://arxiv.org/abs/1811.03751v1,Imagining an Engineer: On GAN-Based Data Augmentation Perpetuating Biases,"The use of synthetic data generated by Generative Adversarial Networks (GANs)
has become quite a popular method to do data augmentation for many
applications. While practitioners celebrate this as an economical way to get
more synthetic data that can be used to train downstream classifiers, it is not
clear that they recognize the inherent pitfalls of this technique. In this
paper, we aim to exhort practitioners against deriving any false sense of
security against data biases based on data augmentation. To drive this point
home, we show that starting with a dataset consisting of head-shots of
engineering researchers, GAN-based augmentation ""imagines"" synthetic engineers,
most of whom have masculine features and white skin color (inferred from a
human subject study conducted on Amazon Mechanical Turk). This demonstrates how
biases inherent in the training data are reinforced, and sometimes even
amplified, by GAN-based data augmentation; it should serve as a cautionary tale
for the lay practitioners.","['Niharika Jain', 'Lydia Manikonda', 'Alberto Olmo Hernandez', 'Sailik Sengupta', 'Subbarao Kambhampati']","['cs.LG', 'cs.AI', 'stat.ML']",2018-11-09 03:02:35+00:00
http://arxiv.org/abs/1811.03744v1,Density estimation for shift-invariant multidimensional distributions,"We study density estimation for classes of shift-invariant distributions over
$\mathbb{R}^d$. A multidimensional distribution is ""shift-invariant"" if,
roughly speaking, it is close in total variation distance to a small shift of
it in any direction. Shift-invariance relaxes smoothness assumptions commonly
used in non-parametric density estimation to allow jump discontinuities. The
different classes of distributions that we consider correspond to different
rates of tail decay.
  For each such class we give an efficient algorithm that learns any
distribution in the class from independent samples with respect to total
variation distance. As a special case of our general result, we show that
$d$-dimensional shift-invariant distributions which satisfy an exponential tail
bound can be learned to total variation distance error $\epsilon$ using
$\tilde{O}_d(1/ \epsilon^{d+2})$ examples and $\tilde{O}_d(1/ \epsilon^{2d+2})$
time. This implies that, for constant $d$, multivariate log-concave
distributions can be learned in $\tilde{O}_d(1/\epsilon^{2d+2})$ time using
$\tilde{O}_d(1/\epsilon^{d+2})$ samples, answering a question of [Diakonikolas,
Kane and Stewart, 2016] All of our results extend to a model of noise-tolerant
density estimation using Huber's contamination model, in which the target
distribution to be learned is a $(1-\epsilon,\epsilon)$ mixture of some unknown
distribution in the class with some other arbitrary and unknown distribution,
and the learning algorithm must output a hypothesis distribution with total
variation distance error $O(\epsilon)$ from the target distribution. We show
that our general results are close to best possible by proving a simple
$\Omega\left(1/\epsilon^d\right)$ information-theoretic lower bound on sample
complexity even for learning bounded distributions that are shift-invariant.","['Anindya De', 'Philip M. Long', 'Rocco A. Servedio']","['cs.LG', 'cs.DS', 'stat.ML']",2018-11-09 02:29:43+00:00
http://arxiv.org/abs/1811.03739v1,Securing Behavior-based Opinion Spam Detection,"Reviews spams are prevalent in e-commerce to manipulate product ranking and
customers decisions maliciously. While spams generated based on simple spamming
strategy can be detected effectively, hardened spammers can evade regular
detectors via more advanced spamming strategies. Previous work gave more
attention to evasion against text and graph-based detectors, but evasions
against behavior-based detectors are largely ignored, leading to
vulnerabilities in spam detection systems. Since real evasion data are scarce,
we first propose EMERAL (Evasion via Maximum Entropy and Rating sAmpLing) to
generate evasive spams to certain existing detectors. EMERAL can simulate
spammers with different goals and levels of knowledge about the detectors,
targeting at different stages of the life cycle of target products. We show
that in the evasion-defense dynamic, only a few evasion types are meaningful to
the spammers, and any spammer will not be able to evade too many detection
signals at the same time. We reveal that some evasions are quite insidious and
can fail all detection signals. We then propose DETER (Defense via Evasion
generaTion using EmeRal), based on model re-training on diverse evasive samples
generated by EMERAL. Experiments confirm that DETER is more accurate in
detecting both suspicious time window and individual spamming reviews. In terms
of security, DETER is versatile enough to be vaccinated against diverse and
unexpected evasions, is agnostic about evasion strategy and can be released
without privacy concern.","['Shuaijun Ge', 'Guixiang Ma', 'Sihong Xie', 'Philip S. Yu']","['cs.LG', 'cs.CR', 'stat.ML']",2018-11-09 02:09:31+00:00
http://arxiv.org/abs/1811.03733v2,Universal Decision-Based Black-Box Perturbations: Breaking Security-Through-Obscurity Defenses,"We study the problem of finding a universal (image-agnostic) perturbation to
fool machine learning (ML) classifiers (e.g., neural nets, decision tress) in
the hard-label black-box setting. Recent work in adversarial ML in the
white-box setting (model parameters are known) has shown that many
state-of-the-art image classifiers are vulnerable to universal adversarial
perturbations: a fixed human-imperceptible perturbation that, when added to any
image, causes it to be misclassified with high probability Kurakin et al.
[2016], Szegedy et al. [2013], Chen et al. [2017a], Carlini and Wagner [2017].
This paper considers a more practical and challenging problem of finding such
universal perturbations in an obscure (or black-box) setting. More
specifically, we use zeroth order optimization algorithms to find such a
universal adversarial perturbation when no model information is revealed-except
that the attacker can make queries to probe the classifier. We further relax
the assumption that the output of a query is continuous valued confidence
scores for all the classes and consider the case where the output is a
hard-label decision. Surprisingly, we found that even in these extremely
obscure regimes, state-of-the-art ML classifiers can be fooled with a very high
probability just by adding a single human-imperceptible image perturbation to
any natural image. The surprising existence of universal perturbations in a
hard-label black-box setting raises serious security concerns with the
existence of a universal noise vector that adversaries can possibly exploit to
break a classifier on most natural images.","['Thomas A. Hogan', 'Bhavya Kailkhura']","['cs.LG', 'cs.AI', 'cs.CR', 'stat.ML']",2018-11-09 01:43:22+00:00
http://arxiv.org/abs/1811.03728v1,Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering,"While machine learning (ML) models are being increasingly trusted to make
decisions in different and varying areas, the safety of systems using such
models has become an increasing concern. In particular, ML models are often
trained on data from potentially untrustworthy sources, providing adversaries
with the opportunity to manipulate them by inserting carefully crafted samples
into the training set. Recent work has shown that this type of attack, called a
poisoning attack, allows adversaries to insert backdoors or trojans into the
model, enabling malicious behavior with simple external backdoor triggers at
inference time and only a blackbox perspective of the model itself. Detecting
this type of attack is challenging because the unexpected behavior occurs only
when a backdoor trigger, which is known only to the adversary, is present.
Model users, either direct users of training data or users of pre-trained model
from a catalog, may not guarantee the safe operation of their ML-based system.
In this paper, we propose a novel approach to backdoor detection and removal
for neural networks. Through extensive experimental results, we demonstrate its
effectiveness for neural networks classifying text and images. To the best of
our knowledge, this is the first methodology capable of detecting poisonous
data crafted to insert backdoors and repairing the model that does not require
a verified and trusted dataset.","['Bryant Chen', 'Wilka Carvalho', 'Nathalie Baracaldo', 'Heiko Ludwig', 'Benjamin Edwards', 'Taesung Lee', 'Ian Molloy', 'Biplav Srivastava']","['cs.LG', 'cs.CR', 'stat.ML']",2018-11-09 01:08:00+00:00
http://arxiv.org/abs/1811.03717v2,Fast determinantal point processes via distortion-free intermediate sampling,"Given a fixed $n\times d$ matrix $\mathbf{X}$, where $n\gg d$, we study the
complexity of sampling from a distribution over all subsets of rows where the
probability of a subset is proportional to the squared volume of the
parallelepiped spanned by the rows (a.k.a. a determinantal point process). In
this task, it is important to minimize the preprocessing cost of the procedure
(performed once) as well as the sampling cost (performed repeatedly). To that
end, we propose a new determinantal point process algorithm which has the
following two properties, both of which are novel: (1) a preprocessing step
which runs in time $O(\text{number-of-non-zeros}(\mathbf{X})\cdot\log
n)+\text{poly}(d)$, and (2) a sampling step which runs in $\text{poly}(d)$
time, independent of the number of rows $n$. We achieve this by introducing a
new regularized determinantal point process (R-DPP), which serves as an
intermediate distribution in the sampling procedure by reducing the number of
rows from $n$ to $\text{poly}(d)$. Crucially, this intermediate distribution
does not distort the probabilities of the target sample. Our key novelty in
defining the R-DPP is the use of a Poisson random variable for controlling the
probabilities of different subset sizes, leading to new determinantal formulas
such as the normalization constant for this distribution. Our algorithm has
applications in many diverse areas where determinantal point processes have
been used, such as machine learning, stochastic optimization, data
summarization and low-rank matrix reconstruction.",['Micha≈Ç Derezi≈Ñski'],"['cs.LG', 'stat.ML']",2018-11-08 23:35:29+00:00
http://arxiv.org/abs/1811.03711v1,Benchmarking Deep Sequential Models on Volatility Predictions for Financial Time Series,"Volatility is a quantity of measurement for the price movements of stocks or
options which indicates the uncertainty within financial markets. As an
indicator of the level of risk or the degree of variation, volatility is
important to analyse the financial market, and it is taken into consideration
in various decision-making processes in financial activities. On the other
hand, recent advancement in deep learning techniques has shown strong
capabilities in modelling sequential data, such as speech and natural language.
In this paper, we empirically study the applicability of the latest deep
structures with respect to the volatility modelling problem, through which we
aim to provide an empirical guidance for the theoretical analysis of the
marriage between deep learning techniques and financial applications in the
future. We examine both the traditional approaches and the deep sequential
models on the task of volatility prediction, including the most recent variants
of convolutional and recurrent networks, such as the dilated architecture.
Accordingly, experiments with real-world stock price datasets are performed on
a set of 1314 daily stock series for 2018 days of transaction. The evaluation
and comparison are based on the negative log likelihood (NLL) of real-world
stock price time series. The result shows that the dilated neural models,
including dilated CNN and Dilated RNN, produce most accurate estimation and
prediction, outperforming various widely-used deterministic models in the GARCH
family and several recently proposed stochastic models. In addition, the high
flexibility and rich expressive power are validated in this study.","['Qiang Zhang', 'Rui Luo', 'Yaodong Yang', 'Yuanyuan Liu']","['cs.LG', 'q-fin.ST', 'stat.ML']",2018-11-08 23:11:38+00:00
http://arxiv.org/abs/1811.03700v2,A Comparison of Lattice-free Discriminative Training Criteria for Purely Sequence-Trained Neural Network Acoustic Models,"In this work, three lattice-free (LF) discriminative training criteria for
purely sequence-trained neural network acoustic models are compared on LVCSR
tasks, namely maximum mutual information (MMI), boosted maximum mutual
information (bMMI) and state-level minimum Bayes risk (sMBR). We demonstrate
that, analogous to LF-MMI, a neural network acoustic model can also be trained
from scratch using LF-bMMI or LF-sMBR criteria respectively without the need of
cross-entropy pre-training. Furthermore, experimental results on
Switchboard-300hrs and Switchboard+Fisher-2100hrs datasets show that models
trained with LF-bMMI consistently outperform those trained with plain LF-MMI
and achieve a relative word error rate (WER) reduction of 5% over competitive
temporal convolution projected LSTM (TDNN-LSTMP) LF-MMI baselines.","['Chao Weng', 'Dong Yu']","['cs.LG', 'cs.AI', 'cs.CL', 'eess.AS', 'stat.ML']",2018-11-08 22:37:55+00:00
http://arxiv.org/abs/1811.03679v3,Practical Bayesian Learning of Neural Networks via Adaptive Optimisation Methods,"We introduce a novel framework for the estimation of the posterior
distribution over the weights of a neural network, based on a new probabilistic
interpretation of adaptive optimisation algorithms such as AdaGrad and Adam. We
demonstrate the effectiveness of our Bayesian Adam method, Badam, by
experimentally showing that the learnt uncertainties correctly relate to the
weights' predictive capabilities by weight pruning. We also demonstrate the
quality of the derived uncertainty measures by comparing the performance of
Badam to standard methods in a Thompson sampling setting for multi-armed
bandits, where good uncertainty measures are required for an agent to balance
exploration and exploitation.","['Samuel Kessler', 'Arnold Salas', 'Vincent W. C. Tan', 'Stefan Zohren', 'Stephen Roberts']","['stat.ML', 'cs.LG']",2018-11-08 21:04:00+00:00
http://arxiv.org/abs/1811.03666v2,Statistical Characteristics of Deep Representations: An Empirical Investigation,"In this study, the effects of eight representation regularization methods are
investigated, including two newly developed rank regularizers (RR). The
investigation shows that the statistical characteristics of representations
such as correlation, sparsity, and rank can be manipulated as intended, during
training. Furthermore, it is possible to improve the baseline performance
simply by trying all the representation regularizers and fine-tuning the
strength of their effects. In contrast to performance improvement, no
consistent relationship between performance and statistical characteristics was
observable. The results indicate that manipulation of statistical
characteristics can be helpful for improving performance, but only indirectly
through its influence on learning dynamics or its tuning effects.","['Daeyoung Choi', 'Kyungeun Lee', 'Duhun Hwang', 'Wonjong Rhee']","['cs.LG', 'stat.ML']",2018-11-08 20:17:50+00:00
http://arxiv.org/abs/1811.03619v3,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training,"Distributed training of deep nets is an important technique to address some
of the present day computing challenges like memory consumption and
computational demands. Classical distributed approaches, synchronous or
asynchronous, are based on the parameter server architecture, i.e., worker
nodes compute gradients which are communicated to the parameter server while
updated parameters are returned. Recently, distributed training with AllReduce
operations gained popularity as well. While many of those operations seem
appealing, little is reported about wall-clock training time improvements. In
this paper, we carefully analyze the AllReduce based setup, propose timing
models which include network latency, bandwidth, cluster size and compute time,
and demonstrate that a pipelined training with a width of two combines the best
of both synchronous and asynchronous training. Specifically, for a setup
consisting of a four-node GPU cluster we show wall-clock time training
improvements of up to 5.4x compared to conventional approaches.","['Youjie Li', 'Mingchao Yu', 'Songze Li', 'Salman Avestimehr', 'Nam Sung Kim', 'Alexander Schwing']","['cs.LG', 'cs.DC', 'stat.ML']",2018-11-08 18:59:55+00:00
http://arxiv.org/abs/1811.03617v2,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training,"Data parallelism can boost the training speed of convolutional neural
networks (CNN), but could suffer from significant communication costs caused by
gradient aggregation. To alleviate this problem, several scalar quantization
techniques have been developed to compress the gradients. But these techniques
could perform poorly when used together with decentralized aggregation
protocols like ring all-reduce (RAR), mainly due to their inability to directly
aggregate compressed gradients. In this paper, we empirically demonstrate the
strong linear correlations between CNN gradients, and propose a gradient vector
quantization technique, named GradiVeQ, to exploit these correlations through
principal component analysis (PCA) for substantial gradient dimension
reduction. GradiVeQ enables direct aggregation of compressed gradients, hence
allows us to build a distributed learning system that parallelizes GradiVeQ
gradient compression and RAR communications. Extensive experiments on popular
CNNs demonstrate that applying GradiVeQ slashes the wall-clock gradient
aggregation time of the original RAR by more than 5X without noticeable
accuracy loss, and reduces the end-to-end training time by almost 50%. The
results also show that GradiVeQ is compatible with scalar quantization
techniques such as QSGD (Quantized SGD), and achieves a much higher speed-up
gain under the same compression ratio.","['Mingchao Yu', 'Zhifeng Lin', 'Krishna Narra', 'Songze Li', 'Youjie Li', 'Nam Sung Kim', 'Alexander Schwing', 'Murali Annavaram', 'Salman Avestimehr']","['cs.LG', 'cs.DC', 'stat.ML']",2018-11-08 18:59:50+00:00
http://arxiv.org/abs/1811.03600v3,Measuring the Effects of Data Parallelism on Neural Network Training,"Recent hardware developments have dramatically increased the scale of data
parallelism available for neural network training. Among the simplest ways to
harness next-generation hardware is to increase the batch size in standard
mini-batch neural network training algorithms. In this work, we aim to
experimentally characterize the effects of increasing the batch size on
training time, as measured by the number of steps necessary to reach a goal
out-of-sample error. We study how this relationship varies with the training
algorithm, model, and data set, and find extremely large variation between
workloads. Along the way, we show that disagreements in the literature on how
batch size affects model quality can largely be explained by differences in
metaparameter tuning and compute budgets at different batch sizes. We find no
evidence that larger batch sizes degrade out-of-sample performance. Finally, we
discuss the implications of our results on efforts to train neural networks
much faster in the future. Our experimental data is publicly available as a
database of 71,638,836 loss measurements taken over the course of training for
168,160 individual models across 35 workloads.","['Christopher J. Shallue', 'Jaehoon Lee', 'Joseph Antognini', 'Jascha Sohl-Dickstein', 'Roy Frostig', 'George E. Dahl']","['cs.LG', 'stat.ML']",2018-11-08 18:33:41+00:00
http://arxiv.org/abs/1811.03970v2,Looking Deeper into Deep Learning Model: Attribution-based Explanations of TextCNN,"Layer-wise Relevance Propagation (LRP) and saliency maps have been recently
used to explain the predictions of Deep Learning models, specifically in the
domain of text classification. Given different attribution-based explanations
to highlight relevant words for a predicted class label, experiments based on
word deleting perturbation is a common evaluation method. This word removal
approach, however, disregards any linguistic dependencies that may exist
between words or phrases in a sentence, which could semantically guide a
classifier to a particular prediction. In this paper, we present a
feature-based evaluation framework for comparing the two attribution methods on
customer reviews (public data sets) and Customer Due Diligence (CDD) extracted
reports (corporate data set). Instead of removing words based on the relevance
score, we investigate perturbations based on embedded features removal from
intermediate layers of Convolutional Neural Networks. Our experimental study is
carried out on embedded-word, embedded-document, and embedded-ngrams
explanations. Using the proposed framework, we provide a visualization tool to
assist analysts in reasoning toward the model's final prediction.","['Wenting Xiong', ""Iftitahu Ni'mah"", 'Juan M. G. Huesca', 'Werner van Ipenburg', 'Jan Veldsink', 'Mykola Pechenizkiy']","['cs.IR', 'cs.LG', 'stat.ML']",2018-11-08 18:23:48+00:00
http://arxiv.org/abs/1811.03575v3,Large-Scale Visual Active Learning with Deep Probabilistic Ensembles,"Annotating the right data for training deep neural networks is an important
challenge. Active learning using uncertainty estimates from Bayesian Neural
Networks (BNNs) could provide an effective solution to this. Despite being
theoretically principled, BNNs require approximations to be applied to
large-scale problems, where both performance and uncertainty estimation are
crucial. In this paper, we introduce Deep Probabilistic Ensembles (DPEs), a
scalable technique that uses a regularized ensemble to approximate a deep BNN.
We conduct a series of large-scale visual active learning experiments to
evaluate DPEs on classification with the CIFAR-10, CIFAR-100 and ImageNet
datasets, and semantic segmentation with the BDD100k dataset. Our models
require significantly less training data to achieve competitive performances,
and steadily improve upon strong active learning baselines as the annotation
budget is increased.","['Kashyap Chitta', 'Jose M. Alvarez', 'Adam Lesnikowski']","['cs.CV', 'cs.LG', 'stat.ML']",2018-11-08 17:56:43+00:00
http://arxiv.org/abs/1811.03571v2,Intrinsic Geometric Vulnerability of High-Dimensional Artificial Intelligence,"The success of modern Artificial Intelligence (AI) technologies depends
critically on the ability to learn non-linear functional dependencies from
large, high dimensional data sets. Despite recent high-profile successes,
empirical evidence indicates that the high predictive performance is often
paired with low robustness, making AI systems potentially vulnerable to
adversarial attacks. In this report, we provide a simple intuitive argument
suggesting that high performance and vulnerability are intrinsically coupled,
and largely dependent on the geometry of typical, high-dimensional data sets.
Our work highlights a major potential pitfall of modern AI systems, and
suggests practical research directions to ameliorate the problem.","['Luca Bortolussi', 'Guido Sanguinetti']","['cs.LG', 'stat.ML']",2018-11-08 17:51:27+00:00
http://arxiv.org/abs/1811.03568v3,A Geometric Approach of Gradient Descent Algorithms in Linear Neural Networks,"In this paper, we propose a geometric framework to analyze the convergence
properties of gradient descent trajectories in the context of linear neural
networks. We translate a well-known empirical observation of linear neural nets
into a conjecture that we call the \emph{overfitting conjecture} which states
that, for almost all training data and initial conditions, the trajectory of
the corresponding gradient descent system converges to a global minimum. This
would imply that the solution achieved by vanilla gradient descent algorithms
is equivalent to that of the least-squares estimation, for linear neural
networks of an arbitrary number of hidden layers. Built upon a key invariance
property induced by the network structure, we first establish convergence of
gradient descent trajectories to critical points of the square loss function in
the case of linear networks of arbitrary depth. Our second result is the proof
of the \emph{overfitting conjecture} in the case of single-hidden-layer linear
networks with an argument based on the notion of normal hyperbolicity and under
a generic property on the training data (i.e., holding for almost all training
data).","['Yacine Chitour', 'Zhenyu Liao', 'Romain Couillet']","['cs.LG', 'stat.ML', 'Primary: 68T07, 37B35, Secondary: 37D10']",2018-11-08 17:45:19+00:00
http://arxiv.org/abs/1811.03567v3,Biologically-plausible learning algorithms can scale to large datasets,"The backpropagation (BP) algorithm is often thought to be biologically
implausible in the brain. One of the main reasons is that BP requires symmetric
weight matrices in the feedforward and feedback pathways. To address this
""weight transport problem"" (Grossberg, 1987), two more biologically plausible
algorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax
BP's weight symmetry requirements and demonstrate comparable learning
capabilities to that of BP on small datasets. However, a recent study by
Bartunov et al. (2018) evaluate variants of target-propagation (TP) and
feedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that
although many of the proposed algorithms perform well on MNIST and CIFAR, they
perform significantly worse than BP on ImageNet. Here, we additionally evaluate
the sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and
FA in that the feedback and feedforward weights share signs but not magnitudes.
We examine the performance of sign-symmetry and feedback alignment on ImageNet
and MS COCO datasets using different network architectures (ResNet-18 and
AlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained
with sign-symmetry can attain classification performance approaching that of
BP-trained networks. These results complement the study by Bartunov et al.
(2018), and establish a new benchmark for future biologically plausible
learning algorithms on more difficult datasets and more complex architectures.","['Will Xiao', 'Honglin Chen', 'Qianli Liao', 'Tomaso Poggio']","['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE', 'stat.ML']",2018-11-08 17:43:59+00:00
http://arxiv.org/abs/1811.03562v2,Real time Traffic Flow Parameters Prediction with Basic Safety Messages at Low Penetration of Connected Vehicles,"The expected low market penetration of connected vehicles (CVs) in the near
future could be a constraint in estimating traffic flow parameters, such as
average travel speed of a roadway segment and average space headway between
vehicles from the CV broadcasted data. This estimated traffic flow parameters
from low penetration of connected vehicles become noisy compared to 100 percent
penetration of CVs, and such noise reduces the real time prediction accuracy of
a machine learning model, such as the accuracy of long short term memory (LSTM)
model in terms of predicting traffic flow parameters. The accurate prediction
of the parameters is important for future traffic condition assessment. To
improve the prediction accuracy using noisy traffic flow parameters, which is
constrained by limited CV market penetration and limited CV data, we developed
a real time traffic data prediction model that combines LSTM with Kalman filter
based Rauch Tung Striebel (RTS) noise reduction model. We conducted a case
study using the Enhanced Next Generation Simulation (NGSIM) dataset, which
contains vehicle trajectory data for every one tenth of a second, to evaluate
the performance of this prediction model. Compared to a baseline LSTM model
performance, for only 5 percent penetration of CVs, the analyses revealed that
combined LSTM and RTS model reduced the mean absolute percentage error (MAPE)
from 19 percent to 5 percent for speed prediction and from 27 percent to 9
percent for space-headway prediction. The statistical significance test with a
95 percent confidence interval confirmed no significant difference in predicted
average speed and average space headway using this LSTM and RTS combination
with only 5 percent CV penetration rate.","['Mizanur Rahman', 'Mashrur Chowdhury', 'Jerome McClendon']","['cs.LG', 'stat.ML']",2018-11-08 17:34:14+00:00
http://arxiv.org/abs/1811.03539v2,Uncovering the Social Interaction in Swarm Intelligence with Network Science,"Swarm intelligence is the collective behavior emerging in systems with
locally interacting components. Because of their self-organization
capabilities, swarm-based systems show essential properties for handling
real-world problems such as robustness, scalability, and flexibility. Yet, we
do not know why swarm-based algorithms work well and neither we can compare the
different approaches in the literature. The lack of a common framework capable
of characterizing these several swarm-based algorithms, transcending their
particularities, has led to a stream of publications inspired by different
aspects of nature without a systematic comparison over existing approaches.
Here, we address this gap by introducing a network-based framework---the
interaction network---to examine computational swarm-based systems via the
optics of the social dynamics of such interaction network; a clear example of
network science being applied to bring further clarity to a complicated field
within artificial intelligence. We discuss the social interactions of four
well-known swarm-based algorithms and provide an in-depth case study of the
Particle Swarm Optimization. The interaction network enables researchers to
study swarm algorithms as systems, removing the algorithm particularities from
the analyses while focusing on the structure of the social interactions.","['Marcos Oliveira', 'Diego Pinheiro', 'Mariana Macedo', 'Carmelo Bastos-Filho', 'Ronaldo Menezes']","['cs.NE', 'cs.AI', 'cs.MA', 'cs.SI', 'stat.ML']",2018-11-08 16:36:11+00:00
http://arxiv.org/abs/1811.03537v2,Iterative Classroom Teaching,"We consider the machine teaching problem in a classroom-like setting wherein
the teacher has to deliver the same examples to a diverse group of students.
Their diversity stems from differences in their initial internal states as well
as their learning rates. We prove that a teacher with full knowledge about the
learning dynamics of the students can teach a target concept to the entire
classroom using O(min{d,N} log(1/eps)) examples, where d is the ambient
dimension of the problem, N is the number of learners, and eps is the accuracy
parameter. We show the robustness of our teaching strategy when the teacher has
limited knowledge of the learners' internal dynamics as provided by a noisy
oracle. Further, we study the trade-off between the learners' workload and the
teacher's cost in teaching the target concept. Our experiments validate our
theoretical results and suggest that appropriately partitioning the classroom
into homogenous groups provides a balance between these two objectives.","['Teresa Yeo', 'Parameswaran Kamalaruban', 'Adish Singla', 'Arpit Merchant', 'Thibault Asselborn', 'Louis Faucon', 'Pierre Dillenbourg', 'Volkan Cevher']","['cs.LG', 'stat.ML']",2018-11-08 16:34:14+00:00
http://arxiv.org/abs/1811.03531v1,A Geometric Perspective on the Transferability of Adversarial Directions,"State-of-the-art machine learning models frequently misclassify inputs that
have been perturbed in an adversarial manner. Adversarial perturbations
generated for a given input and a specific classifier often seem to be
effective on other inputs and even different classifiers. In other words,
adversarial perturbations seem to transfer between different inputs, models,
and even different neural network architectures. In this work, we show that in
the context of linear classifiers and two-layer ReLU networks, there provably
exist directions that give rise to adversarial perturbations for many
classifiers and data points simultaneously. We show that these ""transferable
adversarial directions"" are guaranteed to exist for linear separators of a
given set, and will exist with high probability for linear classifiers trained
on independent sets drawn from the same distribution. We extend our results to
large classes of two-layer ReLU networks. We further show that adversarial
directions for ReLU networks transfer to linear classifiers while the reverse
need not hold, suggesting that adversarial perturbations for more complex
models are more likely to transfer to other classifiers. We validate our
findings empirically, even for deeper ReLU networks.","['Zachary Charles', 'Harrison Rosenberg', 'Dimitris Papailiopoulos']","['cs.LG', 'stat.ML']",2018-11-08 16:23:50+00:00
http://arxiv.org/abs/1811.03516v2,Learning from Demonstration in the Wild,"Learning from demonstration (LfD) is useful in settings where hand-coding
behaviour or a reward function is impractical. It has succeeded in a wide range
of problems but typically relies on manually generated demonstrations or
specially deployed sensors and has not generally been able to leverage the
copious demonstrations available in the wild: those that capture behaviours
that were occurring anyway using sensors that were already deployed for another
purpose, e.g., traffic camera footage capturing demonstrations of natural
behaviour of vehicles, cyclists, and pedestrians. We propose Video to Behaviour
(ViBe), a new approach to learn models of behaviour from unlabelled raw video
data of a traffic scene collected from a single, monocular, initially
uncalibrated camera with ordinary resolution. Our approach calibrates the
camera, detects relevant objects, tracks them through time, and uses the
resulting trajectories to perform LfD, yielding models of naturalistic
behaviour. We apply ViBe to raw videos of a traffic intersection and show that
it can learn purely from videos, without additional expert knowledge.","['Feryal Behbahani', 'Kyriacos Shiarlis', 'Xi Chen', 'Vitaly Kurin', 'Sudhanshu Kasewa', 'Ciprian Stirbu', 'Jo√£o Gomes', 'Supratik Paul', 'Frans A. Oliehoek', 'Jo√£o Messias', 'Shimon Whiteson']","['cs.LG', 'stat.ML']",2018-11-08 16:03:23+00:00
http://arxiv.org/abs/1811.03508v3,A simple yet effective baseline for non-attributed graph classification,"Graphs are complex objects that do not lend themselves easily to typical
learning tasks. Recently, a range of approaches based on graph kernels or graph
neural networks have been developed for graph classification and for
representation learning on graphs in general. As the developed methodologies
become more sophisticated, it is important to understand which components of
the increasingly complex methods are necessary or most effective.
  As a first step, we develop a simple yet meaningful graph representation, and
explore its effectiveness in graph classification. We test our baseline
representation for the graph classification task on a range of graph datasets.
Interestingly, this simple representation achieves similar performance as the
state-of-the-art graph kernels and graph neural networks for non-attributed
graph classification. Its performance on classifying attributed graphs is
slightly weaker as it does not incorporate attributes. However, given its
simplicity and efficiency, we believe that it still serves as an effective
baseline for attributed graph classification. Our graph representation is
efficient (linear-time) to compute. We also provide a simple connection with
the graph neural networks.
  Note that these observations are only for the task of graph classification
while existing methods are often designed for a broader scope including node
embedding and link prediction. The results are also likely biased due to the
limited amount of benchmark datasets available. Nevertheless, the good
performance of our simple baseline calls for the development of new, more
comprehensive benchmark datasets so as to better evaluate and analyze different
graph learning methods. Furthermore, given the computational efficiency of our
graph summary, we believe that it is a good candidate as a baseline method for
future graph classification (or even other graph learning) studies.","['Chen Cai', 'Yusu Wang']","['cs.LG', 'stat.ML']",2018-11-08 15:53:37+00:00
http://arxiv.org/abs/1811.03444v2,Disentangling Latent Factors of Variational Auto-Encoder with Whitening,"After deep generative models were successfully applied to image generation
tasks, learning disentangled latent variables of data has become a crucial part
of deep generative model research. Many models have been proposed to learn an
interpretable and factorized representation of latent variable by modifying
their objective function or model architecture. To disentangle the latent
variable, some models show lower quality of reconstructed images and others
increase the model complexity which is hard to train. In this paper, we propose
a simple disentangling method based on a traditional whitening process. The
proposed method is applied to the latent variables of variational auto-encoder
(VAE), although it can be applied to any generative models with latent
variables. In experiment, we apply the proposed method to simple VAE models and
experiment results confirm that our method finds more interpretable factors
from the latent space while keeping the reconstruction error the same as the
conventional VAE's error.","['Sangchul Hahn', 'Heeyoul Choi']","['cs.LG', 'stat.ML']",2018-11-08 14:33:16+00:00
http://arxiv.org/abs/1811.03436v4,Alpha-Integration Pooling for Convolutional Neural Networks,"Convolutional neural networks (CNNs) have achieved remarkable performance in
many applications, especially in image recognition tasks. As a crucial
component of CNNs, sub-sampling plays an important role for efficient training
or invariance property, and max-pooling and arithmetic average-pooling are
commonly used sub-sampling methods. In addition to the two pooling methods,
however, there could be many other pooling types, such as geometric average,
harmonic average, and so on. Since it is not easy for algorithms to find the
best pooling method, usually the pooling types are assumed a priority, which
might not be optimal for different tasks. In line with the deep learning
philosophy, the type of pooling can be driven by data for a given task. In this
paper, we propose {\it $\alpha$-integration pooling} ($\alpha$I-pooling), which
has a trainable parameter $\alpha$ to find the type of pooling.
$\alpha$I-pooling is a general pooling method including max-pooling and
arithmetic average-pooling as a special case, depending on the parameter
$\alpha$. Experiments show that $\alpha$I-pooling outperforms other pooling
methods including max-pooling, in image recognition tasks. Also, it turns out
that each layer has different optimal pooling type.","['Hayoung Eom', 'Heeyoul Choi']","['cs.LG', 'stat.ML']",2018-11-08 14:25:08+00:00
http://arxiv.org/abs/1811.03433v2,Explainable cardiac pathology classification on cine MRI with motion characterization by semi-supervised learning of apparent flow,"We propose a method to classify cardiac pathology based on a novel approach
to extract image derived features to characterize the shape and motion of the
heart. An original semi-supervised learning procedure, which makes efficient
use of a large amount of non-segmented images and a small amount of images
segmented manually by experts, is developed to generate pixel-wise apparent
flow between two time points of a 2D+t cine MRI image sequence. Combining the
apparent flow maps and cardiac segmentation masks, we obtain a local apparent
flow corresponding to the 2D motion of myocardium and ventricular cavities.
This leads to the generation of time series of the radius and thickness of
myocardial segments to represent cardiac motion. These time series of motion
features are reliable and explainable characteristics of pathological cardiac
motion. Furthermore, they are combined with shape-related features to classify
cardiac pathologies. Using only nine feature values as input, we propose an
explainable, simple and flexible model for pathology classification. On ACDC
training set and testing set, the model achieves 95% and 94% respectively as
classification accuracy. Its performance is hence comparable to that of the
state-of-the-art. Comparison with various other models is performed to outline
some advantages of our model.","['Qiao Zheng', 'Herv√© Delingette', 'Nicholas Ayache']","['cs.CV', 'cs.AI', 'cs.LG', 'stat.ML']",2018-11-08 14:22:05+00:00
http://arxiv.org/abs/1811.03407v1,A Factor Graph Approach to Automated Design of Bayesian Signal Processing Algorithms,"The benefits of automating design cycles for Bayesian inference-based
algorithms are becoming increasingly recognized by the machine learning
community. As a result, interest in probabilistic programming frameworks has
much increased over the past few years. This paper explores a specific
probabilistic programming paradigm, namely message passing in Forney-style
factor graphs (FFGs), in the context of automated design of efficient Bayesian
signal processing algorithms. To this end, we developed ""ForneyLab""
(https://github.com/biaslab/ForneyLab.jl) as a Julia toolbox for message
passing-based inference in FFGs. We show by example how ForneyLab enables
automatic derivation of Bayesian signal processing algorithms, including
algorithms for parameter estimation and model comparison. Crucially, due to the
modular makeup of the FFG framework, both the model specification and inference
methods are readily extensible in ForneyLab. In order to test this framework,
we compared variational message passing as implemented by ForneyLab with
automatic differentiation variational inference (ADVI) and Monte Carlo methods
as implemented by state-of-the-art tools ""Edward"" and ""Stan"". In terms of
performance, extensibility and stability issues, ForneyLab appears to enjoy an
edge relative to its competitors for automated inference in state-space models.","['Marco Cox', 'Thijs van de Laar', 'Bert de Vries']","['cs.LG', 'stat.ML']",2018-11-08 13:53:46+00:00
http://arxiv.org/abs/1811.03403v1,ExGate: Externally Controlled Gating for Feature-based Attention in Artificial Neural Networks,"Perceptual capabilities of artificial systems have come a long way since the
advent of deep learning. These methods have proven to be effective, however
they are not as efficient as their biological counterparts. Visual attention is
a set of mechanisms that are employed in biological visual systems to ease
computational load by only processing pertinent parts of the stimuli. This
paper addresses the implementation of top-down, feature-based attention in an
artificial neural network by use of externally controlled neuron gating. Our
results showed a 5% increase in classification accuracy on the CIFAR-10 dataset
versus a non-gated version, while adding very few parameters. Our gated model
also produces more reasonable errors in predictions by drastically reducing
prediction of classes that belong to a different category to the true class.","['Jarryd Son', 'Amit Mishra']","['cs.LG', 'cs.CV', 'cs.NE', 'stat.ML']",2018-11-08 13:39:49+00:00
http://arxiv.org/abs/1811.03402v2,A Survey on Data Collection for Machine Learning: a Big Data -- AI Integration Perspective,"Data collection is a major bottleneck in machine learning and an active
research topic in multiple communities. There are largely two reasons data
collection has recently become a critical issue. First, as machine learning is
becoming more widely-used, we are seeing new applications that do not
necessarily have enough labeled data. Second, unlike traditional machine
learning, deep learning techniques automatically generate features, which saves
feature engineering costs, but in return may require larger amounts of labeled
data. Interestingly, recent research in data collection comes not only from the
machine learning, natural language, and computer vision communities, but also
from the data management community due to the importance of handling large
amounts of data. In this survey, we perform a comprehensive study of data
collection from a data management point of view. Data collection largely
consists of data acquisition, data labeling, and improvement of existing data
or models. We provide a research landscape of these operations, provide
guidelines on which technique to use when, and identify interesting research
challenges. The integration of machine learning and data management for data
collection is part of a larger trend of Big data and Artificial Intelligence
(AI) integration and opens many opportunities for new research.","['Yuji Roh', 'Geon Heo', 'Steven Euijong Whang']","['cs.LG', 'stat.ML']",2018-11-08 13:37:46+00:00
http://arxiv.org/abs/1811.03392v1,Transformative Machine Learning,"The key to success in machine learning (ML) is the use of effective data
representations. Traditionally, data representations were hand-crafted.
Recently it has been demonstrated that, given sufficient data, deep neural
networks can learn effective implicit representations from simple input
representations. However, for most scientific problems, the use of deep
learning is not appropriate as the amount of available data is limited, and/or
the output models must be explainable. Nevertheless, many scientific problems
do have significant amounts of data available on related tasks, which makes
them amenable to multi-task learning, i.e. learning many related problems
simultaneously. Here we propose a novel and general representation learning
approach for multi-task learning that works successfully with small amounts of
data. The fundamental new idea is to transform an input intrinsic data
representation (i.e., handcrafted features), to an extrinsic representation
based on what a pre-trained set of models predict about the examples. This
transformation has the dual advantages of producing significantly more accurate
predictions, and providing explainable models. To demonstrate the utility of
this transformative learning approach, we have applied it to three real-world
scientific problems: drug-design (quantitative structure activity relationship
learning), predicting human gene expression (across different tissue types and
drug treatments), and meta-learning for machine learning (predicting which
machine learning methods work best for a given problem). In all three problems,
transformative machine learning significantly outperforms the best intrinsic
representation.","['Ivan Olier', 'Oghenejokpeme I. Orhobor', 'Joaquin Vanschoren', 'Ross D. King']","['cs.LG', 'stat.ML']",2018-11-08 13:09:05+00:00
http://arxiv.org/abs/1811.03388v2,Knowledge Tracing Machines: Factorization Machines for Knowledge Tracing,"Knowledge tracing is a sequence prediction problem where the goal is to
predict the outcomes of students over questions as they are interacting with a
learning platform. By tracking the evolution of the knowledge of some student,
one can optimize instruction. Existing methods are either based on temporal
latent variable models, or factor analysis with temporal features. We here show
that factorization machines (FMs), a model for regression or classification,
encompasses several existing models in the educational literature as special
cases, notably additive factor model, performance factor model, and
multidimensional item response theory. We show, using several real datasets of
tens of thousands of users and items, that FMs can estimate student knowledge
accurately and fast even when student data is sparsely observed, and handle
side information such as multiple knowledge components and number of attempts
at item or skill level. Our approach allows to fit student models of higher
dimension than existing models, and provides a testbed to try new combinations
of features in order to improve existing models.","['Jill-J√™nn Vie', 'Hisashi Kashima']","['cs.IR', 'cs.AI', 'cs.LG', 'stat.ML']",2018-11-08 13:02:09+00:00
http://arxiv.org/abs/1811.03377v1,Spectral Simplicial Theory for Feature Selection and Applications to Genomics,"The scale and complexity of modern data sets and the limitations associated
with testing large numbers of hypotheses underline the need for feature
selection methods. Spectral techniques rank features according to their degree
of consistency with an underlying metric structure, but their current
graph-based formulation restricts their applicability to point features. We
extend spectral methods for feature selection to abstract simplicial complexes
and present a general framework which can be applied to 2-point and
higher-order features. Combinatorial Laplacian scores take into account the
topology spanned by the data and reduce to the ordinary Laplacian score in the
case of point features. We demonstrate the utility of spectral simplicial
methods for feature selection with several examples of application to the
analysis of gene expression and multi-modal genomic data. Our results provide a
unifying perspective on topological data analysis and manifold learning
approaches.","['Kiya W. Govek', 'Venkata S. Yamajala', 'Pablo G. Camara']","['stat.ML', 'cs.LG', 'q-bio.QM']",2018-11-08 12:27:49+00:00
http://arxiv.org/abs/1811.03356v1,Linear Memory Networks,"Recurrent neural networks can learn complex transduction problems that
require maintaining and actively exploiting a memory of their inputs. Such
models traditionally consider memory and input-output functionalities
indissolubly entangled. We introduce a novel recurrent architecture based on
the conceptual separation between the functional input-output transformation
and the memory mechanism, showing how they can be implemented through different
neural components. By building on such conceptualization, we introduce the
Linear Memory Network, a recurrent model comprising a feedforward neural
network, realizing the non-linear functional transformation, and a linear
autoencoder for sequences, implementing the memory component. The resulting
architecture can be efficiently trained by building on closed-form solutions to
linear optimization problems. Further, by exploiting equivalence results
between feedforward and recurrent neural networks we devise a pretraining
schema for the proposed architecture. Experiments on polyphonic music datasets
show competitive results against gated recurrent networks and other state of
the art models.","['Davide Bacciu', 'Antonio Carta', 'Alessandro Sperduti']","['cs.LG', 'stat.ML']",2018-11-08 11:08:04+00:00
http://arxiv.org/abs/1811.03322v2,Using Known Information to Accelerate HyperParameters Optimization Based on SMBO,"Automl is the key technology for machine learning problem. Current state of
art hyperparameter optimization methods are based on traditional black-box
optimization methods like SMBO (SMAC, TPE). The objective function of black-box
optimization is non-smooth, or time-consuming to evaluate, or in some way
noisy. Recent years, many researchers offered the work about the properties of
hyperparameters. However, traditional hyperparameter optimization methods do
not take those information into consideration. In this paper, we use gradient
information and machine learning model analysis information to accelerate
traditional hyperparameter optimization methods SMBO. In our L2 norm
experiments, our method yielded state-of-the-art performance, and in many cases
outperformed the previous best configuration approach.","['Cheng Daning', 'Zhang Hanping', 'Xia Fen', 'Li Shigang', 'Zhang Yunquan']","['cs.LG', 'stat.ML']",2018-11-08 09:04:09+00:00
