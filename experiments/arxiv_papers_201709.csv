id,title,abstract,authors,categories,date
http://arxiv.org/abs/1710.06514v3,Robust importance-weighted cross-validation under sample selection bias,"Cross-validation under sample selection bias can, in principle, be done by
importance-weighting the empirical risk. However, the importance-weighted risk
estimator produces sub-optimal hyperparameter estimates in problem settings
where large weights arise with high probability. We study its sampling variance
as a function of the training data distribution and introduce a control variate
to increase its robustness to problematically large weights.","['Wouter M. Kouw', 'Jesse H. Krijthe', 'Marco Loog']","['cs.LG', 'stat.ML']",2017-10-17 22:10:07+00:00
http://arxiv.org/abs/1710.06487v3,Classification and Geometry of General Perceptual Manifolds,"Perceptual manifolds arise when a neural population responds to an ensemble
of sensory signals associated with different physical features (e.g.,
orientation, pose, scale, location, and intensity) of the same perceptual
object. Object recognition and discrimination requires classifying the
manifolds in a manner that is insensitive to variability within a manifold. How
neuronal systems give rise to invariant object classification and recognition
is a fundamental problem in brain theory as well as in machine learning. Here
we study the ability of a readout network to classify objects from their
perceptual manifold representations. We develop a statistical mechanical theory
for the linear classification of manifolds with arbitrary geometry revealing a
remarkable relation to the mathematics of conic decomposition. Novel
geometrical measures of manifold radius and manifold dimension are introduced
which can explain the classification capacity for manifolds of various
geometries. The general theory is demonstrated on a number of representative
manifolds, including L2 ellipsoids prototypical of strictly convex manifolds,
L1 balls representing polytopes consisting of finite sample points, and
orientation manifolds which arise from neurons tuned to respond to a continuous
angle variable, such as object orientation. The effects of label sparsity on
the classification capacity of manifolds are elucidated, revealing a scaling
relation between label sparsity and manifold radius. Theoretical predictions
are corroborated by numerical simulations using recently developed algorithms
to compute maximum margin solutions for manifold dichotomies. Our theory and
its extensions provide a powerful and rich framework for applying statistical
mechanics of linear classification to data arising from neuronal responses to
object stimuli, as well as to artificial deep networks trained for object
recognition tasks.","['SueYeon Chung', 'Daniel D. Lee', 'Haim Sompolinsky']","['cond-mat.dis-nn', 'cond-mat.stat-mech', 'cs.NE', 'q-bio.NC', 'stat.ML']",2017-10-17 20:06:25+00:00
http://arxiv.org/abs/1710.06462v3,S-Isomap++: Multi Manifold Learning from Streaming Data,"Manifold learning based methods have been widely used for non-linear
dimensionality reduction (NLDR). However, in many practical settings, the need
to process streaming data is a challenge for such methods, owing to the high
computational complexity involved. Moreover, most methods operate under the
assumption that the input data is sampled from a single manifold, embedded in a
high dimensional space. We propose a method for streaming NLDR when the
observed data is either sampled from multiple manifolds or irregularly sampled
from a single manifold. We show that existing NLDR methods, such as Isomap,
fail in such situations, primarily because they rely on smoothness and
continuity of the underlying manifold, which is violated in the scenarios
explored in this paper. However, the proposed algorithm is able to learn
effectively in presence of multiple, and potentially intersecting, manifolds,
while allowing for the input data to arrive as a massive stream.","['Suchismit Mahapatra', 'Varun Chandola']","['stat.ML', 'cs.LG']",2017-10-17 18:30:57+00:00
http://arxiv.org/abs/1710.06451v3,A Bayesian Perspective on Generalization and Stochastic Gradient Descent,"We consider two questions at the heart of machine learning; how can we
predict if a minimum will generalize to the test set, and why does stochastic
gradient descent find minima that generalize well? Our work responds to Zhang
et al. (2016), who showed deep neural networks can easily memorize randomly
labeled training data, despite generalizing well on real labels of the same
inputs. We show that the same phenomenon occurs in small linear models. These
observations are explained by the Bayesian evidence, which penalizes sharp
minima but is invariant to model parameterization. We also demonstrate that,
when one holds the learning rate fixed, there is an optimum batch size which
maximizes the test set accuracy. We propose that the noise introduced by small
mini-batches drives the parameters towards minima whose evidence is large.
Interpreting stochastic gradient descent as a stochastic differential equation,
we identify the ""noise scale"" $g = \epsilon (\frac{N}{B} - 1) \approx \epsilon
N/B$, where $\epsilon$ is the learning rate, $N$ the training set size and $B$
the batch size. Consequently the optimum batch size is proportional to both the
learning rate and the size of the training set, $B_{opt} \propto \epsilon N$.
We verify these predictions empirically.","['Samuel L. Smith', 'Quoc V. Le']","['cs.LG', 'cs.AI', 'stat.ML']",2017-10-17 18:08:04+00:00
http://arxiv.org/abs/1710.06382v2,Convergence diagnostics for stochastic gradient descent with constant step size,"Many iterative procedures in stochastic optimization exhibit a transient
phase followed by a stationary phase. During the transient phase the procedure
converges towards a region of interest, and during the stationary phase the
procedure oscillates in that region, commonly around a single point. In this
paper, we develop a statistical diagnostic test to detect such phase transition
in the context of stochastic gradient descent with constant learning rate. We
present theory and experiments suggesting that the region where the proposed
diagnostic is activated coincides with the convergence region. For a class of
loss functions, we derive a closed-form solution describing such region.
Finally, we suggest an application to speed up convergence of stochastic
gradient descent by halving the learning rate each time stationarity is
detected. This leads to a new variant of stochastic gradient descent, which in
many settings is comparable to state-of-art.","['Jerry Chee', 'Panos Toulis']","['stat.ML', 'cs.LG', 'math.ST', 'stat.CO', 'stat.TH']",2017-10-17 16:51:16+00:00
http://arxiv.org/abs/1710.06360v2,Good Arm Identification via Bandit Feedback,"We consider a novel stochastic multi-armed bandit problem called {\em good
arm identification} (GAI), where a good arm is defined as an arm with expected
reward greater than or equal to a given threshold. GAI is a pure-exploration
problem that a single agent repeats a process of outputting an arm as soon as
it is identified as a good one before confirming the other arms are actually
not good. The objective of GAI is to minimize the number of samples for each
process. We find that GAI faces a new kind of dilemma, the {\em
exploration-exploitation dilemma of confidence}, which is different difficulty
from the best arm identification. As a result, an efficient design of
algorithms for GAI is quite different from that for the best arm
identification. We derive a lower bound on the sample complexity of GAI that is
tight up to the logarithmic factor $\mathrm{O}(\log \frac{1}{\delta})$ for
acceptance error rate $\delta$. We also develop an algorithm whose sample
complexity almost matches the lower bound. We also confirm experimentally that
our proposed algorithm outperforms naive algorithms in synthetic settings based
on a conventional bandit problem and clinical trial researches for rheumatoid
arthritis.","['Hideaki Kano', 'Junya Honda', 'Kentaro Sakamaki', 'Kentaro Matsuura', 'Atsuyoshi Nakamura', 'Masashi Sugiyama']",['stat.ML'],2017-10-17 16:08:16+00:00
http://arxiv.org/abs/1710.06276v2,Smooth and Sparse Optimal Transport,"Entropic regularization is quickly emerging as a new standard in optimal
transport (OT). It enables to cast the OT computation as a differentiable and
unconstrained convex optimization problem, which can be efficiently solved
using the Sinkhorn algorithm. However, entropy keeps the transportation plan
strictly positive and therefore completely dense, unlike unregularized OT. This
lack of sparsity can be problematic in applications where the transportation
plan itself is of interest. In this paper, we explore regularizing the primal
and dual OT formulations with a strongly convex term, which corresponds to
relaxing the dual and primal constraints with smooth approximations. We show
how to incorporate squared $2$-norm and group lasso regularizations within that
framework, leading to sparse and group-sparse transportation plans. On the
theoretical side, we bound the approximation error introduced by regularizing
the primal and dual formulations. Our results suggest that, for the regularized
primal, the approximation error can often be smaller with squared $2$-norm than
with entropic regularization. We showcase our proposed framework on the task of
color transfer.","['Mathieu Blondel', 'Vivien Seguy', 'Antoine Rolet']","['stat.ML', 'cs.LG']",2017-10-17 13:42:37+00:00
http://arxiv.org/abs/1710.06273v2,Combinatorial Penalties: Which structures are preserved by convex relaxations?,"We consider the homogeneous and the non-homogeneous convex relaxations for
combinatorial penalty functions defined on support sets. Our study identifies
key differences in the tightness of the resulting relaxations through the
notion of the lower combinatorial envelope of a set-function along with new
necessary conditions for support identification. We then propose a general
adaptive estimator for convex monotone regularizers, and derive new sufficient
conditions for support recovery in the asymptotic setting.","['Marwa El Halabi', 'Francis Bach', 'Volkan Cevher']","['cs.LG', 'stat.ML']",2017-10-17 13:41:21+00:00
http://arxiv.org/abs/1710.06261v1,Convergence Rate of Riemannian Hamiltonian Monte Carlo and Faster Polytope Volume Computation,"We give the first rigorous proof of the convergence of Riemannian Hamiltonian
Monte Carlo, a general (and practical) method for sampling Gibbs distributions.
Our analysis shows that the rate of convergence is bounded in terms of natural
smoothness parameters of an associated Riemannian manifold. We then apply the
method with the manifold defined by the log barrier function to the problems of
(1) uniformly sampling a polytope and (2) computing its volume, the latter by
extending Gaussian cooling to the manifold setting. In both cases, the total
number of steps needed is O^{*}(mn^{\frac{2}{3}}), improving the state of the
art. A key ingredient of our analysis is a proof of an analog of the KLS
conjecture for Gibbs distributions over manifolds.","['Yin Tat Lee', 'Santosh S. Vempala']","['cs.DS', 'math.FA', 'stat.ML']",2017-10-17 13:30:27+00:00
http://arxiv.org/abs/1710.06234v1,Nonlinear Interference Mitigation via Deep Neural Networks,"A neural-network-based approach is presented to efficiently implement digital
backpropagation (DBP). For a 32x100 km fiber-optic link, the resulting
""learned"" DBP significantly reduces the complexity compared to conventional DBP
implementations.","['Christian Häger', 'Henry D. Pfister']","['cs.IT', 'math.IT', 'stat.ML']",2017-10-17 12:23:26+00:00
http://arxiv.org/abs/1710.06219v3,Learning to Warm-Start Bayesian Hyperparameter Optimization,"Hyperparameter optimization aims to find the optimal hyperparameter
configuration of a machine learning model, which provides the best performance
on a validation dataset. Manual search usually leads to get stuck in a local
hyperparameter configuration, and heavily depends on human intuition and
experience. A simple alternative of manual search is random/grid search on a
space of hyperparameters, which still undergoes extensive evaluations of
validation errors in order to find its best configuration. Bayesian
optimization that is a global optimization method for black-box functions is
now popular for hyperparameter optimization, since it greatly reduces the
number of validation error evaluations required, compared to random/grid
search. Bayesian optimization generally finds the best hyperparameter
configuration from random initialization without any prior knowledge. This
motivates us to let Bayesian optimization start from the configurations that
were successful on similar datasets, which are able to remarkably minimize the
number of evaluations. In this paper, we propose deep metric learning to learn
meta-features over datasets such that the similarity over them is effectively
measured by Euclidean distance between their associated meta-features. To this
end, we introduce a Siamese network composed of deep feature and meta-feature
extractors, where deep feature extractor provides a semantic representation of
each instance in a dataset and meta-feature extractor aggregates a set of deep
features to encode a single representation over a dataset. Then, our learned
meta-features are used to select a few datasets similar to the new dataset, so
that hyperparameters in similar datasets are adopted as initializations to
warm-start Bayesian hyperparameter optimization.","['Jungtaek Kim', 'Saehoon Kim', 'Seungjin Choi']","['stat.ML', 'cs.LG']",2017-10-17 11:34:32+00:00
http://arxiv.org/abs/1710.06202v2,Deep Gaussian Covariance Network,"The correlation length-scale next to the noise variance are the most used
hyperparameters for the Gaussian processes. Typically, stationary covariance
functions are used, which are only dependent on the distances between input
points and thus invariant to the translations in the input space. The
optimization of the hyperparameters is commonly done by maximizing the log
marginal likelihood. This works quite well, if the distances are uniform
distributed. In the case of a locally adapted or even sparse input space, the
prediction of a test point can be worse dependent of its position. A possible
solution to this, is the usage of a non-stationary covariance function, where
the hyperparameters are calculated by a deep neural network. So that the
correlation length scales and possibly the noise variance are dependent on the
test point. Furthermore, different types of covariance functions are trained
simultaneously, so that the Gaussian process prediction is an additive overlay
of different covariance matrices. The right covariance functions combination
and its hyperparameters are learned by the deep neural network. Additional, the
Gaussian process will be able to be trained by batches or online and so it can
handle arbitrarily large data sets. We call this framework Deep Gaussian
Covariance Network (DGCP). There are also further extensions to this framework
possible, for example sequentially dependent problems like time series or the
local mixture of experts. The basic framework and some extension possibilities
will be presented in this work. Moreover, a comparison to some recent state of
the art surrogate model methods will be performed, also for a time dependent
problem.","['Kevin Cremanns', 'Dirk Roos']","['cs.LG', 'stat.ML']",2017-10-17 10:57:21+00:00
http://arxiv.org/abs/1710.06169v4,Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation,"Black-box risk scoring models permeate our lives, yet are typically
proprietary or opaque. We propose Distill-and-Compare, a model distillation and
comparison approach to audit such models. To gain insight into black-box
models, we treat them as teachers, training transparent student models to mimic
the risk scores assigned by black-box models. We compare the student model
trained with distillation to a second un-distilled transparent model trained on
ground-truth outcomes, and use differences between the two models to gain
insight into the black-box model. Our approach can be applied in a realistic
setting, without probing the black-box model API. We demonstrate the approach
on four public data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending
Club. We also propose a statistical test to determine if a data set is missing
key features used to train the black-box model. Our test finds that the
ProPublica data is likely missing key feature(s) used in COMPAS.","['Sarah Tan', 'Rich Caruana', 'Giles Hooker', 'Yin Lou']","['stat.ML', 'cs.AI', 'cs.LG']",2017-10-17 08:58:59+00:00
http://arxiv.org/abs/1710.06085v1,"On the challenges of learning with inference networks on sparse, high-dimensional data","We study parameter estimation in Nonlinear Factor Analysis (NFA) where the
generative model is parameterized by a deep neural network. Recent work has
focused on learning such models using inference (or recognition) networks; we
identify a crucial problem when modeling large, sparse, high-dimensional
datasets -- underfitting. We study the extent of underfitting, highlighting
that its severity increases with the sparsity of the data. We propose methods
to tackle it via iterative optimization inspired by stochastic variational
inference \citep{hoffman2013stochastic} and improvements in the sparse data
representation used for inference. The proposed techniques drastically improve
the ability of these powerful models to fit sparse data, achieving
state-of-the-art results on a benchmark text-count dataset and excellent
results on the task of top-N recommendation.","['Rahul G. Krishnan', 'Dawen Liang', 'Matthew Hoffman']","['stat.ML', 'cs.LG']",2017-10-17 04:17:07+00:00
http://arxiv.org/abs/1710.06081v3,Boosting Adversarial Attacks with Momentum,"Deep neural networks are vulnerable to adversarial examples, which poses
security concerns on these algorithms due to the potentially severe
consequences. Adversarial attacks serve as an important surrogate to evaluate
the robustness of deep learning models before they are deployed. However, most
of existing adversarial attacks can only fool a black-box model with a low
success rate. To address this issue, we propose a broad class of momentum-based
iterative algorithms to boost adversarial attacks. By integrating the momentum
term into the iterative process for attacks, our methods can stabilize update
directions and escape from poor local maxima during the iterations, resulting
in more transferable adversarial examples. To further improve the success rates
for black-box attacks, we apply momentum iterative algorithms to an ensemble of
models, and show that the adversarially trained models with a strong defense
ability are also vulnerable to our black-box attacks. We hope that the proposed
methods will serve as a benchmark for evaluating the robustness of various deep
models and defense methods. With this method, we won the first places in NIPS
2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack
competitions.","['Yinpeng Dong', 'Fangzhou Liao', 'Tianyu Pang', 'Hang Su', 'Jun Zhu', 'Xiaolin Hu', 'Jianguo Li']","['cs.LG', 'stat.ML']",2017-10-17 04:03:04+00:00
http://arxiv.org/abs/1710.06078v1,Estimate exponential memory decay in Hidden Markov Model and its applications,"Inference in hidden Markov model has been challenging in terms of scalability
due to dependencies in the observation data. In this paper, we utilize the
inherent memory decay in hidden Markov models, such that the forward and
backward probabilities can be carried out with subsequences, enabling efficient
inference over long sequences of observations. We formulate this forward
filtering process in the setting of the random dynamical system and there exist
Lyapunov exponents in the i.i.d random matrices production. And the rate of the
memory decay is known as $\lambda_2-\lambda_1$, the gap of the top two Lyapunov
exponents almost surely. An efficient and accurate algorithm is proposed to
numerically estimate the gap after the soft-max parametrization. The length of
subsequences $B$ given the controlled error $\epsilon$ is
$B=\log(\epsilon)/(\lambda_2-\lambda_1)$. We theoretically prove the validity
of the algorithm and demonstrate the effectiveness with numerical examples. The
method developed here can be applied to widely used algorithms, such as
mini-batch stochastic gradient method. Moreover, the continuity of Lyapunov
spectrum ensures the estimated $B$ could be reused for the nearby parameter
during the inference.","['Felix X. -F. Ye', 'Yi-an Ma', 'Hong Qian']","['stat.ML', 'stat.ME']",2017-10-17 03:54:11+00:00
http://arxiv.org/abs/1710.06071v1,PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts,"We present PubMed 200k RCT, a new dataset based on PubMed for sequential
sentence classification. The dataset consists of approximately 200,000
abstracts of randomized controlled trials, totaling 2.3 million sentences. Each
sentence of each abstract is labeled with their role in the abstract using one
of the following classes: background, objective, method, result, or conclusion.
The purpose of releasing this dataset is twofold. First, the majority of
datasets for sequential short-text classification (i.e., classification of
short texts that appear in sequences) are small: we hope that releasing a new
large dataset will help develop more accurate algorithms for this task. Second,
from an application perspective, researchers need better tools to efficiently
skim through the literature. Automatically classifying each sentence in an
abstract would help researchers read abstracts more efficiently, especially in
fields where abstracts may be long, such as the medical field.","['Franck Dernoncourt', 'Ji Young Lee']","['cs.CL', 'cs.AI', 'stat.ML']",2017-10-17 03:22:00+00:00
http://arxiv.org/abs/1710.06034v4,Stochastic Variance Reduction for Policy Gradient Estimation,"Recent advances in policy gradient methods and deep learning have
demonstrated their applicability for complex reinforcement learning problems.
However, the variance of the performance gradient estimates obtained from the
simulation is often excessive, leading to poor sample efficiency. In this
paper, we apply the stochastic variance reduced gradient descent (SVRG) to
model-free policy gradient to significantly improve the sample-efficiency. The
SVRG estimation is incorporated into a trust-region Newton conjugate gradient
framework for the policy optimization. On several Mujoco tasks, our method
achieves significantly better performance compared to the state-of-the-art
model-free policy gradient methods in robotic continuous control such as trust
region policy optimization (TRPO)","['Tianbing Xu', 'Qiang Liu', 'Jian Peng']","['cs.LG', 'stat.ML']",2017-10-17 00:05:06+00:00
http://arxiv.org/abs/1710.06030v2,Linear Regression with Sparsely Permuted Data,"In regression analysis of multivariate data, it is tacitly assumed that
response and predictor variables in each observed response-predictor pair
correspond to the same entity or unit. In this paper, we consider the situation
of ""permuted data"" in which this basic correspondence has been lost. Several
recent papers have considered this situation without further assumptions on the
underlying permutation. In applications, the latter is often to known to have
additional structure that can be leveraged. Specifically, we herein consider
the common scenario of ""sparsely permuted data"" in which only a small fraction
of the data is affected by a mismatch between response and predictors. However,
an adverse effect already observed for sparsely permuted data is that the least
squares estimator as well as other estimators not accounting for such partial
mismatch are inconsistent. One approach studied in detail herein is to treat
permuted data as outliers which motivates the use of robust regression
formulations to estimate the regression parameter. The resulting estimate can
subsequently be used to recover the permutation. A notable benefit of the
proposed approach is its computational simplicity given the general lack of
procedures for the above problem that are both statistically sound and
computationally appealing.","['Martin Slawski', 'Emanuel Ben-David']","['math.ST', 'stat.ME', 'stat.ML', 'stat.TH']",2017-10-16 23:24:23+00:00
http://arxiv.org/abs/1710.06012v2,VAMPnets: Deep learning of molecular kinetics,"There is an increasing demand for computing the relevant structures,
equilibria and long-timescale kinetics of biomolecular processes, such as
protein-drug binding, from high-throughput molecular dynamics simulations.
Current methods employ transformation of simulated coordinates into structural
features, dimension reduction, clustering the dimension-reduced data, and
estimation of a Markov state model or related model of the interconversion
rates between molecular structures. This handcrafted approach demands a
substantial amount of modeling expertise, as poor decisions at any step will
lead to large modeling errors. Here we employ the variational approach for
Markov processes (VAMP) to develop a deep learning framework for molecular
kinetics using neural networks, dubbed VAMPnets. A VAMPnet encodes the entire
mapping from molecular coordinates to Markov states, thus combining the whole
data processing pipeline in a single end-to-end framework. Our method performs
equally or better than state-of-the art Markov modeling methods and provides
easily interpretable few-state kinetic models.","['Andreas Mardt', 'Luca Pasquali', 'Hao Wu', 'Frank Noé']","['stat.ML', 'physics.bio-ph', 'physics.chem-ph', 'physics.comp-ph']",2017-10-16 22:21:22+00:00
http://arxiv.org/abs/1710.05989v1,Sparse Linear Isotonic Models,"In machine learning and data mining, linear models have been widely used to
model the response as parametric linear functions of the predictors. To relax
such stringent assumptions made by parametric linear models, additive models
consider the response to be a summation of unknown transformations applied on
the predictors; in particular, additive isotonic models (AIMs) assume the
unknown transformations to be monotone. In this paper, we introduce sparse
linear isotonic models (SLIMs) for highdimensional problems by hybridizing
ideas in parametric sparse linear models and AIMs, which enjoy a few appealing
advantages over both. In the high-dimensional setting, a two-step algorithm is
proposed for estimating the sparse parameters as well as the monotone functions
over predictors. Under mild statistical assumptions, we show that the algorithm
can accurately estimate the parameters. Promising preliminary experiments are
presented to support the theoretical results.","['Sheng Chen', 'Arindam Banerjee']",['stat.ML'],2017-10-16 20:20:45+00:00
http://arxiv.org/abs/1710.05895v1,Spectral Algorithms for Computing Fair Support Vector Machines,"Classifiers and rating scores are prone to implicitly codifying biases, which
may be present in the training data, against protected classes (i.e., age,
gender, or race). So it is important to understand how to design classifiers
and scores that prevent discrimination in predictions. This paper develops
computationally tractable algorithms for designing accurate but fair support
vector machines (SVM's). Our approach imposes a constraint on the covariance
matrices conditioned on each protected class, which leads to a nonconvex
quadratic constraint in the SVM formulation. We develop iterative algorithms to
compute fair linear and kernel SVM's, which solve a sequence of relaxations
constructed using a spectral decomposition of the nonconvex constraint. Its
effectiveness in achieving high prediction accuracy while ensuring fairness is
shown through numerical experiments on several data sets.","['Matt Olfat', 'Anil Aswani']","['cs.LG', 'math.OC', 'stat.ML']",2017-10-16 17:48:23+00:00
http://arxiv.org/abs/1710.05829v3,Non-Euclidean Conditional Expectation and Filtering,"A non-Euclidean generalization of conditional expectation is introduced and
characterized as the minimizer of expected intrinsic squared-distance from a
manifold-valued target. The computational tractable formulation expresses the
non-convex optimization problem as transformations of Euclidean conditional
expectation. This gives computationally tractable filtering equations for the
dynamics of the intrinsic conditional expectation of a manifold-valued signal
and is used to obtain accurate numerical forecasts of efficient portfolios by
incorporating their geometric structure into the estimates.","['Anastasis Kratsios', 'Cody B. Hyndman']","['q-fin.MF', 'math.PR', 'q-fin.CP', 'stat.ML', '60D05, 91G60, 91G10, 62M20, 60G35, 93E11']",2017-10-16 16:51:27+00:00
http://arxiv.org/abs/1710.05778v2,A successive difference-of-convex approximation method for a class of nonconvex nonsmooth optimization problems,"We consider a class of nonconvex nonsmooth optimization problems whose
objective is the sum of a smooth function and a finite number of nonnegative
proper closed possibly nonsmooth functions (whose proximal mappings are easy to
compute), some of which are further composed with linear maps. This kind of
problems arises naturally in various applications when different regularizers
are introduced for inducing simultaneous structures in the solutions. Solving
these problems, however, can be challenging because of the coupled nonsmooth
functions: the corresponding proximal mapping can be hard to compute so that
standard first-order methods such as the proximal gradient algorithm cannot be
applied efficiently. In this paper, we propose a successive
difference-of-convex approximation method for solving this kind of problems. In
this algorithm, we approximate the nonsmooth functions by their Moreau
envelopes in each iteration. Making use of the simple observation that Moreau
envelopes of nonnegative proper closed functions are continuous {\em
difference-of-convex} functions, we can then approximately minimize the
approximation function by first-order methods with suitable majorization
techniques. These first-order methods can be implemented efficiently thanks to
the fact that the proximal mapping of {\em each} nonsmooth function is easy to
compute. Under suitable assumptions, we prove that the sequence generated by
our method is bounded and any accumulation point is a stationary point of the
objective. We also discuss how our method can be applied to concrete
applications such as nonconvex fused regularized optimization problems and
simultaneously structured matrix optimization problems, and illustrate the
performance numerically for these two specific applications.","['Tianxiang Liu', 'Ting Kei Pong', 'Akiko Takeda']","['math.OC', 'stat.ML']",2017-10-16 15:18:28+00:00
http://arxiv.org/abs/1710.05776v2,Nonsmooth Frank-Wolfe using Uniform Affine Approximations,"Frank-Wolfe methods (FW) have gained significant interest in the machine
learning community due to its ability to efficiently solve large problems that
admit a sparse structure (e.g. sparse vectors and low-rank matrices). However
the performance of the existing FW method hinges on the quality of the linear
approximation. This typically restricts FW to smooth functions for which the
approximation quality, indicated by a global curvature measure, is reasonably
good.
  In this paper, we propose a modified FW algorithm amenable to nonsmooth
functions by optimizing for approximation quality over all affine
approximations given a neighborhood of interest. We analyze theoretical
properties of the proposed algorithm and demonstrate that it overcomes many
issues associated with existing methods in the context of nonsmooth low-rank
matrix estimation.","['Edward Cheung', 'Yuying Li']","['stat.ML', 'math.OC']",2017-10-16 15:16:20+00:00
http://arxiv.org/abs/1710.05751v2,Time Series Prediction : Predicting Stock Price,"Time series forecasting is widely used in a multitude of domains. In this
paper, we present four models to predict the stock price using the SPX index as
input time series data. The martingale and ordinary linear models require the
strongest assumption in stationarity which we use as baseline models. The
generalized linear model requires lesser assumptions but is unable to
outperform the martingale. In empirical testing, the RNN model performs the
best comparing to other two models, because it will update the input through
LSTM instantaneously, but also does not beat the martingale. In addition, we
introduce an online to batch algorithm and discrepancy measure to inform
readers the newest research in time series predicting method, which doesn't
require any stationarity or non mixing assumptions in time series data.
Finally, to apply these forecasting to practice, we introduce basic trading
strategies that can create Win win and Zero sum situations.","['Aaron Elliot', 'Cheng Hua Hsu']","['stat.ML', '62-07']",2017-10-16 14:39:38+00:00
http://arxiv.org/abs/1710.05741v2,A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning,"This paper takes a step towards temporal reasoning in a dynamically changing
video, not in the pixel space that constitutes its frames, but in a latent
space that describes the non-linear dynamics of the objects in its world. We
introduce the Kalman variational auto-encoder, a framework for unsupervised
learning of sequential data that disentangles two latent representations: an
object's representation, coming from a recognition model, and a latent state
describing its dynamics. As a result, the evolution of the world can be
imagined and missing data imputed, both without the need to generate high
dimensional frames at each time step. The model is trained end-to-end on videos
of a variety of simulated physical systems, and outperforms competing methods
in generative and missing data imputation tasks.","['Marco Fraccaro', 'Simon Kamronn', 'Ulrich Paquet', 'Ole Winther']","['stat.ML', 'cs.LG']",2017-10-16 14:34:24+00:00
http://arxiv.org/abs/1710.05739v1,On the Hardness of Inventory Management with Censored Demand Data,"We consider a repeated newsvendor problem where the inventory manager has no
prior information about the demand, and can access only censored/sales data. In
analogy to multi-armed bandit problems, the manager needs to simultaneously
""explore"" and ""exploit"" with her inventory decisions, in order to minimize the
cumulative cost. We make no probabilistic assumptions---importantly,
independence or time stationarity---regarding the mechanism that creates the
demand sequence. Our goal is to shed light on the hardness of the problem, and
to develop policies that perform well with respect to the regret criterion,
that is, the difference between the cumulative cost of a policy and that of the
best fixed action/static inventory decision in hindsight, uniformly over all
feasible demand sequences. We show that a simple randomized policy, termed the
Exponentially Weighted Forecaster, combined with a carefully designed cost
estimator, achieves optimal scaling of the expected regret (up to logarithmic
factors) with respect to all three key primitives: the number of time periods,
the number of inventory decisions available, and the demand support. Through
this result, we derive an important insight: the benefit from ""information
stalking"" as well as the cost of censoring are both negligible in this dynamic
learning problem, at least with respect to the regret criterion. Furthermore,
we modify the proposed policy in order to perform well in terms of the tracking
regret, that is, using as benchmark the best sequence of inventory decisions
that switches a limited number of times. Numerical experiments suggest that the
proposed approach outperforms existing ones (that are tailored to, or
facilitated by, time stationarity) on nonstationary demand models. Finally, we
extend the proposed approach and its analysis to a ""combinatorial"" version of
the repeated newsvendor problem.","['Gábor Lugosi', 'Mihalis G. Markakis', 'Gergely Neu']","['cs.LG', 'math.OC', 'stat.ML']",2017-10-16 14:33:59+00:00
http://arxiv.org/abs/1710.05918v1,Convolutional neural networks for structured omics: OmicsCNN and the OmicsConv layer,"Convolutional Neural Networks (CNNs) are a popular deep learning architecture
widely applied in different domains, in particular in classifying over images,
for which the concept of convolution with a filter comes naturally.
Unfortunately, the requirement of a distance (or, at least, of a neighbourhood
function) in the input feature space has so far prevented its direct use on
data types such as omics data. However, a number of omics data are metrizable,
i.e., they can be endowed with a metric structure, enabling to adopt a
convolutional based deep learning framework, e.g., for prediction. We propose a
generalized solution for CNNs on omics data, implemented through a dedicated
Keras layer. In particular, for metagenomics data, a metric can be derived from
the patristic distance on the phylogenetic tree. For transcriptomics data, we
combine Gene Ontology semantic similarity and gene co-expression to define a
distance; the function is defined through a multilayer network where 3 layers
are defined by the GO mutual semantic similarity while the fourth one by gene
co-expression. As a general tool, feature distance on omics data is enabled by
OmicsConv, a novel Keras layer, obtaining OmicsCNN, a dedicated deep learning
framework. Here we demonstrate OmicsCNN on gut microbiota sequencing data, for
Inflammatory Bowel Disease (IBD) 16S data, first on synthetic data and then a
metagenomics collection of gut microbiota of 222 IBD patients.","['Giuseppe Jurman', 'Valerio Maggio', 'Diego Fioravanti', 'Ylenia Giarratano', 'Isotta Landi', 'Margherita Francescatto', 'Claudio Agostinelli', 'Marco Chierici', 'Manlio De Domenico', 'Cesare Furlanello']","['q-bio.QM', 'stat.ML']",2017-10-16 13:58:08+00:00
http://arxiv.org/abs/1710.05654v2,Large Scale Graph Learning from Smooth Signals,"Graphs are a prevalent tool in data science, as they model the inherent
structure of the data. They have been used successfully in unsupervised and
semi-supervised learning. Typically they are constructed either by connecting
nearest samples, or by learning them from data, solving an optimization
problem. While graph learning does achieve a better quality, it also comes with
a higher computational cost. In particular, the current state-of-the-art model
cost is $\mathcal{O}(n^2)$ for $n$ samples. In this paper, we show how to scale
it, obtaining an approximation with leading cost of $\mathcal{O}(n\log(n))$,
with quality that approaches the exact graph learning model. Our algorithm uses
known approximate nearest neighbor techniques to reduce the number of
variables, and automatically selects the correct parameters of the model,
requiring a single intuitive input: the desired edge density.","['Vassilis Kalofolias', 'Nathanaël Perraudin']","['stat.ML', 'cs.LG']",2017-10-16 12:42:15+00:00
http://arxiv.org/abs/1710.05613v3,Is Simple Better? Revisiting Non-linear Matrix Factorization for Learning Incomplete Ratings,"Matrix factorization techniques have been widely used as a method for
collaborative filtering for recommender systems. In recent times, different
variants of deep learning algorithms have been explored in this setting to
improve the task of making a personalized recommendation with user-item
interaction data. The idea that the mapping between the latent user or item
factors and the original features is highly nonlinear suggest that classical
matrix factorization techniques are no longer sufficient. In this paper, we
propose a multilayer nonlinear semi-nonnegative matrix factorization method,
with the motivation that user-item interactions can be modeled more accurately
using a linear combination of non-linear item features. Firstly, we learn
latent factors for representations of users and items from the designed
multilayer nonlinear Semi-NMF approach using explicit ratings. Secondly, the
architecture built is compared with deep-learning algorithms like Restricted
Boltzmann Machine and state-of-the-art Deep Matrix factorization techniques. By
using both supervised rate prediction task and unsupervised clustering in
latent item space, we demonstrate that our proposed approach achieves better
generalization ability in prediction as well as comparable representation
ability as deep matrix factorization in the clustering task.","['Vaibhav Krishna', 'Tian Guo', 'Nino Antulov-Fantulin']","['cs.LG', 'stat.ML']",2017-10-16 10:46:41+00:00
http://arxiv.org/abs/1710.05578v1,Fair Kernel Learning,"New social and economic activities massively exploit big data and machine
learning algorithms to do inference on people's lives. Applications include
automatic curricula evaluation, wage determination, and risk assessment for
credits and loans. Recently, many governments and institutions have raised
concerns about the lack of fairness, equity and ethics in machine learning to
treat these problems. It has been shown that not including sensitive features
that bias fairness, such as gender or race, is not enough to mitigate the
discrimination when other related features are included. Instead, including
fairness in the objective function has been shown to be more efficient.
  We present novel fair regression and dimensionality reduction methods built
on a previously proposed fair classification framework. Both methods rely on
using the Hilbert Schmidt independence criterion as the fairness term. Unlike
previous approaches, this allows us to simplify the problem and to use multiple
sensitive variables simultaneously. Replacing the linear formulation by kernel
functions allows the methods to deal with nonlinear problems. For both linear
and nonlinear formulations the solution reduces to solving simple matrix
inversions or generalized eigenvalue problems. This simplifies the evaluation
of the solutions for different trade-off values between the predictive error
and fairness terms. We illustrate the usefulness of the proposed methods in toy
examples, and evaluate their performance on real world datasets to predict
income using gender and/or race discrimination as sensitive variables, and
contraceptive method prediction under demographic and socio-economic sensitive
descriptors.","['Adrián Pérez-Suay', 'Valero Laparra', 'Gonzalo Mateo-García', 'Jordi Muñoz-Marí', 'Luis Gómez-Chova', 'Gustau Camps-Valls']",['stat.ML'],2017-10-16 09:19:56+00:00
http://arxiv.org/abs/1710.05552v1,Fully adaptive algorithm for pure exploration in linear bandits,"We propose the first fully-adaptive algorithm for pure exploration in linear
bandits---the task to find the arm with the largest expected reward, which
depends on an unknown parameter linearly. While existing methods partially or
entirely fix sequences of arm selections before observing rewards, our method
adaptively changes the arm selection strategy based on past observations at
each round. We show our sample complexity matches the achievable lower bound up
to a constant factor in an extreme case. Furthermore, we evaluate the
performance of the methods by simulations based on both synthetic setting and
real-world data, in which our method shows vast improvement over existing
methods.","['Liyuan Xu', 'Junya Honda', 'Masashi Sugiyama']",['stat.ML'],2017-10-16 08:16:50+00:00
http://arxiv.org/abs/1710.05513v1,Robust Maximum Likelihood Estimation of Sparse Vector Error Correction Model,"In econometrics and finance, the vector error correction model (VECM) is an
important time series model for cointegration analysis, which is used to
estimate the long-run equilibrium variable relationships. The traditional
analysis and estimation methodologies assume the underlying Gaussian
distribution but, in practice, heavy-tailed data and outliers can lead to the
inapplicability of these methods. In this paper, we propose a robust model
estimation method based on the Cauchy distribution to tackle this issue. In
addition, sparse cointegration relations are considered to realize feature
selection and dimension reduction. An efficient algorithm based on the
majorization-minimization (MM) method is applied to solve the proposed
nonconvex problem. The performance of this algorithm is shown through numerical
simulations.","['Ziping Zhao', 'Daniel P. Palomar']","['stat.ML', 'cs.NA', 'q-fin.ST', 'stat.AP', 'stat.CO']",2017-10-16 05:38:27+00:00
http://arxiv.org/abs/1710.05512v1,The Feeling of Success: Does Touch Sensing Help Predict Grasp Outcomes?,"A successful grasp requires careful balancing of the contact forces. Deducing
whether a particular grasp will be successful from indirect measurements, such
as vision, is therefore quite challenging, and direct sensing of contacts
through touch sensing provides an appealing avenue toward more successful and
consistent robotic grasping. However, in order to fully evaluate the value of
touch sensing for grasp outcome prediction, we must understand how touch
sensing can influence outcome prediction accuracy when combined with other
modalities. Doing so using conventional model-based techniques is exceptionally
difficult. In this work, we investigate the question of whether touch sensing
aids in predicting grasp outcomes within a multimodal sensing framework that
combines vision and touch. To that end, we collected more than 9,000 grasping
trials using a two-finger gripper equipped with GelSight high-resolution
tactile sensors on each finger, and evaluated visuo-tactile deep neural network
models to directly predict grasp outcomes from either modality individually,
and from both modalities together. Our experimental results indicate that
incorporating tactile readings substantially improve grasping performance.","['Roberto Calandra', 'Andrew Owens', 'Manu Upadhyaya', 'Wenzhen Yuan', 'Justin Lin', 'Edward H. Adelson', 'Sergey Levine']","['cs.RO', 'cs.CV', 'cs.LG', 'stat.ML']",2017-10-16 05:32:38+00:00
http://arxiv.org/abs/1710.05488v2,A Geometric View of Optimal Transportation and Generative Model,"In this work, we show the intrinsic relations between optimal transportation
and convex geometry, especially the variational approach to solve Alexandrov
problem: constructing a convex polytope with prescribed face normals and
volumes. This leads to a geometric interpretation to generative models, and
leads to a novel framework for generative models. By using the optimal
transportation view of GAN model, we show that the discriminator computes the
Kantorovich potential, the generator calculates the transportation map. For a
large class of transportation costs, the Kantorovich potential can give the
optimal transportation map by a close-form formula. Therefore, it is sufficient
to solely optimize the discriminator. This shows the adversarial competition
can be avoided, and the computational architecture can be simplified.
Preliminary experimental results show the geometric method outperforms WGAN for
approximating probability measures with multiple clusters in low dimensional
space.","['Na Lei', 'Kehua Su', 'Li Cui', 'Shing-Tung Yau', 'David Xianfeng Gu']","['cs.LG', 'stat.ML']",2017-10-16 03:30:09+00:00
http://arxiv.org/abs/1710.05476v3,Calibrated Boosting-Forest,"Excellent ranking power along with well calibrated probability estimates are
needed in many classification tasks. In this paper, we introduce a technique,
Calibrated Boosting-Forest that captures both. This novel technique is an
ensemble of gradient boosting machines that can support both continuous and
binary labels. While offering superior ranking power over any individual
regression or classification model, Calibrated Boosting-Forest is able to
preserve well calibrated posterior probabilities. Along with these benefits, we
provide an alternative to the tedious step of tuning gradient boosting
machines. We demonstrate that tuning Calibrated Boosting-Forest can be reduced
to a simple hyper-parameter selection. We further establish that increasing
this hyper-parameter improves the ranking performance under a diminishing
return. We examine the effectiveness of Calibrated Boosting-Forest on
ligand-based virtual screening where both continuous and binary labels are
available and compare the performance of Calibrated Boosting-Forest with
logistic regression, gradient boosting machine and deep learning. Calibrated
Boosting-Forest achieved an approximately 48% improvement compared to a
state-of-art deep learning model. Moreover, it achieved around 95% improvement
on probability quality measurement compared to the best individual gradient
boosting machine. Calibrated Boosting-Forest offers a benchmark demonstration
that in the field of ligand-based virtual screening, deep learning is not the
universally dominant machine learning model and good calibrated probabilities
can better facilitate virtual screening process.",['Haozhen Wu'],"['stat.ML', 'cs.LG']",2017-10-16 02:49:07+00:00
http://arxiv.org/abs/1710.05468v9,Generalization in Deep Learning,"This paper provides theoretical insights into why and how deep learning can
generalize well, despite its large capacity, complexity, possible algorithmic
instability, nonrobustness, and sharp minima, responding to an open question in
the literature. We also discuss approaches to provide non-vacuous
generalization guarantees for deep learning. Based on theoretical observations,
we propose new open problems and discuss the limitations of our results.","['Kenji Kawaguchi', 'Leslie Pack Kaelbling', 'Yoshua Bengio']","['stat.ML', 'cs.AI', 'cs.LG', 'cs.NE']",2017-10-16 02:21:24+00:00
http://arxiv.org/abs/1710.05420v1,NeuralPower: Predict and Deploy Energy-Efficient Convolutional Neural Networks,"""How much energy is consumed for an inference made by a convolutional neural
network (CNN)?"" With the increased popularity of CNNs deployed on the
wide-spectrum of platforms (from mobile devices to workstations), the answer to
this question has drawn significant attention. From lengthening battery life of
mobile devices to reducing the energy bill of a datacenter, it is important to
understand the energy efficiency of CNNs during serving for making an
inference, before actually training the model. In this work, we propose
NeuralPower: a layer-wise predictive framework based on sparse polynomial
regression, for predicting the serving energy consumption of a CNN deployed on
any GPU platform. Given the architecture of a CNN, NeuralPower provides an
accurate prediction and breakdown for power and runtime across all layers in
the whole network, helping machine learners quickly identify the power,
runtime, or energy bottlenecks. We also propose the ""energy-precision ratio""
(EPR) metric to guide machine learners in selecting an energy-efficient CNN
architecture that better trades off the energy consumption and prediction
accuracy. The experimental results show that the prediction accuracy of the
proposed NeuralPower outperforms the best published model to date, yielding an
improvement in accuracy of up to 68.5%. We also assess the accuracy of
predictions at the network level, by predicting the runtime, power, and energy
of state-of-the-art CNN architectures, achieving an average accuracy of 88.24%
in runtime, 88.34% in power, and 97.21% in energy. We comprehensively
corroborate the effectiveness of NeuralPower as a powerful framework for
machine learners by testing it on different GPU platforms and Deep Learning
software tools.","['Ermao Cai', 'Da-Cheng Juan', 'Dimitrios Stamoulis', 'Diana Marculescu']","['cs.LG', 'cs.PF', 'stat.ML']",2017-10-15 23:39:29+00:00
http://arxiv.org/abs/1710.05387v1,Manifold Regularization for Kernelized LSTD,"Policy evaluation or value function or Q-function approximation is a key
procedure in reinforcement learning (RL). It is a necessary component of policy
iteration and can be used for variance reduction in policy gradient methods.
Therefore its quality has a significant impact on most RL algorithms. Motivated
by manifold regularized learning, we propose a novel kernelized policy
evaluation method that takes advantage of the intrinsic geometry of the state
space learned from data, in order to achieve better sample efficiency and
higher accuracy in Q-function approximation. Applying the proposed method in
the Least-Squares Policy Iteration (LSPI) framework, we observe superior
performance compared to widely used parametric basis functions on two standard
benchmarks in terms of policy quality.","['Xinyan Yan', 'Krzysztof Choromanski', 'Byron Boots', 'Vikas Sindhwani']","['cs.LG', 'cs.AI', 'stat.ML']",2017-10-15 19:59:13+00:00
http://arxiv.org/abs/1710.05384v2,The Scaling Limit of High-Dimensional Online Independent Component Analysis,"We analyze the dynamics of an online algorithm for independent component
analysis in the high-dimensional scaling limit. As the ambient dimension tends
to infinity, and with proper time scaling, we show that the time-varying joint
empirical measure of the target feature vector and the estimates provided by
the algorithm will converge weakly to a deterministic measured-valued process
that can be characterized as the unique solution of a nonlinear PDE. Numerical
solutions of this PDE, which involves two spatial variables and one time
variable, can be efficiently obtained. These solutions provide detailed
information about the performance of the ICA algorithm, as many practical
performance metrics are functionals of the joint empirical measures. Numerical
simulations show that our asymptotic analysis is accurate even for moderate
dimensions. In addition to providing a tool for understanding the performance
of the algorithm, our PDE analysis also provides useful insight. In particular,
in the high-dimensional limit, the original coupled dynamics associated with
the algorithm will be asymptotically ""decoupled"", with each coordinate
independently solving a 1-D effective minimization problem via stochastic
gradient descent. Exploiting this insight to design new algorithms for
achieving optimal trade-offs between computational and statistical efficiency
may prove an interesting line of future research.","['Chuang Wang', 'Yue M. Lu']","['cs.LG', 'cond-mat.dis-nn', 'stat.ML']",2017-10-15 19:14:26+00:00
http://arxiv.org/abs/1710.05381v2,A systematic study of the class imbalance problem in convolutional neural networks,"In this study, we systematically investigate the impact of class imbalance on
classification performance of convolutional neural networks (CNNs) and compare
frequently used methods to address the issue. Class imbalance is a common
problem that has been comprehensively studied in classical machine learning,
yet very limited systematic research is available in the context of deep
learning. In our study, we use three benchmark datasets of increasing
complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of
imbalance on classification and perform an extensive comparison of several
methods to address the issue: oversampling, undersampling, two-phase training,
and thresholding that compensates for prior class probabilities. Our main
evaluation metric is area under the receiver operating characteristic curve
(ROC AUC) adjusted to multi-class tasks since overall accuracy metric is
associated with notable difficulties in the context of imbalanced data. Based
on results from our experiments we conclude that (i) the effect of class
imbalance on classification performance is detrimental; (ii) the method of
addressing class imbalance that emerged as dominant in almost all analyzed
scenarios was oversampling; (iii) oversampling should be applied to the level
that completely eliminates the imbalance, whereas the optimal undersampling
ratio depends on the extent of imbalance; (iv) as opposed to some classical
machine learning models, oversampling does not cause overfitting of CNNs; (v)
thresholding should be applied to compensate for prior class probabilities when
overall number of properly classified cases is of interest.","['Mateusz Buda', 'Atsuto Maki', 'Maciej A. Mazurowski']","['cs.CV', 'cs.AI', 'cs.LG', 'cs.NE', 'stat.ML']",2017-10-15 19:01:43+00:00
http://arxiv.org/abs/1710.05359v4,Information-Theoretic Representation Learning for Positive-Unlabeled Classification,"Recent advances in weakly supervised classification allow us to train a
classifier only from positive and unlabeled (PU) data. However, existing PU
classification methods typically require an accurate estimate of the
class-prior probability, which is a critical bottleneck particularly for
high-dimensional data. This problem has been commonly addressed by applying
principal component analysis in advance, but such unsupervised dimension
reduction can collapse underlying class structure. In this paper, we propose a
novel representation learning method from PU data based on the
information-maximization principle. Our method does not require class-prior
estimation and thus can be used as a preprocessing method for PU
classification. Through experiments, we demonstrate that our method combined
with deep neural networks highly improves the accuracy of PU class-prior
estimation, leading to state-of-the-art PU classification performance.","['Tomoya Sakai', 'Gang Niu', 'Masashi Sugiyama']","['stat.ML', 'cs.LG']",2017-10-15 16:19:37+00:00
http://arxiv.org/abs/1710.05338v7,Accelerated Block Coordinate Proximal Gradients with Applications in High Dimensional Statistics,"Nonconvex optimization problems arise in different research fields and arouse
lots of attention in signal processing, statistics and machine learning. In
this work, we explore the accelerated proximal gradient method and some of its
variants which have been shown to converge under nonconvex context recently. We
show that a novel variant proposed here, which exploits adaptive momentum and
block coordinate update with specific update rules, further improves the
performance of a broad class of nonconvex problems. In applications to sparse
linear regression with regularizations like Lasso, grouped Lasso, capped
$\ell_1$ and SCAP, the proposed scheme enjoys provable local linear
convergence, with experimental justification.","['Tsz Kit Lau', 'Yuan Yao']","['math.OC', 'cs.LG', 'stat.ML']",2017-10-15 14:07:32+00:00
http://arxiv.org/abs/1710.05279v1,Facial Keypoints Detection,"Detect facial keypoints is a critical element in face recognition. However,
there is difficulty to catch keypoints on the face due to complex influences
from original images, and there is no guidance to suitable algorithms. In this
paper, we study different algorithms that can be applied to locate keyponits.
Specifically: our framework (1)prepare the data for further investigation
(2)Using PCA and LBP to process the data (3) Apply different algorithms to
analysis data, including linear regression models, tree based model, neural
network and convolutional neural network, etc. Finally we will give our
conclusion and further research topic. A comprehensive set of experiments on
dataset demonstrates the effectiveness of our framework.",['Shenghao Shi'],"['stat.ML', 'cs.LG']",2017-10-15 05:38:16+00:00
http://arxiv.org/abs/1710.05270v1,Learning Infinite RBMs with Frank-Wolfe,"In this work, we propose an infinite restricted Boltzmann machine~(RBM),
whose maximum likelihood estimation~(MLE) corresponds to a constrained convex
optimization. We consider the Frank-Wolfe algorithm to solve the program, which
provides a sparse solution that can be interpreted as inserting a hidden unit
at each iteration, so that the optimization process takes the form of a
sequence of finite models of increasing complexity. As a side benefit, this can
be used to easily and efficiently identify an appropriate number of hidden
units during the optimization. The resulting model can also be used as an
initialization for typical state-of-the-art RBM training algorithms such as
contrastive divergence, leading to models with consistently higher test
likelihood than random initialization.","['Wei Ping', 'Qiang Liu', 'Alexander Ihler']","['cs.LG', 'cs.AI', 'stat.ML']",2017-10-15 03:38:32+00:00
http://arxiv.org/abs/1710.05241v3,Robust Decentralized Learning Using ADMM with Unreliable Agents,"Many machine learning problems can be formulated as consensus optimization
problems which can be solved efficiently via a cooperative multi-agent system.
However, the agents in the system can be unreliable due to a variety of
reasons: noise, faults and attacks. Providing erroneous updates leads the
optimization process in a wrong direction, and degrades the performance of
distributed machine learning algorithms. This paper considers the problem of
decentralized learning using ADMM in the presence of unreliable agents. First,
we rigorously analyze the effect of erroneous updates (in ADMM learning
iterations) on the convergence behavior of multi-agent system. We show that the
algorithm linearly converges to a neighborhood of the optimal solution under
certain conditions and characterize the neighborhood size analytically. Next,
we provide guidelines for network design to achieve a faster convergence. We
also provide conditions on the erroneous updates for exact convergence to the
optimal solution. Finally, to mitigate the influence of unreliable agents, we
propose \textsf{ROAD}, a robust variant of ADMM, and show its resilience to
unreliable agents with an exact convergence to the optimum.","['Qunwei Li', 'Bhavya Kailkhura', 'Ryan Goldhahn', 'Priyadip Ray', 'Pramod K. Varshney']","['cs.LG', 'stat.ML']",2017-10-14 21:44:32+00:00
http://arxiv.org/abs/1710.05213v1,Simultaneous Matrix Diagonalization for Structural Brain Networks Classification,"This paper considers the problem of brain disease classification based on
connectome data. A connectome is a network representation of a human brain. The
typical connectome classification problem is very challenging because of the
small sample size and high dimensionality of the data. We propose to use
simultaneous approximate diagonalization of adjacency matrices in order to
compute their eigenstructures in more stable way. The obtained approximate
eigenvalues are further used as features for classification. The proposed
approach is demonstrated to be efficient for detection of Alzheimer's disease,
outperforming simple baselines and competing with state-of-the-art approaches
to brain disease classification.","['Nikita Mokrov', 'Maxim Panov', 'Boris A. Gutman', 'Joshua I. Faskowitz', 'Neda Jahanshad', 'Paul M. Thompson']",['stat.ML'],2017-10-14 17:12:42+00:00
http://arxiv.org/abs/1710.05163v2,An Improved Modified Cholesky Decomposition Method for Precision Matrix Estimation,"The modified Cholesky decomposition is commonly used for precision matrix
estimation given a specified order of random variables. However, the order of
variables is often not available or cannot be pre-determined. In this work, we
propose to address the variable order issue in the modified Cholesky
decomposition for sparse precision matrix estimation. The key idea is to
effectively combine a set of estimates obtained from multiple permutations of
variable orders, and to efficiently encourage the sparse structure for the
resultant estimate by the thresholding technique on the ensemble Cholesky
factor matrix. The consistent property of the proposed estimate is established
under some weak regularity conditions. Simulation studies are conducted to
evaluate the performance of the proposed method in comparison with several
existing approaches. The proposed method is also applied into linear
discriminant analysis of real data for classification.","['Xiaoning Kang', 'Xinwei Deng']",['stat.ML'],2017-10-14 11:14:26+00:00
http://arxiv.org/abs/1710.05135v2,When Point Process Meets RNNs: Predicting Fine-Grained User Interests with Mutual Behavioral Infectivity,"Predicting fine-grained interests of users with temporal behavior is
important to personalization and information filtering applications. However,
existing interest prediction methods are incapable of capturing the subtle
degreed user interests towards particular items, and the internal time-varying
drifting attention of individuals is not studied yet. Moreover, the prediction
process can also be affected by inter-personal influence, known as behavioral
mutual infectivity. Inspired by point process in modeling temporal point
process, in this paper we present a deep prediction method based on two
recurrent neural networks (RNNs) to jointly model each user's continuous
browsing history and asynchronous event sequences in the context of inter-user
behavioral mutual infectivity. Our model is able to predict the fine-grained
interest from a user regarding a particular item and corresponding timestamps
when an occurrence of event takes place. The proposed approach is more flexible
to capture the dynamic characteristic of event sequences by using the temporal
point process to model event data and timely update its intensity function by
RNNs. Furthermore, to improve the interpretability of the model, the attention
mechanism is introduced to emphasize both intra-personal and inter-personal
behavior influence over time. Experiments on real datasets demonstrate that our
model outperforms the state-of-the-art methods in fine-grained user interest
prediction.","['Tong Chen', 'Lin Wu', 'Yang Wang', 'Jun Zhang', 'Hongxu Chen', 'Xue Li']","['cs.LG', 'cs.SI', 'stat.ML']",2017-10-14 05:37:55+00:00
http://arxiv.org/abs/1710.05115v3,Benefits from Superposed Hawkes Processes,"The superposition of temporal point processes has been studied for many
years, although the usefulness of such models for practical applications has
not be fully developed. We investigate superposed Hawkes process as an
important class of such models, with properties studied in the framework of
least squares estimation. The superposition of Hawkes processes is demonstrated
to be beneficial for tightening the upper bound of excess risk under certain
conditions, and we show the feasibility of the benefit in typical situations.
The usefulness of superposed Hawkes processes is verified on synthetic data,
and its potential to solve the cold-start problem of recommendation systems is
demonstrated on real-world data.","['Hongteng Xu', 'Dixin Luo', 'Xu Chen', 'Lawrence Carin']",['stat.ML'],2017-10-14 00:53:42+00:00
http://arxiv.org/abs/1710.05114v4,Deep Learning in a Generalized HJM-type Framework Through Arbitrage-Free Regularization,"We introduce a regularization approach to arbitrage-free factor-model
selection. The considered model selection problem seeks to learn the closest
arbitrage-free HJM-type model to any prespecified factor-model. An asymptotic
solution to this, a priori computationally intractable, problem is represented
as the limit of a 1-parameter family of optimizers to computationally tractable
model selection tasks. Each of these simplified model-selection tasks seeks to
learn the most similar model, to the prescribed factor-model, subject to a
penalty detecting when the reference measure is a local martingale-measure for
the entire underlying financial market. A simple expression for the penalty
terms is obtained in the bond market withing the affine-term structure setting,
and it is used to formulate a deep-learning approach to arbitrage-free affine
term-structure modelling. Numerical implementations are also performed to
evaluate the performance in the bond market.","['Anastasis Kratsios', 'Cody B. Hyndman']","['q-fin.MF', 'math.PR', 'q-fin.PR', 'stat.ML']",2017-10-14 00:51:18+00:00
http://arxiv.org/abs/1710.05101v1,Unsupervised Real-Time Control through Variational Empowerment,"We introduce a methodology for efficiently computing a lower bound to
empowerment, allowing it to be used as an unsupervised cost function for policy
learning in real-time control. Empowerment, being the channel capacity between
actions and states, maximises the influence of an agent on its near future. It
has been shown to be a good model of biological behaviour in the absence of an
extrinsic goal. But empowerment is also prohibitively hard to compute,
especially in nonlinear continuous spaces. We introduce an efficient, amortised
method for learning empowerment-maximising policies. We demonstrate that our
algorithm can reliably handle continuous dynamical systems using system
dynamics learned from raw data. The resulting policies consistently drive the
agents into states where they can use their full potential.","['Maximilian Karl', 'Maximilian Soelch', 'Philip Becker-Ehmck', 'Djalel Benbouzid', 'Patrick van der Smagt', 'Justin Bayer']",['stat.ML'],2017-10-13 23:51:38+00:00
http://arxiv.org/abs/1710.05092v1,Dropout as a Low-Rank Regularizer for Matrix Factorization,"Regularization for matrix factorization (MF) and approximation problems has
been carried out in many different ways. Due to its popularity in deep
learning, dropout has been applied also for this class of problems. Despite its
solid empirical performance, the theoretical properties of dropout as a
regularizer remain quite elusive for this class of problems. In this paper, we
present a theoretical analysis of dropout for MF, where Bernoulli random
variables are used to drop columns of the factors. We demonstrate the
equivalence between dropout and a fully deterministic model for MF in which the
factors are regularized by the sum of the product of squared Euclidean norms of
the columns. Additionally, we inspect the case of a variable sized
factorization and we prove that dropout achieves the global minimum of a convex
approximation problem with (squared) nuclear norm regularization. As a result,
we conclude that dropout can be used as a low-rank regularizer with data
dependent singular-value thresholding.","['Jacopo Cavazza', 'Pietro Morerio', 'Benjamin Haeffele', 'Connor Lane', 'Vittorio Murino', 'Rene Vidal']","['cs.LG', 'stat.ML']",2017-10-13 22:47:19+00:00
http://arxiv.org/abs/1710.05091v1,A simple data discretizer,"Data discretization is an important step in the process of machine learning,
since it is easier for classifiers to deal with discrete attributes rather than
continuous attributes. Over the years, several methods of performing
discretization such as Boolean Reasoning, Equal Frequency Binning, Entropy have
been proposed, explored, and implemented. In this article, a simple supervised
discretization approach is introduced. The prime goal of MIL is to maximize
classification accuracy of classifier, minimizing loss of information while
discretization of continuous attributes. The performance of the suggested
approach is compared with the supervised discretization algorithm Minimum
Information Loss (MIL), using the state-of-the-art rule inductive algorithms-
J48 (Java implementation of C4.5 classifier). The presented approach is,
indeed, the modified version of MIL. The empirical results show that the
modified approach performs better in several cases in comparison to the
original MIL algorithm and Minimum Description Length Principle (MDLP) .","['Gourab Mitra', 'Shashidhar Sundareisan', 'Bikash Kanti Sarkar']","['cs.LG', 'cs.DB', 'stat.ML', 'H.2.8']",2017-10-13 22:45:11+00:00
http://arxiv.org/abs/1710.05090v1,Burn-In Demonstrations for Multi-Modal Imitation Learning,"Recent work on imitation learning has generated policies that reproduce
expert behavior from multi-modal data. However, past approaches have focused
only on recreating a small number of distinct, expert maneuvers, or have relied
on supervised learning techniques that produce unstable policies. This work
extends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce
behavior over an extended period of time. Our approach involves reformulating
the typical imitation learning setting to include ""burn-in demonstrations"" upon
which policies are conditioned at test time. We demonstrate that our approach
outperforms standard InfoGAIL in maximizing the mutual information between
predicted and unseen style labels in road scene simulations, and we show that
our method leads to policies that imitate expert autonomous driving systems
over long time horizons.","['Alex Kuefler', 'Mykel J. Kochenderfer']","['cs.LG', 'stat.ML']",2017-10-13 22:29:51+00:00
http://arxiv.org/abs/1710.05086v2,A deep generative model for single-cell RNA sequencing with application to detecting differentially expressed genes,"We propose a probabilistic model for interpreting gene expression levels that
are observed through single-cell RNA sequencing. In the model, each cell has a
low-dimensional latent representation. Additional latent variables account for
technical effects that may erroneously set some observations of gene expression
levels to zero. Conditional distributions are specified by neural networks,
giving the proposed model enough flexibility to fit the data well. We use
variational inference and stochastic optimization to approximate the posterior
distribution. The inference procedure scales to over one million cells, whereas
competing algorithms do not. Even for smaller datasets, for several tasks, the
proposed procedure outperforms state-of-the-art methods like ZIFA and
ZINB-WaVE. We also extend our framework to take into account batch effects and
other confounding factors and propose a natural Bayesian hypothesis framework
for differential expression that outperforms tradition DESeq2.","['Romain Lopez', 'Jeffrey Regier', 'Michael Cole', 'Michael Jordan', 'Nir Yosef']","['cs.LG', 'q-bio.GN', 'stat.ML']",2017-10-13 21:47:48+00:00
http://arxiv.org/abs/1710.05080v1,DSCOVR: Randomized Primal-Dual Block Coordinate Algorithms for Asynchronous Distributed Optimization,"Machine learning with big data often involves large optimization models. For
distributed optimization over a cluster of machines, frequent communication and
synchronization of all model parameters (optimization variables) can be very
costly. A promising solution is to use parameter servers to store different
subsets of the model parameters, and update them asynchronously at different
machines using local datasets. In this paper, we focus on distributed
optimization of large linear models with convex loss functions, and propose a
family of randomized primal-dual block coordinate algorithms that are
especially suitable for asynchronous distributed implementation with parameter
servers. In particular, we work with the saddle-point formulation of such
problems which allows simultaneous data and model partitioning, and exploit its
structure by doubly stochastic coordinate optimization with variance reduction
(DSCOVR). Compared with other first-order distributed algorithms, we show that
DSCOVR may require less amount of overall computation and communication, and
less or no synchronization. We discuss the implementation details of the DSCOVR
algorithms, and present numerical experiments on an industrial distributed
computing system.","['Lin Xiao', 'Adams Wei Yu', 'Qihang Lin', 'Weizhu Chen']","['math.OC', 'stat.ML']",2017-10-13 21:19:01+00:00
http://arxiv.org/abs/1710.05053v2,Automated Scalable Bayesian Inference via Hilbert Coresets,"The automation of posterior inference in Bayesian data analysis has enabled
experts and nonexperts alike to use more sophisticated models, engage in faster
exploratory modeling and analysis, and ensure experimental reproducibility.
However, standard automated posterior inference algorithms are not tractable at
the scale of massive modern datasets, and modifications to make them so are
typically model-specific, require expert tuning, and can break theoretical
guarantees on inferential quality. Building on the Bayesian coresets framework,
this work instead takes advantage of data redundancy to shrink the dataset
itself as a preprocessing step, providing fully-automated, scalable Bayesian
inference with theoretical guarantees. We begin with an intuitive reformulation
of Bayesian coreset construction as sparse vector sum approximation, and
demonstrate that its automation and performance-based shortcomings arise from
the use of the supremum norm. To address these shortcomings we develop Hilbert
coresets, i.e., Bayesian coresets constructed under a norm induced by an
inner-product on the log-likelihood function space. We propose two Hilbert
coreset construction algorithms---one based on importance sampling, and one
based on the Frank-Wolfe algorithm---along with theoretical guarantees on
approximation quality as a function of coreset size. Since the exact
computation of the proposed inner-products is model-specific, we automate the
construction with a random finite-dimensional projection of the log-likelihood
functions. The resulting automated coreset construction algorithm is simple to
implement, and experiments on a variety of models with real and synthetic
datasets show that it provides high-quality posterior approximations and a
significant reduction in the computational cost of inference.","['Trevor Campbell', 'Tamara Broderick']","['stat.ML', 'cs.LG', 'stat.CO']",2017-10-13 19:13:40+00:00
http://arxiv.org/abs/1710.05050v1,Learning Independent Features with Adversarial Nets for Non-linear ICA,"Reliable measures of statistical dependence could be useful tools for
learning independent features and performing tasks like source separation using
Independent Component Analysis (ICA). Unfortunately, many of such measures,
like the mutual information, are hard to estimate and optimize directly. We
propose to learn independent features with adversarial objectives which
optimize such measures implicitly. These objectives compare samples from the
joint distribution and the product of the marginals without the need to compute
any probability densities. We also propose two methods for obtaining samples
from the product of the marginals using either a simple resampling trick or a
separate parametric distribution. Our experiments show that this strategy can
easily be applied to different types of model architectures and solve both
linear and non-linear ICA problems.","['Philemon Brakel', 'Yoshua Bengio']",['stat.ML'],2017-10-13 18:29:56+00:00
http://arxiv.org/abs/1710.05012v1,"Potential Conditional Mutual Information: Estimators, Properties and Applications","The conditional mutual information I(X;Y|Z) measures the average information
that X and Y contain about each other given Z. This is an important primitive
in many learning problems including conditional independence testing, graphical
model inference, causal strength estimation and time-series problems. In
several applications, it is desirable to have a functional purely of the
conditional distribution p_{Y|X,Z} rather than of the joint distribution
p_{X,Y,Z}. We define the potential conditional mutual information as the
conditional mutual information calculated with a modified joint distribution
p_{Y|X,Z} q_{X,Z}, where q_{X,Z} is a potential distribution, fixed airport. We
develop K nearest neighbor based estimators for this functional, employing
importance sampling, and a coupling trick, and prove the finite k consistency
of such an estimator. We demonstrate that the estimator has excellent practical
performance and show an application in dynamical system inference.","['Arman Rahimzamani', 'Sreeram Kannan']","['cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2017-10-13 17:26:18+00:00
http://arxiv.org/abs/1710.04934v2,RADNET: Radiologist Level Accuracy using Deep Learning for HEMORRHAGE detection in CT Scans,"We describe a deep learning approach for automated brain hemorrhage detection
from computed tomography (CT) scans. Our model emulates the procedure followed
by radiologists to analyse a 3D CT scan in real-world. Similar to radiologists,
the model sifts through 2D cross-sectional slices while paying close attention
to potential hemorrhagic regions. Further, the model utilizes 3D context from
neighboring slices to improve predictions at each slice and subsequently,
aggregates the slice-level predictions to provide diagnosis at CT level. We
refer to our proposed approach as Recurrent Attention DenseNet (RADnet) as it
employs original DenseNet architecture along with adding the components of
attention for slice level predictions and recurrent neural network layer for
incorporating 3D context. The real-world performance of RADnet has been
benchmarked against independent analysis performed by three senior radiologists
for 77 brain CTs. RADnet demonstrates 81.82% hemorrhage prediction accuracy at
CT level that is comparable to radiologists. Further, RADnet achieves higher
recall than two of the three radiologists, which is remarkable.","['Monika Grewal', 'Muktabh Mayank Srivastava', 'Pulkit Kumar', 'Srikrishna Varadarajan']","['cs.CV', 'stat.ML']",2017-10-13 14:14:39+00:00
http://arxiv.org/abs/1710.04924v1,Two-stage Algorithm for Fairness-aware Machine Learning,"Algorithmic decision making process now affects many aspects of our lives.
Standard tools for machine learning, such as classification and regression, are
subject to the bias in data, and thus direct application of such off-the-shelf
tools could lead to a specific group being unfairly discriminated. Removing
sensitive attributes of data does not solve this problem because a
\textit{disparate impact} can arise when non-sensitive attributes and sensitive
attributes are correlated. Here, we study a fair machine learning algorithm
that avoids such a disparate impact when making a decision. Inspired by the
two-stage least squares method that is widely used in the field of economics,
we propose a two-stage algorithm that removes bias in the training data. The
proposed algorithm is conceptually simple. Unlike most of existing fair
algorithms that are designed for classification tasks, the proposed method is
able to (i) deal with regression tasks, (ii) combine explanatory attributes to
remove reverse discrimination, and (iii) deal with numerical sensitive
attributes. The performance and fairness of the proposed algorithm are
evaluated in simulations with synthetic and real-world datasets.","['Junpei Komiyama', 'Hajime Shimao']","['stat.ML', 'cs.AI', 'cs.LG']",2017-10-13 13:58:42+00:00
http://arxiv.org/abs/1710.04881v2,User Modelling for Avoiding Overfitting in Interactive Knowledge Elicitation for Prediction,"In human-in-the-loop machine learning, the user provides information beyond
that in the training data. Many algorithms and user interfaces have been
designed to optimize and facilitate this human--machine interaction; however,
fewer studies have addressed the potential defects the designs can cause.
Effective interaction often requires exposing the user to the training data or
its statistics. The design of the system is then critical, as this can lead to
double use of data and overfitting, if the user reinforces noisy patterns in
the data. We propose a user modelling methodology, by assuming simple rational
behaviour, to correct the problem. We show, in a user study with 48
participants, that the method improves predictive performance in a sparse
linear regression sentiment analysis task, where graded user knowledge on
feature relevance is elicited. We believe that the key idea of inferring user
knowledge with probabilistic user models has general applicability in guarding
against overfitting and improving interactive machine learning.","['Pedram Daee', 'Tomi Peltola', 'Aki Vehtari', 'Samuel Kaski']","['cs.HC', 'cs.LG', 'stat.ML', 'H.1.2; I.2.6; H.3.3']",2017-10-13 11:52:19+00:00
http://arxiv.org/abs/1710.04874v1,A Method of Generating Random Weights and Biases in Feedforward Neural Networks with Random Hidden Nodes,"Neural networks with random hidden nodes have gained increasing interest from
researchers and practical applications. This is due to their unique features
such as very fast training and universal approximation property. In these
networks the weights and biases of hidden nodes determining the nonlinear
feature mapping are set randomly and are not learned. Appropriate selection of
the intervals from which weights and biases are selected is extremely
important. This topic has not yet been sufficiently explored in the literature.
In this work a method of generating random weights and biases is proposed. This
method generates the parameters of the hidden nodes in such a way that
nonlinear fragments of the activation functions are located in the input space
regions with data and can be used to construct the surface approximating a
nonlinear target function. The weights and biases are dependent on the input
data range and activation function type. The proposed methods allows us to
control the generalization degree of the model. These all lead to improvement
in approximation performance of the network. Several experiments show very
promising results.",['Grzegorz Dudek'],"['cs.NE', 'cs.LG', 'stat.ML']",2017-10-13 11:23:18+00:00
http://arxiv.org/abs/1710.04872v1,Manifold regularization based on Nystr{ö}m type subsampling,"In this paper, we study the Nystr{\""o}m type subsampling for large scale
kernel methods to reduce the computational complexities of big data. We discuss
the multi-penalty regularization scheme based on Nystr{\""o}m type subsampling
which is motivated from well-studied manifold regularization schemes. We
develop a theoretical analysis of multi-penalty least-square regularization
scheme under the general source condition in vector-valued function setting,
therefore the results can also be applied to multi-task learning problems. We
achieve the optimal minimax convergence rates of multi-penalty regularization
using the concept of effective dimension for the appropriate subsampling size.
We discuss an aggregation approach based on linear function strategy to combine
various Nystr{\""o}m approximants. Finally, we demonstrate the performance of
multi-penalty regularization based on Nystr{\""o}m type subsampling on
Caltech-101 data set for multi-class image classification and NSL-KDD benchmark
data set for intrusion detection problem.","['Abhishake Rastogi', 'Sivananthan Sampath']","['stat.ML', 'cs.LG']",2017-10-13 11:13:38+00:00
http://arxiv.org/abs/1710.05758v1,TensorQuant - A Simulation Toolbox for Deep Neural Network Quantization,"Recent research implies that training and inference of deep neural networks
(DNN) can be computed with low precision numerical representations of the
training/test data, weights and gradients without a general loss in accuracy.
The benefit of such compact representations is twofold: they allow a
significant reduction of the communication bottleneck in distributed DNN
training and faster neural network implementations on hardware accelerators
like FPGAs. Several quantization methods have been proposed to map the original
32-bit floating point problem to low-bit representations. While most related
publications validate the proposed approach on a single DNN topology, it
appears to be evident, that the optimal choice of the quantization method and
number of coding bits is topology dependent. To this end, there is no general
theory available, which would allow users to derive the optimal quantization
during the design of a DNN topology. In this paper, we present a quantization
tool box for the TensorFlow framework. TensorQuant allows a transparent
quantization simulation of existing DNN topologies during training and
inference. TensorQuant supports generic quantization methods and allows
experimental evaluation of the impact of the quantization on single layers as
well as on the full topology. In a first series of experiments with
TensorQuant, we show an analysis of fix-point quantizations of popular CNN
topologies.","['Dominik Marek Loroch', 'Norbert Wehn', 'Franz-Josef Pfreundt', 'Janis Keuper']","['cs.CV', 'cs.LG', 'stat.ML']",2017-10-13 10:15:27+00:00
http://arxiv.org/abs/1710.04837v1,Recent Advances in Zero-shot Recognition,"With the recent renaissance of deep convolution neural networks, encouraging
breakthroughs have been achieved on the supervised recognition tasks, where
each class has sufficient training data and fully annotated training data.
However, to scale the recognition to a large number of classes with few or now
training samples for each class remains an unsolved problem. One approach to
scaling up the recognition is to develop models capable of recognizing unseen
categories without any training instances, or zero-shot recognition/ learning.
This article provides a comprehensive review of existing zero-shot recognition
techniques covering various aspects ranging from representations of models, and
from datasets and evaluation settings. We also overview related recognition
tasks including one-shot and open set recognition which can be used as natural
extensions of zero-shot recognition when limited number of class samples become
available or when zero-shot recognition is implemented in a real-world setting.
Importantly, we highlight the limitations of existing approaches and point out
future research directions in this existing new research area.","['Yanwei Fu', 'Tao Xiang', 'Yu-Gang Jiang', 'Xiangyang Xue', 'Leonid Sigal', 'Shaogang Gong']","['cs.CV', 'cs.AI', 'cs.LG', 'cs.MM', 'stat.ML']",2017-10-13 08:29:29+00:00
http://arxiv.org/abs/1710.04833v4,Machine Learning by Unitary Tensor Network of Hierarchical Tree Structure,"The resemblance between the methods used in quantum-many body physics and in
machine learning has drawn considerable attention. In particular, tensor
networks (TNs) and deep learning architectures bear striking similarities to
the extent that TNs can be used for machine learning. Previous results used
one-dimensional TNs in image recognition, showing limited scalability and
flexibilities. In this work, we train two-dimensional hierarchical TNs to solve
image recognition problems, using a training algorithm derived from the
multi-scale entanglement renormalization ansatz. This approach introduces
mathematical connections among quantum many-body physics, quantum information
theory, and machine learning. While keeping the TN unitary in the training
phase, TN states are defined, which encode classes of images into quantum
many-body states. We study the quantum features of the TN states, including
quantum entanglement and fidelity. We find these quantities could be properties
that characterize the image classes, as well as the machine learning tasks.","['Ding Liu', 'Shi-Ju Ran', 'Peter Wittek', 'Cheng Peng', 'Raul Blázquez García', 'Gang Su', 'Maciej Lewenstein']","['stat.ML', 'cond-mat.str-el', 'physics.comp-ph', 'quant-ph']",2017-10-13 08:24:09+00:00
http://arxiv.org/abs/1710.04806v2,Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions,"Deep neural networks are widely used for classification. These deep models
often suffer from a lack of interpretability -- they are particularly difficult
to understand because of their non-linear nature. As a result, neural networks
are often treated as ""black box"" models, and in the past, have been trained
purely to optimize the accuracy of predictions. In this work, we create a novel
network architecture for deep learning that naturally explains its own
reasoning for each prediction. This architecture contains an autoencoder and a
special prototype layer, where each unit of that layer stores a weight vector
that resembles an encoded training input. The encoder of the autoencoder allows
us to do comparisons within the latent space, while the decoder allows us to
visualize the learned prototypes. The training objective has four terms: an
accuracy term, a term that encourages every prototype to be similar to at least
one encoded input, a term that encourages every encoded input to be close to at
least one prototype, and a term that encourages faithful reconstruction by the
autoencoder. The distances computed in the prototype layer are used as part of
the classification process. Since the prototypes are learned during training,
the learned network naturally comes with explanations for each prediction, and
the explanations are loyal to what the network actually computes.","['Oscar Li', 'Hao Liu', 'Chaofan Chen', 'Cynthia Rudin']","['cs.AI', 'cs.LG', 'stat.ML']",2017-10-13 05:12:03+00:00
http://arxiv.org/abs/1710.04792v1,Sparse Weighted Canonical Correlation Analysis,"Given two data matrices $X$ and $Y$, sparse canonical correlation analysis
(SCCA) is to seek two sparse canonical vectors $u$ and $v$ to maximize the
correlation between $Xu$ and $Yv$. However, classical and sparse CCA models
consider the contribution of all the samples of data matrices and thus cannot
identify an underlying specific subset of samples. To this end, we propose a
novel sparse weighted canonical correlation analysis (SWCCA), where weights are
used for regularizing different samples. We solve the $L_0$-regularized SWCCA
($L_0$-SWCCA) using an alternating iterative algorithm. We apply $L_0$-SWCCA to
synthetic data and real-world data to demonstrate its effectiveness and
superiority compared to related methods. Lastly, we consider also SWCCA with
different penalties like LASSO (Least absolute shrinkage and selection
operator) and Group LASSO, and extend it for integrating more than three data
matrices.","['Wenwen Min', 'Juan Liu', 'Shihua Zhang']","['cs.LG', 'stat.ML', 'I.5.1; H.2.8; G.1.6']",2017-10-13 03:42:39+00:00
http://arxiv.org/abs/1710.04759v2,Bayesian Hypernetworks,"We study Bayesian hypernetworks: a framework for approximate Bayesian
inference in neural networks. A Bayesian hypernetwork $\h$ is a neural network
which learns to transform a simple noise distribution, $p(\vec\epsilon) =
\N(\vec 0,\mat I)$, to a distribution $q(\pp) := q(h(\vec\epsilon))$ over the
parameters $\pp$ of another neural network (the ""primary network"")\@. We train
$q$ with variational inference, using an invertible $\h$ to enable efficient
estimation of the variational lower bound on the posterior $p(\pp | \D)$ via
sampling. In contrast to most methods for Bayesian deep learning, Bayesian
hypernets can represent a complex multimodal approximate posterior with
correlations between parameters, while enabling cheap iid sampling of~$q(\pp)$.
In practice, Bayesian hypernets can provide a better defense against
adversarial examples than dropout, and also exhibit competitive performance on
a suite of tasks which evaluate model uncertainty, including regularization,
active learning, and anomaly detection.","['David Krueger', 'Chin-Wei Huang', 'Riashat Islam', 'Ryan Turner', 'Alexandre Lacoste', 'Aaron Courville']","['stat.ML', 'cs.AI', 'cs.LG']",2017-10-13 00:27:57+00:00
http://arxiv.org/abs/1710.04749v2,Explaining Aviation Safety Incidents Using Deep Temporal Multiple Instance Learning,"Although aviation accidents are rare, safety incidents occur more frequently
and require a careful analysis to detect and mitigate risks in a timely manner.
Analyzing safety incidents using operational data and producing event-based
explanations is invaluable to airline companies as well as to governing
organizations such as the Federal Aviation Administration (FAA) in the United
States. However, this task is challenging because of the complexity involved in
mining multi-dimensional heterogeneous time series data, the lack of
time-step-wise annotation of events in a flight, and the lack of scalable tools
to perform analysis over a large number of events. In this work, we propose a
precursor mining algorithm that identifies events in the multidimensional time
series that are correlated with the safety incident. Precursors are valuable to
systems health and safety monitoring and in explaining and forecasting safety
incidents. Current methods suffer from poor scalability to high dimensional
time series data and are inefficient in capturing temporal behavior. We propose
an approach by combining multiple-instance learning (MIL) and deep recurrent
neural networks (DRNN) to take advantage of MIL's ability to learn using weakly
supervised data and DRNN's ability to model temporal behavior. We describe the
algorithm, the data, the intuition behind taking a MIL approach, and a
comparative analysis of the proposed algorithm with baseline models. We also
discuss the application to a real-world aviation safety problem using data from
a commercial airline company and discuss the model's abilities and
shortcomings, with some final remarks about possible deployment directions.",['Vijay Manikandan Janakiraman'],"['cs.CV', 'cs.AI', 'stat.AP', 'stat.ML']",2017-10-12 23:42:00+00:00
http://arxiv.org/abs/1710.04735v1,On the Runtime-Efficacy Trade-off of Anomaly Detection Techniques for Real-Time Streaming Data,"Ever growing volume and velocity of data coupled with decreasing attention
span of end users underscore the critical need for real-time analytics. In this
regard, anomaly detection plays a key role as an application as well as a means
to verify data fidelity. Although the subject of anomaly detection has been
researched for over 100 years in a multitude of disciplines such as, but not
limited to, astronomy, statistics, manufacturing, econometrics, marketing, most
of the existing techniques cannot be used as is on real-time data streams.
Further, the lack of characterization of performance -- both with respect to
real-timeliness and accuracy -- on production data sets makes model selection
very challenging. To this end, we present an in-depth analysis, geared towards
real-time streaming data, of anomaly detection techniques. Given the
requirements with respect to real-timeliness and accuracy, the analysis
presented in this paper should serve as a guide for selection of the ""best""
anomaly detection technique. To the best of our knowledge, this is the first
characterization of anomaly detection techniques proposed in very diverse set
of fields, using production data sets corresponding to a wide set of
application domains.","['Dhruv Choudhary', 'Arun Kejariwal', 'Francois Orsini']","['stat.ML', 'cs.IR', 'cs.LG', 'eess.SP']",2017-10-12 21:57:55+00:00
http://arxiv.org/abs/1710.04725v2,Hyperparameter Importance Across Datasets,"With the advent of automated machine learning, automated hyperparameter
optimization methods are by now routinely used in data mining. However, this
progress is not yet matched by equal progress on automatic analyses that yield
information beyond performance-optimizing hyperparameter settings. In this
work, we aim to answer the following two questions: Given an algorithm, what
are generally its most important hyperparameters, and what are typically good
values for these? We present methodology and a framework to answer these
questions based on meta-learning across many datasets. We apply this
methodology using the experimental meta-data available on OpenML to determine
the most important hyperparameters of support vector machines, random forests
and Adaboost, and to infer priors for all their hyperparameters. The results,
obtained fully automatically, provide a quantitative basis to focus efforts in
both manual algorithm design and in automated hyperparameter optimization. The
conducted experiments confirm that the hyperparameters selected by the proposed
method are indeed the most important ones and that the obtained priors also
lead to statistically significant improvements in hyperparameter optimization.","['J. N. van Rijn', 'F. Hutter']","['stat.ML', 'cs.LG']",2017-10-12 21:27:38+00:00
http://arxiv.org/abs/1710.04677v1,Game-Theoretic Design of Secure and Resilient Distributed Support Vector Machines with Adversaries,"With a large number of sensors and control units in networked systems,
distributed support vector machines (DSVMs) play a fundamental role in scalable
and efficient multi-sensor classification and prediction tasks. However, DSVMs
are vulnerable to adversaries who can modify and generate data to deceive the
system to misclassification and misprediction. This work aims to design defense
strategies for DSVM learner against a potential adversary. We establish a
game-theoretic framework to capture the conflicting interests between the DSVM
learner and the attacker. The Nash equilibrium of the game allows predicting
the outcome of learning algorithms in adversarial environments, and enhancing
the resilience of the machine learning through dynamic distributed learning
algorithms. We show that the DSVM learner is less vulnerable when he uses a
balanced network with fewer nodes and higher degree. We also show that adding
more training samples is an efficient defense strategy against an attacker. We
present secure and resilient DSVM algorithms with verification method and
rejection method, and show their resiliency against adversary with numerical
experiments.","['Rui Zhang', 'Quanyan Zhu']","['stat.ML', 'cs.GT']",2017-10-12 18:10:14+00:00
http://arxiv.org/abs/1710.04584v4,Towards Scalable Spectral Clustering via Spectrum-Preserving Sparsification,"The eigendeomposition of nearest-neighbor (NN) graph Laplacian matrices is
the main computational bottleneck in spectral clustering. In this work, we
introduce a highly-scalable, spectrum-preserving graph sparsification algorithm
that enables to build ultra-sparse NN (u-NN) graphs with guaranteed
preservation of the original graph spectrums, such as the first few
eigenvectors of the original graph Laplacian. Our approach can immediately lead
to scalable spectral clustering of large data networks without sacrificing
solution quality. The proposed method starts from constructing low-stretch
spanning trees (LSSTs) from the original graphs, which is followed by
iteratively recovering small portions of ""spectrally critical"" off-tree edges
to the LSSTs by leveraging a spectral off-tree embedding scheme. To determine
the suitable amount of off-tree edges to be recovered to the LSSTs, an
eigenvalue stability checking scheme is proposed, which enables to robustly
preserve the first few Laplacian eigenvectors within the sparsified graph.
Additionally, an incremental graph densification scheme is proposed for
identifying extra edges that have been missing in the original NN graphs but
can still play important roles in spectral clustering tasks. Our experimental
results for a variety of well-known data sets show that the proposed method can
dramatically reduce the complexity of NN graphs, leading to significant
speedups in spectral clustering.","['Yongyu Wang', 'Zhuo Feng']","['cs.LG', 'cs.AI', 'stat.ML']",2017-10-12 16:09:29+00:00
http://arxiv.org/abs/1710.04582v1,Is Epicurus the father of Reinforcement Learning?,"The Epicurean Philosophy is commonly thought as simplistic and hedonistic.
Here I discuss how this is a misconception and explore its link to
Reinforcement Learning. Based on the letters of Epicurus, I construct an
objective function for hedonism which turns out to be equivalent of the
Reinforcement Learning objective function when omitting the discount factor. I
then discuss how Plato and Aristotle 's views that can be also loosely linked
to Reinforcement Learning, as well as their weaknesses in relationship to it.
Finally, I emphasise the close affinity of the Epicurean views and the Bellman
equation.",['Eleni Vasilaki'],"['cs.LG', 'cs.AI', 'stat.ML']",2017-10-12 16:07:18+00:00
http://arxiv.org/abs/1710.04580v1,Additivity of Information in Multilayer Networks via Additive Gaussian Noise Transforms,"Multilayer (or deep) networks are powerful probabilistic models based on
multiple stages of a linear transform followed by a non-linear (possibly
random) function. In general, the linear transforms are defined by matrices and
the non-linear functions are defined by information channels. These models have
gained great popularity due to their ability to characterize complex
probabilistic relationships arising in a wide variety of inference problems.
The contribution of this paper is a new method for analyzing the fundamental
limits of statistical inference in settings where the model is known. The
validity of our method can be established in a number of settings and is
conjectured to hold more generally. A key assumption made throughout is that
the matrices are drawn randomly from orthogonally invariant distributions.
  Our method yields explicit formulas for 1) the mutual information; 2) the
minimum mean-squared error (MMSE); 3) the existence and locations of certain
phase-transitions with respect to the problem parameters; and 4) the stationary
points for the state evolution of approximate message passing algorithms. When
applied to the special case of models with multivariate Gaussian channels our
method is rigorous and has close connections to free probability theory for
random matrices. When applied to the general case of non-Gaussian channels, our
method provides a simple alternative to the replica method from statistical
physics. A key observation is that the combined effects of the individual
components in the model (namely the matrices and the channels) are additive
when viewed in a certain transform domain.",['Galen Reeves'],"['cs.IT', 'cs.LG', 'math.IT', 'stat.ML']",2017-10-12 16:02:19+00:00
http://arxiv.org/abs/1710.04556v1,New efficient algorithms for multiple change-point detection with kernels,"Several statistical approaches based on reproducing kernels have been
proposed to detect abrupt changes arising in the full distribution of the
observations and not only in the mean or variance. Some of these approaches
enjoy good statistical properties (oracle inequality, \ldots). Nonetheless,
they have a high computational cost both in terms of time and memory. This
makes their application difficult even for small and medium sample sizes ($n<
10^4$). This computational issue is addressed by first describing a new
efficient and exact algorithm for kernel multiple change-point detection with
an improved worst-case complexity that is quadratic in time and linear in
space. It allows dealing with medium size signals (up to $n \approx 10^5$).
Second, a faster but approximation algorithm is described. It is based on a
low-rank approximation to the Gram matrix. It is linear in time and space. This
approximation algorithm can be applied to large-scale signals ($n \geq 10^6$).
These exact and approximation algorithms have been implemented in \texttt{R}
and \texttt{C} for various kernels. The computational and statistical
performances of these new algorithms have been assessed through empirical
experiments. The runtime of the new algorithms is observed to be faster than
that of other considered procedures. Finally, simulations confirmed the higher
statistical accuracy of kernel-based approaches to detect changes that are not
only in the mean. These simulations also illustrate the flexibility of
kernel-based approaches to analyze complex biological profiles made of DNA copy
number and allele B frequencies. An R package implementing the approach will be
made available on github.","['Alain Celisse', 'Guillemette Marot', 'Morgane Pierre-Jean', 'Guillem Rigaill']","['math.ST', 'stat.CO', 'stat.ML', 'stat.TH']",2017-10-12 15:08:52+00:00
http://arxiv.org/abs/1710.04521v1,Subjectively Interesting Subgroup Discovery on Real-valued Targets,"Deriving insights from high-dimensional data is one of the core problems in
data mining. The difficulty mainly stems from the fact that there are
exponentially many variable combinations to potentially consider, and there are
infinitely many if we consider weighted combinations, even for linear
combinations. Hence, an obvious question is whether we can automate the search
for interesting patterns and visualizations. In this paper, we consider the
setting where a user wants to learn as efficiently as possible about
real-valued attributes. For example, to understand the distribution of crime
rates in different geographic areas in terms of other (numerical, ordinal
and/or categorical) variables that describe the areas. We introduce a method to
find subgroups in the data that are maximally informative (in the formal
Information Theoretic sense) with respect to a single or set of real-valued
target attributes. The subgroup descriptions are in terms of a succinct set of
arbitrarily-typed other attributes. The approach is based on the Subjective
Interestingness framework FORSIED to enable the use of prior knowledge when
finding most informative non-redundant patterns, and hence the method also
supports iterative data mining.","['Jefrey Lijffijt', 'Bo Kang', 'Wouter Duivesteijn', 'Kai Puolamäki', 'Emilia Oikarinen', 'Tijl De Bie']","['stat.ML', 'cs.IT', 'math.IT']",2017-10-12 14:04:19+00:00
http://arxiv.org/abs/1710.04486v1,Multimodal Observation and Interpretation of Subjects Engaged in Problem Solving,"In this paper we present the first results of a pilot experiment in the
capture and interpretation of multimodal signals of human experts engaged in
solving challenging chess problems. Our goal is to investigate the extent to
which observations of eye-gaze, posture, emotion and other physiological
signals can be used to model the cognitive state of subjects, and to explore
the integration of multiple sensor modalities to improve the reliability of
detection of human displays of awareness and emotion. We observed chess players
engaged in problems of increasing difficulty while recording their behavior.
Such recordings can be used to estimate a participant's awareness of the
current situation and to predict ability to respond effectively to challenging
situations. Results show that a multimodal approach is more accurate than a
unimodal one. By combining body posture, visual attention and emotion, the
multimodal approach can reach up to 93% of accuracy when determining player's
chess expertise while unimodal approach reaches 86%. Finally this experiment
validates the use of our equipment as a general and reproducible tool for the
study of participants engaged in screen-based interaction and/or problem
solving.","['Thomas Guntz', 'Raffaella Balzarini', 'Dominique Vaufreydaz', 'James L. Crowley']","['cs.HC', 'cs.CV', 'stat.ML']",2017-10-12 12:59:42+00:00
http://arxiv.org/abs/1710.04462v1,Effects of Images with Different Levels of Familiarity on EEG,"Evaluating human brain potentials during watching different images can be
used for memory evaluation, information retrieving, guilty-innocent
identification and examining the brain response. In this study, the effects of
watching images, with different levels of familiarity, on subjects'
Electroencephalogram (EEG) have been studied. Three different groups of images
with three familiarity levels of ""unfamiliar"", ""familiar"" and ""very familiar""
have been considered for this study. EEG signals of 21 subjects (14 men) were
recorded. After signal acquisition, pre-processing, including noise and
artifact removal, were performed on epochs of data. Features, including
spatial-statistical, wavelet, frequency and harmonic parameters, and also
correlation between recording channels, were extracted from the data. Then, we
evaluated the efficiency of the extracted features by using p-value and also an
orthogonal feature selection method (combination of Gram-Schmitt method and
Fisher discriminant ratio) for feature dimensional reduction. As the final step
of feature selection, we used 'add-r take-away l' method for choosing the most
discriminative features. For data classification, including all two-class and
three-class cases, we applied Support Vector Machine (SVM) on the extracted
features. The correct classification rates (CCR) for ""unfamiliar-familiar"",
""unfamiliar-very familiar"" and ""familiar-very familiar"" cases were 85.6%,
92.6%, and 70.6%, respectively. The best results of classifications were
obtained in pre-frontal and frontal regions of brain. Also, wavelet, frequency
and harmonic features were among the most discriminative features. Finally, in
three-class case, the best CCR was 86.8%.","['Ali Saeedi', 'Ehsan Arbabi']","['stat.ML', 'q-bio.NC']",2017-10-12 11:39:48+00:00
http://arxiv.org/abs/1710.04461v2,An Improved Naive Bayes Classifier-based Noise Detection Technique for Classifying User Phone Call Behavior,"The presence of noisy instances in mobile phone data is a fundamental issue
for classifying user phone call behavior (i.e., accept, reject, missed and
outgoing), with many potential negative consequences. The classification
accuracy may decrease and the complexity of the classifiers may increase due to
the number of redundant training samples. To detect such noisy instances from a
training dataset, researchers use naive Bayes classifier (NBC) as it identifies
misclassified instances by taking into account independence assumption and
conditional probabilities of the attributes. However, some of these
misclassified instances might indicate usages behavioral patterns of individual
mobile phone users. Existing naive Bayes classifier based noise detection
techniques have not considered this issue and, thus, are lacking in
classification accuracy. In this paper, we propose an improved noise detection
technique based on naive Bayes classifier for effectively classifying users'
phone call behaviors. In order to improve the classification accuracy, we
effectively identify noisy instances from the training dataset by analyzing the
behavioral patterns of individuals. We dynamically determine a noise threshold
according to individual's unique behavioral patterns by using both the naive
Bayes classifier and Laplace estimator. We use this noise threshold to identify
noisy instances. To measure the effectiveness of our technique in classifying
user phone call behavior, we employ the most popular classification algorithm
(e.g., decision tree). Experimental results on the real phone call log dataset
show that our proposed technique more accurately identifies the noisy instances
from the training datasets that leads to better classification accuracy.","['Iqbal H. Sarker', 'Muhammad Ashad Kabir', 'Alan Colman', 'Jun Han']","['cs.LG', 'cs.SI', 'stat.ML']",2017-10-12 11:37:21+00:00
http://arxiv.org/abs/1710.04450v1,Self-Taught Support Vector Machine,"In this paper, a new approach for classification of target task using limited
labeled target data as well as enormous unlabeled source data is proposed which
is called self-taught learning. The target and source data can be drawn from
different distributions. In the previous approaches, covariate shift assumption
is considered where the marginal distributions p(x) change over domains and the
conditional distributions p(y|x) remain the same. In our approach, we propose a
new objective function which simultaneously learns a common space T(.) where
the conditional distributions over domains p(T(x)|y) remain the same and learns
robust SVM classifiers for target task using both source and target data in the
new representation. Hence, in the proposed objective function, the hidden label
of the source data is also incorporated. We applied the proposed approach on
Caltech-256, MSRC+LMO datasets and compared the performance of our algorithm to
the available competing methods. Our method has a superior performance to the
successful existing algorithms.",['Parvin Razzaghi'],"['cs.CV', 'cs.LG', 'stat.ML']",2017-10-12 11:12:30+00:00
http://arxiv.org/abs/1710.04404v3,Sum-Product-Quotient Networks,"We present a novel tractable generative model that extends Sum-Product
Networks (SPNs) and significantly boosts their power. We call it
Sum-Product-Quotient Networks (SPQNs), whose core concept is to incorporate
conditional distributions into the model by direct computation using quotient
nodes, e.g. $P(A|B) = \frac{P(A,B)}{P(B)}$. We provide sufficient conditions
for the tractability of SPQNs that generalize and relax the decomposable and
complete tractability conditions of SPNs. These relaxed conditions give rise to
an exponential boost to the expressive efficiency of our model, i.e. we prove
that there are distributions which SPQNs can compute efficiently but require
SPNs to be of exponential size. Thus, we narrow the gap in expressivity between
tractable graphical models and other Neural Network-based generative models.","['Or Sharir', 'Amnon Shashua']","['cs.LG', 'cs.NE', 'stat.ML']",2017-10-12 08:18:07+00:00
http://arxiv.org/abs/1710.04382v1,Marginal sequential Monte Carlo for doubly intractable models,"Bayesian inference for models that have an intractable partition function is
known as a doubly intractable problem, where standard Monte Carlo methods are
not applicable. The past decade has seen the development of auxiliary variable
Monte Carlo techniques (M{\o}ller et al., 2006; Murray et al., 2006) for
tackling this problem; these approaches being members of the more general class
of pseudo-marginal, or exact-approximate, Monte Carlo algorithms (Andrieu and
Roberts, 2009), which make use of unbiased estimates of intractable posteriors.
Everitt et al. (2017) investigated the use of exact-approximate importance
sampling (IS) and sequential Monte Carlo (SMC) in doubly intractable problems,
but focussed only on SMC algorithms that used data-point tempering. This paper
describes SMC samplers that may use alternative sequences of distributions, and
describes ways in which likelihood estimates may be improved adaptively as the
algorithm progresses, building on ideas from Moores et al. (2015). This
approach is compared with a number of alternative algorithms for doubly
intractable problems, including approximate Bayesian computation (ABC), which
we show is closely related to the method of M{\o}ller et al. (2006).","['Richard G. Everitt', 'Dennis Prangle', 'Philip Maybank', 'Mark Bell']","['stat.CO', 'cs.AI', 'physics.data-an', 'stat.ME', 'stat.ML']",2017-10-12 06:36:14+00:00
http://arxiv.org/abs/1710.04373v1,Deep Learning in Multiple Multistep Time Series Prediction,"The project aims to research on combining deep learning specifically
Long-Short Memory (LSTM) and basic statistics in multiple multistep time series
prediction. LSTM can dive into all the pages and learn the general trends of
variation in a large scope, while the well selected medians for each page can
keep the special seasonality of different pages so that the future trend will
not fluctuate too much from the reality. A recent Kaggle competition on 145K
Web Traffic Time Series Forecasting [1] is used to thoroughly illustrate and
test this idea.",['Chuanyun Zang'],"['stat.ML', 'cs.LG']",2017-10-12 05:28:05+00:00
http://arxiv.org/abs/1710.04350v1,A Unified Neural Network Approach for Estimating Travel Time and Distance for a Taxi Trip,"In building intelligent transportation systems such as taxi or rideshare
services, accurate prediction of travel time and distance is crucial for
customer experience and resource management. Using the NYC taxi dataset, which
contains taxi trips data collected from GPS-enabled taxis [23], this paper
investigates the use of deep neural networks to jointly predict taxi trip time
and distance. We propose a model, called ST-NN (Spatio-Temporal Neural
Network), which first predicts the travel distance between an origin and a
destination GPS coordinate, then combines this prediction with the time of day
to predict the travel time. The beauty of ST-NN is that it uses only the raw
trips data without requiring further feature engineering and provides a joint
estimate of travel time and distance. We compare the performance of ST-NN to
that of state-of-the-art travel time estimation methods, and we observe that
the proposed approach generalizes better than state-of-the-art methods. We show
that ST-NN approach significantly reduces the mean absolute error for both
predicted travel time and distance, about 17% for travel time prediction. We
also observe that the proposed approach is more robust to outliers present in
the dataset by testing the performance of ST-NN on the datasets with and
without outliers.","['Ishan Jindal', 'Tony', 'Qin', 'Xuewen Chen', 'Matthew Nokleby', 'Jieping Ye']","['stat.ML', 'cs.LG']",2017-10-12 03:21:16+00:00
http://arxiv.org/abs/1710.04908v2,Graph Convolutional Networks for Classification with a Structured Label Space,"It is a usual practice to ignore any structural information underlying
classes in multi-class classification. In this paper, we propose a graph
convolutional network (GCN) augmented neural network classifier to exploit a
known, underlying graph structure of labels. The proposed approach resembles an
(approximate) inference procedure in, for instance, a conditional random field
(CRF). We evaluate the proposed approach on document classification and object
recognition and report both accuracies and graph-theoretic metrics that
correspond to the consistency of the model's prediction. The experiment results
reveal that the proposed model outperforms a baseline method which ignores the
graph structures of a label space in terms of graph-theoretic metrics.","['Meihao Chen', 'Zhuoru Lin', 'Kyunghyun Cho']","['cs.LG', 'stat.ML']",2017-10-12 02:39:18+00:00
http://arxiv.org/abs/1710.04340v2,Learning Koopman Invariant Subspaces for Dynamic Mode Decomposition,"Spectral decomposition of the Koopman operator is attracting attention as a
tool for the analysis of nonlinear dynamical systems. Dynamic mode
decomposition is a popular numerical algorithm for Koopman spectral analysis;
however, we often need to prepare nonlinear observables manually according to
the underlying dynamics, which is not always possible since we may not have any
a priori knowledge about them. In this paper, we propose a fully data-driven
method for Koopman spectral analysis based on the principle of learning Koopman
invariant subspaces from observed data. To this end, we propose minimization of
the residual sum of squares of linear least-squares regression to estimate a
set of functions that transforms data into a form in which the linear
regression fits well. We introduce an implementation with neural networks and
evaluate performance empirically using nonlinear dynamical systems and
applications.","['Naoya Takeishi', 'Yoshinobu Kawahara', 'Takehisa Yairi']","['cs.LG', 'math.DS', 'stat.ML']",2017-10-12 01:37:46+00:00
http://arxiv.org/abs/1710.04329v1,Efficient Data-Driven Geologic Feature Detection from Pre-stack Seismic Measurements using Randomized Machine-Learning Algorithm,"Conventional seismic techniques for detecting the subsurface geologic
features are challenged by limited data coverage, computational inefficiency,
and subjective human factors. We developed a novel data-driven geological
feature detection approach based on pre-stack seismic measurements. Our
detection method employs an efficient and accurate machine-learning detection
approach to extract useful subsurface geologic features automatically.
Specifically, our method is based on kernel ridge regression model. The
conventional kernel ridge regression can be computationally prohibited because
of the large volume of seismic measurements. We employ a data reduction
technique in combination with the conventional kernel ridge regression method
to improve the computational efficiency and reduce memory usage. In particular,
we utilize a randomized numerical linear algebra technique, named Nystr\""om
method, to effectively reduce the dimensionality of the feature space without
compromising the information content required for accurate detection. We
provide thorough computational cost analysis to show efficiency of our new
geological feature detection methods. We further validate the performance of
our new subsurface geologic feature detection method using synthetic surface
seismic data for 2D acoustic and elastic velocity models. Our numerical
examples demonstrate that our new detection method significantly improves the
computational efficiency while maintaining comparable accuracy. Interestingly,
we show that our method yields a speed-up ratio on the order of $\sim10^2$ to
$\sim 10^3$ in a multi-core computational environment.","['Youzuo Lin', 'Shusen Wang', 'Jayaraman Thiagarajan', 'George Guthrie', 'David Coblentz']","['cs.LG', 'stat.ML']",2017-10-11 23:04:49+00:00
http://arxiv.org/abs/1710.04328v1,What Would a Graph Look Like in This Layout? A Machine Learning Approach to Large Graph Visualization,"Using different methods for laying out a graph can lead to very different
visual appearances, with which the viewer perceives different information.
Selecting a ""good"" layout method is thus important for visualizing a graph. The
selection can be highly subjective and dependent on the given task. A common
approach to selecting a good layout is to use aesthetic criteria and visual
inspection. However, fully calculating various layouts and their associated
aesthetic metrics is computationally expensive. In this paper, we present a
machine learning approach to large graph visualization based on computing the
topological similarity of graphs using graph kernels. For a given graph, our
approach can show what the graph would look like in different layouts and
estimate their corresponding aesthetic metrics. An important contribution of
our work is the development of a new framework to design graph kernels. Our
experimental study shows that our estimation calculation is considerably faster
than computing the actual layouts and their aesthetic metrics. Also, our graph
kernels outperform the state-of-the-art ones in both time and accuracy. In
addition, we conducted a user study to demonstrate that the topological
similarity computed with our graph kernel matches perceptual similarity
assessed by human users.","['Oh-Hyun Kwon', 'Tarik Crnovrsanin', 'Kwan-Liu Ma']","['cs.SI', 'cs.CG', 'cs.GR', 'stat.ML']",2017-10-11 23:00:14+00:00
http://arxiv.org/abs/1710.04325v1,Improved Coresets for Kernel Density Estimates,"We study the construction of coresets for kernel density estimates. That is
we show how to approximate the kernel density estimate described by a large
point set with another kernel density estimate with a much smaller point set.
For characteristic kernels (including Gaussian and Laplace kernels), our
approximation preserves the $L_\infty$ error between kernel density estimates
within error $\epsilon$, with coreset size $2/\epsilon^2$, but no other aspects
of the data, including the dimension, the diameter of the point set, or the
bandwidth of the kernel common to other approximations. When the dimension is
unrestricted, we show this bound is tight for these kernels as well as a much
broader set.
  This work provides a careful analysis of the iterative Frank-Wolfe algorithm
adapted to this context, an algorithm called \emph{kernel herding}. This
analysis unites a broad line of work that spans statistics, machine learning,
and geometry.
  When the dimension $d$ is constant, we demonstrate much tighter bounds on the
size of the coreset specifically for Gaussian kernels, showing that it is
bounded by the size of the coreset for axis-aligned rectangles. Currently the
best known constructive bound is $O(\frac{1}{\epsilon} \log^d
\frac{1}{\epsilon})$, and non-constructively, this can be improved by
$\sqrt{\log \frac{1}{\epsilon}}$. This improves the best constant dimension
bounds polynomially for $d \geq 3$.","['Jeff M. Phillips', 'Wai Ming Tai']","['cs.LG', 'cs.CG', 'stat.ML']",2017-10-11 22:35:29+00:00
http://arxiv.org/abs/1710.04273v4,Stochastic Gradient Descent in Continuous Time: A Central Limit Theorem,"Stochastic gradient descent in continuous time (SGDCT) provides a
computationally efficient method for the statistical learning of
continuous-time models, which are widely used in science, engineering, and
finance. The SGDCT algorithm follows a (noisy) descent direction along a
continuous stream of data. The parameter updates occur in continuous time and
satisfy a stochastic differential equation. This paper analyzes the asymptotic
convergence rate of the SGDCT algorithm by proving a central limit theorem
(CLT) for strongly convex objective functions and, under slightly stronger
conditions, for non-convex objective functions as well. An $L^{p}$ convergence
rate is also proven for the algorithm in the strongly convex case. The
mathematical analysis lies at the intersection of stochastic analysis and
statistical learning.","['Justin Sirignano', 'Konstantinos Spiliopoulos']","['math.PR', 'math.ST', 'q-fin.CP', 'stat.ML', 'stat.TH']",2017-10-11 19:41:36+00:00
http://arxiv.org/abs/1710.04248v1,Local Convergence of Proximal Splitting Methods for Rank Constrained Problems,"We analyze the local convergence of proximal splitting algorithms to solve
optimization problems that are convex besides a rank constraint. For this, we
show conditions under which the proximal operator of a function involving the
rank constraint is locally identical to the proximal operator of its convex
envelope, hence implying local convergence. The conditions imply that the
non-convex algorithms locally converge to a solution whenever a convex
relaxation involving the convex envelope can be expected to solve the
non-convex problem.","['Christian Grussler', 'Pontus Giselsson']","['math.OC', 'cs.LG', 'stat.ML', '90C26, 90C30, 90C59, 90C06']",2017-10-11 18:35:21+00:00
http://arxiv.org/abs/1710.04234v2,Maximum Margin Interval Trees,"Learning a regression function using censored or interval-valued output data
is an important problem in fields such as genomics and medicine. The goal is to
learn a real-valued prediction function, and the training output labels
indicate an interval of possible values. Whereas most existing algorithms for
this task are linear models, in this paper we investigate learning nonlinear
tree models. We propose to learn a tree by minimizing a margin-based
discriminative objective function, and we provide a dynamic programming
algorithm for computing the optimal solution in log-linear time. We show
empirically that this algorithm achieves state-of-the-art speed and prediction
accuracy in a benchmark of several data sets.","['Alexandre Drouin', 'Toby Dylan Hocking', 'François Laviolette']","['stat.ML', 'cs.DS', 'cs.LG', 'stat.AP']",2017-10-11 18:02:38+00:00
http://arxiv.org/abs/1710.04177v2,The Social Bow Tie,"Understanding tie strength in social networks, and the factors that influence
it, have received much attention in a myriad of disciplines for decades.
Several models incorporating indicators of tie strength have been proposed and
used to quantify relationships in social networks, and a standard set of
structural network metrics have been applied to predominantly online social
media sites to predict tie strength. Here, we introduce the concept of the
""social bow tie"" framework, a small subgraph of the network that consists of a
collection of nodes and ties that surround a tie of interest, forming a
topological structure that resembles a bow tie. We also define several
intuitive and interpretable metrics that quantify properties of the bow tie. We
use random forests and regression models to predict categorical and continuous
measures of tie strength from different properties of the bow tie, including
nodal attributes. We also investigate what aspects of the bow tie are most
predictive of tie strength in two distinct social networks: a collection of 75
rural villages in India and a nationwide call network of European mobile phone
users. Our results indicate several of the bow tie metrics are highly
predictive of tie strength, and we find the more the social circles of two
individuals overlap, the stronger their tie, consistent with previous findings.
However, we also find that the more tightly-knit their non-overlapping social
circles, the weaker the tie. This new finding complements our current
understanding of what drives the strength of ties in social networks.","['Heather Mattie', 'Kenth Engø-Monsen', 'Rich Ling', 'Jukka-Pekka Onnela']","['cs.SI', 'physics.soc-ph', 'stat.ML']",2017-10-11 17:12:05+00:00
http://arxiv.org/abs/1710.04170v1,Concentration of Multilinear Functions of the Ising Model with Applications to Network Data,"We prove near-tight concentration of measure for polynomial functions of the
Ising model under high temperature. For any degree $d$, we show that a
degree-$d$ polynomial of a $n$-spin Ising model exhibits exponential tails that
scale as $\exp(-r^{2/d})$ at radius $r=\tilde{\Omega}_d(n^{d/2})$. Our
concentration radius is optimal up to logarithmic factors for constant $d$,
improving known results by polynomial factors in the number of spins. We
demonstrate the efficacy of polynomial functions as statistics for testing the
strength of interactions in social networks in both synthetic and real world
data.","['Constantinos Daskalakis', 'Nishanth Dikkala', 'Gautam Kamath']","['math.PR', 'cs.LG', 'math-ph', 'math.MP', 'math.ST', 'stat.ML', 'stat.TH']",2017-10-11 16:55:14+00:00
http://arxiv.org/abs/1710.04099v1,Wembedder: Wikidata entity embedding web service,"I present a web service for querying an embedding of entities in the Wikidata
knowledge graph. The embedding is trained on the Wikidata dump using Gensim's
Word2Vec implementation and a simple graph walk. A REST API is implemented.
Together with the Wikidata API the web service exposes a multilingual resource
for over 600'000 Wikidata items and properties.",['Finn Årup Nielsen'],"['stat.ML', 'cs.CL', 'cs.LG', 'I.2.4; H.3.5']",2017-10-11 14:56:27+00:00
