id,title,abstract,authors,categories,date
http://arxiv.org/abs/1907.04450v1,SNAP: Finding Approximate Second-Order Stationary Solutions Efficiently for Non-convex Linearly Constrained Problems,"This paper proposes low-complexity algorithms for finding approximate
second-order stationary points (SOSPs) of problems with smooth non-convex
objective and linear constraints. While finding (approximate) SOSPs is
computationally intractable, we first show that generic instances of the
problem can be solved efficiently. More specifically, for a generic problem
instance, certain strict complementarity (SC) condition holds for all
Karush-Kuhn-Tucker (KKT) solutions (with probability one). The SC condition is
then used to establish an equivalence relationship between two different
notions of SOSPs, one of which is computationally easy to verify. Based on this
particular notion of SOSP, we design an algorithm named the Successive
Negative-curvature grAdient Projection (SNAP), which successively performs
either conventional gradient projection or some negative curvature based
projection steps to find SOSPs. SNAP and its first-order extension SNAP$^+$,
require $\mathcal{O}(1/\epsilon^{2.5})$ iterations to compute an $(\epsilon,
\sqrt{\epsilon})$-SOSP, and their per-iteration computational complexities are
polynomial in the number of constraints and problem dimension. To our
knowledge, this is the first time that first-order algorithms with polynomial
per-iteration complexity and global sublinear rate have been designed to find
SOSPs of the important class of non-convex problems with linear constraints.","['Songtao Lu', 'Meisam Razaviyayn', 'Bo Yang', 'Kejun Huang', 'Mingyi Hong']","['math.OC', 'cs.CC', 'stat.ML']",2019-07-09 22:46:41+00:00
http://arxiv.org/abs/1907.04433v2,GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing,"We present GluonCV and GluonNLP, the deep learning toolkits for computer
vision and natural language processing based on Apache MXNet (incubating).
These toolkits provide state-of-the-art pre-trained models, training scripts,
and training logs, to facilitate rapid prototyping and promote reproducible
research. We also provide modular APIs with flexible building blocks to enable
efficient customization. Leveraging the MXNet ecosystem, the deep learning
models in GluonCV and GluonNLP can be deployed onto a variety of platforms with
different programming languages. The Apache 2.0 license has been adopted by
GluonCV and GluonNLP to allow for software distribution, modification, and
usage.","['Jian Guo', 'He He', 'Tong He', 'Leonard Lausen', 'Mu Li', 'Haibin Lin', 'Xingjian Shi', 'Chenguang Wang', 'Junyuan Xie', 'Sheng Zha', 'Aston Zhang', 'Hang Zhang', 'Zhi Zhang', 'Zhongyue Zhang', 'Shuai Zheng', 'Yi Zhu']","['cs.LG', 'cs.CL', 'cs.CV', 'stat.ML']",2019-07-09 21:59:44+00:00
http://arxiv.org/abs/1907.05358v1,"StrokeSave: A Novel, High-Performance Mobile Application for Stroke Diagnosis using Deep Learning and Computer Vision","According to the WHO, Cerebrovascular Stroke, or CS, is the second largest
cause of death worldwide. Current diagnosis of CS relies on labor and cost
intensive neuroimaging techniques, unsuitable for areas with inadequate access
to quality medical facilities. Thus, there is a great need for an efficient
diagnosis alternative. StrokeSave is a platform for users to self-diagnose for
prevalence to stroke. The mobile app is continuously updated with heart rate,
blood pressure, and blood oxygen data from sensors on the patient wrist. Once
these measurements reach a threshold for possible stroke, the patient takes
facial images and vocal recordings to screen for paralysis attributed to
stroke. A custom designed lens attached to a phone's camera then takes retinal
images for the deep learning model to classify based on presence of retinopathy
and sends a comprehensive diagnosis. The deep learning model, which consists of
a RNN trained on 100 voice slurred audio files, a SVM trained on 410 vascular
data points, and a CNN trained on 520 retinopathy images, achieved a holistic
accuracy of 95.0 percent when validated on 327 samples. This value exceeds that
of clinical examination accuracy, which is around 40 to 89 percent, further
demonstrating the vital utility of such a medical device. Through this
automated platform, users receive efficient, highly accurate diagnosis without
professional medical assistance, revolutionizing medical diagnosis of CS and
potentially saving millions of lives.",['Ankit Gupta'],"['cs.CV', 'cs.LG', 'eess.IV', 'stat.ML']",2019-07-09 21:01:58+00:00
http://arxiv.org/abs/1907.04409v2,Global Optimality Guarantees for Nonconvex Unsupervised Video Segmentation,"In this paper, we consider the problem of unsupervised video object
segmentation via background subtraction. Specifically, we pose the nonsemantic
extraction of a video's moving objects as a nonconvex optimization problem via
a sum of sparse and low-rank matrices. The resulting formulation, a nonnegative
variant of robust principal component analysis, is more computationally
tractable than its commonly employed convex relaxation, although not generally
solvable to global optimality. In spite of this limitation, we derive intuitive
and interpretable conditions on the video data under which the uniqueness and
global optimality of the object segmentation are guaranteed using local search
methods. We illustrate these novel optimality criteria through example
segmentations using real video data.","['Brendon G. Anderson', 'Somayeh Sojoudi']","['cs.LG', 'cs.CV', 'math.OC', 'stat.ML']",2019-07-09 20:53:13+00:00
http://arxiv.org/abs/1907.04377v2,Convergence Rates for Gaussian Mixtures of Experts,"We provide a theoretical treatment of over-specified Gaussian mixtures of
experts with covariate-free gating networks. We establish the convergence rates
of the maximum likelihood estimation (MLE) for these models. Our proof
technique is based on a novel notion of \emph{algebraic independence} of the
expert functions. Drawing on optimal transport theory, we establish a
connection between the algebraic independence and a certain class of partial
differential equations (PDEs). Exploiting this connection allows us to derive
convergence rates and minimax lower bounds for parameter estimation.","['Nhat Ho', 'Chiao-Yu Yang', 'Michael I. Jordan']","['math.ST', 'cs.LG', 'stat.ML', 'stat.TH']",2019-07-09 19:31:37+00:00
http://arxiv.org/abs/1907.04371v5,Ordered SGD: A New Stochastic Optimization Framework for Empirical Risk Minimization,"We propose a new stochastic optimization framework for empirical risk
minimization problems such as those that arise in machine learning. The
traditional approaches, such as (mini-batch) stochastic gradient descent (SGD),
utilize an unbiased gradient estimator of the empirical average loss. In
contrast, we develop a computationally efficient method to construct a gradient
estimator that is purposely biased toward those observations with higher
current losses. On the theory side, we show that the proposed method minimizes
a new ordered modification of the empirical average loss, and is guaranteed to
converge at a sublinear rate to a global optimum for convex loss and to a
critical point for weakly convex (non-convex) loss. Furthermore, we prove a new
generalization bound for the proposed algorithm. On the empirical side, the
numerical experiments show that our proposed method consistently improves the
test errors compared with the standard mini-batch SGD in various models
including SVM, logistic regression, and deep learning problems.","['Kenji Kawaguchi', 'Haihao Lu']","['stat.ML', 'cs.LG', 'math.OC']",2019-07-09 19:09:51+00:00
http://arxiv.org/abs/1907.04358v1,Making Study Populations Visible through Knowledge Graphs,"Treatment recommendations within Clinical Practice Guidelines (CPGs) are
largely based on findings from clinical trials and case studies, referred to
here as research studies, that are often based on highly selective clinical
populations, referred to here as study cohorts. When medical practitioners
apply CPG recommendations, they need to understand how well their patient
population matches the characteristics of those in the study cohort, and thus
are confronted with the challenges of locating the study cohort information and
making an analytic comparison. To address these challenges, we develop an
ontology-enabled prototype system, which exposes the population descriptions in
research studies in a declarative manner, with the ultimate goal of allowing
medical practitioners to better understand the applicability and
generalizability of treatment recommendations. We build a Study Cohort Ontology
(SCO) to encode the vocabulary of study population descriptions, that are often
reported in the first table in the published work, thus they are often referred
to as Table 1. We leverage the well-used Semanticscience Integrated Ontology
(SIO) for defining property associations between classes. Further, we model the
key components of Table 1s, i.e., collections of study subjects, subject
characteristics, and statistical measures in RDF knowledge graphs. We design
scenarios for medical practitioners to perform population analysis, and
generate cohort similarity visualizations to determine the applicability of a
study population to the clinical population of interest. Our semantic approach
to make study populations visible, by standardized representations of Table 1s,
allows users to quickly derive clinically relevant inferences about study
populations.","['Shruthi Chari', 'Miao Qi', 'Nkcheniyere N. Agu', 'Oshani Seneviratne', 'James P. McCusker', 'Kristin P. Bennett', 'Amar K. Das', 'Deborah L. McGuinness']","['cs.LO', 'q-bio.PE', 'stat.ML']",2019-07-09 18:27:55+00:00
http://arxiv.org/abs/1907.04275v3,Learning to Optimize Domain Specific Normalization for Domain Generalization,"We propose a simple but effective multi-source domain generalization
technique based on deep neural networks by incorporating optimized
normalization layers that are specific to individual domains. Our approach
employs multiple normalization methods while learning separate affine
parameters per domain. For each domain, the activations are normalized by a
weighted average of multiple normalization statistics. The normalization
statistics are kept track of separately for each normalization type if
necessary. Specifically, we employ batch and instance normalizations in our
implementation to identify the best combination of these two normalization
methods in each domain. The optimized normalization layers are effective to
enhance the generalizability of the learned model. We demonstrate the
state-of-the-art accuracy of our algorithm in the standard domain
generalization benchmarks, as well as viability to further tasks such as
multi-source domain adaptation and domain generalization in the presence of
label noise.","['Seonguk Seo', 'Yumin Suh', 'Dongwan Kim', 'Geeho Kim', 'Jongwoo Han', 'Bohyung Han']","['cs.LG', 'stat.ML']",2019-07-09 16:24:31+00:00
http://arxiv.org/abs/1907.05231v1,Variance-Based Risk Estimations in Markov Processes via Transformation with State Lumping,"Variance plays a crucial role in risk-sensitive reinforcement learning, and
most risk measures can be analyzed via variance. In this paper, we consider two
law-invariant risks as examples: mean-variance risk and exponential utility
risk. With the aid of the state-augmentation transformation (SAT), we show
that, the two risks can be estimated in Markov decision processes (MDPs) with a
stochastic transition-based reward and a randomized policy. To relieve the
enlarged state space, a novel definition of isotopic states is proposed for
state lumping, considering the special structure of the transformed transition
probability. In the numerical experiment, we illustrate state lumping in the
SAT, errors from a naive reward simplification, and the validity of the SAT for
the two risk estimations.","['Shuai Ma', 'Jia Yuan Yu']","['cs.LG', 'cs.AI', 'stat.ML']",2019-07-09 16:04:33+00:00
http://arxiv.org/abs/1907.04233v1,Contextual One-Class Classification in Data Streams,"In machine learning, the one-class classification problem occurs when
training instances are only available from one class. It has been observed that
making use of this class's structure, or its different contexts, may improve
one-class classifier performance. Although this observation has been
demonstrated for static data, a rigorous application of the idea within the
data stream environment is lacking. To address this gap, we propose the use of
context to guide one-class classifier learning in data streams, paying
particular attention to the challenges presented by the dynamic learning
environment. We present three frameworks that learn contexts and conduct
experiments with synthetic and benchmark data streams. We conclude that the
paradigm of contexts in data streams can be used to improve the performance of
streaming one-class classifiers.","['Richard Hugh Moulton', 'Herna L. Viktor', 'Nathalie Japkowicz', 'João Gama']","['cs.LG', 'stat.ML']",2019-07-09 15:14:38+00:00
http://arxiv.org/abs/1907.04232v2,Unified Optimal Analysis of the (Stochastic) Gradient Method,"In this note we give a simple proof for the convergence of stochastic
gradient (SGD) methods on $\mu$-convex functions under a (milder than standard)
$L$-smoothness assumption. We show that for carefully chosen stepsizes SGD
converges after $T$ iterations as $O\left( LR^2 \exp
\bigl[-\frac{\mu}{4L}T\bigr] + \frac{\sigma^2}{\mu T} \right)$ where $\sigma^2$
measures the variance in the stochastic noise. For deterministic gradient
descent (GD) and SGD in the interpolation setting we have $\sigma^2 =0$ and we
recover the exponential convergence rate. The bound matches with the best known
iteration complexity of GD and SGD, up to constants.",['Sebastian U. Stich'],"['cs.LG', 'cs.NA', 'math.NA', 'math.OC', 'stat.ML']",2019-07-09 15:14:25+00:00
http://arxiv.org/abs/1907.04670v4,Improving the Performance of the LSTM and HMM Model via Hybridization,"Language models based on deep neural networks and traditional stochastic
modelling have become both highly functional and effective in recent times. In
this work, a general survey into the two types of language modelling is
conducted. We investigate the effectiveness of the Hidden Markov Model (HMM),
and the Long Short-Term Memory Model (LSTM). We analyze the hidden state
structures common to both models, and present an analysis on structural
similarity of the hidden states, common to both HMM's and LSTM's. We compare
the LSTM's predictive accuracy and hidden state output with respect to the HMM
for a varying number of hidden states. In this work, we justify that the less
complex HMM can serve as an appropriate approximation of the LSTM model.","['Larkin Liu', 'Yu-Chung Lin', 'Joshua Reid']","['cs.LG', 'cs.CL', 'stat.CO', 'stat.ML']",2019-07-09 15:12:51+00:00
http://arxiv.org/abs/1907.04223v2,Characterizing Inter-Layer Functional Mappings of Deep Learning Models,"Deep learning architectures have demonstrated state-of-the-art performance
for object classification and have become ubiquitous in commercial products.
These methods are often applied without understanding (a) the difficulty of a
classification task given the input data, and (b) how a specific deep learning
architecture transforms that data. To answer (a) and (b), we illustrate the
utility of a multivariate nonparametric estimator of class separation, the
Henze-Penrose (HP) statistic, in the original as well as layer-induced
representations. Given an $N$-class problem, our contribution defines the
$C(N,2)$ combinations of HP statistics as a sample from a distribution of
class-pair separations. This allows us to characterize the distributional
change to class separation induced at each layer of the model. Fisher
permutation tests are used to detect statistically significant changes within a
model. By comparing the HP statistic distributions between layers, one can
statistically characterize: layer adaptation during training, the contribution
of each layer to the classification task, and the presence or absence of
consistency between training and validation data. This is demonstrated for a
simple deep neural network using CIFAR10 with random-labels, CIFAR10, and MNIST
datasets.","['Donald Waagen', 'Katie Rainey', 'Jamie Gantert', 'David Gray', 'Megan King', 'M. Shane Thompson', 'Jonathan Barton', 'Will Waldron', 'Samantha Livingston', 'Don Hulsey']","['stat.ML', 'cs.LG']",2019-07-09 14:58:59+00:00
http://arxiv.org/abs/1907.05269v1,Influence of Pointing on Learning to Count: A Neuro-Robotics Model,"In this paper a neuro-robotics model capable of counting using gestures is
introduced. The contribution of gestures to learning to count is tested with
various model and training conditions. Two studies were presented in this
article. In the first, we combine different modalities of the robot's neural
network, in the second, a novel training procedure for it is proposed. The
model is trained with pointing data from an iCub robot simulator. The behaviour
of the model is in line with that of human children in terms of performance
change depending on gesture production.","['Leszek Pecyna', 'Angelo Cangelosi']","['cs.CV', 'cs.LG', 'cs.RO', 'stat.ML']",2019-07-09 13:59:36+00:00
http://arxiv.org/abs/1907.04164v2,Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a Noisy Quadratic Model,"Increasing the batch size is a popular way to speed up neural network
training, but beyond some critical batch size, larger batch sizes yield
diminishing returns. In this work, we study how the critical batch size changes
based on properties of the optimization algorithm, including acceleration and
preconditioning, through two different lenses: large scale experiments, and
analysis of a simple noisy quadratic model (NQM). We experimentally demonstrate
that optimization algorithms that employ preconditioning, specifically Adam and
K-FAC, result in much larger critical batch sizes than stochastic gradient
descent with momentum. We also demonstrate that the NQM captures many of the
essential features of real neural network training, despite being drastically
simpler to work with. The NQM predicts our results with preconditioned
optimizers, previous results with accelerated gradient descent, and other
results around optimal learning rates and large batch training, making it a
useful tool to generate testable predictions about neural network optimization.","['Guodong Zhang', 'Lala Li', 'Zachary Nado', 'James Martens', 'Sushant Sachdeva', 'George E. Dahl', 'Christopher J. Shallue', 'Roger Grosse']","['cs.LG', 'stat.ML']",2019-07-09 13:44:10+00:00
http://arxiv.org/abs/1907.04155v5,GP-VAE: Deep Probabilistic Time Series Imputation,"Multivariate time series with missing values are common in areas such as
healthcare and finance, and have grown in number and complexity over the years.
This raises the question whether deep learning methodologies can outperform
classical data imputation methods in this domain. However, naive applications
of deep learning fall short in giving reliable confidence estimates and lack
interpretability. We propose a new deep sequential latent variable model for
dimensionality reduction and data imputation. Our modeling assumption is simple
and interpretable: the high dimensional time series has a lower-dimensional
representation which evolves smoothly in time according to a Gaussian process.
The non-linear dimensionality reduction in the presence of missing data is
achieved using a VAE approach with a novel structured variational
approximation. We demonstrate that our approach outperforms several classical
and deep learning-based data imputation methods on high-dimensional data from
the domains of computer vision and healthcare, while additionally improving the
smoothness of the imputations and providing interpretable uncertainty
estimates.","['Vincent Fortuin', 'Dmitry Baranchuk', 'Gunnar Rätsch', 'Stephan Mandt']","['stat.ML', 'cs.LG']",2019-07-09 13:34:49+00:00
http://arxiv.org/abs/1907.04150v1,Nonnegative Matrix Factorization with Local Similarity Learning,"Existing nonnegative matrix factorization methods focus on learning global
structure of the data to construct basis and coefficient matrices, which
ignores the local structure that commonly exists among data. In this paper, we
propose a new type of nonnegative matrix factorization method, which learns
local similarity and clustering in a mutually enhancing way. The learned new
representation is more representative in that it better reveals inherent
geometric property of the data. Nonlinear expansion is given and efficient
multiplicative updates are developed with theoretical convergence guarantees.
Extensive experimental results have confirmed the effectiveness of the proposed
model.","['Chong Peng', 'Zhao Kang', 'Chenglizhao Chen', 'Qiang Cheng']","['cs.LG', 'cs.CV', 'stat.ML']",2019-07-09 13:25:50+00:00
http://arxiv.org/abs/1907.04138v3,Characterization of Overlap in Observational Studies,"Overlap between treatment groups is required for non-parametric estimation of
causal effects. If a subgroup of subjects always receives the same
intervention, we cannot estimate the effect of intervention changes on that
subgroup without further assumptions. When overlap does not hold globally,
characterizing local regions of overlap can inform the relevance of causal
conclusions for new subjects, and can help guide additional data collection. To
have impact, these descriptions must be interpretable for downstream users who
are not machine learning experts, such as policy makers. We formalize overlap
estimation as a problem of finding minimum volume sets subject to coverage
constraints and reduce this problem to binary classification with Boolean rule
classifiers. We then generalize this method to estimate overlap in off-policy
policy evaluation. In several real-world applications, we demonstrate that
these rules have comparable accuracy to black-box estimators and provide
intuitive and informative explanations that can inform policy making.","['Michael Oberst', 'Fredrik D. Johansson', 'Dennis Wei', 'Tian Gao', 'Gabriel Brat', 'David Sontag', 'Kush R. Varshney']","['cs.LG', 'stat.ML']",2019-07-09 13:18:47+00:00
http://arxiv.org/abs/1907.04135v2,The What-If Tool: Interactive Probing of Machine Learning Models,"A key challenge in developing and deploying Machine Learning (ML) systems is
understanding their performance across a wide range of inputs. To address this
challenge, we created the What-If Tool, an open-source application that allows
practitioners to probe, visualize, and analyze ML systems, with minimal coding.
The What-If Tool lets practitioners test performance in hypothetical
situations, analyze the importance of different data features, and visualize
model behavior across multiple models and subsets of input data. It also lets
practitioners measure systems according to multiple ML fairness metrics. We
describe the design of the tool, and report on real-life usage at different
organizations.","['James Wexler', 'Mahima Pushkarna', 'Tolga Bolukbasi', 'Martin Wattenberg', 'Fernanda Viegas', 'Jimbo Wilson']","['cs.LG', 'stat.ML', 'H.5.2']",2019-07-09 13:16:24+00:00
http://arxiv.org/abs/1907.05270v2,A Deep Neural Network for Finger Counting and Numerosity Estimation,"In this paper, we present neuro-robotics models with a deep artificial neural
network capable of generating finger counting positions and number estimation.
We first train the model in an unsupervised manner where each layer is treated
as a Restricted Boltzmann Machine or an autoencoder. Such a model is further
trained in a supervised way. This type of pre-training is tested on our
baseline model and two methods of pre-training are compared. The network is
extended to produce finger counting positions. The performance in number
estimation of such an extended model is evaluated. We test the hypothesis if
the subitizing process can be obtained by one single model used also for
estimation of higher numerosities. The results confirm the importance of
unsupervised training in our enumeration task and show some similarities to
human behaviour in the case of subitizing.","['Leszek Pecyna', 'Angelo Cangelosi', 'Alessandro Di Nuovo']","['cs.CV', 'cs.LG', 'cs.RO', 'stat.ML']",2019-07-09 13:10:28+00:00
http://arxiv.org/abs/1907.05336v1,Adaptive Margin Ranking Loss for Knowledge Graph Embeddings via a Correntropy Objective Function,"Translation-based embedding models have gained significant attention in link
prediction tasks for knowledge graphs. TransE is the primary model among
translation-based embeddings and is well-known for its low complexity and high
efficiency. Therefore, most of the earlier works have modified the score
function of the TransE approach in order to improve the performance of link
prediction tasks. Nevertheless, proven theoretically and experimentally, the
performance of TransE strongly depends on the loss function. Margin Ranking
Loss (MRL) has been one of the earlier loss functions which is widely used for
training TransE. However, the scores of positive triples are not necessarily
enforced to be sufficiently small to fulfill the translation from head to tail
by using relation vector (original assumption of TransE). To tackle this
problem, several loss functions have been proposed recently by adding upper
bounds and lower bounds to the scores of positive and negative samples.
Although highly effective, previously developed models suffer from an expansion
in search space for a selection of the hyperparameters (in particular the upper
and lower bounds of scores) on which the performance of the translation-based
models is highly dependent. In this paper, we propose a new loss function
dubbed Adaptive Margin Loss (AML) for training translation-based embedding
models. The formulation of the proposed loss function enables an adaptive and
automated adjustment of the margin during the learning process. Therefore,
instead of obtaining two values (upper bound and lower bound), only the center
of a margin needs to be determined. During learning, the margin is expanded
automatically until it converges. In our experiments on a set of standard
benchmark datasets including Freebase and WordNet, the effectiveness of AML is
confirmed for training TransE on link prediction tasks.","['Mojtaba Nayyeri', 'Xiaotian Zhou', 'Sahar Vahdati', 'Hamed Shariat Yazdi', 'Jens Lehmann']","['cs.CL', 'cs.AI', 'cs.LG', 'stat.ML']",2019-07-09 12:32:40+00:00
http://arxiv.org/abs/1907.04108v3,Scaling Limit of Neural Networks with the Xavier Initialization and Convergence to a Global Minimum,"We analyze single-layer neural networks with the Xavier initialization in the
asymptotic regime of large numbers of hidden units and large numbers of
stochastic gradient descent training steps. The evolution of the neural network
during training can be viewed as a stochastic system and, using techniques from
stochastic analysis, we prove the neural network converges in distribution to a
random ODE with a Gaussian distribution. The limit is completely different than
in the typical mean-field results for neural networks due to the
$\frac{1}{\sqrt{N}}$ normalization factor in the Xavier initialization (versus
the $\frac{1}{N}$ factor in the typical mean-field framework). Although the
pre-limit problem of optimizing a neural network is non-convex (and therefore
the neural network may converge to a local minimum), the limit equation
minimizes a (quadratic) convex objective function and therefore converges to a
global minimum. Furthermore, under reasonable assumptions, the matrix in the
limiting quadratic objective function is positive definite and thus the neural
network (in the limit) will converge to a global minimum with zero loss on the
training set.","['Justin Sirignano', 'Konstantinos Spiliopoulos']","['math.PR', 'cs.LG', 'stat.ML']",2019-07-09 12:17:03+00:00
http://arxiv.org/abs/1907.04102v1,Quantifying Confounding Bias in Neuroimaging Datasets with Causal Inference,"Neuroimaging datasets keep growing in size to address increasingly complex
medical questions. However, even the largest datasets today alone are too small
for training complex machine learning models. A potential solution is to
increase sample size by pooling scans from several datasets. In this work, we
combine 12,207 MRI scans from 15 studies and show that simple pooling is often
ill-advised due to introducing various types of biases in the training data.
First, we systematically define these biases. Second, we detect bias by
experimentally showing that scans can be correctly assigned to their respective
dataset with 73.3% accuracy. Finally, we propose to tell causal from
confounding factors by quantifying the extent of confounding and causality in a
single dataset using causal inference. We achieve this by finding the simplest
graphical model in terms of Kolmogorov complexity. As Kolmogorov complexity is
not directly computable, we employ the minimum description length to
approximate it. We empirically show that our approach is able to estimate
plausible causal relationships from real neuroimaging data.","['Christian Wachinger', 'Benjamin Gutierrez Becker', 'Anna Rieckmann', 'Sebastian Pölsterl']","['cs.LG', 'cs.CV', 'eess.IV', 'stat.ML']",2019-07-09 11:57:22+00:00
http://arxiv.org/abs/1907.04092v1,Tensor p-shrinkage nuclear norm for low-rank tensor completion,"In this paper, a new definition of tensor p-shrinkage nuclear norm (p-TNN) is
proposed based on tensor singular value decomposition (t-SVD). In particular,
it can be proved that p-TNN is a better approximation of the tensor average
rank than the tensor nuclear norm when p < 1. Therefore, by employing the
p-shrinkage nuclear norm, a novel low-rank tensor completion (LRTC) model is
proposed to estimate a tensor from its partial observations. Statistically, the
upper bound of recovery error is provided for the LRTC model. Furthermore, an
efficient algorithm, accelerated by the adaptive momentum scheme, is developed
to solve the resulting nonconvex optimization problem. It can be further
guaranteed that the algorithm enjoys a global convergence rate under the
smoothness assumption. Numerical experiments conducted on both synthetic and
real-world data sets verify our results and demonstrate the superiority of our
p-TNN in LRTC problems over several state-of-the-art methods.","['Chunsheng Liu', 'Hong Shan', 'Chunlei Chen']","['cs.LG', 'stat.ML']",2019-07-09 11:37:15+00:00
http://arxiv.org/abs/1907.04081v4,Kernel Hypothesis Testing with Set-valued Data,"We present a general framework for hypothesis testing on distributions of
sets of individual examples. Sets may represent many common data sources such
as groups of observations in time series, collections of words in text or a
batch of images of a given phenomenon. This observation pattern, however,
differs from the common assumptions required for hypothesis testing: each set
differs in size, may have differing levels of noise, and also may incorporate
nuisance variability, irrelevant for the analysis of the phenomenon of
interest; all features that bias test decisions if not accounted for. In this
paper, we propose to interpret sets as independent samples from a collection of
latent probability distributions, and introduce kernel two-sample and
independence tests in this latent space of distributions. We prove the
consistency of tests and observe them to outperform in a wide range of
synthetic experiments. Finally, we showcase their use in practice with
experiments of healthcare and climate data, where previously heuristics were
needed for feature extraction and testing.","['Alexis Bellot', 'Mihaela van der Schaar']","['stat.ME', 'stat.ML']",2019-07-09 11:17:35+00:00
http://arxiv.org/abs/1907.04068v2,Conditional Independence Testing using Generative Adversarial Networks,"We consider the hypothesis testing problem of detecting conditional
dependence, with a focus on high-dimensional feature spaces. Our contribution
is a new test statistic based on samples from a generative adversarial network
designed to approximate directly a conditional distribution that encodes the
null hypothesis, in a manner that maximizes power (the rate of true negatives).
We show that such an approach requires only that density approximation be
viable in order to ensure that we control type I error (the rate of false
positives); in particular, no assumptions need to be made on the form of the
distributions or feature dependencies. Using synthetic simulations with
high-dimensional data we demonstrate significant gains in power over competing
methods. In addition, we illustrate the use of our test to discover causal
markers of disease in genetic data.","['Alexis Bellot', 'Mihaela van der Schaar']","['stat.ML', 'cs.LG']",2019-07-09 10:24:40+00:00
http://arxiv.org/abs/1907.04050v1,k-GANs: Ensemble of Generative Models with Semi-Discrete Optimal Transport,"Generative adversarial networks (GANs) are the state of the art in generative
modeling. Unfortunately, most GAN methods are susceptible to mode collapse,
meaning that they tend to capture only a subset of the modes of the true
distribution. A possible way of dealing with this problem is to use an ensemble
of GANs, where (ideally) each network models a single mode. In this paper, we
introduce a principled method for training an ensemble of GANs using
semi-discrete optimal transport theory. In our approach, each generative
network models the transportation map between a point mass (Dirac measure) and
the restriction of the data distribution on a tile of a Voronoi tessellation
that is defined by the location of the point masses. We iteratively train the
generative networks and the point masses until convergence. The resulting
k-GANs algorithm has strong theoretical connection with the k-medoids
algorithm. In our experiments, we show that our ensemble method consistently
outperforms baseline GANs.","['Luca Ambrogioni', 'Umut Güçlü', 'Marcel van Gerven']","['stat.ML', 'cs.LG']",2019-07-09 08:57:49+00:00
http://arxiv.org/abs/1907.04028v1,PathRank: A Multi-Task Learning Framework to Rank Paths in Spatial Networks,"Modern navigation services often provide multiple paths connecting the same
source and destination for users to select. Hence, ranking such paths becomes
increasingly important, which directly affects the service quality. We present
PathRank, a data-driven framework for ranking paths based on historical
trajectories using multi-task learning. If a trajectory used path P from source
s to destination d, PathRank considers this as an evidence that P is preferred
over all other paths from s to d. Thus, a path that is similar to P should have
a larger ranking score than a path that is dissimilar to P. Based on this
intuition, PathRank models path ranking as a regression problem, where each
path is associated with a ranking score.
  To enable PathRank, we first propose an effective method to generate a
compact set of training data: for each trajectory, we generate a small set of
diversified paths. Next, we propose a multi-task learning framework to solve
the regression problem. In particular, a spatial network embedding is proposed
to embed each vertex to a feature vector by considering both road network
topology and spatial properties, such as distances and travel times. Since a
path is represented by a sequence of vertices, which is now a sequence of
feature vectors after embedding, recurrent neural network is applied to model
the sequence. The objective function is designed to consider errors on both
ranking scores and spatial properties, making the framework a multi-task
learning framework. Empirical studies on a substantial trajectory data set
offer insight into the designed properties of the proposed framework and
indicating that it is effective and practical.","['Sean Bin Yang', 'Bin Yang']","['cs.LG', 'cs.DB', 'stat.ML']",2019-07-09 07:45:55+00:00
http://arxiv.org/abs/1907.04027v3,Iteratively Reweighted $\ell_1$-Penalized Robust Regression,"This paper investigates tradeoffs among optimization errors, statistical
rates of convergence and the effect of heavy-tailed errors for high-dimensional
robust regression with nonconvex regularization. When the additive errors in
linear models have only bounded second moment, we show that iteratively
reweighted $\ell_1$-penalized adaptive Huber regression estimator satisfies
exponential deviation bounds and oracle properties, including the oracle
convergence rate and variable selection consistency, under a weak beta-min
condition. Computationally, we need as many as $O(\log s + \log\log d)$
iterations to reach such an oracle estimator, where $s$ and $d$ denote the
sparsity and ambient dimension, respectively. Extension to a general class of
robust loss functions is also considered. Numerical studies lend strong support
to our methodology and theory.","['Xiaoou Pan', 'Qiang Sun', 'Wen-Xin Zhou']","['math.ST', 'stat.ML', 'stat.TH']",2019-07-09 07:45:04+00:00
http://arxiv.org/abs/1907.04021v2,SVGD: A Virtual Gradients Descent Method for Stochastic Optimization,"Inspired by dynamic programming, we propose Stochastic Virtual Gradient
Descent (SVGD) algorithm where the Virtual Gradient is defined by computational
graph and automatic differentiation. The method is computationally efficient
and has little memory requirements. We also analyze the theoretical convergence
properties and implementation of the algorithm. Experimental results on
multiple datasets and network models show that SVGD has advantages over other
stochastic optimization methods.","['Zheng Li', 'Shi Shu']","['cs.LG', 'math.OC', 'stat.ML']",2019-07-09 07:28:13+00:00
http://arxiv.org/abs/1907.04018v3,Data-Independent Neural Pruning via Coresets,"Previous work showed empirically that large neural networks can be
significantly reduced in size while preserving their accuracy. Model
compression became a central research topic, as it is crucial for deployment of
neural networks on devices with limited computational and memory resources. The
majority of the compression methods are based on heuristics and offer no
worst-case guarantees on the trade-off between the compression rate and the
approximation error for an arbitrarily new sample. We propose the first
efficient, data-independent neural pruning algorithm with a provable trade-off
between its compression rate and the approximation error for any future test
sample. Our method is based on the coreset framework, which finds a small
weighted subset of points that provably approximates the original inputs.
Specifically, we approximate the output of a layer of neurons by a coreset of
neurons in the previous layer and discard the rest. We apply this framework in
a layer-by-layer fashion from the top to the bottom. Unlike previous works, our
coreset is data independent, meaning that it provably guarantees the accuracy
of the function for any input $x\in \mathbb{R}^d$, including an adversarial
one. We demonstrate the effectiveness of our method on popular network
architectures. In particular, our coresets yield 90\% compression of the
LeNet-300-100 architecture on MNIST while improving the accuracy.","['Ben Mussay', 'Margarita Osadchy', 'Vladimir Braverman', 'Samson Zhou', 'Dan Feldman']","['cs.LG', 'stat.ML']",2019-07-09 07:11:39+00:00
http://arxiv.org/abs/1907.04004v3,Incremental Intervention Effects in Studies with Dropout and Many Timepoints,"Modern longitudinal studies collect feature data at many timepoints, often of
the same order of sample size. Such studies are typically affected by {dropout}
and positivity violations. We tackle these problems by generalizing effects of
recent incremental interventions (which shift propensity scores rather than set
treatment values deterministically) to accommodate multiple outcomes and
subject dropout. We give an identifying expression for incremental intervention
effects when dropout is conditionally ignorable (without requiring treatment
positivity), and derive the nonparametric efficiency bound for estimating such
effects. Then we present efficient nonparametric estimators, showing that they
converge at fast parametric rates and yield uniform inferential guarantees,
even when nuisance functions are estimated flexibly at slower rates. We also
study the variance ratio of incremental intervention effects relative to more
conventional deterministic effects in a novel infinite time horizon setting,
where the number of timepoints can grow with sample size, and show that
incremental intervention effects yield near-exponential gains in statistical
precision in this setup. Finally we conclude with simulations and apply our
methods in a study of the effect of low-dose aspirin on pregnancy outcomes.","['Kwangho Kim', 'Edward H. Kennedy', 'Ashley I. Naimi']","['stat.ME', 'stat.ML', '62G05']",2019-07-09 06:26:41+00:00
http://arxiv.org/abs/1907.04003v1,Mean Spectral Normalization of Deep Neural Networks for Embedded Automation,"Deep Neural Networks (DNNs) have begun to thrive in the field of automation
systems, owing to the recent advancements in standardising various aspects such
as architecture, optimization techniques, and regularization. In this paper, we
take a step towards a better understanding of Spectral Normalization (SN) and
its potential for standardizing regularization of a wider range of Deep
Learning models, following an empirical approach. We conduct several
experiments to study their training dynamics, in comparison with the ubiquitous
Batch Normalization (BN) and show that SN increases the gradient sparsity and
controls the gradient variance. Furthermore, we show that SN suffers from a
phenomenon, we call the mean-drift effect, which mitigates its performance. We,
then, propose a weight reparameterization called as the Mean Spectral
Normalization (MSN) to resolve the mean drift, thereby significantly improving
the network's performance. Our model performs ~16% faster as compared to BN in
practice, and has fewer trainable parameters. We also show the performance of
our MSN for small, medium, and large CNNs - 3-layer CNN, VGG7 and DenseNet-BC,
respectively - and unsupervised image generation tasks using Generative
Adversarial Networks (GANs) to evaluate its applicability for a broad range of
embedded automation tasks.","['Anand Krishnamoorthy Subramanian', 'Nak Young Chong']","['cs.LG', 'stat.ML']",2019-07-09 06:24:22+00:00
http://arxiv.org/abs/1907.03989v1,"All Sparse PCA Models Are Wrong, But Some Are Useful. Part I: Computation of Scores, Residuals and Explained Variance","Sparse Principal Component Analysis (sPCA) is a popular matrix factorization
approach based on Principal Component Analysis (PCA) that combines variance
maximization and sparsity with the ultimate goal of improving data
interpretation. When moving from PCA to sPCA, there are a number of
implications that the practitioner needs to be aware of. A relevant one is that
scores and loadings in sPCA may not be orthogonal. For this reason, the
traditional way of computing scores, residuals and variance explained that is
used in the classical PCA cannot directly be applied to sPCA models. This also
affects how sPCA components should be visualized. In this paper we illustrate
this problem both theoretically and numerically using simulations for several
state-of-the-art sPCA algorithms, and provide proper computation of the
different elements mentioned. We show that sPCA approaches present disparate
and limited performance when modeling noise-free, sparse data. In a follow-up
paper, we discuss the theoretical properties that lead to this problem.","['J. Camacho', 'A. K. Smilde', 'E. Saccenti', 'J. A. Westerhuis']","['stat.ML', 'cs.LG']",2019-07-09 05:27:20+00:00
http://arxiv.org/abs/1907.03976v3,Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations,"The performance of imitation learning is typically upper-bounded by the
performance of the demonstrator. While recent empirical results demonstrate
that ranked demonstrations allow for better-than-demonstrator performance,
preferences over demonstrations may be difficult to obtain, and little is known
theoretically about when such methods can be expected to successfully
extrapolate beyond the performance of the demonstrator. To address these
issues, we first contribute a sufficient condition for better-than-demonstrator
imitation learning and provide theoretical results showing why preferences over
demonstrations can better reduce reward function ambiguity when performing
inverse reinforcement learning. Building on this theory, we introduce
Disturbance-based Reward Extrapolation (D-REX), a ranking-based imitation
learning method that injects noise into a policy learned through behavioral
cloning to automatically generate ranked demonstrations. These ranked
demonstrations are used to efficiently learn a reward function that can then be
optimized using reinforcement learning. We empirically validate our approach on
simulated robot and Atari imitation learning benchmarks and show that D-REX
outperforms standard imitation learning approaches and can significantly
surpass the performance of the demonstrator. D-REX is the first imitation
learning approach to achieve significant extrapolation beyond the
demonstrator's performance without additional side-information or supervision,
such as rewards or human preferences. By generating rankings automatically, we
show that preference-based inverse reinforcement learning can be applied in
traditional imitation learning settings where only unlabeled demonstrations are
available.","['Daniel S. Brown', 'Wonjoon Goo', 'Scott Niekum']","['cs.LG', 'stat.ML']",2019-07-09 04:11:53+00:00
http://arxiv.org/abs/1907.03947v1,Understanding Player Engagement and In-Game Purchasing Behavior with Ensemble Learning,"As video games attract more and more players, the major challenge for game
studios is to retain them. We present a deep behavioral analysis of churn (game
abandonment) and what we called ""purchase churn"" (the transition from paying to
non-paying user). A series of churning behavior profiles are identified, which
allows a classification of churners in terms of whether they eventually return
to the game (false churners)--or start purchasing again (false purchase
churners)--and their subsequent behavior. The impact of excluding some or all
of these churners from the training sample is then explored in several churn
and purchase churn prediction models. Our results suggest that discarding
certain combinations of ""zombies"" (players whose activity is extremely
sporadic) and false churners has a significant positive impact in all models
considered.","['Anna Guitart', 'Ana Fernández del Río', 'África Periáñez']","['stat.ML', 'cs.AI', 'cs.LG']",2019-07-09 02:40:40+00:00
http://arxiv.org/abs/1907.03755v2,Applications of a Novel Knowledge Discovery and Data Mining Process Model for Metabolomics,"This work demonstrates the execution of a novel process model for knowledge
discovery and data mining for metabolomics (MeKDDaM). It aims to illustrate
MeKDDaM process model applicability using four different real-world
applications and to highlight its strengths and unique features. The
demonstrated applications provide coverage for metabolite profiling, target
analysis, and metabolic fingerprinting. The data analysed in these applications
were captured by chromatographic separation and mass spectrometry technique
(LC-MS), Fourier transform infrared spectroscopy (FT-IR), and nuclear magnetic
resonance spectroscopy (NMR) and involve the analysis of plant, animal, and
human samples. The process was executed using both data-driven and
hypothesis-driven data mining approaches in order to perform various data
mining goals and tasks by applying a number of data mining techniques. The
applications were selected to achieve a range of analytical goals and research
questions and to provide coverage for metabolite profiling, target analysis,
and metabolic fingerprinting using datasets that were captured by NMR, LC-MS,
and FT-IR using samples of a plant, animal, and human origin. The process was
applied using an implementation environment which was created in order to
provide a computer-aided realisation of the process model execution.","['Ahmed BaniMustafa', 'Nigel Hardy']","['q-bio.QM', 'cs.DB', 'cs.LG', 'stat.ML', 'H.2.8; I.2.4; I.2.6; I.5.1; D.2.9; K.6.3; I.5; I.2; D.2; J.3']",2019-07-09 01:14:55+00:00
http://arxiv.org/abs/1907.04318v1,Computer-Aided Data Mining: Automating a Novel Knowledge Discovery and Data Mining Process Model for Metabolomics,"This work presents MeKDDaM-SAGA, computer-aided automation software for
implementing a novel knowledge discovery and data mining process model that was
designed for performing justifiable, traceable and reproducible metabolomics
data analysis. The process model focuses on achieving metabolomics analytical
objectives and on considering the nature of its involved data. MeKDDaM-SAGA was
successfully used for guiding the process model execution in a number of
metabolomics applications. It satisfies the requirements of the proposed
process model design and execution. The software realises the process model
layout, structure and flow and it enables its execution externally using
various data mining and machine learning tools or internally using a number of
embedded facilities that were built for performing a number of automated
activities such as data preprocessing, data exploration, data acclimatization,
modelling, evaluation and visualization. MeKDDaM-SAGA was developed using
object-oriented software engineering methodology and was constructed in Java.
It consists of 241 design classes that were designed to implement 27 use-cases.
The software uses an XML database to guarantee portability and uses a GUI
interface to ensure its user-friendliness. It implements an internal embedded
version control system that is used to realise and manage the process flow,
feedback and iterations and to enable undoing and redoing the execution of the
process phases, activities, and the internal tasks within its phases.","['Ahmed BaniMustafa', 'Nigel Hardy']","['q-bio.QM', 'cs.DB', 'cs.LG', 'stat.ML', 'H.2.8; I.2.4; I.2.6; I.5.1; D.2.9; K.6.3; I.5; I.2; D.2; J.3']",2019-07-09 01:14:53+00:00
http://arxiv.org/abs/1907.03870v1,Profiling Players with Engagement Predictions,"The possibility of using player engagement predictions to profile high
spending video game users is explored. In particular, individual-player
survival curves in terms of days after first login, game level reached and
accumulated playtime are used to classify players into different groups.
Lifetime value predictions for each player---generated using a deep learning
method based on long short-term memory---are also included in the analysis, and
the relations between all these variables are thoroughly investigated. Our
results suggest this constitutes a promising approach to user profiling.","['Ana Fernández del Río', 'Pei Pei Chen', 'África Periáñez']","['cs.LG', 'cs.SI', 'stat.ML']",2019-07-09 01:13:38+00:00
http://arxiv.org/abs/1907.03925v1,Non-technical Loss Detection with Statistical Profile Images Based on Semi-supervised Learning,"In order to keep track of the operational state of power grid, the world's
largest sensor systems, smart grid, was built by deploying hundreds of millions
of smart meters. Such system makes it possible to discover and make quick
response to any hidden threat to the entire power grid. Non-technical losses
(NTLs) have always been a major concern for its consequent security risks as
well as immeasurable revenue loss. However, various causes of NTL may have
different characteristics reflected in the data. Accurately capturing these
anomalies faced with such large scale of collected data records is rather
tricky as a result. In this paper, we proposed a new methodology of detecting
abnormal electricity consumptions. We did a transformation of the collected
time-series data which turns it into an image representation that could well
reflect users' relatively long term consumption behaviors. Inspired by the
excellent neural network architecture used for objective detection in computer
vision domain, we designed our deep learning model that takes the transformed
images as input and yields joint featured inferred from the multiple aspects
the input provides. Considering the limited labeled samples, especially the
abnormal ones, we used our model in a semi-supervised fashion that is brought
out in recent years. The model is tested on samples which are verified by
on-field inspections and our method showed significant improvement.","['Jiangteng Li', 'Fei Wang']","['cs.LG', 'stat.ML']",2019-07-09 01:06:03+00:00
http://arxiv.org/abs/1907.03922v2,Are deep ResNets provably better than linear predictors?,"Recent results in the literature indicate that a residual network (ResNet)
composed of a single residual block outperforms linear predictors, in the sense
that all local minima in its optimization landscape are at least as good as the
best linear predictor. However, these results are limited to a single residual
block (i.e., shallow ResNets), instead of the deep ResNets composed of multiple
residual blocks. We take a step towards extending this result to deep ResNets.
We start by two motivating examples. First, we show that there exist datasets
for which all local minima of a fully-connected ReLU network are no better than
the best linear predictor, whereas a ResNet has strictly better local minima.
Second, we show that even at the global minimum, the representation obtained
from the residual block outputs of a 2-block ResNet do not necessarily improve
monotonically over subsequent blocks, which highlights a fundamental difficulty
in analyzing deep ResNets. Our main theorem on deep ResNets shows under simple
geometric conditions that, any critical point in the optimization landscape is
either (i) at least as good as the best linear predictor; or (ii) the Hessian
at this critical point has a strictly negative eigenvalue. Notably, our theorem
shows that a chain of multiple skip-connections can improve the optimization
landscape, whereas existing results study direct skip-connections to the last
hidden layer or output layer. Finally, we complement our results by showing
benign properties of the ""near-identity regions"" of deep ResNets, showing
depth-independent upper bounds for the risk attained at critical points as well
as the Rademacher complexity.","['Chulhee Yun', 'Suvrit Sra', 'Ali Jadbabaie']","['cs.LG', 'math.OC', 'stat.ML']",2019-07-09 00:58:34+00:00
http://arxiv.org/abs/1907.03907v1,Latent ODEs for Irregularly-Sampled Time Series,"Time series with non-uniform intervals occur in many applications, and are
difficult to model using standard recurrent neural networks (RNNs). We
generalize RNNs to have continuous-time hidden dynamics defined by ordinary
differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use
ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE
model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps
between observations, and can explicitly model the probability of observation
times using Poisson processes. We show experimentally that these ODE-based
models outperform their RNN-based counterparts on irregularly-sampled data.","['Yulia Rubanova', 'Ricky T. Q. Chen', 'David Duvenaud']","['cs.LG', 'stat.ML']",2019-07-08 23:21:32+00:00
http://arxiv.org/abs/1907.03875v2,Multi-Scale Vector Quantization with Reconstruction Trees,"We propose and study a multi-scale approach to vector quantization. We
develop an algorithm, dubbed reconstruction trees, inspired by decision trees.
Here the objective is parsimonious reconstruction of unsupervised data, rather
than classification. Contrasted to more standard vector quantization methods,
such as K-means, the proposed approach leverages a family of given partitions,
to quickly explore the data in a coarse to fine-- multi-scale-- fashion. Our
main technical contribution is an analysis of the expected distortion achieved
by the proposed algorithm, when the data are assumed to be sampled from a fixed
unknown distribution. In this context, we derive both asymptotic and finite
sample results under suitable regularity assumptions on the distribution. As a
special case, we consider the setting where the data generating distribution is
supported on a compact Riemannian sub-manifold. Tools from differential
geometry and concentration of measure are useful in our analysis.","['Enrico Cecini', 'Ernesto De Vito', 'Lorenzo Rosasco']","['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2019-07-08 21:11:24+00:00
http://arxiv.org/abs/1907.03821v2,Thompson Sampling on Symmetric $α$-Stable Bandits,"Thompson Sampling provides an efficient technique to introduce prior
knowledge in the multi-armed bandit problem, along with providing remarkable
empirical performance. In this paper, we revisit the Thompson Sampling
algorithm under rewards drawn from symmetric $\alpha$-stable distributions,
which are a class of heavy-tailed probability distributions utilized in finance
and economics, in problems such as modeling stock prices and human behavior. We
present an efficient framework for posterior inference, which leads to two
algorithms for Thompson Sampling in this setting. We prove finite-time regret
bounds for both algorithms, and demonstrate through a series of experiments the
stronger performance of Thompson Sampling in this setting. With our results, we
provide an exposition of symmetric $\alpha$-stable distributions in sequential
decision-making, and enable sequential Bayesian inference in applications from
diverse fields in finance and complex systems that operate on heavy-tailed
features.","['Abhimanyu Dubey', 'Alex Pentland']","['cs.LG', 'stat.ML']",2019-07-08 19:32:22+00:00
http://arxiv.org/abs/1907.03816v2,The Power of Comparisons for Actively Learning Linear Classifiers,"In the world of big data, large but costly to label datasets dominate many
fields. Active learning, a semi-supervised alternative to the standard
PAC-learning model, was introduced to explore whether adaptive labeling could
learn concepts with exponentially fewer labeled samples. While previous results
show that active learning performs no better than its supervised alternative
for important concept classes such as linear separators, we show that by adding
weak distributional assumptions and allowing comparison queries, active
learning requires exponentially fewer samples. Further, we show that these
results hold as well for a stronger model of learning called Reliable and
Probably Useful (RPU) learning. In this model, our learner is not allowed to
make mistakes, but may instead answer ""I don't know."" While previous negative
results showed this model to have intractably large sample complexity for label
queries, we show that comparison queries make RPU-learning at worst
logarithmically more expensive in both the passive and active regimes.","['Max Hopkins', 'Daniel M. Kane', 'Shachar Lovett']","['cs.LG', 'cs.CG', 'stat.ML', '68Q32']",2019-07-08 19:08:59+00:00
http://arxiv.org/abs/1907.03813v1,Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection,"Nearest-neighbor (NN) procedures are well studied and widely used in both
supervised and unsupervised learning problems. In this paper we are concerned
with investigating the performance of NN-based methods for anomaly detection.
We first show through extensive simulations that NN methods compare favorably
to some of the other state-of-the-art algorithms for anomaly detection based on
a set of benchmark synthetic datasets. We further consider the performance of
NN methods on real datasets, and relate it to the dimensionality of the
problem. Next, we analyze the theoretical properties of NN-methods for anomaly
detection by studying a more general quantity called distance-to-measure (DTM),
originally developed in the literature on robust geometric and topological
inference. We provide finite-sample uniform guarantees for the empirical DTM
and use them to derive misclassification rates for anomalous observations under
various settings. In our analysis we rely on Huber's contamination model and
formulate mild geometric regularity assumptions on the underlying distribution
of the data.","['Xiaoyi Gu', 'Leman Akoglu', 'Alessandro Rinaldo']","['stat.ML', 'cs.LG', 'math.ST', 'stat.TH']",2019-07-08 18:58:35+00:00
http://arxiv.org/abs/1907.03802v1,Personalised aesthetics with residual adapters,"The use of computational methods to evaluate aesthetics in photography has
gained interest in recent years due to the popularization of convolutional
neural networks and the availability of new annotated datasets. Most studies in
this area have focused on designing models that do not take into account
individual preferences for the prediction of the aesthetic value of pictures.
We propose a model based on residual learning that is capable of learning
subjective, user specific preferences over aesthetics in photography, while
surpassing the state-of-the-art methods and keeping a limited number of
user-specific parameters in the model. Our model can also be used for picture
enhancement, and it is suitable for content-based or hybrid recommender systems
in which the amount of computational resources is limited.","['Carlos Rodríguez-Pardo', 'Hakan Bilen']","['cs.CV', 'cs.LG', 'stat.ML', '68T10 (Primary), 68T45 (Secondary)', 'I.2.10; I.5.4; I.4.3']",2019-07-08 18:40:16+00:00
http://arxiv.org/abs/1907.03799v3,Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches,"Robotic vision is a field where continual learning can play a significant
role. An embodied agent operating in a complex environment subject to frequent
and unpredictable changes is required to learn and adapt continuously. In the
context of object recognition, for example, a robot should be able to learn
(without forgetting) objects of never before seen classes as well as improving
its recognition capabilities as new instances of already known classes are
discovered. Ideally, continual learning should be triggered by the availability
of short videos of single objects and performed on-line on on-board hardware
with fine-grained updates. In this paper, we introduce a novel continual
learning protocol based on the CORe50 benchmark and propose two rehearsal-free
continual learning techniques, CWR* and AR1*, that can learn effectively even
in the challenging case of nearly 400 small non-i.i.d. incremental batches. In
particular, our experiments show that AR1* can outperform other
state-of-the-art rehearsal-free techniques by more than 15% accuracy in some
cases, with a very light and constant computational and memory overhead across
training batches.","['Vincenzo Lomonaco', 'Davide Maltoni', 'Lorenzo Pellegrini']","['cs.LG', 'cs.CV', 'cs.NE', 'stat.ML']",2019-07-08 18:32:25+00:00
http://arxiv.org/abs/1907.03793v2,A Hybrid Stochastic Optimization Framework for Stochastic Composite Nonconvex Optimization,"We introduce a new approach to develop stochastic optimization algorithms for
a class of stochastic composite and possibly nonconvex optimization problems.
The main idea is to combine two stochastic estimators to create a new hybrid
one. We first introduce our hybrid estimator and then investigate its
fundamental properties to form a foundational theory for algorithmic
development. Next, we apply our theory to develop several variants of
stochastic gradient methods to solve both expectation and finite-sum composite
optimization problems. Our first algorithm can be viewed as a variant of
proximal stochastic gradient methods with a single-loop, but can achieve
$\mathcal{O}(\sigma^3\varepsilon^{-1} + \sigma \varepsilon^{-3})$-oracle
complexity bound, matching the best-known ones from state-of-the-art
double-loop algorithms in the literature, where $\sigma > 0$ is the variance
and $\varepsilon$ is a desired accuracy. Then, we consider two different
variants of our method: adaptive step-size and restarting schemes that have
similar theoretical guarantees as in our first algorithm. We also study two
mini-batch variants of the proposed methods. In all cases, we achieve the
best-known complexity bounds under standard assumptions. We test our methods on
several numerical examples with real datasets and compare them with
state-of-the-arts. Our numerical experiments show that the new methods are
comparable and, in many cases, outperform their competitors.","['Quoc Tran-Dinh', 'Nhan H. Pham', 'Dzung T. Phan', 'Lam M. Nguyen']","['math.OC', 'cs.LG', 'stat.ML']",2019-07-08 18:12:37+00:00
http://arxiv.org/abs/1907.03792v2,Asymptotic Bayes risk for Gaussian mixture in a semi-supervised setting,"Semi-supervised learning (SSL) uses unlabeled data for training and has been
shown to greatly improve performance when compared to a supervised approach on
the labeled data available. This claim depends both on the amount of labeled
data available and on the algorithm used.
  In this paper, we compute analytically the gap between the best
fully-supervised approach using only labeled data and the best semi-supervised
approach using both labeled and unlabeled data. We quantify the best possible
increase in performance obtained thanks to the unlabeled data, i.e. we compute
the accuracy increase due to the information contained in the unlabeled data.
Our work deals with a simple high-dimensional Gaussian mixture model for the
data in a Bayesian setting. Our rigorous analysis builds on recent theoretical
breakthroughs in high-dimensional inference and a large body of mathematical
tools from statistical physics initially developed for spin glasses.","['Marc Lelarge', 'Leo Miolane']","['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2019-07-08 18:08:05+00:00
http://arxiv.org/abs/1907.03783v3,Comparing EM with GD in Mixture Models of Two Components,"The expectation-maximization (EM) algorithm has been widely used in
minimizing the negative log likelihood (also known as cross entropy) of mixture
models. However, little is understood about the goodness of the fixed points it
converges to. In this paper, we study the regions where one component is
missing in two-component mixture models, which we call one-cluster regions. We
analyze the propensity of such regions to trap EM and gradient descent (GD) for
mixtures of two Gaussians and mixtures of two Bernoullis. In the case of
Gaussian mixtures, EM escapes one-cluster regions exponentially fast, while GD
escapes them linearly fast. In the case of mixtures of Bernoullis, we find that
there exist one-cluster regions that are stable for GD and therefore trap GD,
but those regions are unstable for EM, allowing EM to escape. Those regions are
local minima that appear universally in experiments and can be arbitrarily bad.
This work implies that EM is less likely than GD to converge to certain bad
local optima in mixture models.","['Guojun Zhang', 'Pascal Poupart', 'George Trimponias']","['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2019-07-08 18:00:32+00:00
http://arxiv.org/abs/1907.03741v2,"Expressive power of tensor-network factorizations for probabilistic modeling, with applications from hidden Markov models to quantum machine learning","Tensor-network techniques have enjoyed outstanding success in physics, and
have recently attracted attention in machine learning, both as a tool for the
formulation of new learning algorithms and for enhancing the mathematical
understanding of existing methods. Inspired by these developments, and the
natural correspondence between tensor networks and probabilistic graphical
models, we provide a rigorous analysis of the expressive power of various
tensor-network factorizations of discrete multivariate probability
distributions. These factorizations include non-negative tensor-trains/MPS,
which are in correspondence with hidden Markov models, and Born machines, which
are naturally related to local quantum circuits. When used to model probability
distributions, they exhibit tractable likelihoods and admit efficient learning
algorithms. Interestingly, we prove that there exist probability distributions
for which there are unbounded separations between the resource requirements of
some of these tensor-network factorizations. Particularly surprising is the
fact that using complex instead of real tensors can lead to an arbitrarily
large reduction in the number of parameters of the network. Additionally, we
introduce locally purified states (LPS), a new factorization inspired by
techniques for the simulation of quantum systems, with provably better
expressive power than all other representations considered. The ramifications
of this result are explored through numerical experiments. Our findings imply
that LPS should be considered over hidden Markov models, and furthermore
provide guidelines for the design of local quantum circuits for probabilistic
modeling.","['Ivan Glasser', 'Ryan Sweke', 'Nicola Pancotti', 'Jens Eisert', 'J. Ignacio Cirac']","['cs.LG', 'cond-mat.str-el', 'math.OC', 'quant-ph', 'stat.ML']",2019-07-08 17:54:26+00:00
http://arxiv.org/abs/1907.05283v1,A Comparison of Super-Resolution and Nearest Neighbors Interpolation Applied to Object Detection on Satellite Data,"As Super-Resolution (SR) has matured as a research topic, it has been applied
to additional topics beyond image reconstruction. In particular, combining
classification or object detection tasks with a super-resolution preprocessing
stage has yielded improvements in accuracy especially with objects that are
small relative to the scene. While SR has shown promise, a study comparing SR
and naive upscaling methods such as Nearest Neighbors (NN) interpolation when
applied as a preprocessing step for object detection has not been performed. We
apply the topic to satellite data and compare the Multi-scale Deep
Super-Resolution (MDSR) system to NN on the xView challenge dataset. To do so,
we propose a pipeline for processing satellite data that combines multi-stage
image tiling and upscaling, the YOLOv2 object detection architecture, and label
stitching. We compare the effects of training models using an upscaling factor
of 4, upscaling images from 30cm Ground Sample Distance (GSD) to an effective
GSD of 7.5cm. Upscaling by this factor significantly improves detection
results, increasing Average Precision (AP) of a generalized vehicle class by 23
percent. We demonstrate that while SR produces upscaled images that are more
visually pleasing than their NN counterparts, object detection networks see
little difference in accuracy with images upsampled using NN obtaining nearly
identical results to the MDSRx4 enhanced images with a difference of 0.0002 AP
between the two methods.","['Evan Koester', 'Cem Safak Sahin']","['cs.CV', 'cs.LG', 'eess.IV', 'stat.ML']",2019-07-08 17:03:12+00:00
http://arxiv.org/abs/1907.03715v1,Predicting Customer Call Intent by Analyzing Phone Call Transcripts based on CNN for Multi-Class Classification,"Auto dealerships receive thousands of calls daily from customers who are
interested in sales, service, vendors and jobseekers. With so many calls, it is
very important for auto dealers to understand the intent of these calls to
provide positive customer experiences that ensure customer satisfaction, deep
customer engagement to boost sales and revenue, and optimum allocation of
agents or customer service representatives across the business. In this paper,
we define the problem of customer phone call intent as a multi-class
classification problem stemming from the large database of recorded phone call
transcripts. To solve this problem, we develop a convolutional neural network
(CNN)-based supervised learning model to classify the customer calls into four
intent categories: sales, service, vendor and jobseeker. Experimental results
show that with the thrust of our scalable data labeling method to provide
sufficient training data, the CNN-based predictive model performs very well on
long text classification according to the quantitative metrics of F1-Score,
precision, recall, and accuracy.","['Junmei Zhong', 'William Li']","['cs.LG', 'cs.CL', 'stat.ML', '97R40']",2019-07-08 16:39:23+00:00
http://arxiv.org/abs/1907.03712v2,Policy-Gradient Algorithms Have No Guarantees of Convergence in Linear Quadratic Games,"We show by counterexample that policy-gradient algorithms have no guarantees
of even local convergence to Nash equilibria in continuous action and state
space multi-agent settings. To do so, we analyze gradient-play in N-player
general-sum linear quadratic games, a classic game setting which is recently
emerging as a benchmark in the field of multi-agent learning. In such games the
state and action spaces are continuous and global Nash equilibria can be found
be solving coupled Ricatti equations. Further, gradient-play in LQ games is
equivalent to multi agent policy-gradient. We first show that these games are
surprisingly not convex games. Despite this, we are still able to show that the
only critical points of the gradient dynamics are global Nash equilibria. We
then give sufficient conditions under which policy-gradient will avoid the Nash
equilibria, and generate a large number of general-sum linear quadratic games
that satisfy these conditions. In such games we empirically observe the players
converging to limit cycles for which the time average does not coincide with a
Nash equilibrium. The existence of such games indicates that one of the most
popular approaches to solving reinforcement learning problems in the classic
reinforcement learning setting has no local guarantee of convergence in
multi-agent settings. Further, the ease with which we can generate these
counterexamples suggests that such situations are not mere edge cases and are
in fact quite common.","['Eric Mazumdar', 'Lillian J. Ratliff', 'Michael I. Jordan', 'S. Shankar Sastry']","['cs.LG', 'stat.ML']",2019-07-08 16:35:03+00:00
http://arxiv.org/abs/1907.03698v1,TrackNet: A Deep Learning Network for Tracking High-speed and Tiny Objects in Sports Applications,"Ball trajectory data are one of the most fundamental and useful information
in the evaluation of players' performance and analysis of game strategies.
Although vision-based object tracking techniques have been developed to analyze
sport competition videos, it is still challenging to recognize and position a
high-speed and tiny ball accurately. In this paper, we develop a deep learning
network, called TrackNet, to track the tennis ball from broadcast videos in
which the ball images are small, blurry, and sometimes with afterimage tracks
or even invisible. The proposed heatmap-based deep learning network is trained
to not only recognize the ball image from a single frame but also learn flying
patterns from consecutive frames. TrackNet takes images with a size of
$640\times360$ to generate a detection heatmap from either a single frame or
several consecutive frames to position the ball and can achieve high precision
even on public domain videos. The network is evaluated on the video of the
men's singles final at the 2017 Summer Universiade, which is available on
YouTube. The precision, recall, and F1-measure of TrackNet reach $99.7\%$,
$97.3\%$, and $98.5\%$, respectively. To prevent overfitting, 9 additional
videos are partially labeled together with a subset from the previous dataset
to implement 10-fold cross-validation, and the precision, recall, and
F1-measure are $95.3\%$, $75.7\%$, and $84.3\%$, respectively. A conventional
image processing algorithm is also implemented to compare with TrackNet. Our
experiments indicate that TrackNet outperforms conventional method by a big
margin and achieves exceptional ball tracking performance. The dataset and demo
video are available at https://nol.cs.nctu.edu.tw/ndo3je6av9/.","['Yu-Chuan Huang', 'I-No Liao', 'Ching-Hsuan Chen', 'Tsì-Uí İk', 'Wen-Chih Peng']","['cs.LG', 'cs.CV', 'cs.MM', 'stat.ML']",2019-07-08 16:08:43+00:00
http://arxiv.org/abs/1907.03687v1,General non-linear Bellman equations,"We consider a general class of non-linear Bellman equations. These open up a
design space of algorithms that have interesting properties, which has two
potential advantages. First, we can perhaps better model natural phenomena. For
instance, hyperbolic discounting has been proposed as a mathematical model that
matches human and animal data well, and can therefore be used to explain
preference orderings. We present a different mathematical model that matches
the same data, but that makes very different predictions under other
circumstances. Second, the larger design space can perhaps lead to algorithms
that perform better, similar to how discount factors are often used in practice
even when the true objective is undiscounted. We show that many of the
resulting Bellman operators still converge to a fixed point, and therefore that
the resulting algorithms are reasonable and inherit many beneficial properties
of their linear counterparts.","['Hado van Hasselt', 'John Quan', 'Matteo Hessel', 'Zhongwen Xu', 'Diana Borsa', 'Andre Barreto']","['cs.LG', 'cs.AI', 'stat.ML']",2019-07-08 15:51:01+00:00
http://arxiv.org/abs/1907.04240v1,Bayesian deep learning with hierarchical prior: Predictions from limited and noisy data,"Datasets in engineering applications are often limited and contaminated,
mainly due to unavoidable measurement noise and signal distortion. Thus, using
conventional data-driven approaches to build a reliable discriminative model,
and further applying this identified surrogate to uncertainty analysis remains
to be very challenging. A deep learning approach is presented to provide
predictions based on limited and noisy data. To address noise perturbation, the
Bayesian learning method that naturally facilitates an automatic updating
mechanism is considered to quantify and propagate model uncertainties into
predictive quantities. Specifically, hierarchical Bayesian modeling (HBM) is
first adopted to describe model uncertainties, which allows the prior
assumption to be less subjective, while also makes the proposed surrogate more
robust. Next, the Bayesian inference is seamlessly integrated into the DL
framework, which in turn supports probabilistic programming by yielding a
probability distribution of the quantities of interest rather than their point
estimates. Variational inference (VI) is implemented for the posterior
distribution analysis where the intractable marginalization of the likelihood
function over parameter space is framed in an optimization format, and
stochastic gradient descent method is applied to solve this optimization
problem. Finally, Monte Carlo simulation is used to obtain an unbiased
estimator in the predictive phase of Bayesian inference, where the proposed
Bayesian deep learning (BDL) scheme is able to offer confidence bounds for the
output estimation by analyzing propagated uncertainties. The effectiveness of
Bayesian shrinkage is demonstrated in improving predictive performance using
contaminated data, and various examples are provided to illustrate concepts,
methodologies, and algorithms of this proposed BDL modeling technique.","['Xihaier Luo', 'Ahsan Kareem']","['stat.ML', 'cs.LG', 'eess.SP', 'physics.comp-ph']",2019-07-08 15:37:40+00:00
http://arxiv.org/abs/1907.03680v2,Robust Guarantees for Perception-Based Control,"Motivated by vision-based control of autonomous vehicles, we consider the
problem of controlling a known linear dynamical system for which partial state
information, such as vehicle position, is extracted from complex and nonlinear
data, such as a camera image. Our approach is to use a learned perception map
that predicts some linear function of the state and to design a corresponding
safe set and robust controller for the closed loop system with this sensing
scheme. We show that under suitable smoothness assumptions on both the
perception map and the generative model relating state to complex and nonlinear
data, parameters of the safe set can be learned via appropriately dense
sampling of the state space. We then prove that the resulting
perception-control loop has favorable generalization properties. We illustrate
the usefulness of our approach on a synthetic example and on the self-driving
car simulation platform CARLA.","['Sarah Dean', 'Nikolai Matni', 'Benjamin Recht', 'Vickie Ye']","['math.OC', 'cs.LG', 'stat.ML']",2019-07-08 15:35:56+00:00
http://arxiv.org/abs/1907.04916v1,"Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR","Sequence-to-sequence (seq2seq) based ASR systems have shown state-of-the-art
performances while having clear advantages in terms of simplicity. However,
comparisons are mostly done on speaker independent (SI) ASR systems, though
speaker adapted conventional systems are commonly used in practice for
improving robustness to speaker and environment variations. In this paper, we
apply speaker adaptation to seq2seq models with the goal of matching the
performance of conventional ASR adaptation. Specifically, we investigate
Kullback-Leibler divergence (KLD) as well as Linear Hidden Network (LHN) based
adaptation for seq2seq ASR, using different amounts (up to 20 hours) of
adaptation data per speaker. Our SI models are trained on large amounts of
dictation data and achieve state-of-the-art results. We obtained 25% relative
word error rate (WER) improvement with KLD adaptation of the seq2seq model vs.
18.7% gain from acoustic model adaptation in the conventional system. We also
show that the WER of the seq2seq model decreases log-linearly with the amount
of adaptation data. Finally, we analyze adaptation based on the minimum WER
criterion and adapting the language model (LM) for score fusion with the
speaker adapted seq2seq model, which result in further improvements of the
seq2seq system performance.","['Felix Weninger', 'Jesús Andrés-Ferrer', 'Xinwei Li', 'Puming Zhan']","['eess.AS', 'cs.CL', 'cs.LG', 'cs.SD', 'stat.ML']",2019-07-08 15:09:40+00:00
http://arxiv.org/abs/1907.04666v1,Routine Modeling with Time Series Metric Learning,"Traditionally, the automatic recognition of human activities is performed
with supervised learning algorithms on limited sets of specific activities.
This work proposes to recognize recurrent activity patterns, called routines,
instead of precisely defined activities. The modeling of routines is defined as
a metric learning problem, and an architecture, called SS2S, based on
sequence-to-sequence models is proposed to learn a distance between time
series. This approach only relies on inertial data and is thus non intrusive
and preserves privacy. Experimental results show that a clustering algorithm
provided with the learned distance is able to recover daily routines.","['Paul Compagnon', 'Grégoire Lefebvre', 'Stefan Duffner', 'Christophe Garcia']","['cs.LG', 'cs.AI', 'stat.ML']",2019-07-08 14:10:01+00:00
http://arxiv.org/abs/1907.03572v1,Towards Explainable Music Emotion Recognition: The Route via Mid-level Features,"Emotional aspects play an important part in our interaction with music.
However, modelling these aspects in MIR systems have been notoriously
challenging since emotion is an inherently abstract and subjective experience,
thus making it difficult to quantify or predict in the first place, and to make
sense of the predictions in the next. In an attempt to create a model that can
give a musically meaningful and intuitive explanation for its predictions, we
propose a VGG-style deep neural network that learns to predict emotional
characteristics of a musical piece together with (and based on)
human-interpretable, mid-level perceptual features. We compare this to
predicting emotion directly with an identical network that does not take into
account the mid-level features and observe that the loss in predictive
performance of going through the mid-level features is surprisingly low, on
average. The design of our network allows us to visualize the effects of
perceptual features on individual emotion predictions, and we argue that the
small loss in performance in going through the mid-level features is justified
by the gain in explainability of the predictions.","['Shreyan Chowdhury', 'Andreu Vall', 'Verena Haunschmid', 'Gerhard Widmer']","['cs.SD', 'cs.LG', 'stat.ML']",2019-07-08 12:58:02+00:00
http://arxiv.org/abs/1907.03540v2,ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning,"End-to-end automatic speech recognition (ASR) models are increasingly large
and complex to achieve the best possible accuracy. In this paper, we build an
AutoML system that uses reinforcement learning (RL) to optimize the per-layer
compression ratios when applied to a state-of-the-art attention based
end-to-end ASR model composed of several LSTM layers. We use singular value
decomposition (SVD) low-rank matrix factorization as the compression method.
For our RL-based AutoML system, we focus on practical considerations such as
the choice of the reward/punishment functions, the formation of an effective
search space, and the creation of a representative but small data set for quick
evaluation between search steps. Finally, we present accuracy results on
LibriSpeech of the model compressed by our AutoML system, and we compare it to
manually-compressed models. Our results show that in the absence of retraining
our RL-based search is an effective and practical method to compress a
production-grade ASR system. When retraining is possible, we show that our
AutoML system can select better highly-compressed seed models compared to
manually hand-crafted rank selection, thus allowing for more compression than
previously possible.","['Łukasz Dudziak', 'Mohamed S. Abdelfattah', 'Ravichander Vipperla', 'Stefanos Laskaridis', 'Nicholas D. Lane']","['cs.LG', 'cs.AI', 'eess.AS', 'stat.ML']",2019-07-08 12:10:18+00:00
http://arxiv.org/abs/1907.03511v1,A Multi-Stage Clustering Framework for Automotive Radar Data,"Radar sensors provide a unique method for executing environmental perception
tasks towards autonomous driving. Especially their capability to perform well
in adverse weather conditions often makes them superior to other sensors such
as cameras or lidar. Nevertheless, the high sparsity and low dimensionality of
the commonly used detection data level is a major challenge for subsequent
signal processing. Therefore, the data points are often merged in order to form
larger entities from which more information can be gathered. The merging
process is often implemented in form of a clustering algorithm. This article
describes a novel approach for first filtering out static background data
before applying a twostage clustering approach. The two-stage clustering
follows the same paradigm as the idea for data association itself: First,
clustering what is ought to belong together in a low dimensional parameter
space, then, extracting additional features from the newly created clusters in
order to perform a final clustering step. Parameters are optimized for
filtering and both clustering steps. All techniques are assessed both
individually and as a whole in order to demonstrate their effectiveness. Final
results indicate clear benefits of the first two methods and also the cluster
merging process under specific circumstances.","['Nicolas Scheiner', 'Nils Appenrodt', 'Jürgen Dickmann', 'Bernhard Sick']","['cs.LG', 'cs.RO', 'eess.IV', 'eess.SP', 'stat.ML']",2019-07-08 11:10:16+00:00
http://arxiv.org/abs/1907.03507v1,Physics Informed Extreme Learning Machine (PIELM) -- A rapid method for the numerical solution of partial differential equations,"There has been rapid progress recently on the application of deep networks to
the solution of partial differential equations, collectively labelled as
Physics Informed Neural Networks (PINNs). In this paper, we develop Physics
Informed Extreme Learning Machine (PIELM), a rapid version of PINNs which can
be applied to stationary and time dependent linear partial differential
equations. We demonstrate that PIELM matches or exceeds the accuracy of PINNs
on a range of problems. We also discuss the limitations of neural network based
approaches, including our PIELM, in the solution of PDEs on large domains and
suggest an extension, a distributed version of our algorithm -{}- DPIELM. We
show that DPIELM produces excellent results comparable to conventional
numerical techniques in the solution of time-dependent problems. Collectively,
this work contributes towards making the use of neural networks in the solution
of partial differential equations in complex domains as a competitive
alternative to conventional discretization techniques.","['Vikas Dwivedi', 'Balaji Srinivasan']","['cs.LG', 'physics.comp-ph', 'stat.ML']",2019-07-08 11:02:08+00:00
http://arxiv.org/abs/1907.03452v2,Deep splitting method for parabolic PDEs,"In this paper we introduce a numerical method for nonlinear parabolic PDEs
that combines operator splitting with deep learning. It divides the PDE
approximation problem into a sequence of separate learning problems. Since the
computational graph for each of the subproblems is comparatively small, the
approach can handle extremely high-dimensional PDEs. We test the method on
different examples from physics, stochastic control and mathematical finance.
In all cases, it yields very good results in up to 10,000 dimensions with short
run times.","['Christian Beck', 'Sebastian Becker', 'Patrick Cheridito', 'Arnulf Jentzen', 'Ariel Neufeld']","['math.NA', 'cs.LG', 'cs.NA', 'math.PR', 'stat.ML', '35K15, 65C05, 65M22, 65M75, 91G20, 93E20']",2019-07-08 08:30:23+00:00
http://arxiv.org/abs/1907.03451v2,General Control Functions for Causal Effect Estimation from Instrumental Variables,"Causal effect estimation relies on separating the variation in the outcome
into parts due to the treatment and due to the confounders. To achieve this
separation, practitioners often use external sources of randomness that only
influence the treatment called instrumental variables (IVs). We study variables
constructed from treatment and IV that help estimate effects, called control
functions. We characterize general control functions for effect estimation in a
meta-identification result. Then, we show that structural assumptions on the
treatment process allow the construction of general control functions, thereby
guaranteeing identification. To construct general control functions and
estimate effects, we develop the general control function method (GCFN). GCFN's
first stage called variational decoupling (VDE) constructs general control
functions by recovering the residual variation in the treatment given the IV.
Using VDE's control function, GCFN's second stage estimates effects via
regression. Further, we develop semi-supervised GCFN to construct general
control functions using subsets of data that have both IV and confounders
observed as supervision; this needs no structural treatment process
assumptions. We evaluate GCFN on low and high dimensional simulated data and on
recovering the causal effect of slave export on modern community trust.","['Aahlad Manas Puli', 'Rajesh Ranganath']","['cs.LG', 'stat.ML']",2019-07-08 08:27:12+00:00
http://arxiv.org/abs/1907.03426v1,Multivariate-Information Adversarial Ensemble for Scalable Joint Distribution Matching,"A broad range of cross-$m$-domain generation researches boil down to matching
a joint distribution by deep generative models (DGMs). Hitherto algorithms
excel in pairwise domains while as $m$ increases, remain struggling to scale
themselves to fit a joint distribution. In this paper, we propose a
domain-scalable DGM, i.e., MMI-ALI for $m$-domain joint distribution matching.
As an $m$-domain ensemble model of ALIs \cite{dumoulin2016adversarially},
MMI-ALI is adversarially trained with maximizing Multivariate Mutual
Information (MMI) w.r.t. joint variables of each pair of domains and their
shared feature. The negative MMIs are upper bounded by a series of feasible
losses that provably lead to matching $m$-domain joint distributions. MMI-ALI
linearly scales as $m$ increases and thus, strikes a right balance between
efficacy and scalability. We evaluate MMI-ALI in diverse challenging $m$-domain
scenarios and verify its superiority.","['Ziliang Chen', 'Zhanfu Yang', 'Xiaoxi Wang', 'Xiaodan Liang', 'Xiaopeng Yan', 'Guanbin Li', 'Liang Lin']","['cs.LG', 'stat.ML']",2019-07-08 07:11:54+00:00
http://arxiv.org/abs/1907.04669v1,Optimal Explanations of Linear Models,"When predictive models are used to support complex and important decisions,
the ability to explain a model's reasoning can increase trust, expose hidden
biases, and reduce vulnerability to adversarial attacks. However, attempts at
interpreting models are often ad hoc and application-specific, and the concept
of interpretability itself is not well-defined. We propose a general
optimization framework to create explanations for linear models. Our
methodology decomposes a linear model into a sequence of models of increasing
complexity using coordinate updates on the coefficients. Computing this
decomposition optimally is a difficult optimization problem for which we
propose exact algorithms and scalable heuristics. By solving this problem, we
can derive a parametrized family of interpretability metrics for linear models
that generalizes typical proxies, and study the tradeoff between
interpretability and predictive accuracy.","['Dimitris Bertsimas', 'Arthur Delarue', 'Patrick Jaillet', 'Sebastien Martin']","['cs.LG', 'stat.ML']",2019-07-08 06:59:05+00:00
http://arxiv.org/abs/1907.03419v1,The Price of Interpretability,"When quantitative models are used to support decision-making on complex and
important topics, understanding a model's ``reasoning'' can increase trust in
its predictions, expose hidden biases, or reduce vulnerability to adversarial
attacks. However, the concept of interpretability remains loosely defined and
application-specific. In this paper, we introduce a mathematical framework in
which machine learning models are constructed in a sequence of interpretable
steps. We show that for a variety of models, a natural choice of interpretable
steps recovers standard interpretability proxies (e.g., sparsity in linear
models). We then generalize these proxies to yield a parametrized family of
consistent measures of model interpretability. This formal definition allows us
to quantify the ``price'' of interpretability, i.e., the tradeoff with
predictive accuracy. We demonstrate practical algorithms to apply our framework
on real and synthetic datasets.","['Dimitris Bertsimas', 'Arthur Delarue', 'Patrick Jaillet', 'Sebastien Martin']","['cs.LG', 'stat.ML']",2019-07-08 06:42:59+00:00
http://arxiv.org/abs/1907.03411v2,Unbiased estimators for random design regression,"In linear regression we wish to estimate the optimum linear least squares
predictor for a distribution over $d$-dimensional input points and real-valued
responses, based on a small sample. Under standard random design analysis,
where the sample is drawn i.i.d. from the input distribution, the least squares
solution for that sample can be viewed as the natural estimator of the optimum.
Unfortunately, this estimator almost always incurs an undesirable bias coming
from the randomness of the input points, which is a significant bottleneck in
model averaging. In this paper we show that it is possible to draw a non-i.i.d.
sample of input points such that, regardless of the response model, the least
squares solution is an unbiased estimator of the optimum. Moreover, this sample
can be produced efficiently by augmenting a previously drawn i.i.d. sample with
an additional set of $d$ points, drawn jointly according to a certain
determinantal point process constructed from the input distribution rescaled by
the squared volume spanned by the points. Motivated by this, we develop a
theoretical framework for studying volume-rescaled sampling, and in the process
prove a number of new matrix expectation identities. We use them to show that
for any input distribution and $\epsilon>0$ there is a random design consisting
of $O(d\log d+ d/\epsilon)$ points from which an unbiased estimator can be
constructed whose expected square loss over the entire distribution is bounded
by $1+\epsilon$ times the loss of the optimum. We provide efficient algorithms
for generating such unbiased estimators in a number of practical settings and
support our claims experimentally.","['Michał Dereziński', 'Manfred K. Warmuth', 'Daniel Hsu']","['stat.ML', 'cs.LG']",2019-07-08 06:01:19+00:00
http://arxiv.org/abs/1907.04924v1,Infer Implicit Contexts in Real-time Online-to-Offline Recommendation,"Understanding users' context is essential for successful recommendations,
especially for Online-to-Offline (O2O) recommendation, such as Yelp, Groupon,
and Koubei. Different from traditional recommendation where individual
preference is mostly static, O2O recommendation should be dynamic to capture
variation of users' purposes across time and location. However, precisely
inferring users' real-time contexts information, especially those implicit
ones, is extremely difficult, and it is a central challenge for O2O
recommendation. In this paper, we propose a new approach, called Mixture
Attentional Constrained Denoise AutoEncoder (MACDAE), to infer implicit
contexts and consequently, to improve the quality of real-time O2O
recommendation. In MACDAE, we first leverage the interaction among users,
items, and explicit contexts to infer users' implicit contexts, then combine
the learned implicit-context representation into an end-to-end model to make
the recommendation. MACDAE works quite well in the real system. We conducted
both offline and online evaluations of the proposed approach. Experiments on
several real-world datasets (Yelp, Dianping, and Koubei) show our approach
could achieve significant improvements over state-of-the-arts. Furthermore,
online A/B test suggests a 2.9% increase for click-through rate and 5.6%
improvement for conversion rate in real-world traffic. Our model has been
deployed in the product of ""Guess You Like"" recommendation in Koubei.","['Xichen Ding', 'Jie Tang', 'Tracy Liu', 'Cheng Xu', 'Yaping Zhang', 'Feng Shi', 'Qixia Jiang', 'Dan Shen']","['cs.IR', 'cs.LG', 'stat.ML']",2019-07-08 05:37:30+00:00
http://arxiv.org/abs/1907.04907v1,Topic Modeling in Embedding Spaces,"Topic modeling analyzes documents to learn meaningful patterns of words.
However, existing topic models fail to learn interpretable topics when working
with large and heavy-tailed vocabularies. To this end, we develop the Embedded
Topic Model (ETM), a generative model of documents that marries traditional
topic models with word embeddings. In particular, it models each word with a
categorical distribution whose natural parameter is the inner product between a
word embedding and an embedding of its assigned topic. To fit the ETM, we
develop an efficient amortized variational inference algorithm. The ETM
discovers interpretable topics even with large vocabularies that include rare
words and stop words. It outperforms existing document models, such as latent
Dirichlet allocation (LDA), in terms of both topic quality and predictive
performance.","['Adji B. Dieng', 'Francisco J. R. Ruiz', 'David M. Blei']","['cs.IR', 'cs.CL', 'cs.LG', 'stat.ML']",2019-07-08 03:50:57+00:00
http://arxiv.org/abs/1907.04197v1,Attending to Emotional Narratives,"Attention mechanisms in deep neural networks have achieved excellent
performance on sequence-prediction tasks. Here, we show that these
recently-proposed attention-based mechanisms---in particular, the Transformer
with its parallelizable self-attention layers, and the Memory Fusion Network
with attention across modalities and time---also generalize well to multimodal
time-series emotion recognition. Using a recently-introduced dataset of
emotional autobiographical narratives, we adapt and apply these two attention
mechanisms to predict emotional valence over time. Our models perform extremely
well, in some cases reaching a performance comparable with human raters. We end
with a discussion of the implications of attention mechanisms to affective
computing.","['Zhengxuan Wu', 'Xiyu Zhang', 'Tan Zhi-Xuan', 'Jamil Zaki', 'Desmond C. Ong']","['cs.LG', 'cs.CL', 'stat.ML']",2019-07-08 03:50:43+00:00
http://arxiv.org/abs/1907.03389v1,Blending-target Domain Adaptation by Adversarial Meta-Adaptation Networks,"(Unsupervised) Domain Adaptation (DA) seeks for classifying target instances
when solely provided with source labeled and target unlabeled examples for
training. Learning domain-invariant features helps to achieve this goal,
whereas it underpins unlabeled samples drawn from a single or multiple explicit
target domains (Multi-target DA). In this paper, we consider a more realistic
transfer scenario: our target domain is comprised of multiple sub-targets
implicitly blended with each other, so that learners could not identify which
sub-target each unlabeled sample belongs to. This Blending-target Domain
Adaptation (BTDA) scenario commonly appears in practice and threatens the
validities of most existing DA algorithms, due to the presence of domain gaps
and categorical misalignments among these hidden sub-targets.
  To reap the transfer performance gains in this new scenario, we propose
Adversarial Meta-Adaptation Network (AMEAN). AMEAN entails two adversarial
transfer learning processes. The first is a conventional adversarial transfer
to bridge our source and mixed target domains. To circumvent the intra-target
category misalignment, the second process presents as ``learning to adapt'': It
deploys an unsupervised meta-learner receiving target data and their ongoing
feature-learning feedbacks, to discover target clusters as our
``meta-sub-target'' domains. These meta-sub-targets auto-design our
meta-sub-target DA loss, which empirically eliminates the implicit category
mismatching in our mixed target. We evaluate AMEAN and a variety of DA
algorithms in three benchmarks under the BTDA setup. Empirical results show
that BTDA is a quite challenging transfer setup for most existing DA
algorithms, yet AMEAN significantly outperforms these state-of-the-art
baselines and effectively restrains the negative transfer effects in BTDA.","['Ziliang Chen', 'Jingyu Zhuang', 'Xiaodan Liang', 'Liang Lin']","['cs.LG', 'stat.ML']",2019-07-08 02:54:35+00:00
http://arxiv.org/abs/1907.03382v2,Etalumis: Bringing Probabilistic Programming to Scientific Simulators at Scale,"Probabilistic programming languages (PPLs) are receiving widespread attention
for performing Bayesian inference in complex generative models. However,
applications to science remain limited because of the impracticability of
rewriting complex scientific simulators in a PPL, the computational cost of
inference, and the lack of scalable implementations. To address these, we
present a novel PPL framework that couples directly to existing scientific
simulators through a cross-platform probabilistic execution protocol and
provides Markov chain Monte Carlo (MCMC) and deep-learning-based inference
compilation (IC) engines for tractable inference. To guide IC inference, we
perform distributed training of a dynamic 3DCNN--LSTM architecture with a
PyTorch-MPI-based framework on 1,024 32-core CPU nodes of the Cori
supercomputer with a global minibatch size of 128k: achieving a performance of
450 Tflop/s through enhancements to PyTorch. We demonstrate a Large Hadron
Collider (LHC) use-case with the C++ Sherpa simulator and achieve the
largest-scale posterior inference in a Turing-complete PPL.","['Atılım Güneş Baydin', 'Lei Shao', 'Wahid Bhimji', 'Lukas Heinrich', 'Lawrence Meadows', 'Jialin Liu', 'Andreas Munk', 'Saeid Naderiparizi', 'Bradley Gram-Hansen', 'Gilles Louppe', 'Mingfei Ma', 'Xiaohui Zhao', 'Philip Torr', 'Victor Lee', 'Kyle Cranmer', 'Prabhat', 'Frank Wood']","['cs.LG', 'cs.PF', 'stat.ML', '68T37, 68T05, 62P35', 'G.3; I.2.6; J.2']",2019-07-08 02:03:36+00:00
http://arxiv.org/abs/1907.04202v2,Variational Inference MPC for Bayesian Model-based Reinforcement Learning,"In recent studies on model-based reinforcement learning (MBRL), incorporating
uncertainty in forward dynamics is a state-of-the-art strategy to enhance
learning performance, making MBRLs competitive to cutting-edge model free
methods, especially in simulated robotics tasks. Probabilistic ensembles with
trajectory sampling (PETS) is a leading type of MBRL, which employs Bayesian
inference to dynamics modeling and model predictive control (MPC) with
stochastic optimization via the cross entropy method (CEM). In this paper, we
propose a novel extension to the uncertainty-aware MBRL. Our main contributions
are twofold: Firstly, we introduce a variational inference MPC, which
reformulates various stochastic methods, including CEM, in a Bayesian fashion.
Secondly, we propose a novel instance of the framework, called probabilistic
action ensembles with trajectory sampling (PaETS). As a result, our Bayesian
MBRL can involve multimodal uncertainties both in dynamics and optimal
trajectories. In comparison to PETS, our method consistently improves
asymptotic performance on several challenging locomotion tasks.","['Masashi Okada', 'Tadahiro Taniguchi']","['cs.LG', 'cs.SY', 'eess.SY', 'stat.ML']",2019-07-08 01:54:08+00:00
http://arxiv.org/abs/1907.03373v2,Privacy-Preserving Classification with Secret Vector Machines,"Today, large amounts of valuable data are distributed among millions of
user-held devices, such as personal computers, phones, or Internet-of-things
devices. Many companies collect such data with the goal of using it for
training machine learning models allowing them to improve their services.
User-held data is, however, often sensitive, and collecting it is problematic
in terms of privacy. We address this issue by proposing a novel way of training
a supervised classifier in a distributed setting akin to the recently proposed
federated learning paradigm, but under the stricter privacy requirement that
the server that trains the model is assumed to be untrusted and potentially
malicious. We thus preserve user privacy by design, rather than by trust. In
particular, our framework, called secret vector machine (SecVM), provides an
algorithm for training linear support vector machines (SVM) in a setting in
which data-holding clients communicate with an untrusted server by exchanging
messages designed to not reveal any personally identifiable information. We
evaluate our model in two ways. First, in an offline evaluation, we train SecVM
to predict user gender from tweets, showing that we can preserve user privacy
without sacrificing classification performance. Second, we implement SecVM's
distributed framework for the Cliqz web browser and deploy it for predicting
user gender in a large-scale online evaluation with thousands of clients,
outperforming baselines by a large margin and thus showcasing that SecVM is
suitable for production environments.","['Valentin Hartmann', 'Konark Modi', 'Josep M. Pujol', 'Robert West']","['cs.LG', 'cs.CR', 'stat.ML']",2019-07-08 00:57:10+00:00
http://arxiv.org/abs/1907.04483v2,Copula Representations and Error Surface Projections for the Exclusive Or Problem,"The exclusive or (xor) function is one of the simplest examples that
illustrate why nonlinear feedforward networks are superior to linear regression
for machine learning applications. We review the xor representation and
approximation problems and discuss their solutions in terms of probabilistic
logic and associative copula functions. After briefly reviewing the
specification of feedforward networks, we compare the dynamics of learned error
surfaces with different activation functions such as RELU and tanh through a
set of colorful three-dimensional charts. The copula representations extend xor
from Boolean to real values, thereby providing a convenient way to demonstrate
the concept of cross-validation on in-sample and out-sample data sets. Our
approach is pedagogical and is meant to be a machine learning prolegomenon.",['Roy S. Freedman'],"['cs.LG', 'stat.ML']",2019-07-08 00:20:25+00:00
http://arxiv.org/abs/1907.03361v1,Copula & Marginal Flows: Disentangling the Marginal from its Joint,"Deep generative networks such as GANs and normalizing flows flourish in the
context of high-dimensional tasks such as image generation. However, so far
exact modeling or extrapolation of distributional properties such as the tail
asymptotics generated by a generative network is not available. In this paper,
we address this issue for the first time in the deep learning literature by
making two novel contributions. First, we derive upper bounds for the tails
that can be expressed by a generative network and demonstrate Lp-space related
properties. There we show specifically that in various situations an optimal
generative network does not exist. Second, we introduce and propose copula and
marginal generative flows (CM flows) which allow for an exact modeling of the
tail and any prior assumption on the CDF up to an approximation of the uniform
distribution. Our numerical results support the use of CM flows.","['Magnus Wiese', 'Robert Knobloch', 'Ralf Korn']","['cs.LG', 'stat.ML']",2019-07-07 22:45:26+00:00
http://arxiv.org/abs/1907.03346v3,Individual Regret in Cooperative Nonstochastic Multi-Armed Bandits,"We study agents communicating over an underlying network by exchanging
messages, in order to optimize their individual regret in a common
nonstochastic multi-armed bandit problem. We derive regret minimization
algorithms that guarantee for each agent $v$ an individual expected regret of
$\widetilde{O}\left(\sqrt{\left(1+\frac{K}{\left|\mathcal{N}\left(v\right)\right|}\right)T}\right)$,
where $T$ is the number of time steps, $K$ is the number of actions and
$\mathcal{N}\left(v\right)$ is the set of neighbors of agent $v$ in the
communication graph. We present algorithms both for the case that the
communication graph is known to all the agents, and for the case that the graph
is unknown. When the graph is unknown, each agent knows only the set of its
neighbors and an upper bound on the total number of agents. The individual
regret between the models differs only by a logarithmic factor. Our work
resolves an open problem from [Cesa-Bianchi et al., 2019b].","['Yogev Bar-On', 'Yishay Mansour']","['cs.LG', 'stat.ML']",2019-07-07 20:58:29+00:00
http://arxiv.org/abs/1907.03343v1,Fast and Provable ADMM for Learning with Generative Priors,"In this work, we propose a (linearized) Alternating Direction
Method-of-Multipliers (ADMM) algorithm for minimizing a convex function subject
to a nonconvex constraint. We focus on the special case where such constraint
arises from the specification that a variable should lie in the range of a
neural network. This is motivated by recent successful applications of
Generative Adversarial Networks (GANs) in tasks like compressive sensing,
denoising and robustness against adversarial examples. The derived rates for
our algorithm are characterized in terms of certain geometric properties of the
generator network, which we show hold for feedforward architectures, under mild
assumptions. Unlike gradient descent (GD), it can efficiently handle non-smooth
objectives as well as exploit efficient partial minimization procedures, thus
being faster in many practical scenarios.","['Fabian Latorre Gómez', 'Armin Eftekhari', 'Volkan Cevher']","['cs.LG', 'math.OC', 'stat.ML']",2019-07-07 20:09:58+00:00
http://arxiv.org/abs/1907.03334v1,Case-Based Reasoning for Assisting Domain Experts in Processing Fraud Alerts of Black-Box Machine Learning Models,"In many contexts, it can be useful for domain experts to understand to what
extent predictions made by a machine learning model can be trusted. In
particular, estimates of trustworthiness can be useful for fraud analysts who
process machine learning-generated alerts of fraudulent transactions. In this
work, we present a case-based reasoning (CBR) approach that provides evidence
on the trustworthiness of a prediction in the form of a visualization of
similar previous instances. Different from previous works, we consider
similarity of local post-hoc explanations of predictions and show empirically
that our visualization can be useful for processing alerts. Furthermore, our
approach is perceived useful and easy to use by fraud analysts at a major Dutch
bank.","['Hilde J. P. Weerts', 'Werner van Ipenburg', 'Mykola Pechenizkiy']","['cs.LG', 'cs.HC', 'stat.ML']",2019-07-07 19:12:49+00:00
http://arxiv.org/abs/1907.03329v1,Fast ES-RNN: A GPU Implementation of the ES-RNN Algorithm,"Due to their prevalence, time series forecasting is crucial in multiple
domains. We seek to make state-of-the-art forecasting fast, accessible, and
generalizable. ES-RNN is a hybrid between classical state space forecasting
models and modern RNNs that achieved a 9.4% sMAPE improvement in the M4
competition. Crucially, ES-RNN implementation requires per-time series
parameters. By vectorizing the original implementation and porting the
algorithm to a GPU, we achieve up to 322x training speedup depending on batch
size with similar results as those reported in the original submission. Our
code can be found at: https://github.com/damitkwr/ESRNN-GPU","['Andrew Redd', 'Kaung Khin', 'Aldo Marini']","['cs.LG', 'stat.ML']",2019-07-07 18:23:17+00:00
http://arxiv.org/abs/1907.03324v1,A Human-Grounded Evaluation of SHAP for Alert Processing,"In the past years, many new explanation methods have been proposed to achieve
interpretability of machine learning predictions. However, the utility of these
methods in practical applications has not been researched extensively. In this
paper we present the results of a human-grounded evaluation of SHAP, an
explanation method that has been well-received in the XAI and related
communities. In particular, we study whether this local model-agnostic
explanation method can be useful for real human domain experts to assess the
correctness of positive predictions, i.e. alerts generated by a classifier. We
performed experimentation with three different groups of participants (159 in
total), who had basic knowledge of explainable machine learning. We performed a
qualitative analysis of recorded reflections of experiment participants
performing alert processing with and without SHAP information. The results
suggest that the SHAP explanations do impact the decision-making process,
although the model's confidence score remains to be a leading source of
evidence. We statistically test whether there is a significant difference in
task utility metrics between tasks for which an explanation was available and
tasks in which it was not provided. As opposed to common intuitions, we did not
find a significant difference in alert processing performance when a SHAP
explanation is available compared to when it is not.","['Hilde J. P. Weerts', 'Werner van Ipenburg', 'Mykola Pechenizkiy']","['cs.LG', 'cs.HC', 'stat.ML']",2019-07-07 17:50:06+00:00
http://arxiv.org/abs/1907.04201v3,Thompson Sampling for Combinatorial Network Optimization in Unknown Environments,"Influence maximization, adaptive routing, and dynamic spectrum allocation all
require choosing the right action from a large set of alternatives. Thanks to
the advances in combinatorial optimization, these and many similar problems can
be efficiently solved given an environment with known stochasticity. In this
paper, we take this one step further and focus on combinatorial optimization in
unknown environments. We consider a very general learning framework called
combinatorial multi-armed bandit with probabilistically triggered arms and a
very powerful Bayesian algorithm called Combinatorial Thompson Sampling (CTS).
Under the semi-bandit feedback model and assuming access to an oracle without
knowing the expected base arm outcomes beforehand, we show that when the
expected reward is Lipschitz continuous in the expected base arm outcomes CTS
achieves $O(\sum_{i =1}^m\log T/(p_i\Delta_i))$ regret and
$O(\max\{\mathbb{E}[m\sqrt{T\log T/p^*}],\mathbb{E}[m^2/p^*]\})$ Bayesian
regret, where $m$ denotes the number of base arms, $p_i$ and $\Delta_i$ denote
the minimum non-zero triggering probability and the minimum suboptimality gap
of base arm $i$ respectively, $T$ denotes the time horizon, and $p^*$ denotes
the overall minimum non-zero triggering probability. We also show that when the
expected reward satisfies the triggering probability modulated Lipschitz
continuity, CTS achieves $O(\max\{m\sqrt{T\log T},m^2\})$ Bayesian regret, and
when triggering probabilities are non-zero for all base arms, CTS achieves
$O(1/p^*\log(1/p^*))$ regret independent of the time horizon. Finally, we
numerically compare CTS with algorithms based on upper confidence bounds in
several networking problems and show that CTS outperforms these algorithms by
at least an order of magnitude in majority of the cases.","['Alihan Hüyük', 'Cem Tekin']","['cs.LG', 'stat.ML']",2019-07-07 17:03:00+00:00
http://arxiv.org/abs/1907.03750v1,Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision,"Lack of labeled training data is a major bottleneck for neural network based
aspect and opinion term extraction on product reviews. To alleviate this
problem, we first propose an algorithm to automatically mine extraction rules
from existing training examples based on dependency parsing results. The mined
rules are then applied to label a large amount of auxiliary data. Finally, we
study training procedures to train a neural model which can learn from both the
data automatically labeled by the rules and a small amount of data accurately
annotated by human. Experimental results show that although the mined rules
themselves do not perform well due to their limited flexibility, the
combination of human annotated data and rule labeled auxiliary data can improve
the neural model and allow it to achieve performance better than or comparable
with the current state-of-the-art.","['Hongliang Dai', 'Yangqiu Song']","['cs.CL', 'cs.LG', 'stat.ML']",2019-07-07 12:59:04+00:00
http://arxiv.org/abs/1907.03247v1,Resource-Efficient Computing in Wearable Systems,"We propose two optimization techniques to minimize memory usage and
computation while meeting system timing constraints for real-time
classification in wearable systems. Our method derives a hierarchical
classifier structure for Support Vector Machine (SVM) in order to reduce the
amount of computations, based on the probability distribution of output classes
occurrences. Also, we propose a memory optimization technique based on SVM
parameters, which results in storing fewer support vectors and as a result
requiring less memory. To demonstrate the efficiency of our proposed
techniques, we performed an activity recognition experiment and were able to
save up to 35% and 56% in memory storage when classifying 14 and 6 different
activities, respectively. In addition, we demonstrated that there is a
trade-off between accuracy of classification and memory savings, which can be
controlled based on application requirements.","['Mahdi Pedram', 'Mahsan Rofouei', 'Francesco Fraternali', 'Zhila Esna Ashari', 'Hassan Ghasemzadeh']","['cs.LG', 'stat.ML']",2019-07-07 08:26:30+00:00
http://arxiv.org/abs/1907.03236v2,Quantum-inspired canonical correlation analysis for exponentially large dimensional data,"Canonical correlation analysis (CCA) is a technique to find statistical
dependencies between a pair of multivariate data. However, its application to
high dimensional data is limited due to the resulting time complexity. While
the conventional CCA algorithm requires polynomial time, we have developed an
algorithm that approximates CCA with computational time proportional to the
logarithm of the input dimensionality using quantum-inspired computation. The
computational efficiency and approximation performance of the proposed
quantum-inspired CCA (qiCCA) algorithm are experimentally demonstrated.
Furthermore, the fast computation of qiCCA allows us to directly apply CCA even
after nonlinearly mapping raw input data into very high dimensional spaces.
Experiments performed using a benchmark dataset demonstrated that, by mapping
the raw input data into the high dimensional spaces with second-order
monomials, the proposed qiCCA extracted more correlations than linear CCA and
was comparable to deep CCA and kernel CCA. These results suggest that qiCCA is
considerably useful and quantum-inspired computation has the potential to
unlock a new field in which exponentially large dimensional data can be
analyzed.","['Naoko Koide-Majima', 'Kei Majima']","['cs.LG', 'quant-ph', 'stat.ML']",2019-07-07 07:35:55+00:00
http://arxiv.org/abs/1907.03222v1,IRNet: A General Purpose Deep Residual Regression Framework for Materials Discovery,"Materials discovery is crucial for making scientific advances in many
domains. Collections of data from experiments and first-principle computations
have spurred interest in applying machine learning methods to create predictive
models capable of mapping from composition and crystal structures to materials
properties. Generally, these are regression problems with the input being a 1D
vector composed of numerical attributes representing the material composition
and/or crystal structure. While neural networks consisting of fully connected
layers have been applied to such problems, their performance often suffers from
the vanishing gradient problem when network depth is increased. In this paper,
we study and propose design principles for building deep regression networks
composed of fully connected layers with numerical vectors as input. We
introduce a novel deep regression network with individual residual learning,
IRNet, that places shortcut connections after each layer so that each layer
learns the residual mapping between its output and input. We use the problem of
learning properties of inorganic materials from numerical attributes derived
from material composition and/or crystal structure to compare IRNet's
performance against that of other machine learning techniques. Using multiple
datasets from the Open Quantum Materials Database (OQMD) and Materials Project
for training and evaluation, we show that IRNet provides significantly better
prediction performance than the state-of-the-art machine learning approaches
currently used by domain scientists. We also show that IRNet's use of
individual residual learning leads to better convergence during the training
phase than when shortcut connections are between multi-layer stacks while
maintaining the same number of parameters.","['Dipendra Jha', 'Logan Ward', 'Zijiang Yang', 'Christopher Wolverton', 'Ian Foster', 'Wei-keng Liao', 'Alok Choudhary', 'Ankit Agrawal']","['physics.comp-ph', 'cs.LG', 'stat.ML']",2019-07-07 05:19:35+00:00
http://arxiv.org/abs/1907.03215v7,Stochastic Gradient and Langevin Processes,"We prove quantitative convergence rates at which discrete Langevin-like
processes converge to the invariant distribution of a related stochastic
differential equation. We study the setup where the additive noise can be
non-Gaussian and state-dependent and the potential function can be non-convex.
We show that the key properties of these processes depend on the potential
function and the second moment of the additive noise. We apply our theoretical
findings to studying the convergence of Stochastic Gradient Descent (SGD) for
non-convex problems and corroborate them with experiments using SGD to train
deep neural networks on the CIFAR-10 dataset.","['Xiang Cheng', 'Dong Yin', 'Peter L. Bartlett', 'Michael I. Jordan']","['cs.LG', 'stat.ML']",2019-07-07 03:27:17+00:00
http://arxiv.org/abs/1907.03211v4,Convolutional dictionary learning based auto-encoders for natural exponential-family distributions,"We introduce a class of auto-encoder neural networks tailored to data from
the natural exponential family (e.g., count data). The architectures are
inspired by the problem of learning the filters in a convolutional generative
model with sparsity constraints, often referred to as convolutional dictionary
learning (CDL). Our work is the first to combine ideas from convolutional
generative models and deep learning for data that are naturally modeled with a
non-Gaussian distribution (e.g., binomial and Poisson). This perspective
provides us with a scalable and flexible framework that can be re-purposed for
a wide range of tasks and assumptions on the generative model. Specifically,
the iterative optimization procedure for solving CDL, an unsupervised task, is
mapped to an unfolded and constrained neural network, with iterative
adjustments to the inputs to account for the generative distribution. We also
show that the framework can easily be extended for discriminative training,
appropriate for a supervised task. We demonstrate 1) that fitting the
generative model to learn, in an unsupervised fashion, the latent stimulus that
underlies neural spiking data leads to better goodness-of-fit compared to other
baselines, 2) competitive performance compared to state-of-the-art algorithms
for supervised Poisson image denoising, with significantly fewer parameters,
and 3) gradient dynamics of shallow binomial auto-encoder.","['Bahareh Tolooshams', 'Andrew H. Song', 'Simona Temereanca', 'Demba Ba']","['cs.LG', 'stat.AP', 'stat.ML']",2019-07-07 01:45:42+00:00
http://arxiv.org/abs/1907.03207v1,"Towards Robust, Locally Linear Deep Networks","Deep networks realize complex mappings that are often understood by their
locally linear behavior at or around points of interest. For example, we use
the derivative of the mapping with respect to its inputs for sensitivity
analysis, or to explain (obtain coordinate relevance for) a prediction. One key
challenge is that such derivatives are themselves inherently unstable. In this
paper, we propose a new learning problem to encourage deep networks to have
stable derivatives over larger regions. While the problem is challenging in
general, we focus on networks with piecewise linear activation functions. Our
algorithm consists of an inference step that identifies a region around a point
where linear approximation is provably stable, and an optimization step to
expand such regions. We propose a novel relaxation to scale the algorithm to
realistic models. We illustrate our method with residual and recurrent networks
on image and sequence datasets.","['Guang-He Lee', 'David Alvarez-Melis', 'Tommi S. Jaakkola']","['cs.LG', 'stat.ML']",2019-07-07 00:18:22+00:00
http://arxiv.org/abs/1907.03199v2,What graph neural networks cannot learn: depth vs width,"This paper studies the expressive power of graph neural networks falling
within the message-passing framework (GNNmp). Two results are presented. First,
GNNmp are shown to be Turing universal under sufficient conditions on their
depth, width, node attributes, and layer expressiveness. Second, it is
discovered that GNNmp can lose a significant portion of their power when their
depth and width is restricted. The proposed impossibility statements stem from
a new technique that enables the repurposing of seminal results from
distributed computing and leads to lower bounds for an array of decision,
optimization, and estimation problems involving graphs. Strikingly, several of
these problems are deemed impossible unless the product of a GNNmp's depth and
width exceeds a polynomial of the graph size; this dependence remains
significant even for tasks that appear simple or when considering
approximation.",['Andreas Loukas'],"['cs.LG', 'stat.ML']",2019-07-06 22:26:17+00:00
http://arxiv.org/abs/1907.03192v2,Volume Doubling Condition and a Local Poincaré Inequality on Unweighted Random Geometric Graphs,"The aim of this paper is to establish two fundamental measure-metric
properties of particular random geometric graphs. We consider
$\varepsilon$-neighborhood graphs whose vertices are drawn independently and
identically distributed from a common distribution defined on a regular
submanifold of $\mathbb{R}^K$. We show that a volume doubling condition (VD)
and local Poincar\'e inequality (LPI) hold for the random geometric graph (with
high probability, and uniformly over all shortest path distance balls in a
certain radius range) under suitable regularity conditions of the underlying
submanifold and the sampling distribution.","['Franziska Göbel', 'Gilles Blanchard']","['math.PR', 'cs.LG', 'stat.ML']",2019-07-06 21:36:47+00:00
http://arxiv.org/abs/1907.03190v1,Testing Mixtures of Discrete Distributions,"There has been significant study on the sample complexity of testing
properties of distributions over large domains. For many properties, it is
known that the sample complexity can be substantially smaller than the domain
size. For example, over a domain of size $n$, distinguishing the uniform
distribution from distributions that are far from uniform in $\ell_1$-distance
uses only $O(\sqrt{n})$ samples.
  However, the picture is very different in the presence of arbitrary noise,
even when the amount of noise is quite small. In this case, one must
distinguish if samples are coming from a distribution that is $\epsilon$-close
to uniform from the case where the distribution is $(1-\epsilon)$-far from
uniform. The latter task requires nearly linear in $n$ samples [Valiant 2008,
Valian and Valiant 2011].
  In this work, we present a noise model that on one hand is more tractable for
the testing problem, and on the other hand represents a rich class of noise
families. In our model, the noisy distribution is a mixture of the original
distribution and noise, where the latter is known to the tester either
explicitly or via sample access; the form of the noise is also known a priori.
Focusing on the identity and closeness testing problems leads to the following
mixture testing question: Given samples of distributions $p, q_1,q_2$, can we
test if $p$ is a mixture of $q_1$ and $q_2$? We consider this general question
in various scenarios that differ in terms of how the tester can access the
distributions, and show that indeed this problem is more tractable. Our results
show that the sample complexity of our testers are exactly the same as for the
classical non-mixture case.","['Maryam Aliakbarpour', 'Ravi Kumar', 'Ronitt Rubinfeld']","['math.ST', 'cs.DS', 'stat.ML', 'stat.TH']",2019-07-06 21:24:54+00:00
http://arxiv.org/abs/1907.04928v1,Bag-of-Audio-Words based on Autoencoder Codebook for Continuous Emotion Prediction,"In this paper we present a novel approach for extracting a Bag-of-Words (BoW)
representation based on a Neural Network codebook. The conventional BoW model
is based on a dictionary (codebook) built from elementary representations which
are selected randomly or by using a clustering algorithm on a training dataset.
A metric is then used to assign unseen elementary representations to the
closest dictionary entries in order to produce a histogram. In the proposed
approach, an autoencoder (AE) encompasses the role of both the dictionary
creation and the assignment metric. The dimension of the encoded layer of the
AE corresponds to the size of the dictionary and the output of its neurons
represents the assignment metric. Experimental results for the continuous
emotion prediction task on the AVEC 2017 audio dataset have shown an
improvement of the Concordance Correlation Coefficient (CCC) from 0.225 to
0.322 for arousal dimension and from 0.244 to 0.368 for valence dimension
relative to the conventional BoW version implemented in a baseline system.","['Mohammed Senoussaoui', 'Patrick Cardinal', 'Alessandro Lameiras Koerich']","['eess.AS', 'cs.LG', 'cs.SD', 'stat.ML']",2019-07-06 21:16:53+00:00
http://arxiv.org/abs/1907.03182v1,Towards Testing Monotonicity of Distributions Over General Posets,"In this work, we consider the sample complexity required for testing the
monotonicity of distributions over partial orders. A distribution $p$ over a
poset is monotone if, for any pair of domain elements $x$ and $y$ such that $x
\preceq y$, $p(x) \leq p(y)$. To understand the sample complexity of this
problem, we introduce a new property called bigness over a finite domain, where
the distribution is $T$-big if the minimum probability for any domain element
is at least $T$. We establish a lower bound of $\Omega(n/\log n)$ for testing
bigness of distributions on domains of size $n$. We then build on these lower
bounds to give $\Omega(n/\log{n})$ lower bounds for testing monotonicity over a
matching poset of size $n$ and significantly improved lower bounds over the
hypercube poset. We give sublinear sample complexity bounds for testing bigness
and for testing monotonicity over the matching poset.
  We then give a number of tools for analyzing upper bounds on the sample
complexity of
  the monotonicity testing problem.","['Maryam Aliakbarpour', 'Themis Gouleakis', 'John Peebles', 'Ronitt Rubinfeld', 'Anak Yodpinyanee']","['cs.DS', 'math.ST', 'stat.ML', 'stat.TH']",2019-07-06 20:45:01+00:00
http://arxiv.org/abs/1907.03179v1,Weakly-supervised Knowledge Graph Alignment with Adversarial Learning,"This paper studies aligning knowledge graphs from different sources or
languages. Most existing methods train supervised methods for the alignment,
which usually require a large number of aligned knowledge triplets. However,
such a large number of aligned knowledge triplets may not be available or are
expensive to obtain in many domains. Therefore, in this paper we propose to
study aligning knowledge graphs in fully-unsupervised or weakly-supervised
fashion, i.e., without or with only a few aligned triplets. We propose an
unsupervised framework to align the entity and relation embddings of different
knowledge graphs with an adversarial learning framework. Moreover, a
regularization term which maximizes the mutual information between the
embeddings of different knowledge graphs is used to mitigate the problem of
mode collapse when learning the alignment functions. Such a framework can be
further seamlessly integrated with existing supervised methods by utilizing a
limited number of aligned triples as guidance. Experimental results on multiple
datasets prove the effectiveness of our proposed approach in both the
unsupervised and the weakly-supervised settings.","['Meng Qu', 'Jian Tang', 'Yoshua Bengio']","['cs.LG', 'cs.AI', 'stat.ML']",2019-07-06 20:31:13+00:00
http://arxiv.org/abs/1907.03178v4,XGBoostLSS -- An extension of XGBoost to probabilistic forecasting,"We propose a new framework of XGBoost that predicts the entire conditional
distribution of a univariate response variable. In particular, XGBoostLSS
models all moments of a parametric distribution (i.e., mean, location, scale
and shape [LSS]) instead of the conditional mean only. Choosing from a wide
range of continuous, discrete and mixed discrete-continuous distribution,
modelling and predicting the entire conditional distribution greatly enhances
the flexibility of XGBoost, as it allows to gain additional insight into the
data generating process, as well as to create probabilistic forecasts from
which prediction intervals and quantiles of interest can be derived. We present
both a simulation study and real world examples that demonstrate the virtues of
our approach.",['Alexander März'],"['stat.ML', 'cs.AI', 'cs.LG', 'stat.ME']",2019-07-06 20:25:16+00:00
