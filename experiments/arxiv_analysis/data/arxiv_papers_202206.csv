id,title,abstract,authors,categories,date
http://arxiv.org/abs/2207.11621v3,"A Universal Trade-off Between the Model Size, Test Loss, and Training Loss of Linear Predictors","In this work we establish an algorithm and distribution independent
non-asymptotic trade-off between the model size, excess test loss, and training
loss of linear predictors. Specifically, we show that models that perform well
on the test data (have low excess loss) are either ""classical"" -- have training
loss close to the noise level, or are ""modern"" -- have a much larger number of
parameters compared to the minimum needed to fit the training data exactly.
  We also provide a more precise asymptotic analysis when the limiting spectral
distribution of the whitened features is Marchenko-Pastur. Remarkably, while
the Marchenko-Pastur analysis is far more precise near the interpolation peak,
where the number of parameters is just enough to fit the training data, it
coincides exactly with the distribution independent bound as the level of
overparametrization increases.","['Nikhil Ghosh', 'Mikhail Belkin']","['stat.ML', 'cs.LG']",2022-07-23 23:25:16+00:00
http://arxiv.org/abs/2207.11597v3,Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference,"We present a non-asymptotic lower bound on the eigenspectrum of the design
matrix generated by any linear bandit algorithm with sub-linear regret when the
action set has well-behaved curvature. Specifically, we show that the minimum
eigenvalue of the expected design matrix grows as $\Omega(\sqrt{n})$ whenever
the expected cumulative regret of the algorithm is $O(\sqrt{n})$, where $n$ is
the learning horizon, and the action-space has a constant Hessian around the
optimal arm. This shows that such action-spaces force a polynomial lower bound
rather than a logarithmic lower bound, as shown by \cite{lattimore2017end}, in
discrete (i.e., well-separated) action spaces. Furthermore, while the previous
result is shown to hold only in the asymptotic regime (as $n \to \infty$), our
result for these ""locally rich"" action spaces is any-time. Additionally, under
a mild technical assumption, we obtain a similar lower bound on the minimum
eigen value holding with high probability.
  We apply our result to two practical scenarios -- \emph{model selection} and
\emph{clustering} in linear bandits. For model selection, we show that an
epoch-based linear bandit algorithm adapts to the true model complexity at a
rate exponential in the number of epochs, by virtue of our novel spectral
bound. For clustering, we consider a multi agent framework where we show, by
leveraging the spectral result, that no forced exploration is necessary -- the
agents can run a linear bandit algorithm and estimate their underlying
parameters at once, and hence incur a low regret.","['Debangshu Banerjee', 'Avishek Ghosh', 'Sayak Ray Chowdhury', 'Aditya Gopalan']","['cs.LG', 'cs.AI', 'stat.ML']",2022-07-23 20:25:07+00:00
http://arxiv.org/abs/2207.11251v1,Variational Temporal Deconfounder for Individualized Treatment Effect Estimation from Longitudinal Observational Data,"Estimating treatment effects, especially individualized treatment effects
(ITE), using observational data is challenging due to the complex situations of
confounding bias. Existing approaches for estimating treatment effects from
longitudinal observational data are usually built upon a strong assumption of
""unconfoundedness"", which is hard to fulfill in real-world practice. In this
paper, we propose the Variational Temporal Deconfounder (VTD), an approach that
leverages deep variational embeddings in the longitudinal setting using proxies
(i.e., surrogate variables that serve for unobservable variables).
Specifically, VTD leverages observed proxies to learn a hidden embedding that
reflects the true hidden confounders in the observational data. As such, our
VTD method does not rely on the ""unconfoundedness"" assumption. We test our VTD
method on both synthetic and real-world clinical data, and the results show
that our approach is effective when hidden confounding is the leading bias
compared to other existing models.","['Zheng Feng', 'Mattia Prosperi', 'Jiang Bian']","['stat.ML', 'cs.LG']",2022-07-23 16:43:12+00:00
http://arxiv.org/abs/2207.11385v1,Causal Fairness Analysis,"Decision-making systems based on AI and machine learning have been used
throughout a wide range of real-world scenarios, including healthcare, law
enforcement, education, and finance. It is no longer far-fetched to envision a
future where autonomous systems will be driving entire business decisions and,
more broadly, supporting large-scale decision-making infrastructure to solve
society's most challenging problems. Issues of unfairness and discrimination
are pervasive when decisions are being made by humans, and remain (or are
potentially amplified) when decisions are made using machines with little
transparency, accountability, and fairness. In this paper, we introduce a
framework for \textit{causal fairness analysis} with the intent of filling in
this gap, i.e., understanding, modeling, and possibly solving issues of
fairness in decision-making settings. The main insight of our approach will be
to link the quantification of the disparities present on the observed data with
the underlying, and often unobserved, collection of causal mechanisms that
generate the disparity in the first place, challenge we call the Fundamental
Problem of Causal Fairness Analysis (FPCFA). In order to solve the FPCFA, we
study the problem of decomposing variations and empirical measures of fairness
that attribute such variations to structural mechanisms and different units of
the population. Our effort culminates in the Fairness Map, which is the first
systematic attempt to organize and explain the relationship between different
criteria found in the literature. Finally, we study which causal assumptions
are minimally needed for performing causal fairness analysis and propose a
Fairness Cookbook, which allows data scientists to assess the existence of
disparate impact and disparate treatment.","['Drago Plecko', 'Elias Bareinboim']","['cs.AI', 'cs.LG', 'stat.ML']",2022-07-23 01:06:34+00:00
http://arxiv.org/abs/2207.11353v2,A Supervised Tensor Dimension Reduction-Based Prognostics Model for Applications with Incomplete Imaging Data,"This paper proposes a supervised dimension reduction methodology for tensor
data which has two advantages over most image-based prognostic models. First,
the model does not require tensor data to be complete which expands its
application to incomplete data. Second, it utilizes time-to-failure (TTF) to
supervise the extraction of low-dimensional features which makes the extracted
features more effective for the subsequent prognostic. Besides, an optimization
algorithm is proposed for parameter estimation and closed-form solutions are
derived under certain distributions.","['Chengyu Zhou', 'Xiaolei Fang']","['cs.LG', 'eess.IV', 'stat.ML']",2022-07-22 22:06:17+00:00
http://arxiv.org/abs/2207.11208v2,Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection,"Variational inference has recently emerged as a popular alternative to the
classical Markov chain Monte Carlo (MCMC) in large-scale Bayesian inference.
The core idea is to trade statistical accuracy for computational efficiency. In
this work, we study these statistical and computational trade-offs in
variational inference via a case study in inferential model selection. Focusing
on Gaussian inferential models (or variational approximating families) with
diagonal plus low-rank precision matrices, we initiate a theoretical study of
the trade-offs in two aspects, Bayesian posterior inference error and
frequentist uncertainty quantification error. From the Bayesian posterior
inference perspective, we characterize the error of the variational posterior
relative to the exact posterior. We prove that, given a fixed computation
budget, a lower-rank inferential model produces variational posteriors with a
higher statistical approximation error, but a lower computational error; it
reduces variance in stochastic optimization and, in turn, accelerates
convergence. From the frequentist uncertainty quantification perspective, we
consider the precision matrix of the variational posterior as an uncertainty
estimate, which involves an additional statistical error originating from the
sampling uncertainty of the data. As a consequence, for small datasets, the
inferential model need not be full-rank to achieve optimal estimation error
(even with unlimited computation budget).","['Kush Bhatia', 'Nikki Lijing Kuang', 'Yi-An Ma', 'Yixin Wang']","['stat.ML', 'cs.LG']",2022-07-22 17:16:05+00:00
http://arxiv.org/abs/2207.11165v1,High dimensional stochastic linear contextual bandit with missing covariates,"Recent works in bandit problems adopted lasso convergence theory in the
sequential decision-making setting. Even with fully observed contexts, there
are technical challenges that hinder the application of existing lasso
convergence theory: 1) proving the restricted eigenvalue condition under
conditionally sub-Gaussian noise and 2) accounting for the dependence between
the context variables and the chosen actions. This paper studies the effect of
missing covariates on regret for stochastic linear bandit algorithms. Our work
provides a high-probability upper bound on the regret incurred by the proposed
algorithm in terms of covariate sampling probabilities, showing that the regret
degrades due to missingness by at most $\zeta_{min}^2$, where $\zeta_{min}$ is
the minimum probability of observing covariates in the context vector. We
illustrate our algorithm for the practical application of experimental design
for collecting gene expression data by a sequential selection of class
discriminating DNA probes.","['Byoungwook Jang', 'Julia Nepper', 'Marc Chevrette', 'Jo Handelsman', 'Alfred O. Hero III']","['stat.ML', 'cs.LG']",2022-07-22 16:06:22+00:00
http://arxiv.org/abs/2207.11164v1,Generalized Identifiability Bounds for Mixture Models with Grouped Samples,"Recent work has shown that finite mixture models with $m$ components are
identifiable, while making no assumptions on the mixture components, so long as
one has access to groups of samples of size $2m-1$ which are known to come from
the same mixture component. In this work we generalize that result and show
that, if every subset of $k$ mixture components of a mixture model are linearly
independent, then that mixture model is identifiable with only $(2m-1)/(k-1)$
samples per group. We further show that this value cannot be improved. We prove
an analogous result for a stronger form of identifiability known as
""determinedness"" along with a corresponding lower bound. This independence
assumption almost surely holds if mixture components are chosen randomly from a
$k$-dimensional space. We describe some implications of our results for
multinomial mixture models and topic modeling.","['Robert A. Vandermeulen', 'René Saitenmacher']","['math.ST', 'cs.LG', 'stat.ML', 'stat.TH', '62G07, 62G05']",2022-07-22 16:01:51+00:00
http://arxiv.org/abs/2207.11159v3,Network Revenue Management with Demand Learning and Fair Resource-Consumption Balancing,"In addition to maximizing the total revenue, decision-makers in lots of
industries would like to guarantee balanced consumption across different
resources. For instance, in the retailing industry, ensuring a balanced
consumption of resources from different suppliers enhances fairness and helps
main a healthy channel relationship; in the cloud computing industry,
resource-consumption balance helps increase customer satisfaction and reduce
operational costs. Motivated by these practical needs, this paper studies the
price-based network revenue management (NRM) problem with both demand learning
and fair resource-consumption balancing. We introduce the regularized revenue,
i.e., the total revenue with a balancing regularization, as our objective to
incorporate fair resource-consumption balancing into the revenue maximization
goal. We propose a primal-dual-type online policy with the
Upper-Confidence-Bound (UCB) demand learning method to maximize the regularized
revenue. We adopt several innovative techniques to make our algorithm a unified
and computationally efficient framework for the continuous price set and a wide
class of balancing regularizers. Our algorithm achieves a worst-case regret of
$\widetilde O(N^{5/2}\sqrt{T})$, where $N$ denotes the number of products and
$T$ denotes the number of time periods. Numerical experiments in a few NRM
examples demonstrate the effectiveness of our algorithm in simultaneously
achieving revenue maximization and fair resource-consumption balancing","['Xi Chen', 'Jiameng Lyu', 'Yining Wang', 'Yuan Zhou']","['stat.ML', 'cs.CY', 'cs.LG']",2022-07-22 15:55:49+00:00
http://arxiv.org/abs/2207.11158v3,SPRT-based Efficient Best Arm Identification in Stochastic Bandits,"This paper investigates the best arm identification (BAI) problem in
stochastic multi-armed bandits in the fixed confidence setting. The general
class of the exponential family of bandits is considered. The existing
algorithms for the exponential family of bandits face computational challenges.
To mitigate these challenges, the BAI problem is viewed and analyzed as a
sequential composite hypothesis testing task, and a framework is proposed that
adopts the likelihood ratio-based tests known to be effective for sequential
testing. Based on this test statistic, a BAI algorithm is designed that
leverages the canonical sequential probability ratio tests for arm selection
and is amenable to tractable analysis for the exponential family of bandits.
This algorithm has two key features: (1) its sample complexity is
asymptotically optimal, and (2) it is guaranteed to be $\delta-$PAC. Existing
efficient approaches focus on the Gaussian setting and require Thompson
sampling for the arm deemed the best and the challenger arm. Additionally, this
paper analytically quantifies the computational expense of identifying the
challenger in an existing approach. Finally, numerical experiments are provided
to support the analysis.","['Arpan Mukherjee', 'Ali Tajer']","['stat.ML', 'cs.LG']",2022-07-22 15:54:53+00:00
http://arxiv.org/abs/2207.10939v1,Statistical Hypothesis Testing Based on Machine Learning: Large Deviations Analysis,"We study the performance -- and specifically the rate at which the error
probability converges to zero -- of Machine Learning (ML) classification
techniques. Leveraging the theory of large deviations, we provide the
mathematical conditions for a ML classifier to exhibit error probabilities that
vanish exponentially, say $\sim \exp\left(-n\,I + o(n) \right)$, where $n$ is
the number of informative observations available for testing (or another
relevant parameter, such as the size of the target in an image) and $I$ is the
error rate. Such conditions depend on the Fenchel-Legendre transform of the
cumulant-generating function of the Data-Driven Decision Function (D3F, i.e.,
what is thresholded before the final binary decision is made) learned in the
training phase. As such, the D3F and, consequently, the related error rate $I$,
depend on the given training set, which is assumed of finite size.
Interestingly, these conditions can be verified and tested numerically
exploiting the available dataset, or a synthetic dataset, generated according
to the available information on the underlying statistical model. In other
words, the classification error probability convergence to zero and its rate
can be computed on a portion of the dataset available for training. Coherently
with the large deviations theory, we can also establish the convergence, for
$n$ large enough, of the normalized D3F statistic to a Gaussian distribution.
This property is exploited to set a desired asymptotic false alarm probability,
which empirically turns out to be accurate even for quite realistic values of
$n$. Furthermore, approximate error probability curves $\sim \zeta_n
\exp\left(-n\,I \right)$ are provided, thanks to the refined asymptotic
derivation (often referred to as exact asymptotics), where $\zeta_n$ represents
the most representative sub-exponential terms of the error probabilities.","['Paolo Braca', 'Leonardo M. Millefiori', 'Augusto Aubry', 'Stefano Marano', 'Antonio De Maio', 'Peter Willett']","['stat.ML', 'cs.AI', 'cs.LG', 'eess.SP', 'math.PR', 'stat.AP']",2022-07-22 08:30:10+00:00
http://arxiv.org/abs/2207.10849v1,ASR Error Detection via Audio-Transcript entailment,"Despite improved performances of the latest Automatic Speech Recognition
(ASR) systems, transcription errors are still unavoidable. These errors can
have a considerable impact in critical domains such as healthcare, when used to
help with clinical documentation. Therefore, detecting ASR errors is a critical
first step in preventing further error propagation to downstream applications.
To this end, we propose a novel end-to-end approach for ASR error detection
using audio-transcript entailment. To the best of our knowledge, we are the
first to frame this problem as an end-to-end entailment task between the audio
segment and its corresponding transcript segment. Our intuition is that there
should be a bidirectional entailment between audio and transcript when there is
no recognition error and vice versa. The proposed model utilizes an acoustic
encoder and a linguistic encoder to model the speech and transcript
respectively. The encoded representations of both modalities are fused to
predict the entailment. Since doctor-patient conversations are used in our
experiments, a particular emphasis is placed on medical terms. Our proposed
model achieves classification error rates (CER) of 26.2% on all transcription
errors and 23% on medical errors specifically, leading to improvements upon a
strong baseline by 12% and 15.4%, respectively.","['Nimshi Venkat Meripo', 'Sandeep Konam']","['cs.CL', 'cs.SD', 'eess.AS', 'stat.ML']",2022-07-22 02:47:15+00:00
http://arxiv.org/abs/2207.10786v4,Delayed Feedback in Generalised Linear Bandits Revisited,"The stochastic generalised linear bandit is a well-understood model for
sequential decision-making problems, with many algorithms achieving
near-optimal regret guarantees under immediate feedback. However, the stringent
requirement for immediate rewards is unmet in many real-world applications
where the reward is almost always delayed. We study the phenomenon of delayed
rewards in generalised linear bandits in a theoretical manner. We show that a
natural adaptation of an optimistic algorithm to the delayed feedback achieves
a regret bound where the penalty for the delays is independent of the horizon.
This result significantly improves upon existing work, where the best known
regret bound has the delay penalty increasing with the horizon. We verify our
theoretical results through experiments on simulated data.","['Benjamin Howson', 'Ciara Pike-Burke', 'Sarah Filippi']","['cs.LG', 'stat.ML']",2022-07-21 23:35:01+00:00
http://arxiv.org/abs/2207.10781v1,Data-Driven Stochastic AC-OPF using Gaussian Processes,"In recent years, electricity generation has been responsible for more than a
quarter of the greenhouse gas emissions in the US. Integrating a significant
amount of renewables into a power grid is probably the most accessible way to
reduce carbon emissions from power grids and slow down climate change.
Unfortunately, the most accessible renewable power sources, such as wind and
solar, are highly fluctuating and thus bring a lot of uncertainty to power grid
operations and challenge existing optimization and control policies. The
chance-constrained alternating current (AC) optimal power flow (OPF) framework
finds the minimum cost generation dispatch maintaining the power grid
operations within security limits with a prescribed probability. Unfortunately,
the AC-OPF problem's chance-constrained extension is non-convex,
computationally challenging, and requires knowledge of system parameters and
additional assumptions on the behavior of renewable distribution. Known linear
and convex approximations to the above problems, though tractable, are too
conservative for operational practice and do not consider uncertainty in system
parameters. This paper presents an alternative data-driven approach based on
Gaussian process (GP) regression to close this gap. The GP approach learns a
simple yet non-convex data-driven approximation to the AC power flow equations
that can incorporate uncertainty inputs. The latter is then used to determine
the solution of CC-OPF efficiently, by accounting for both input and parameter
uncertainty. The practical efficiency of the proposed approach using different
approximations for GP-uncertainty propagation is illustrated over numerous IEEE
test cases.","['Mile Mitrovic', 'Aleksandr Lukashevich', 'Petr Vorobev', 'Vladimir Terzija', 'Semen Budenny', 'Yury Maximov', 'Deepjyoti Deka']","['stat.ML', 'cs.LG', 'cs.SY', 'eess.SY']",2022-07-21 23:02:35+00:00
http://arxiv.org/abs/2207.12124v1,Inference of Regulatory Networks Through Temporally Sparse Data,"A major goal in genomics is to properly capture the complex dynamical
behaviors of gene regulatory networks (GRNs). This includes inferring the
complex interactions between genes, which can be used for a wide range of
genomics analyses, including diagnosis or prognosis of diseases and finding
effective treatments for chronic diseases such as cancer. Boolean networks have
emerged as a successful class of models for capturing the behavior of GRNs. In
most practical settings, inference of GRNs should be achieved through limited
and temporally sparse genomics data. A large number of genes in GRNs leads to a
large possible topology candidate space, which often cannot be exhaustively
searched due to the limitation in computational resources. This paper develops
a scalable and efficient topology inference for GRNs using Bayesian
optimization and kernel-based methods. Rather than an exhaustive search over
possible topologies, the proposed method constructs a Gaussian Process (GP)
with a topology-inspired kernel function to account for correlation in the
likelihood function. Then, using the posterior distribution of the GP model,
the Bayesian optimization efficiently searches for the topology with the
highest likelihood value by optimally balancing between exploration and
exploitation. The performance of the proposed method is demonstrated through
comprehensive numerical experiments using a well-known mammalian cell-cycle
network.","['Mohammad Alali', 'Mahdi Imani']","['q-bio.MN', 'cs.LG', 'stat.ME', 'stat.ML', '62M05']",2022-07-21 22:48:12+00:00
http://arxiv.org/abs/2207.10772v1,Deep Sufficient Representation Learning via Mutual Information,"We propose a mutual information-based sufficient representation learning
(MSRL) approach, which uses the variational formulation of the mutual
information and leverages the approximation power of deep neural networks. MSRL
learns a sufficient representation with the maximum mutual information with the
response and a user-selected distribution. It can easily handle
multi-dimensional continuous or categorical response variables. MSRL is shown
to be consistent in the sense that the conditional probability density function
of the response variable given the learned representation converges to the
conditional probability density function of the response variable given the
predictor. Non-asymptotic error bounds for MSRL are also established under
suitable conditions. To establish the error bounds, we derive a generalized
Dudley's inequality for an order-two U-process indexed by deep neural networks,
which may be of independent interest. We discuss how to determine the intrinsic
dimension of the underlying data distribution. Moreover, we evaluate the
performance of MSRL via extensive numerical experiments and real data analysis
and demonstrate that MSRL outperforms some existing nonlinear sufficient
dimension reduction methods.","['Siming Zheng', 'Yuanyuan Lin', 'Jian Huang']","['stat.ML', 'cs.LG', '62G05, 68T07']",2022-07-21 22:13:21+00:00
http://arxiv.org/abs/2207.10716v2,JAWS: Auditing Predictive Uncertainty Under Covariate Shift,"We propose \textbf{JAWS}, a series of wrapper methods for distribution-free
uncertainty quantification tasks under covariate shift, centered on the core
method \textbf{JAW}, the \textbf{JA}ckknife+ \textbf{W}eighted with
data-dependent likelihood-ratio weights. JAWS also includes computationally
efficient \textbf{A}pproximations of JAW using higher-order influence
functions: \textbf{JAWA}. Theoretically, we show that JAW relaxes the
jackknife+'s assumption of data exchangeability to achieve the same
finite-sample coverage guarantee even under covariate shift. JAWA further
approaches the JAW guarantee in the limit of the sample size or the influence
function order under common regularity assumptions. Moreover, we propose a
general approach to repurposing predictive interval-generating methods and
their guarantees to the reverse task: estimating the probability that a
prediction is erroneous, based on user-specified error criteria such as a safe
or acceptable tolerance threshold around the true label. We then propose
\textbf{JAW-E} and \textbf{JAWA-E} as the repurposed proposed methods for this
\textbf{E}rror assessment task. Practically, JAWS outperform state-of-the-art
predictive inference baselines in a variety of biased real world data sets for
interval-generation and error-assessment predictive uncertainty auditing tasks.","['Drew Prinster', 'Anqi Liu', 'Suchi Saria']","['cs.LG', 'stat.ML']",2022-07-21 19:12:33+00:00
http://arxiv.org/abs/2207.10673v2,Correcting Model Bias with Sparse Implicit Processes,"Model selection in machine learning (ML) is a crucial part of the Bayesian
learning procedure. Model choice may impose strong biases on the resulting
predictions, which can hinder the performance of methods such as Bayesian
neural networks and neural samplers. On the other hand, newly proposed
approaches for Bayesian ML exploit features of approximate inference in
function space with implicit stochastic processes (a generalization of Gaussian
processes). The approach of Sparse Implicit Processes (SIP) is particularly
successful in this regard, since it is fully trainable and achieves flexible
predictions. Here, we expand on the original experiments to show that SIP is
capable of correcting model bias when the data generating mechanism differs
strongly from the one implied by the model. We use synthetic datasets to show
that SIP is capable of providing predictive distributions that reflect the data
better than the exact predictions of the initial, but wrongly assumed model.","['Simón Rodríguez Santana', 'Luis A. Ortega', 'Daniel Hernández-Lobato', 'Bryan Zaldívar']","['stat.ML', 'cs.LG', 'stat.CO']",2022-07-21 18:00:01+00:00
http://arxiv.org/abs/2207.10541v3,Unveiling the Latent Space Geometry of Push-Forward Generative Models,"Many deep generative models are defined as a push-forward of a Gaussian
measure by a continuous generator, such as Generative Adversarial Networks
(GANs) or Variational Auto-Encoders (VAEs). This work explores the latent space
of such deep generative models. A key issue with these models is their tendency
to output samples outside of the support of the target distribution when
learning disconnected distributions. We investigate the relationship between
the performance of these models and the geometry of their latent space.
Building on recent developments in geometric measure theory, we prove a
sufficient condition for optimality in the case where the dimension of the
latent space is larger than the number of modes. Through experiments on GANs,
we demonstrate the validity of our theoretical results and gain new insights
into the latent space geometry of these models. Additionally, we propose a
truncation method that enforces a simplicial cluster structure in the latent
space and improves the performance of GANs.","['Thibaut Issenhuth', 'Ugo Tanielian', 'Jérémie Mary', 'David Picard']","['cs.LG', 'cs.AI', 'stat.ML']",2022-07-21 15:29:35+00:00
http://arxiv.org/abs/2207.10539v1,Estimating value at risk: LSTM vs. GARCH,"Estimating value-at-risk on time series data with possibly heteroscedastic
dynamics is a highly challenging task. Typically, we face a small data problem
in combination with a high degree of non-linearity, causing difficulties for
both classical and machine-learning estimation algorithms. In this paper, we
propose a novel value-at-risk estimator using a long short-term memory (LSTM)
neural network and compare its performance to benchmark GARCH estimators.
  Our results indicate that even for a relatively short time series, the LSTM
could be used to refine or monitor risk estimation processes and correctly
identify the underlying risk dynamics in a non-parametric fashion. We evaluate
the estimator on both simulated and market data with a focus on
heteroscedasticity, finding that LSTM exhibits a similar performance to GARCH
estimators on simulated data, whereas on real market data it is more sensitive
towards increasing or decreasing volatility and outperforms all existing
estimators of value-at-risk in terms of exception rate and mean quantile score.","['Weronika Ormaniec', 'Marcin Pitera', 'Sajad Safarveisi', 'Thorsten Schmidt']","['q-fin.RM', 'q-fin.ST', 'stat.ML']",2022-07-21 15:26:07+00:00
http://arxiv.org/abs/2207.11228v1,Classifying Crop Types using Gaussian Bayesian Models and Neural Networks on GHISACONUS USGS data from NASA Hyperspectral Satellite Imagery,"Hyperspectral Imagining is a type of digital imaging in which each pixel
contains typically hundreds of wavelengths of light providing spectroscopic
information about the materials present in the pixel. In this paper we provide
classification methods for determining crop type in the USGS GHISACONUS data,
which contains around 7,000 pixel spectra from the five major U.S. agricultural
crops (winter wheat, rice, corn, soybeans, and cotton) collected by the NASA
Hyperion satellite, and includes the spectrum, geolocation, crop type, and
stage of growth for each pixel. We apply standard LDA and QDA as well as
Bayesian custom versions that compute the joint probability of crop type and
stage, and then the marginal probability for crop type, outperforming the
non-Bayesian methods. We also test a single layer neural network with dropout
on the data, which performs comparable to LDA and QDA but not as well as the
Bayesian methods.",['Bill Basener'],"['cs.CV', 'cs.AI', 'stat.AP', 'stat.ML', '92-08, 68T37, 92C55']",2022-07-21 14:22:05+00:00
http://arxiv.org/abs/2207.10486v1,Bayesian Recurrent Units and the Forward-Backward Algorithm,"Using Bayes's theorem, we derive a unit-wise recurrence as well as a backward
recursion similar to the forward-backward algorithm. The resulting Bayesian
recurrent units can be integrated as recurrent neural networks within deep
learning frameworks, while retaining a probabilistic interpretation from the
direct correspondence with hidden Markov models. Whilst the contribution is
mainly theoretical, experiments on speech recognition indicate that adding the
derived units at the end of state-of-the-art recurrent architectures can
improve the performance at a very low cost in terms of trainable parameters.","['Alexandre Bittar', 'Philip N. Garner']","['stat.ML', 'cs.LG']",2022-07-21 14:00:52+00:00
http://arxiv.org/abs/2207.10442v1,Estimation of Non-Crossing Quantile Regression Process with Deep ReQU Neural Networks,"We propose a penalized nonparametric approach to estimating the quantile
regression process (QRP) in a nonseparable model using rectifier quadratic unit
(ReQU) activated deep neural networks and introduce a novel penalty function to
enforce non-crossing of quantile regression curves. We establish the
non-asymptotic excess risk bounds for the estimated QRP and derive the mean
integrated squared error for the estimated QRP under mild smoothness and
regularity conditions. To establish these non-asymptotic risk and estimation
error bounds, we also develop a new error bound for approximating $C^s$ smooth
functions with $s >0$ and their derivatives using ReQU activated neural
networks. This is a new approximation result for ReQU networks and is of
independent interest and may be useful in other problems. Our numerical
experiments demonstrate that the proposed method is competitive with or
outperforms two existing methods, including methods using reproducing kernels
and random forests, for nonparametric quantile regression.","['Guohao Shen', 'Yuling Jiao', 'Yuanyuan Lin', 'Joel L. Horowitz', 'Jian Huang']","['stat.ML', 'cs.LG', '62G05, 62G08, 68T07']",2022-07-21 12:26:45+00:00
http://arxiv.org/abs/2207.10334v1,Efficient Search of Multiple Neural Architectures with Different Complexities via Importance Sampling,"Neural architecture search (NAS) aims to automate architecture design
processes and improve the performance of deep neural networks. Platform-aware
NAS methods consider both performance and complexity and can find
well-performing architectures with low computational resources. Although
ordinary NAS methods result in tremendous computational costs owing to the
repetition of model training, one-shot NAS, which trains the weights of a
supernetwork containing all candidate architectures only once during the search
process, has been reported to result in a lower search cost. This study focuses
on the architecture complexity-aware one-shot NAS that optimizes the objective
function composed of the weighted sum of two metrics, such as the predictive
performance and number of parameters. In existing methods, the architecture
search process must be run multiple times with different coefficients of the
weighted sum to obtain multiple architectures with different complexities. This
study aims at reducing the search cost associated with finding multiple
architectures. The proposed method uses multiple distributions to generate
architectures with different complexities and updates each distribution using
the samples obtained from multiple distributions based on importance sampling.
The proposed method allows us to obtain multiple architectures with different
complexities in a single architecture search, resulting in reducing the search
cost. The proposed method is applied to the architecture search of
convolutional neural networks on the CIAFR-10 and ImageNet datasets.
Consequently, compared with baseline methods, the proposed method finds
multiple architectures with varying complexities while requiring less
computational effort.","['Yuhei Noda', 'Shota Saito', 'Shinichi Shirakawa']","['cs.NE', 'cs.LG', 'stat.ML']",2022-07-21 07:06:03+00:00
http://arxiv.org/abs/2207.10283v3,One-vs-the-Rest Loss to Focus on Important Samples in Adversarial Training,"This paper proposes a new loss function for adversarial training. Since
adversarial training has difficulties, e.g., necessity of high model capacity,
focusing on important data points by weighting cross-entropy loss has attracted
much attention. However, they are vulnerable to sophisticated attacks, e.g.,
Auto-Attack. This paper experimentally reveals that the cause of their
vulnerability is their small margins between logits for the true label and the
other labels. Since neural networks classify the data points based on the
logits, logit margins should be large enough to avoid flipping the largest
logit by the attacks. Importance-aware methods do not increase logit margins of
important samples but decrease those of less-important samples compared with
cross-entropy loss. To increase logit margins of important samples, we propose
switching one-vs-the-rest loss (SOVR), which switches from cross-entropy to
one-vs-the-rest loss for important samples that have small logit margins. We
prove that one-vs-the-rest loss increases logit margins two times larger than
the weighted cross-entropy loss for a simple problem. We experimentally confirm
that SOVR increases logit margins of important samples unlike existing methods
and achieves better robustness against Auto-Attack than importance-aware
methods.","['Sekitoshi Kanai', ""Shin'ya Yamaguchi"", 'Masanori Yamada', 'Hiroshi Takahashi', 'Kentaro Ohno', 'Yasutoshi Ida']","['cs.LG', 'cs.AI', 'stat.ML']",2022-07-21 03:28:25+00:00
http://arxiv.org/abs/2207.10231v2,On minimax density estimation via measure transport,"We study the convergence properties, in Hellinger and related distances, of
nonparametric density estimators based on measure transport. These estimators
represent the measure of interest as the pushforward of a chosen reference
distribution under a transport map, where the map is chosen via a maximum
likelihood objective (equivalently, minimizing an empirical Kullback-Leibler
loss) or a penalized version thereof. We establish concentration inequalities
for a general class of penalized measure transport estimators, by combining
techniques from M-estimation with analytical properties of the transport-based
density representation. We then demonstrate the implications of our theory for
the case of triangular Knothe-Rosenblatt (KR) transports on the $d$-dimensional
unit cube, and show that both penalized and unpenalized versions of such
estimators achieve minimax optimal convergence rates over H\""older classes of
densities. Specifically, we establish optimal rates for unpenalized
nonparametric maximum likelihood estimation over bounded H\""older-type balls,
and then for certain Sobolev-penalized estimators and sieved wavelet
estimators.","['Sven Wang', 'Youssef Marzouk']","['math.ST', 'math.PR', 'stat.ML', 'stat.TH', '62G07, 62G20']",2022-07-20 23:56:00+00:00
http://arxiv.org/abs/2207.10199v2,Provably tuning the ElasticNet across instances,"An important unresolved challenge in the theory of regularization is to set
the regularization coefficients of popular techniques like the ElasticNet with
general provable guarantees. We consider the problem of tuning the
regularization parameters of Ridge regression, LASSO, and the ElasticNet across
multiple problem instances, a setting that encompasses both cross-validation
and multi-task hyperparameter optimization. We obtain a novel structural result
for the ElasticNet which characterizes the loss as a function of the tuning
parameters as a piecewise-rational function with algebraic boundaries. We use
this to bound the structural complexity of the regularized loss functions and
show generalization guarantees for tuning the ElasticNet regression
coefficients in the statistical setting. We also consider the more challenging
online learning setting, where we show vanishing average expected regret
relative to the optimal parameter pair. We further extend our results to tuning
classification algorithms obtained by thresholding regression fits regularized
by Ridge, LASSO, or ElasticNet. Our results are the first general
learning-theoretic guarantees for this important class of problems that avoid
strong assumptions on the data distribution. Furthermore, our guarantees hold
for both validation and popular information criterion objectives.","['Maria-Florina Balcan', 'Mikhail Khodak', 'Dravyansh Sharma', 'Ameet Talwalkar']","['cs.LG', 'stat.ML']",2022-07-20 21:22:40+00:00
http://arxiv.org/abs/2207.10074v2,Semantic uncertainty intervals for disentangled latent spaces,"Meaningful uncertainty quantification in computer vision requires reasoning
about semantic information -- say, the hair color of the person in a photo or
the location of a car on the street. To this end, recent breakthroughs in
generative modeling allow us to represent semantic information in disentangled
latent spaces, but providing uncertainties on the semantic latent variables has
remained challenging. In this work, we provide principled uncertainty intervals
that are guaranteed to contain the true semantic factors for any underlying
generative model. The method does the following: (1) it uses quantile
regression to output a heuristic uncertainty interval for each element in the
latent space (2) calibrates these uncertainties such that they contain the true
value of the latent for a new, unseen input. The endpoints of these calibrated
intervals can then be propagated through the generator to produce interpretable
uncertainty visualizations for each semantic factor. This technique reliably
communicates semantically meaningful, principled, and instance-adaptive
uncertainty in inverse problems like image super-resolution and image
completion.","['Swami Sankaranarayanan', 'Anastasios N. Angelopoulos', 'Stephen Bates', 'Yaniv Romano', 'Phillip Isola']","['cs.CV', 'cs.AI', 'cs.LG', 'stat.ML']",2022-07-20 17:58:10+00:00
http://arxiv.org/abs/2207.10046v1,Adaptive Step-Size Methods for Compressed SGD,"Compressed Stochastic Gradient Descent (SGD) algorithms have been recently
proposed to address the communication bottleneck in distributed and
decentralized optimization problems, such as those that arise in federated
machine learning. Existing compressed SGD algorithms assume the use of
non-adaptive step-sizes(constant or diminishing) to provide theoretical
convergence guarantees. Typically, the step-sizes are fine-tuned in practice to
the dataset and the learning algorithm to provide good empirical performance.
Such fine-tuning might be impractical in many learning scenarios, and it is
therefore of interest to study compressed SGD using adaptive step-sizes.
Motivated by prior work on adaptive step-size methods for SGD to train neural
networks efficiently in the uncompressed setting, we develop an adaptive
step-size method for compressed SGD. In particular, we introduce a scaling
technique for the descent step in compressed SGD, which we use to establish
order-optimal convergence rates for convex-smooth and strong convex-smooth
objectives under an interpolation condition and for non-convex objectives under
a strong growth condition. We also show through simulation examples that
without this scaling, the algorithm can fail to converge. We present
experimental results on deep neural networks for real-world datasets, and
compare the performance of our proposed algorithm with previously proposed
compressed SGD methods in literature, and demonstrate improved performance on
ResNet-18, ResNet-34 and DenseNet architectures for CIFAR-100 and CIFAR-10
datasets at various levels of compression.","['Adarsh M. Subramaniam', 'Akshayaa Magesh', 'Venugopal V. Veeravalli']","['stat.ML', 'cs.LG']",2022-07-20 17:20:58+00:00
http://arxiv.org/abs/2207.09960v1,Measuring and signing fairness as performance under multiple stakeholder distributions,"As learning machines increase their influence on decisions concerning human
lives, analyzing their fairness properties becomes a subject of central
importance. Yet, our best tools for measuring the fairness of learning systems
are rigid fairness metrics encapsulated as mathematical one-liners, offer
limited power to the stakeholders involved in the prediction task, and are easy
to manipulate when we exhort excessive pressure to optimize them. To advance
these issues, we propose to shift focus from shaping fairness metrics to
curating the distributions of examples under which these are computed. In
particular, we posit that every claim about fairness should be immediately
followed by the tagline ""Fair under what examples, and collected by whom?"". By
highlighting connections to the literature in domain generalization, we propose
to measure fairness as the ability of the system to generalize under multiple
stress tests -- distributions of examples with social relevance. We encourage
each stakeholder to curate one or multiple stress tests containing examples
reflecting their (possibly conflicting) interests. The machine passes or fails
each stress test by falling short of or exceeding a pre-defined metric value.
The test results involve all stakeholders in a discussion about how to improve
the learning system, and provide flexible assessments of fairness dependent on
context and based on interpretable data. We provide full implementation
guidelines for stress testing, illustrate both the benefits and shortcomings of
this framework, and introduce a cryptographic scheme to enable a degree of
prediction accountability from system providers.","['David Lopez-Paz', 'Diane Bouchacourt', 'Levent Sagun', 'Nicolas Usunier']","['stat.ML', 'cs.CY', 'cs.LG']",2022-07-20 15:10:02+00:00
http://arxiv.org/abs/2207.09944v4,Probable Domain Generalization via Quantile Risk Minimization,"Domain generalization (DG) seeks predictors which perform well on unseen test
distributions by leveraging data drawn from multiple related training
distributions or domains. To achieve this, DG is commonly formulated as an
average- or worst-case problem over the set of possible domains. However,
predictors that perform well on average lack robustness while predictors that
perform well in the worst case tend to be overly-conservative. To address this,
we propose a new probabilistic framework for DG where the goal is to learn
predictors that perform well with high probability. Our key idea is that
distribution shifts seen during training should inform us of probable shifts at
test time, which we realize by explicitly relating training and test domains as
draws from the same underlying meta-distribution. To achieve probable DG, we
propose a new optimization problem called Quantile Risk Minimization (QRM). By
minimizing the $\alpha$-quantile of predictor's risk distribution over domains,
QRM seeks predictors that perform well with probability $\alpha$. To solve QRM
in practice, we propose the Empirical QRM (EQRM) algorithm and provide: (i) a
generalization bound for EQRM; and (ii) the conditions under which EQRM
recovers the causal predictor as $\alpha \to 1$. In our experiments, we
introduce a more holistic quantile-focused evaluation protocol for DG and
demonstrate that EQRM outperforms state-of-the-art baselines on datasets from
WILDS and DomainBed.","['Cian Eastwood', 'Alexander Robey', 'Shashank Singh', 'Julius von Kügelgen', 'Hamed Hassani', 'George J. Pappas', 'Bernhard Schölkopf']","['stat.ML', 'cs.AI', 'cs.CV', 'cs.LG']",2022-07-20 14:41:09+00:00
http://arxiv.org/abs/2207.09874v5,Stream-based active learning with linear models,"The proliferation of automated data collection schemes and the advances in
sensorics are increasing the amount of data we are able to monitor in
real-time. However, given the high annotation costs and the time required by
quality inspections, data is often available in an unlabeled form. This is
fostering the use of active learning for the development of soft sensors and
predictive models. In production, instead of performing random inspections to
obtain product information, labels are collected by evaluating the information
content of the unlabeled data. Several query strategy frameworks for regression
have been proposed in the literature but most of the focus has been dedicated
to the static pool-based scenario. In this work, we propose a new strategy for
the stream-based scenario, where instances are sequentially offered to the
learner, which must instantaneously decide whether to perform the quality check
to obtain the label or discard the instance. The approach is inspired by the
optimal experimental design theory and the iterative aspect of the
decision-making process is tackled by setting a threshold on the
informativeness of the unlabeled data points. The proposed approach is
evaluated using numerical simulations and the Tennessee Eastman Process
simulator. The results confirm that selecting the examples suggested by the
proposed algorithm allows for a faster reduction in the prediction error.","['Davide Cacciarelli', 'Murat Kulahci', 'John Sølve Tyssedal']","['stat.ML', 'cs.LG']",2022-07-20 13:15:23+00:00
http://arxiv.org/abs/2207.09821v3,Journal Impact Factor and Peer Review Thoroughness and Helpfulness: A Supervised Machine Learning Study,"The journal impact factor (JIF) is often equated with journal quality and the
quality of the peer review of the papers submitted to the journal. We examined
the association between the content of peer review and JIF by analysing 10,000
peer review reports submitted to 1,644 medical and life sciences journals. Two
researchers hand-coded a random sample of 2,000 sentences. We then trained
machine learning models to classify all 187,240 sentences as contributing or
not contributing to content categories. We examined the association between ten
groups of journals defined by JIF deciles and the content of peer reviews using
linear mixed-effects models, adjusting for the length of the review. The JIF
ranged from 0.21 to 74.70. The length of peer reviews increased from the lowest
(median number of words 185) to the JIF group (387 words). The proportion of
sentences allocated to different content categories varied widely, even within
JIF groups. For thoroughness, sentences on 'Materials and Methods' were more
common in the highest JIF journals than in the lowest JIF group (difference of
7.8 percentage points; 95% CI 4.9 to 10.7%). The trend for 'Presentation and
Reporting' went in the opposite direction, with the highest JIF journals giving
less emphasis to such content (difference -8.9%; 95% CI -11.3 to -6.5%). For
helpfulness, reviews for higher JIF journals devoted less attention to
'Suggestion and Solution' and provided fewer Examples than lower impact factor
journals. No, or only small differences were evident for other content
categories. In conclusion, peer review in journals with higher JIF tends to be
more thorough in discussing the methods used but less helpful in terms of
suggesting solutions and providing examples. Differences were modest and
variability high, indicating that the JIF is a bad predictor for the quality of
peer review of an individual manuscript.","['Anna Severin', 'Michaela Strinzel', 'Matthias Egger', 'Tiago Barros', 'Alexander Sokolov', 'Julia Vilstrup Mouatt', 'Stefan Müller']","['cs.DL', 'cs.LG', 'stat.ML']",2022-07-20 11:14:15+00:00
http://arxiv.org/abs/2207.09768v4,Learning Counterfactually Invariant Predictors,"Notions of counterfactual invariance (CI) have proven essential for
predictors that are fair, robust, and generalizable in the real world. We
propose graphical criteria that yield a sufficient condition for a predictor to
be counterfactually invariant in terms of a conditional independence in the
observational distribution. In order to learn such predictors, we propose a
model-agnostic framework, called Counterfactually Invariant Prediction (CIP),
building on the Hilbert-Schmidt Conditional Independence Criterion (HSCIC), a
kernel-based conditional dependence measure. Our experimental results
demonstrate the effectiveness of CIP in enforcing counterfactual invariance
across various simulated and real-world datasets including scalar and
multi-variate settings.","['Francesco Quinzan', 'Cecilia Casolo', 'Krikamol Muandet', 'Yucen Luo', 'Niki Kilbertus']","['cs.LG', 'stat.ML']",2022-07-20 09:23:35+00:00
http://arxiv.org/abs/2207.09688v2,Intrinsic dimension estimation for discrete metrics,"Real world-datasets characterized by discrete features are ubiquitous: from
categorical surveys to clinical questionnaires, from unweighted networks to DNA
sequences. Nevertheless, the most common unsupervised dimensional reduction
methods are designed for continuous spaces, and their use for discrete spaces
can lead to errors and biases. In this letter we introduce an algorithm to
infer the intrinsic dimension (ID) of datasets embedded in discrete spaces. We
demonstrate its accuracy on benchmark datasets, and we apply it to analyze a
metagenomic dataset for species fingerprinting, finding a surprisingly small
ID, of order 2. This suggests that evolutive pressure acts on a low-dimensional
manifold despite the high-dimensionality of sequences' space.","['Iuri Macocco', 'Aldo Glielmo', 'Jacopo Grilli', 'Alessandro Laio']","['stat.ML', 'cs.LG', 'physics.comp-ph']",2022-07-20 06:38:36+00:00
http://arxiv.org/abs/2207.09660v2,Alternating minimization for generalized rank one matrix sensing: Sharp predictions from a random initialization,"We consider the problem of estimating the factors of a rank-$1$ matrix with
i.i.d. Gaussian, rank-$1$ measurements that are nonlinearly transformed and
corrupted by noise. Considering two prototypical choices for the nonlinearity,
we study the convergence properties of a natural alternating update rule for
this nonconvex optimization problem starting from a random initialization. We
show sharp convergence guarantees for a sample-split version of the algorithm
by deriving a deterministic recursion that is accurate even in high-dimensional
problems. Notably, while the infinite-sample population update is uninformative
and suggests exact recovery in a single step, the algorithm -- and our
deterministic prediction -- converges geometrically fast from a random
initialization. Our sharp, non-asymptotic analysis also exposes several other
fine-grained properties of this problem, including how the nonlinearity and
noise level affect convergence behavior.
  On a technical level, our results are enabled by showing that the empirical
error recursion can be predicted by our deterministic sequence within
fluctuations of the order $n^{-1/2}$ when each iteration is run with $n$
observations. Our technique leverages leave-one-out tools originating in the
literature on high-dimensional $M$-estimation and provides an avenue for
sharply analyzing higher-order iterative algorithms from a random
initialization in other high-dimensional optimization problems with random
data.","['Kabir Aladin Chandrasekher', 'Mengqi Lou', 'Ashwin Pananjady']","['math.OC', 'math.PR', 'math.ST', 'stat.ML', 'stat.TH']",2022-07-20 05:31:05+00:00
http://arxiv.org/abs/2207.09560v3,Holistic Robust Data-Driven Decisions,"The design of data-driven formulations for machine learning and
decision-making with good out-of-sample performance is a key challenge. The
observation that good in-sample performance does not guarantee good
out-of-sample performance is generally known as overfitting. Practical
overfitting can typically not be attributed to a single cause but instead is
caused by several factors all at once. We consider here three overfitting
sources: (i) statistical error as a result of working with finite sample data,
(ii) data noise which occurs when the data points are measured only with finite
precision, and finally (iii) data misspecification in which a small fraction of
all data may be wholly corrupted. We argue that although existing data-driven
formulations may be robust against one of these three sources in isolation they
do not provide holistic protection against all overfitting sources
simultaneously. We design a novel data-driven formulation which does guarantee
such holistic protection and is furthermore computationally viable. Our
distributionally robust optimization formulation can be interpreted as a novel
combination of a Kullback-Leibler and Levy-Prokhorov robust optimization
formulation which is novel in its own right. However, we show how in the
context of classification and regression problems that several popular
regularized and robust formulations reduce to a particular case of our proposed
novel formulation. Finally, we apply the proposed HR formulation on a portfolio
selection problem with real stock data, and analyze its risk/return tradeoff
against several benchmarks formulations. Our experiments show that our novel
ambiguity set provides a significantly better risk/return trade-off.","['Amine Bennouna', 'Bart Van Parys']","['stat.ML', 'cs.LG']",2022-07-19 21:28:51+00:00
http://arxiv.org/abs/2207.09535v1,Forget-me-not! Contrastive Critics for Mitigating Posterior Collapse,"Variational autoencoders (VAEs) suffer from posterior collapse, where the
powerful neural networks used for modeling and inference optimize the objective
without meaningfully using the latent representation. We introduce inference
critics that detect and incentivize against posterior collapse by requiring
correspondence between latent variables and the observations. By connecting the
critic's objective to the literature in self-supervised contrastive
representation learning, we show both theoretically and empirically that
optimizing inference critics increases the mutual information between
observations and latents, mitigating posterior collapse. This approach is
straightforward to implement and requires significantly less training time than
prior methods, yet obtains competitive results on three established datasets.
Overall, the approach lays the foundation to bridge the previously disconnected
frameworks of contrastive learning and probabilistic modeling with variational
autoencoders, underscoring the benefits both communities may find at their
intersection.","['Sachit Menon', 'David Blei', 'Carl Vondrick']","['cs.LG', 'stat.ML']",2022-07-19 20:07:17+00:00
http://arxiv.org/abs/2207.09511v1,Approximation Power of Deep Neural Networks: an explanatory mathematical survey,"The goal of this survey is to present an explanatory review of the
approximation properties of deep neural networks. Specifically, we aim at
understanding how and why deep neural networks outperform other classical
linear and nonlinear approximation methods. This survey consists of three
chapters. In Chapter 1 we review the key ideas and concepts underlying deep
networks and their compositional nonlinear structure. We formalize the neural
network problem by formulating it as an optimization problem when solving
regression and classification problems. We briefly discuss the stochastic
gradient descent algorithm and the back-propagation formulas used in solving
the optimization problem and address a few issues related to the performance of
neural networks, including the choice of activation functions, cost functions,
overfitting issues, and regularization. In Chapter 2 we shift our focus to the
approximation theory of neural networks. We start with an introduction to the
concept of density in polynomial approximation and in particular study the
Stone-Weierstrass theorem for real-valued continuous functions. Then, within
the framework of linear approximation, we review a few classical results on the
density and convergence rate of feedforward networks, followed by more recent
developments on the complexity of deep networks in approximating Sobolev
functions. In Chapter 3, utilizing nonlinear approximation theory, we further
elaborate on the power of depth and approximation superiority of deep ReLU
networks over other classical methods of nonlinear approximation.",['Mohammad Motamed'],"['cs.LG', 'cs.NA', 'math.NA', 'stat.ML']",2022-07-19 18:47:44+00:00
http://arxiv.org/abs/2207.09390v1,Neural Greedy Pursuit for Feature Selection,"We propose a greedy algorithm to select $N$ important features among $P$
input features for a non-linear prediction problem. The features are selected
one by one sequentially, in an iterative loss minimization procedure. We use
neural networks as predictors in the algorithm to compute the loss and hence,
we refer to our method as neural greedy pursuit (NGP). NGP is efficient in
selecting $N$ features when $N \ll P$, and it provides a notion of feature
importance in a descending order following the sequential selection procedure.
We experimentally show that NGP provides better performance than several
feature selection methods such as DeepLIFT and Drop-one-out loss. In addition,
we experimentally show a phase transition behavior in which perfect selection
of all $N$ features without false positives is possible when the training data
size exceeds a threshold.","['Sandipan Das', 'Alireza M. Javid', 'Prakash Borpatra Gohain', 'Yonina C. Eldar', 'Saikat Chatterjee']","['cs.LG', 'stat.ML']",2022-07-19 16:39:16+00:00
http://arxiv.org/abs/2207.09340v5,A coherence parameter characterizing generative compressed sensing with Fourier measurements,"In Bora et al. (2017), a mathematical framework was developed for compressed
sensing guarantees in the setting where the measurement matrix is Gaussian and
the signal structure is the range of a generative neural network (GNN). The
problem of compressed sensing with GNNs has since been extensively analyzed
when the measurement matrix and/or network weights follow a subgaussian
distribution. We move beyond the subgaussian assumption, to measurement
matrices that are derived by sampling uniformly at random rows of a unitary
matrix (including subsampled Fourier measurements as a special case).
Specifically, we prove the first known restricted isometry guarantee for
generative compressed sensing with subsampled isometries and provide recovery
bounds, addressing an open problem of Scarlett et al. (2022, p. 10). Recovery
efficacy is characterized by the coherence, a new parameter, which measures the
interplay between the range of the network and the measurement matrix. Our
approach relies on subspace counting arguments and ideas central to
high-dimensional probability. Furthermore, we propose a regularization strategy
for training GNNs to have favourable coherence with the measurement operator.
We provide compelling numerical simulations that support this regularized
training strategy: our strategy yields low coherence networks that require
fewer measurements for signal recovery. This, together with our theoretical
results, supports coherence as a natural quantity for characterizing generative
compressed sensing with subsampled isometries.","['Aaron Berk', 'Simone Brugiapaglia', 'Babhru Joshi', 'Yaniv Plan', 'Matthew Scott', 'Özgür Yilmaz']","['cs.IT', 'cs.LG', 'eess.SP', 'math.IT', 'math.PR', 'stat.ML', '68T07, 60F10, 68P30, 94A08, 94A16']",2022-07-19 15:49:41+00:00
http://arxiv.org/abs/2207.09336v1,Uncertainty in Contrastive Learning: On the Predictability of Downstream Performance,"The superior performance of some of today's state-of-the-art deep learning
models is to some extent owed to extensive (self-)supervised contrastive
pretraining on large-scale datasets. In contrastive learning, the network is
presented with pairs of positive (similar) and negative (dissimilar) datapoints
and is trained to find an embedding vector for each datapoint, i.e., a
representation, which can be further fine-tuned for various downstream tasks.
In order to safely deploy these models in critical decision-making systems, it
is crucial to equip them with a measure of their uncertainty or reliability.
However, due to the pairwise nature of training a contrastive model, and the
lack of absolute labels on the output (an abstract embedding vector), adapting
conventional uncertainty estimation techniques to such models is non-trivial.
In this work, we study whether the uncertainty of such a representation can be
quantified for a single datapoint in a meaningful way. In other words, we
explore if the downstream performance on a given datapoint is predictable,
directly from its pre-trained embedding. We show that this goal can be achieved
by directly estimating the distribution of the training data in the embedding
space and accounting for the local consistency of the representations. Our
experiments show that this notion of uncertainty for an embedding vector often
strongly correlates with its downstream accuracy.","['Shervin Ardeshir', 'Navid Azizan']","['cs.LG', 'cs.AI', 'cs.CV', 'eess.IV', 'stat.ML']",2022-07-19 15:44:59+00:00
http://arxiv.org/abs/2207.09322v4,Probabilistic Reconciliation of Count Time Series,"Forecast reconciliation is an important research topic. Yet, there is
currently neither formal framework nor practical method for the probabilistic
reconciliation of count time series. In this paper we propose a definition of
coherency and reconciled probabilistic forecast which applies to both
real-valued and count variables and a novel method for probabilistic
reconciliation. It is based on a generalization of Bayes' rule and it can
reconcile both real-value and count variables. When applied to count variables,
it yields a reconciled probability mass function. Our experiments with the
temporal reconciliation of count variables show a major forecast improvement
compared to the probabilistic Gaussian reconciliation.","['Giorgio Corani', 'Dario Azzimonti', 'Nicolò Rubattu']","['stat.ME', 'stat.ML']",2022-07-19 15:23:09+00:00
http://arxiv.org/abs/2207.09304v2,A sharp uniform-in-time error estimate for Stochastic Gradient Langevin Dynamics,"We establish a sharp uniform-in-time error estimate for the Stochastic
Gradient Langevin Dynamics (SGLD), which is a popular sampling algorithm. Under
mild assumptions, we obtain a uniform-in-time $O(\eta^2)$ bound for the
KL-divergence between the SGLD iteration and the Langevin diffusion, where
$\eta$ is the step size (or learning rate). Our analysis is also valid for
varying step sizes. Based on this, we are able to obtain an $O(\eta)$ bound for
the distance between the SGLD iteration and the invariant distribution of the
Langevin diffusion, in terms of Wasserstein or total variation distances.","['Lei Li', 'Yuliang Wang']","['math.PR', 'cs.LG', 'stat.ML']",2022-07-19 14:38:52+00:00
http://arxiv.org/abs/2207.09299v1,Data-driven initialization of deep learning solvers for Hamilton-Jacobi-Bellman PDEs,"A deep learning approach for the approximation of the Hamilton-Jacobi-Bellman
partial differential equation (HJB PDE) associated to the Nonlinear Quadratic
Regulator (NLQR) problem. A state-dependent Riccati equation control law is
first used to generate a gradient-augmented synthetic dataset for supervised
learning. The resulting model becomes a warm start for the minimization of a
loss function based on the residual of the HJB PDE. The combination of
supervised learning and residual minimization avoids spurious solutions and
mitigate the data inefficiency of a supervised learning-only approach.
Numerical tests validate the different advantages of the proposed methodology.","['Anastasia Borovykh', 'Dante Kalise', 'Alexis Laignelet', 'Panos Parpas']","['math.OC', 'stat.ML']",2022-07-19 14:34:07+00:00
http://arxiv.org/abs/2207.09239v2,Assaying Out-Of-Distribution Generalization in Transfer Learning,"Since out-of-distribution generalization is a generally ill-posed problem,
various proxy targets (e.g., calibration, adversarial robustness, algorithmic
corruptions, invariance across shifts) were studied across different research
programs resulting in different recommendations. While sharing the same
aspirational goal, these approaches have never been tested under the same
experimental conditions on real data. In this paper, we take a unified view of
previous work, highlighting message discrepancies that we address empirically,
and providing recommendations on how to measure the robustness of a model and
how to improve it. To this end, we collect 172 publicly available dataset pairs
for training and out-of-distribution evaluation of accuracy, calibration error,
adversarial attacks, environment invariance, and synthetic corruptions. We
fine-tune over 31k networks, from nine different architectures in the many- and
few-shot setting. Our findings confirm that in- and out-of-distribution
accuracies tend to increase jointly, but show that their relation is largely
dataset-dependent, and in general more nuanced and more complex than posited by
previous, smaller scale studies.","['Florian Wenzel', 'Andrea Dittadi', 'Peter Vincent Gehler', 'Carl-Johann Simon-Gabriel', 'Max Horn', 'Dominik Zietlow', 'David Kernert', 'Chris Russell', 'Thomas Brox', 'Bernt Schiele', 'Bernhard Schölkopf', 'Francesco Locatello']","['cs.LG', 'stat.ML']",2022-07-19 12:52:33+00:00
http://arxiv.org/abs/2207.09225v1,Similarity of Pre-trained and Fine-tuned Representations,"In transfer learning, only the last part of the networks - the so-called head
- is often fine-tuned. Representation similarity analysis shows that the most
significant change still occurs in the head even if all weights are updatable.
However, recent results from few-shot learning have shown that representation
change in the early layers, which are mostly convolutional, is beneficial,
especially in the case of cross-domain adaption. In our paper, we find out
whether that also holds true for transfer learning. In addition, we analyze the
change of representation in transfer learning, both during pre-training and
fine-tuning, and find out that pre-trained structure is unlearned if not
usable.","['Thomas Goerttler', 'Klaus Obermayer']","['cs.LG', 'cs.AI', 'stat.ML']",2022-07-19 12:23:08+00:00
http://arxiv.org/abs/2207.09139v1,Heterogeneous Treatment Effect with Trained Kernels of the Nadaraya-Watson Regression,"A new method for estimating the conditional average treatment effect is
proposed in the paper. It is called TNW-CATE (the Trainable Nadaraya-Watson
regression for CATE) and based on the assumption that the number of controls is
rather large whereas the number of treatments is small. TNW-CATE uses the
Nadaraya-Watson regression for predicting outcomes of patients from the control
and treatment groups. The main idea behind TNW-CATE is to train kernels of the
Nadaraya-Watson regression by using a weight sharing neural network of a
specific form. The network is trained on controls, and it replaces standard
kernels with a set of neural subnetworks with shared parameters such that every
subnetwork implements the trainable kernel, but the whole network implements
the Nadaraya-Watson estimator. The network memorizes how the feature vectors
are located in the feature space. The proposed approach is similar to the
transfer learning when domains of source and target data are similar, but tasks
are different. Various numerical simulation experiments illustrate TNW-CATE and
compare it with the well-known T-learner, S-learner and X-learner for several
types of the control and treatment outcome functions. The code of proposed
algorithms implementing TNW-CATE is available in
https://github.com/Stasychbr/TNW-CATE.","['Andrei V. Konstantinov', 'Stanislav R. Kirpichenko', 'Lev V. Utkin']","['cs.LG', 'stat.ML']",2022-07-19 09:21:01+00:00
http://arxiv.org/abs/2207.09097v1,Lazy Estimation of Variable Importance for Large Neural Networks,"As opaque predictive models increasingly impact many areas of modern life,
interest in quantifying the importance of a given input variable for making a
specific prediction has grown. Recently, there has been a proliferation of
model-agnostic methods to measure variable importance (VI) that analyze the
difference in predictive power between a full model trained on all variables
and a reduced model that excludes the variable(s) of interest. A bottleneck
common to these methods is the estimation of the reduced model for each
variable (or subset of variables), which is an expensive process that often
does not come with theoretical guarantees. In this work, we propose a fast and
flexible method for approximating the reduced model with important inferential
guarantees. We replace the need for fully retraining a wide neural network by a
linearization initialized at the full model parameters. By adding a ridge-like
penalty to make the problem convex, we prove that when the ridge penalty
parameter is sufficiently large, our method estimates the variable importance
measure with an error rate of $O(\frac{1}{\sqrt{n}})$ where $n$ is the number
of training samples. We also show that our estimator is asymptotically normal,
enabling us to provide confidence bounds for the VI estimates. We demonstrate
through simulations that our method is fast and accurate under several
data-generating regimes, and we demonstrate its real-world applicability on a
seasonal climate forecasting example.","['Yue Gao', 'Abby Stevens', 'Rebecca Willet', 'Garvesh Raskutti']","['stat.ML', 'cs.LG']",2022-07-19 06:28:17+00:00
http://arxiv.org/abs/2207.09016v1,The role of the geometric mean in case-control studies,"Historically used in settings where the outcome is rare or data collection is
expensive, outcome-dependent sampling is relevant to many modern settings where
data is readily available for a biased sample of the target population, such as
public administrative data. Under outcome-dependent sampling, common effect
measures such as the average risk difference and the average risk ratio are not
identified, but the conditional odds ratio is. Aggregation of the conditional
odds ratio is challenging since summary measures are generally not identified.
Furthermore, the marginal odds ratio can be larger (or smaller) than all
conditional odds ratios. This so-called non-collapsibility of the odds ratio is
avoidable if we use an alternative aggregation to the standard arithmetic mean.
We provide a new definition of collapsibility that makes this choice of
aggregation method explicit, and we demonstrate that the odds ratio is
collapsible under geometric aggregation. We describe how to partially identify,
estimate, and do inference on the geometric odds ratio under outcome-dependent
sampling. Our proposed estimator is based on the efficient influence function
and therefore has doubly robust-style properties.","['Amanda Coston', 'Edward H. Kennedy']","['stat.ME', 'econ.EM', 'stat.ML']",2022-07-19 01:42:52+00:00
http://arxiv.org/abs/2207.08977v1,Calibrated ensembles can mitigate accuracy tradeoffs under distribution shift,"We often see undesirable tradeoffs in robust machine learning where
out-of-distribution (OOD) accuracy is at odds with in-distribution (ID)
accuracy: a robust classifier obtained via specialized techniques such as
removing spurious features often has better OOD but worse ID accuracy compared
to a standard classifier trained via ERM. In this paper, we find that
ID-calibrated ensembles -- where we simply ensemble the standard and robust
models after calibrating on only ID data -- outperforms prior state-of-the-art
(based on self-training) on both ID and OOD accuracy. On eleven natural
distribution shift datasets, ID-calibrated ensembles obtain the best of both
worlds: strong ID accuracy and OOD accuracy. We analyze this method in stylized
settings, and identify two important conditions for ensembles to perform well
both ID and OOD: (1) we need to calibrate the standard and robust models (on ID
data, because OOD data is unavailable), (2) OOD has no anticorrelated spurious
features.","['Ananya Kumar', 'Tengyu Ma', 'Percy Liang', 'Aditi Raghunathan']","['cs.LG', 'stat.ML']",2022-07-18 23:14:44+00:00
http://arxiv.org/abs/2207.08963v1,The m-connecting imset and factorization for ADMG models,"Directed acyclic graph (DAG) models have become widely studied and applied in
statistics and machine learning -- indeed, their simplicity facilitates
efficient procedures for learning and inference. Unfortunately, these models
are not closed under marginalization, making them poorly equipped to handle
systems with latent confounding. Acyclic directed mixed graph (ADMG) models
characterize margins of DAG models, making them far better suited to handle
such systems. However, ADMG models have not seen wide-spread use due to their
complexity and a shortage of statistical tools for their analysis. In this
paper, we introduce the m-connecting imset which provides an alternative
representation for the independence models induced by ADMGs. Furthermore, we
define the m-connecting factorization criterion for ADMG models, characterized
by a single equation, and prove its equivalence to the global Markov property.
The m-connecting imset and factorization criterion provide two new statistical
tools for learning and inference with ADMG models. We demonstrate the
usefulness of these tools by formulating and evaluating a consistent scoring
criterion with a closed form solution.","['Bryan Andrews', 'Gregory F. Cooper', 'Thomas S. Richardson', 'Peter Spirtes']","['stat.ML', 'cs.LG', 'stat.ME']",2022-07-18 22:29:15+00:00
http://arxiv.org/abs/2207.08956v1,Online Learning with Off-Policy Feedback,"We study the problem of online learning in adversarial bandit problems under
a partial observability model called off-policy feedback. In this sequential
decision making problem, the learner cannot directly observe its rewards, but
instead sees the ones obtained by another unknown policy run in parallel
(behavior policy). Instead of a standard exploration-exploitation dilemma, the
learner has to face another challenge in this setting: due to limited
observations outside of their control, the learner may not be able to estimate
the value of each policy equally well. To address this issue, we propose a set
of algorithms that guarantee regret bounds that scale with a natural notion of
mismatch between any comparator policy and the behavior policy, achieving
improved performance against comparators that are well-covered by the
observations. We also provide an extension to the setting of adversarial linear
contextual bandits, and verify the theoretical guarantees via a set of
experiments. Our key algorithmic idea is adapting the notion of pessimistic
reward estimators that has been recently popular in the context of off-policy
reinforcement learning.","['Germano Gabbianelli', 'Matteo Papini', 'Gergely Neu']","['cs.LG', 'stat.ML']",2022-07-18 21:57:16+00:00
http://arxiv.org/abs/2207.08942v2,Implicit Regularization with Polynomial Growth in Deep Tensor Factorization,"We study the implicit regularization effects of deep learning in tensor
factorization. While implicit regularization in deep matrix and 'shallow'
tensor factorization via linear and certain type of non-linear neural networks
promotes low-rank solutions with at most quadratic growth, we show that its
effect in deep tensor factorization grows polynomially with the depth of the
network. This provides a remarkably faithful description of the observed
experimental behaviour. Using numerical experiments, we demonstrate the
benefits of this implicit regularization in yielding a more accurate estimation
and better convergence properties.","['Kais Hariz', 'Hachem Kadri', 'Stéphane Ayache', 'Maher Moakher', 'Thierry Artières']","['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']",2022-07-18 21:04:37+00:00
http://arxiv.org/abs/2207.08911v3,Deeply-Learned Generalized Linear Models with Missing Data,"Deep Learning (DL) methods have dramatically increased in popularity in
recent years, with significant growth in their application to supervised
learning problems in the biomedical sciences. However, the greater prevalence
and complexity of missing data in modern biomedical datasets present
significant challenges for DL methods. Here, we provide a formal treatment of
missing data in the context of deeply learned generalized linear models, a
supervised DL architecture for regression and classification problems. We
propose a new architecture, \textit{dlglm}, that is one of the first to be able
to flexibly account for both ignorable and non-ignorable patterns of
missingness in input features and response at training time. We demonstrate
through statistical simulation that our method outperforms existing approaches
for supervised learning tasks in the presence of missing not at random (MNAR)
missingness. We conclude with a case study of a Bank Marketing dataset from the
UCI Machine Learning Repository, in which we predict whether clients subscribed
to a product based on phone survey data. Supplementary materials for this
article are available online.","['David K Lim', 'Naim U Rashid', 'Junier B Oliva', 'Joseph G Ibrahim']","['stat.ML', 'cs.LG', 'stat.CO', 'stat.ME']",2022-07-18 20:00:13+00:00
http://arxiv.org/abs/2207.08896v2,On the Study of Sample Complexity for Polynomial Neural Networks,"As a general type of machine learning approach, artificial neural networks
have established state-of-art benchmarks in many pattern recognition and data
analysis tasks. Among various kinds of neural networks architectures,
polynomial neural networks (PNNs) have been recently shown to be analyzable by
spectrum analysis via neural tangent kernel, and particularly effective at
image generation and face recognition. However, acquiring theoretical insight
into the computation and sample complexity of PNNs remains an open problem. In
this paper, we extend the analysis in previous literature to PNNs and obtain
novel results on sample complexity of PNNs, which provides some insights in
explaining the generalization ability of PNNs.","['Chao Pan', 'Chuanyi Zhang']","['cs.LG', 'stat.ML']",2022-07-18 19:10:53+00:00
http://arxiv.org/abs/2207.08869v1,FLAIR: Federated Learning Annotated Image Repository,"Cross-device federated learning is an emerging machine learning (ML) paradigm
where a large population of devices collectively train an ML model while the
data remains on the devices. This research field has a unique set of practical
challenges, and to systematically make advances, new datasets curated to be
compatible with this paradigm are needed. Existing federated learning
benchmarks in the image domain do not accurately capture the scale and
heterogeneity of many real-world use cases. We introduce FLAIR, a challenging
large-scale annotated image dataset for multi-label classification suitable for
federated learning. FLAIR has 429,078 images from 51,414 Flickr users and
captures many of the intricacies typically encountered in federated learning,
such as heterogeneous user data and a long-tailed label distribution. We
implement multiple baselines in different learning setups for different tasks
on this dataset. We believe FLAIR can serve as a challenging benchmark for
advancing the state-of-the art in federated learning. Dataset access and the
code for the benchmark are available at
\url{https://github.com/apple/ml-flair}.","['Congzheng Song', 'Filip Granqvist', 'Kunal Talwar']","['cs.LG', 'cs.CR', 'cs.CV', 'stat.ML']",2022-07-18 18:27:04+00:00
http://arxiv.org/abs/2207.08799v3,Hidden Progress in Deep Learning: SGD Learns Parities Near the Computational Limit,"There is mounting evidence of emergent phenomena in the capabilities of deep
learning methods as we scale up datasets, model sizes, and training times.
While there are some accounts of how these resources modulate statistical
capacity, far less is known about their effect on the computational problem of
model training. This work conducts such an exploration through the lens of
learning a $k$-sparse parity of $n$ bits, a canonical discrete search problem
which is statistically easy but computationally hard. Empirically, we find that
a variety of neural networks successfully learn sparse parities, with
discontinuous phase transitions in the training curves. On small instances,
learning abruptly occurs at approximately $n^{O(k)}$ iterations; this nearly
matches SQ lower bounds, despite the apparent lack of a sparse prior. Our
theoretical analysis shows that these observations are not explained by a
Langevin-like mechanism, whereby SGD ""stumbles in the dark"" until it finds the
hidden set of features (a natural algorithm which also runs in $n^{O(k)}$
time). Instead, we show that SGD gradually amplifies the sparse solution via a
Fourier gap in the population gradient, making continual progress that is
invisible to loss and error metrics.","['Boaz Barak', 'Benjamin L. Edelman', 'Surbhi Goel', 'Sham Kakade', 'Eran Malach', 'Cyril Zhang']","['cs.LG', 'cs.NE', 'math.OC', 'stat.ML']",2022-07-18 17:55:05+00:00
http://arxiv.org/abs/2207.08770v1,Package for Fast ABC-Boost,"This report presents the open-source package which implements the series of
our boosting works in the past years. In particular, the package includes
mainly three lines of techniques, among which the following two are already the
standard implementations in popular boosted tree platforms:
  (i) The histogram-based (feature-binning) approach makes the tree
implementation convenient and efficient. In Li et al (2007), a simple
fixed-length adaptive binning algorithm was developed. In this report, we
demonstrate that such a simple algorithm is still surprisingly effective
compared to more sophisticated variants in popular tree platforms.
  (ii) The explicit gain formula in Li (20010) for tree splitting based on
second-order derivatives of the loss function typically improves, often
considerably, over the first-order methods. Although the gain formula in Li
(2010) was derived for logistic regression loss, it is a generic formula for
loss functions with second-derivatives. For example, the open-source package
also includes $L_p$ regression for $p\geq 1$.
  The main contribution of this package is the ABC-Boost (adaptive base class
boosting) for multi-class classification. The initial work in Li (2008) derived
a new set of derivatives of the classical multi-class logistic regression by
specifying a ""base class"". The accuracy can be substantially improved if the
base class is chosen properly. The major technical challenge is to design a
search strategy to select the base class. The prior published works implemented
an exhaustive search procedure to find the base class which is computationally
too expensive. Recently, a new report (Li and Zhao, 20022) presents a unified
framework of ""Fast ABC-Boost"" which allows users to efficiently choose the
proper search space for the base class.
  The package provides interfaces for linux, windows, mac, matlab, R, python.","['Ping Li', 'Weijie Zhao']","['stat.ML', 'cs.LG']",2022-07-18 17:22:32+00:00
http://arxiv.org/abs/2207.08735v1,An Information-Theoretic Analysis of Bayesian Reinforcement Learning,"Building on the framework introduced by Xu and Raginksy [1] for supervised
learning problems, we study the best achievable performance for model-based
Bayesian reinforcement learning problems. With this purpose, we define minimum
Bayesian regret (MBR) as the difference between the maximum expected cumulative
reward obtainable either by learning from the collected data or by knowing the
environment and its dynamics. We specialize this definition to reinforcement
learning problems modeled as Markov decision processes (MDPs) whose kernel
parameters are unknown to the agent and whose uncertainty is expressed by a
prior distribution. One method for deriving upper bounds on the MBR is
presented and specific bounds based on the relative entropy and the Wasserstein
distance are given. We then focus on two particular cases of MDPs, the
multi-armed bandit problem (MAB) and the online optimization with partial
feedback problem. For the latter problem, we show that our bounds can recover
from below the current information-theoretic bounds by Russo and Van Roy [2].","['Amaury Gouverneur', 'Borja Rodríguez-Gálvez', 'Tobias J. Oechtering', 'Mikael Skoglund']","['cs.LG', 'stat.ML']",2022-07-18 16:28:01+00:00
http://arxiv.org/abs/2207.08667v1,pGMM Kernel Regression and Comparisons with Boosted Trees,"In this work, we demonstrate the advantage of the pGMM (``powered generalized
min-max'') kernel in the context of (ridge) regression. In recent prior
studies, the pGMM kernel has been extensively evaluated for classification
tasks, for logistic regression, support vector machines, as well as deep neural
networks. In this paper, we provide an experimental study on ridge regression,
to compare the pGMM kernel regression with the ordinary ridge linear regression
as well as the RBF kernel ridge regression. Perhaps surprisingly, even without
a tuning parameter (i.e., $p=1$ for the power parameter of the pGMM kernel),
the pGMM kernel already performs well. Furthermore, by tuning the parameter
$p$, this (deceptively simple) pGMM kernel even performs quite comparably to
boosted trees.
  Boosting and boosted trees are very popular in machine learning practice. For
regression tasks, typically, practitioners use $L_2$ boost, i.e., for
minimizing the $L_2$ loss. Sometimes for the purpose of robustness, the $L_1$
boost might be a choice. In this study, we implement $L_p$ boost for $p\geq 1$
and include it in the package of ``Fast ABC-Boost''. Perhaps also surprisingly,
the best performance (in terms of $L_2$ regression loss) is often attained at
$p>2$, in some cases at $p\gg 2$. This phenomenon has already been demonstrated
by Li et al (UAI 2010) in the context of k-nearest neighbor classification
using $L_p$ distances. In summary, the implementation of $L_p$ boost provides
practitioners the additional flexibility of tuning boosting algorithms for
potentially achieving better accuracy in regression applications.","['Ping Li', 'Weijie Zhao']","['stat.ML', 'cs.LG']",2022-07-18 15:06:30+00:00
http://arxiv.org/abs/2207.08645v4,Active Exploration for Inverse Reinforcement Learning,"Inverse Reinforcement Learning (IRL) is a powerful paradigm for inferring a
reward function from expert demonstrations. Many IRL algorithms require a known
transition model and sometimes even a known expert policy, or they at least
require access to a generative model. However, these assumptions are too strong
for many real-world applications, where the environment can be accessed only
through sequential interaction. We propose a novel IRL algorithm: Active
exploration for Inverse Reinforcement Learning (AceIRL), which actively
explores an unknown environment and expert policy to quickly learn the expert's
reward function and identify a good policy. AceIRL uses previous observations
to construct confidence intervals that capture plausible reward functions and
find exploration policies that focus on the most informative regions of the
environment. AceIRL is the first approach to active IRL with sample-complexity
bounds that does not require a generative model of the environment. AceIRL
matches the sample complexity of active IRL with a generative model in the
worst case. Additionally, we establish a problem-dependent bound that relates
the sample complexity of AceIRL to the suboptimality gap of a given IRL
problem. We empirically evaluate AceIRL in simulations and find that it
significantly outperforms more naive exploration strategies.","['David Lindner', 'Andreas Krause', 'Giorgia Ramponi']","['cs.LG', 'cs.AI', 'stat.ML']",2022-07-18 14:45:55+00:00
http://arxiv.org/abs/2207.08643v2,A Sublinear-Time Quantum Algorithm for Approximating Partition Functions,"We present a novel quantum algorithm for estimating Gibbs partition functions
in sublinear time with respect to the logarithm of the size of the state space.
This is the first speed-up of this type to be obtained over the seminal
nearly-linear time algorithm of \v{S}tefankovi\v{c}, Vempala and Vigoda [JACM,
2009]. Our result also preserves the quadratic speed-up in precision and
spectral gap achieved in previous work by exploiting the properties of quantum
Markov chains. As an application, we obtain new polynomial improvements over
the best-known algorithms for computing the partition function of the Ising
model, counting the number of $k$-colorings, matchings or independent sets of a
graph, and estimating the volume of a convex body.
  Our approach relies on developing new variants of the quantum phase and
amplitude estimation algorithms that return nearly unbiased estimates with low
variance and without destroying their initial quantum state. We extend these
subroutines into a nearly unbiased quantum mean estimator that reduces the
variance quadratically faster than the classical empirical mean. No such
estimator was known to exist prior to our work. These properties, which are of
general interest, lead to better convergence guarantees within the paradigm of
simulated annealing for computing partition functions.","['Arjan Cornelissen', 'Yassine Hamoudi']","['quant-ph', 'cs.CC', 'cs.DS', 'math.ST', 'stat.ML', 'stat.TH']",2022-07-18 14:41:48+00:00
http://arxiv.org/abs/2207.08574v1,ManiFeSt: Manifold-based Feature Selection for Small Data Sets,"In this paper, we present a new method for few-sample supervised feature
selection (FS). Our method first learns the manifold of the feature space of
each class using kernels capturing multi-feature associations. Then, based on
Riemannian geometry, a composite kernel is computed, extracting the differences
between the learned feature associations. Finally, a FS score based on spectral
analysis is proposed. Considering multi-feature associations makes our method
multivariate by design. This in turn allows for the extraction of the hidden
manifold underlying the features and avoids overfitting, facilitating
few-sample FS. We showcase the efficacy of our method on illustrative examples
and several benchmarks, where our method demonstrates higher accuracy in
selecting the informative features compared to competing methods. In addition,
we show that our FS leads to improved classification and better generalization
when applied to test data.","['David Cohen', 'Tal Shnitzer', 'Yuval Kluger', 'Ronen Talmon']","['stat.ML', 'cs.LG', 'eess.SP']",2022-07-18 12:58:01+00:00
http://arxiv.org/abs/2207.08556v1,A Certifiable Security Patch for Object Tracking in Self-Driving Systems via Historical Deviation Modeling,"Self-driving cars (SDC) commonly implement the perception pipeline to detect
the surrounding obstacles and track their moving trajectories, which lays the
ground for the subsequent driving decision making process. Although the
security of obstacle detection in SDC is intensively studied, not until very
recently the attackers start to exploit the vulnerability of the tracking
module. Compared with solely attacking the object detectors, this new attack
strategy influences the driving decision more effectively with less attack
budgets. However, little is known on whether the revealed vulnerability remains
effective in end-to-end self-driving systems and, if so, how to mitigate the
threat.
  In this paper, we present the first systematic research on the security of
object tracking in SDC. Through a comprehensive case study on the full
perception pipeline of a popular open-sourced self-driving system, Baidu's
Apollo, we prove the mainstream multi-object tracker (MOT) based on Kalman
Filter (KF) is unsafe even with an enabled multi-sensor fusion mechanism. Our
root cause analysis reveals, the vulnerability is innate to the design of
KF-based MOT, which shall error-handle the prediction results from the object
detectors yet the adopted KF algorithm is prone to trust the observation more
when its deviation from the prediction is larger. To address this design flaw,
we propose a simple yet effective security patch for KF-based MOT, the core of
which is an adaptive strategy to balance the focus of KF on observations and
predictions according to the anomaly index of the observation-prediction
deviation, and has certified effectiveness against a generalized hijacking
attack model. Extensive evaluation on $4$ KF-based existing MOT implementations
(including 2D and 3D, academic and Apollo ones) validate the defense
effectiveness and the trivial performance overhead of our approach.","['Xudong Pan', 'Qifan Xiao', 'Mi Zhang', 'Min Yang']","['cs.CR', 'stat.ML']",2022-07-18 12:30:24+00:00
http://arxiv.org/abs/2207.08815v1,Why do tree-based models still outperform deep learning on tabular data?,"While deep learning has enabled tremendous progress on text and image
datasets, its superiority on tabular data is not clear. We contribute extensive
benchmarks of standard and novel deep learning methods as well as tree-based
models such as XGBoost and Random Forests, across a large number of datasets
and hyperparameter combinations. We define a standard set of 45 datasets from
varied domains with clear characteristics of tabular data and a benchmarking
methodology accounting for both fitting models and finding good
hyperparameters. Results show that tree-based models remain state-of-the-art on
medium-sized data ($\sim$10K samples) even without accounting for their
superior speed. To understand this gap, we conduct an empirical investigation
into the differing inductive biases of tree-based models and Neural Networks
(NNs). This leads to a series of challenges which should guide researchers
aiming to build tabular-specific NNs: 1. be robust to uninformative features,
2. preserve the orientation of the data, and 3. be able to easily learn
irregular functions. To stimulate research on tabular architectures, we
contribute a standard benchmark and raw data for baselines: every point of a 20
000 compute hours hyperparameter search for each learner.","['Léo Grinsztajn', 'Edouard Oyallon', 'Gaël Varoquaux']","['cs.LG', 'cs.AI', 'stat.ME', 'stat.ML']",2022-07-18 08:36:08+00:00
http://arxiv.org/abs/2207.08406v1,Kullback-Leibler and Renyi divergences in reproducing kernel Hilbert space and Gaussian process settings,"In this work, we present formulations for regularized Kullback-Leibler and
R\'enyi divergences via the Alpha Log-Determinant (Log-Det) divergences between
positive Hilbert-Schmidt operators on Hilbert spaces in two different settings,
namely (i) covariance operators and Gaussian measures defined on reproducing
kernel Hilbert spaces (RKHS); and (ii) Gaussian processes with squared
integrable sample paths. For characteristic kernels, the first setting leads to
divergences between arbitrary Borel probability measures on a complete,
separable metric space. We show that the Alpha Log-Det divergences are
continuous in the Hilbert-Schmidt norm, which enables us to apply laws of large
numbers for Hilbert space-valued random variables. As a consequence of this, we
show that, in both settings, the infinite-dimensional divergences can be
consistently and efficiently estimated from their finite-dimensional versions,
using finite-dimensional Gram matrices/Gaussian measures and finite sample
data, with {\it dimension-independent} sample complexities in all cases. RKHS
methodology plays a central role in the theoretical analysis in both settings.
The mathematical formulation is illustrated by numerical experiments.",['Minh Ha Quang'],"['stat.ML', 'cs.LG']",2022-07-18 06:40:46+00:00
http://arxiv.org/abs/2207.08347v2,Private Convex Optimization in General Norms,"We propose a new framework for differentially private optimization of convex
functions which are Lipschitz in an arbitrary norm $\|\cdot\|$. Our algorithms
are based on a regularized exponential mechanism which samples from the density
$\propto \exp(-k(F+\mu r))$ where $F$ is the empirical loss and $r$ is a
regularizer which is strongly convex with respect to $\|\cdot\|$, generalizing
a recent work of [Gopi, Lee, Liu '22] to non-Euclidean settings. We show that
this mechanism satisfies Gaussian differential privacy and solves both DP-ERM
(empirical risk minimization) and DP-SCO (stochastic convex optimization) by
using localization tools from convex geometry. Our framework is the first to
apply to private convex optimization in general normed spaces and directly
recovers non-private SCO rates achieved by mirror descent as the privacy
parameter $\epsilon \to \infty$. As applications, for Lipschitz optimization in
$\ell_p$ norms for all $p \in (1, 2)$, we obtain the first optimal
privacy-utility tradeoffs; for $p = 1$, we improve tradeoffs obtained by the
recent works [Asi, Feldman, Koren, Talwar '21, Bassily, Guzman, Nandi '21] by
at least a logarithmic factor. Our $\ell_p$ norm and Schatten-$p$ norm
optimization frameworks are complemented with polynomial-time samplers whose
query complexity we explicitly bound.","['Sivakanth Gopi', 'Yin Tat Lee', 'Daogao Liu', 'Ruoqi Shen', 'Kevin Tian']","['cs.LG', 'cs.CR', 'math.OC', 'stat.ML']",2022-07-18 02:02:22+00:00
http://arxiv.org/abs/2207.08306v1,Nonparametric regression with modified ReLU networks,"We consider regression estimation with modified ReLU neural networks in which
network weight matrices are first modified by a function $\alpha$ before being
multiplied by input vectors. We give an example of continuous, piecewise linear
function $\alpha$ for which the empirical risk minimizers over the classes of
modified ReLU networks with $l_1$ and squared $l_2$ penalties attain, up to a
logarithmic factor, the minimax rate of prediction of unknown $\beta$-smooth
function.","['Aleksandr Beknazaryan', 'Hailin Sang']","['stat.ML', 'cs.LG', 'math.ST', 'stat.TH', '62G08', 'I.2.6']",2022-07-17 21:46:06+00:00
http://arxiv.org/abs/2207.08268v3,Online Lewis Weight Sampling,"The seminal work of Cohen and Peng introduced Lewis weight sampling to the
theoretical computer science community, yielding fast row sampling algorithms
for approximating $d$-dimensional subspaces of $\ell_p$ up to $(1+\epsilon)$
error. Several works have extended this important primitive to other settings,
including the online coreset and sliding window models. However, these results
are only for $p\in\{1,2\}$, and results for $p=1$ require a suboptimal $\tilde
O(d^2/\epsilon^2)$ samples.
  In this work, we design the first nearly optimal $\ell_p$ subspace embeddings
for all $p\in(0,\infty)$ in the online coreset and sliding window models. In
both models, our algorithms store $\tilde O(d^{1\lor(p/2)}/\epsilon^2)$ rows.
This answers a substantial generalization of the main open question of
[BDMMUWZ2020], and gives the first results for all $p\notin\{1,2\}$.
  Towards our result, we give the first analysis of ""one-shot'' Lewis weight
sampling of sampling rows proportionally to their Lewis weights, with sample
complexity $\tilde O(d^{p/2}/\epsilon^2)$ for $p>2$. Previously, this scheme
was only known to have sample complexity $\tilde O(d^{p/2}/\epsilon^5)$,
whereas $\tilde O(d^{p/2}/\epsilon^2)$ is known if a more sophisticated
recursive sampling is used. The recursive sampling cannot be implemented
online, thus necessitating an analysis of one-shot Lewis weight sampling. Our
analysis uses a novel connection to online numerical linear algebra.
  As an application, we obtain the first one-pass streaming coreset algorithms
for $(1+\epsilon)$ approximation of important generalized linear models, such
as logistic regression and $p$-probit regression. Our upper bounds are
parameterized by a complexity parameter $\mu$ introduced by [MSSW2018], and we
show the first lower bounds showing that a linear dependence on $\mu$ is
necessary.","['David P. Woodruff', 'Taisuke Yasuda']","['cs.DS', 'cs.LG', 'stat.ML']",2022-07-17 19:40:51+00:00
http://arxiv.org/abs/2207.08257v1,Uniform Stability for First-Order Empirical Risk Minimization,"We consider the problem of designing uniformly stable first-order
optimization algorithms for empirical risk minimization. Uniform stability is
often used to obtain generalization error bounds for optimization algorithms,
and we are interested in a general approach to achieve it. For Euclidean
geometry, we suggest a black-box conversion which given a smooth optimization
algorithm, produces a uniformly stable version of the algorithm while
maintaining its convergence rate up to logarithmic factors. Using this
reduction we obtain a (nearly) optimal algorithm for smooth optimization with
convergence rate $\widetilde{O}(1/T^2)$ and uniform stability $O(T^2/n)$,
resolving an open problem of Chen et al. (2018); Attia and Koren (2021). For
more general geometries, we develop a variant of Mirror Descent for smooth
optimization with convergence rate $\widetilde{O}(1/T)$ and uniform stability
$O(T/n)$, leaving open the question of devising a general conversion method as
in the Euclidean case.","['Amit Attia', 'Tomer Koren']","['cs.LG', 'math.OC', 'stat.ML']",2022-07-17 18:53:50+00:00
http://arxiv.org/abs/2207.08229v2,Guaranteed Discovery of Control-Endogenous Latent States with Multi-Step Inverse Models,"In many sequential decision-making tasks, the agent is not able to model the
full complexity of the world, which consists of multitudes of relevant and
irrelevant information. For example, a person walking along a city street who
tries to model all aspects of the world would quickly be overwhelmed by a
multitude of shops, cars, and people moving in and out of view, each following
their own complex and inscrutable dynamics. Is it possible to turn the agent's
firehose of sensory information into a minimal latent state that is both
necessary and sufficient for an agent to successfully act in the world? We
formulate this question concretely, and propose the Agent Control-Endogenous
State Discovery algorithm (AC-State), which has theoretical guarantees and is
practically demonstrated to discover the minimal control-endogenous latent
state which contains all of the information necessary for controlling the
agent, while fully discarding all irrelevant information. This algorithm
consists of a multi-step inverse model (predicting actions from distant
observations) with an information bottleneck. AC-State enables localization,
exploration, and navigation without reward or demonstrations. We demonstrate
the discovery of the control-endogenous latent state in three domains:
localizing a robot arm with distractions (e.g., changing lighting conditions
and background), exploring a maze alongside other agents, and navigating in the
Matterport house simulator.","['Alex Lamb', 'Riashat Islam', 'Yonathan Efroni', 'Aniket Didolkar', 'Dipendra Misra', 'Dylan Foster', 'Lekan Molu', 'Rajan Chari', 'Akshay Krishnamurthy', 'John Langford']","['cs.LG', 'cs.RO', 'stat.ML']",2022-07-17 17:06:52+00:00
http://arxiv.org/abs/2207.08219v1,Gradients should stay on Path: Better Estimators of the Reverse- and Forward KL Divergence for Normalizing Flows,"We propose an algorithm to estimate the path-gradient of both the reverse and
forward Kullback-Leibler divergence for an arbitrary manifestly invertible
normalizing flow. The resulting path-gradient estimators are straightforward to
implement, have lower variance, and lead not only to faster convergence of
training but also to better overall approximation results compared to standard
total gradient estimators. We also demonstrate that path-gradient training is
less susceptible to mode-collapse. In light of our results, we expect that
path-gradient estimators will become the new standard method to train
normalizing flows for variational inference.","['Lorenz Vaitl', 'Kim A. Nicoli', 'Shinichi Nakajima', 'Pan Kessel']","['cs.LG', 'stat.ML']",2022-07-17 16:27:41+00:00
http://arxiv.org/abs/2207.08204v2,Fast Composite Optimization and Statistical Recovery in Federated Learning,"As a prevalent distributed learning paradigm, Federated Learning (FL) trains
a global model on a massive amount of devices with infrequent communication.
This paper investigates a class of composite optimization and statistical
recovery problems in the FL setting, whose loss function consists of a
data-dependent smooth loss and a non-smooth regularizer. Examples include
sparse linear regression using Lasso, low-rank matrix recovery using nuclear
norm regularization, etc. In the existing literature, federated composite
optimization algorithms are designed only from an optimization perspective
without any statistical guarantees. In addition, they do not consider commonly
used (restricted) strong convexity in statistical recovery problems. We advance
the frontiers of this problem from both optimization and statistical
perspectives. From optimization upfront, we propose a new algorithm named
\textit{Fast Federated Dual Averaging} for strongly convex and smooth loss and
establish state-of-the-art iteration and communication complexity in the
composite setting. In particular, we prove that it enjoys a fast rate, linear
speedup, and reduced communication rounds. From statistical upfront, for
restricted strongly convex and smooth loss, we design another algorithm, namely
\textit{Multi-stage Federated Dual Averaging}, and prove a high probability
complexity bound with linear speedup up to optimal statistical precision.
Experiments in both synthetic and real data demonstrate that our methods
perform better than other baselines. To the best of our knowledge, this is the
first work providing fast optimization algorithms and statistical recovery
guarantees for composite problems in FL.","['Yajie Bao', 'Michael Crawshaw', 'Shan Luo', 'Mingrui Liu']","['cs.LG', 'stat.ML']",2022-07-17 15:31:21+00:00
http://arxiv.org/abs/2207.08200v1,Uncertainty Calibration in Bayesian Neural Networks via Distance-Aware Priors,"As we move away from the data, the predictive uncertainty should increase,
since a great variety of explanations are consistent with the little available
information. We introduce Distance-Aware Prior (DAP) calibration, a method to
correct overconfidence of Bayesian deep learning models outside of the training
domain. We define DAPs as prior distributions over the model parameters that
depend on the inputs through a measure of their distance from the training set.
DAP calibration is agnostic to the posterior inference method, and it can be
performed as a post-processing step. We demonstrate its effectiveness against
several baselines in a variety of classification and regression problems,
including benchmarks designed to test the quality of predictive distributions
away from the data.","['Gianluca Detommaso', 'Alberto Gasparin', 'Andrew Wilson', 'Cedric Archambeau']","['stat.ML', 'cs.AI', 'cs.LG']",2022-07-17 15:10:25+00:00
http://arxiv.org/abs/2207.08130v1,Discover Life Skills for Planning with Bandits via Observing and Learning How the World Works,"We propose a novel approach for planning agents to compose abstract skills
via observing and learning from historical interactions with the world. Our
framework operates in a Markov state-space model via a set of actions under
unknown pre-conditions. We formulate skills as high-level abstract policies
that propose action plans based on the current state. Each policy learns new
plans by observing the states' transitions while the agent interacts with the
world. Such an approach automatically learns new plans to achieve specific
intended effects, but the success of such plans is often dependent on the
states in which they are applicable. Therefore, we formulate the evaluation of
such plans as infinitely many multi-armed bandit problems, where we balance the
allocation of resources on evaluating the success probability of existing arms
and exploring new options. The result is a planner capable of automatically
learning robust high-level skills under a noisy environment; such skills
implicitly learn the action pre-condition without explicit knowledge. We show
that this planning approach is experimentally very competitive in
high-dimensional state space domains.",['Tin Lai'],"['cs.AI', 'cs.RO', 'stat.ML']",2022-07-17 10:05:54+00:00
http://arxiv.org/abs/2207.08074v2,Mean-field Variational Inference via Wasserstein Gradient Flow,"Variational inference, such as the mean-field (MF) approximation, requires
certain conjugacy structures for efficient computation. These can impose
unnecessary restrictions on the viable prior distribution family and further
constraints on the variational approximation family. In this work, we introduce
a general computational framework to implement MF variational inference for
Bayesian models, with or without latent variables, using the Wasserstein
gradient flow (WGF), a modern mathematical technique for realizing a gradient
flow over the space of probability measures. Theoretically, we analyze the
algorithmic convergence of the proposed approaches, providing an explicit
expression for the contraction factor. We also strengthen existing results on
MF variational posterior concentration from a polynomial to an exponential
contraction, by utilizing the fixed point equation of the time-discretized WGF.
Computationally, we propose a new constraint-free function approximation method
using neural networks to numerically realize our algorithm. This method is
shown to be more precise and efficient than traditional particle approximation
methods based on Langevin dynamics.","['Rentian Yao', 'Yun Yang']","['math.ST', 'stat.CO', 'stat.ML', 'stat.TH']",2022-07-17 04:05:32+00:00
http://arxiv.org/abs/2207.08050v1,Repairing Systematic Outliers by Learning Clean Subspaces in VAEs,"Data cleaning often comprises outlier detection and data repair. Systematic
errors result from nearly deterministic transformations that occur repeatedly
in the data, e.g. specific image pixels being set to default values or
watermarks. Consequently, models with enough capacity easily overfit to these
errors, making detection and repair difficult. Seeing as a systematic outlier
is a combination of patterns of a clean instance and systematic error patterns,
our main insight is that inliers can be modelled by a smaller representation
(subspace) in a model than outliers. By exploiting this, we propose Clean
Subspace Variational Autoencoder (CLSVAE), a novel semi-supervised model for
detection and automated repair of systematic errors. The main idea is to
partition the latent space and model inlier and outlier patterns separately.
CLSVAE is effective with much less labelled data compared to previous related
models, often with less than 2% of the data. We provide experiments using three
image datasets in scenarios with different levels of corruption and labelled
set sizes, comparing to relevant baselines. CLSVAE provides superior repairs
without human intervention, e.g. with just 0.25% of labelled data we see a
relative error decrease of 58% compared to the closest baseline.","['Simao Eduardo', 'Kai Xu', 'Alfredo Nazabal', 'Charles Sutton']","['cs.LG', 'stat.ML']",2022-07-17 01:28:23+00:00
http://arxiv.org/abs/2207.08041v2,Personalized PCA: Decoupling Shared and Unique Features,"In this paper, we tackle a significant challenge in PCA: heterogeneity. When
data are collected from different sources with heterogeneous trends while still
sharing some congruency, it is critical to extract shared knowledge while
retaining the unique features of each source. To this end, we propose
personalized PCA (PerPCA), which uses mutually orthogonal global and local
principal components to encode both unique and shared features. We show that,
under mild conditions, both unique and shared features can be identified and
recovered by a constrained optimization problem, even if the covariance
matrices are immensely different. Also, we design a fully federated algorithm
inspired by distributed Stiefel gradient descent to solve the problem. The
algorithm introduces a new group of operations called generalized retractions
to handle orthogonality constraints, and only requires global PCs to be shared
across sources. We prove the linear convergence of the algorithm under suitable
assumptions. Comprehensive numerical experiments highlight PerPCA's superior
performance in feature extraction and prediction from heterogeneous datasets.
As a systematic approach to decouple shared and unique features from
heterogeneous datasets, PerPCA finds applications in several tasks, including
video segmentation, topic extraction, and feature clustering.","['Naichen Shi', 'Raed Al Kontar']","['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']",2022-07-17 00:09:47+00:00
http://arxiv.org/abs/2207.08026v1,Rewiring Networks for Graph Neural Network Training Using Discrete Geometry,"Information over-squashing is a phenomenon of inefficient information
propagation between distant nodes on networks. It is an important problem that
is known to significantly impact the training of graph neural networks (GNNs),
as the receptive field of a node grows exponentially. To mitigate this problem,
a preprocessing procedure known as rewiring is often applied to the input
network. In this paper, we investigate the use of discrete analogues of
classical geometric notions of curvature to model information flow on networks
and rewire them. We show that these classical notions achieve state-of-the-art
performance in GNN training accuracy on a variety of real-world network
datasets. Moreover, compared to the current state-of-the-art, these classical
notions exhibit a clear advantage in computational runtime by several orders of
magnitude.","['Jakub Bober', 'Anthea Monod', 'Emil Saucan', 'Kevin N. Webster']","['stat.ML', 'cs.LG']",2022-07-16 21:50:39+00:00
http://arxiv.org/abs/2207.07948v2,Collaborative Learning in Kernel-based Bandits for Distributed Users,"We study collaborative learning among distributed clients facilitated by a
central server. Each client is interested in maximizing a personalized
objective function that is a weighted sum of its local objective and a global
objective. Each client has direct access to random bandit feedback on its local
objective, but only has a partial view of the global objective and relies on
information exchange with other clients for collaborative learning. We adopt
the kernel-based bandit framework where the objective functions belong to a
reproducing kernel Hilbert space. We propose an algorithm based on surrogate
Gaussian process (GP) models and establish its order-optimal regret performance
(up to polylogarithmic factors). We also show that the sparse approximations of
the GP models can be employed to reduce the communication overhead across
clients.","['Sudeep Salgia', 'Sattar Vakili', 'Qing Zhao']","['stat.ML', 'cs.LG']",2022-07-16 13:41:42+00:00
http://arxiv.org/abs/2207.07908v1,Multiscale Causal Structure Learning,"The inference of causal structures from observed data plays a key role in
unveiling the underlying dynamics of the system. This paper exposes a novel
method, named Multiscale-Causal Structure Learning (MS-CASTLE), to estimate the
structure of linear causal relationships occurring at different time scales.
Differently from existing approaches, MS-CASTLE takes explicitly into account
instantaneous and lagged inter-relations between multiple time series,
represented at different scales, hinging on stationary wavelet transform and
non-convex optimization. MS-CASTLE incorporates, as a special case, a
single-scale version named SS-CASTLE, which compares favorably in terms of
computational efficiency, performance and robustness with respect to the state
of the art onto synthetic data. We used MS-CASTLE to study the multiscale
causal structure of the risk of 15 global equity markets, during covid-19
pandemic, illustrating how MS-CASTLE can extract meaningful information thanks
to its multiscale analysis, outperforming SS-CASTLE. We found that the most
persistent and strongest interactions occur at mid-term time resolutions.
Moreover, we identified the stock markets that drive the risk during the
considered period: Brazil, Canada and Italy. The proposed approach can be
exploited by financial investors who, depending to their investment horizon,
can manage the risk within equity portfolios from a causal perspective.","[""Gabriele D'Acunto"", 'Paolo Di Lorenzo', 'Sergio Barbarossa']","['cs.LG', 'stat.ME', 'stat.ML']",2022-07-16 11:47:32+00:00
http://arxiv.org/abs/2207.07753v3,Do Not Sleep on Traditional Machine Learning: Simple and Interpretable Techniques Are Competitive to Deep Learning for Sleep Scoring,"Over the last few years, research in automatic sleep scoring has mainly
focused on developing increasingly complex deep learning architectures.
However, recently these approaches achieved only marginal improvements, often
at the expense of requiring more data and more expensive training procedures.
Despite all these efforts and their satisfactory performance, automatic sleep
staging solutions are not widely adopted in a clinical context yet. We argue
that most deep learning solutions for sleep scoring are limited in their
real-world applicability as they are hard to train, deploy, and reproduce.
Moreover, these solutions lack interpretability and transparency, which are
often key to increase adoption rates. In this work, we revisit the problem of
sleep stage classification using classical machine learning. Results show that
competitive performance can be achieved with a conventional machine learning
pipeline consisting of preprocessing, feature extraction, and a simple machine
learning model. In particular, we analyze the performance of a linear model and
a non-linear (gradient boosting) model. Our approach surpasses state-of-the-art
(that uses the same data) on two public datasets: Sleep-EDF SC-20 (MF1 0.810)
and Sleep-EDF ST (MF1 0.795), while achieving competitive results on Sleep-EDF
SC-78 (MF1 0.775) and MASS SS3 (MF1 0.817). We show that, for the sleep stage
scoring task, the expressiveness of an engineered feature vector is on par with
the internally learned representations of deep learning models. This
observation opens the door to clinical adoption, as a representative feature
vector allows to leverage both the interpretability and successful track record
of traditional machine learning models.","['Jeroen Van Der Donckt', 'Jonas Van Der Donckt', 'Emiel Deprost', 'Nicolas Vandenbussche', 'Michael Rademaker', 'Gilles Vandewiele', 'Sofie Van Hoecke']","['stat.ML', 'cs.AI', 'cs.LG', 'eess.SP']",2022-07-15 21:03:11+00:00
http://arxiv.org/abs/2207.07732v1,Partial Disentanglement via Mechanism Sparsity,"Disentanglement via mechanism sparsity was introduced recently as a
principled approach to extract latent factors without supervision when the
causal graph relating them in time is sparse, and/or when actions are observed
and affect them sparsely. However, this theory applies only to ground-truth
graphs satisfying a specific criterion. In this work, we introduce a
generalization of this theory which applies to any ground-truth graph and
specifies qualitatively how disentangled the learned representation is expected
to be, via a new equivalence relation over models we call consistency. This
equivalence captures which factors are expected to remain entangled and which
are not based on the specific form of the ground-truth graph. We call this
weaker form of identifiability partial disentanglement. The graphical criterion
that allows complete disentanglement, proposed in an earlier work, can be
derived as a special case of our theory. Finally, we enforce graph sparsity
with constrained optimization and illustrate our theory and algorithm in
simulations.","['Sébastien Lachapelle', 'Simon Lacoste-Julien']","['stat.ML', 'cs.LG']",2022-07-15 20:06:12+00:00
http://arxiv.org/abs/2207.07697v1,POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging,"Fine-tuning models on edge devices like mobile phones would enable
privacy-preserving personalization over sensitive data. However, edge training
has historically been limited to relatively small models with simple
architectures because training is both memory and energy intensive. We present
POET, an algorithm to enable training large neural networks on memory-scarce
battery-operated edge devices. POET jointly optimizes the integrated search
search spaces of rematerialization and paging, two algorithms to reduce the
memory consumption of backpropagation. Given a memory budget and a run-time
constraint, we formulate a mixed-integer linear program (MILP) for
energy-optimal training. Our approach enables training significantly larger
models on embedded devices while reducing energy consumption while not
modifying mathematical correctness of backpropagation. We demonstrate that it
is possible to fine-tune both ResNet-18 and BERT within the memory constraints
of a Cortex-M class embedded device while outperforming current edge training
methods in energy efficiency. POET is an open-source project available at
https://github.com/ShishirPatil/poet","['Shishir G. Patil', 'Paras Jain', 'Prabal Dutta', 'Ion Stoica', 'Joseph E. Gonzalez']","['cs.LG', 'cs.CV', 'cs.DC', 'stat.ML']",2022-07-15 18:36:29+00:00
http://arxiv.org/abs/2207.07635v1,Is a Caption Worth a Thousand Images? A Controlled Study for Representation Learning,"The development of CLIP [Radford et al., 2021] has sparked a debate on
whether language supervision can result in vision models with more transferable
representations than traditional image-only methods. Our work studies this
question through a carefully controlled comparison of two approaches in terms
of their ability to learn representations that generalize to downstream
classification tasks. We find that when the pre-training dataset meets certain
criteria -- it is sufficiently large and contains descriptive captions with low
variability -- image-only methods do not match CLIP's transfer performance,
even when they are trained with more image data. However, contrary to what one
might expect, there are practical settings in which these criteria are not met,
wherein added supervision through captions is actually detrimental. Motivated
by our findings, we devise simple prescriptions to enable CLIP to better
leverage the language information present in existing pre-training datasets.","['Shibani Santurkar', 'Yann Dubois', 'Rohan Taori', 'Percy Liang', 'Tatsunori Hashimoto']","['cs.CV', 'cs.LG', 'stat.ML']",2022-07-15 17:50:51+00:00
http://arxiv.org/abs/2207.07624v2,Feed-Forward Latent Domain Adaptation,"We study a new highly-practical problem setting that enables
resource-constrained edge devices to adapt a pre-trained model to their local
data distributions. Recognizing that device's data are likely to come from
multiple latent domains that include a mixture of unlabelled domain-relevant
and domain-irrelevant examples, we focus on the comparatively under-studied
problem of latent domain adaptation. Considering limitations of edge devices,
we aim to only use a pre-trained model and adapt it in a feed-forward way,
without using back-propagation and without access to the source data. Modelling
these realistic constraints bring us to the novel and practically important
problem setting of feed-forward latent domain adaptation. Our solution is to
meta-learn a network capable of embedding the mixed-relevance target dataset
and dynamically adapting inference for target examples using cross-attention.
The resulting framework leads to consistent improvements over strong ERM
baselines. We also show that our framework sometimes even improves on the upper
bound of domain-supervised adaptation, where only domain-relevant instances are
provided for adaptation. This suggests that human annotated domain labels may
not always be optimal, and raises the possibility of doing better through
automated instance selection.","['Ondrej Bohdal', 'Da Li', 'Shell Xu Hu', 'Timothy Hospedales']","['cs.LG', 'stat.ML']",2022-07-15 17:37:42+00:00
http://arxiv.org/abs/2207.07612v1,Blessing of Nonconvexity in Deep Linear Models: Depth Flattens the Optimization Landscape Around the True Solution,"This work characterizes the effect of depth on the optimization landscape of
linear regression, showing that, despite their nonconvexity, deeper models have
more desirable optimization landscape. We consider a robust and
over-parameterized setting, where a subset of measurements are grossly
corrupted with noise and the true linear model is captured via an $N$-layer
linear neural network. On the negative side, we show that this problem
\textit{does not} have a benign landscape: given any $N\geq 1$, with constant
probability, there exists a solution corresponding to the ground truth that is
neither local nor global minimum. However, on the positive side, we prove that,
for any $N$-layer model with $N\geq 2$, a simple sub-gradient method becomes
oblivious to such ``problematic'' solutions; instead, it converges to a
balanced solution that is not only close to the ground truth but also enjoys a
flat local landscape, thereby eschewing the need for ""early stopping"". Lastly,
we empirically verify that the desirable optimization landscape of deeper
models extends to other robust learning tasks, including deep matrix recovery
and deep ReLU networks with $\ell_1$-loss.","['Jianhao Ma', 'Salar Fattahi']","['cs.LG', 'stat.ML']",2022-07-15 17:11:26+00:00
http://arxiv.org/abs/2207.07589v1,A two-step machine learning approach to statistical post-processing of weather forecasts for power generation,"By the end of 2021, the renewable energy share of the global electricity
capacity reached 38.3% and the new installations are dominated by wind and
solar energy, showing global increases of 12.7% and 18.5%, respectively.
However, both wind and photovoltaic energy sources are highly volatile making
planning difficult for grid operators, so accurate forecasts of the
corresponding weather variables are essential for reliable electricity
predictions. The most advanced approach in weather prediction is the ensemble
method, which opens the door for probabilistic forecasting; though ensemble
forecast are often underdispersive and subject to systematic bias. Hence, they
require some form of statistical post-processing, where parametric models
provide full predictive distributions of the weather variables at hand. We
propose a general two-step machine learning-based approach to calibrating
ensemble weather forecasts, where in the first step improved point forecasts
are generated, which are then together with various ensemble statistics serve
as input features of the neural network estimating the parameters of the
predictive distribution. In two case studies based of 100m wind speed and
global horizontal irradiance forecasts of the operational ensemble pre diction
system of the Hungarian Meteorological Service, the predictive performance of
this novel method is compared with the forecast skill of the raw ensemble and
the state-of-the-art parametric approaches. Both case studies confirm that at
least up to 48h statistical post-processing substantially improves the
predictive performance of the raw ensemble for all considered forecast
horizons. The investigated variants of the proposed two-step method outperform
in skill their competitors and the suggested new approach is well applicable
for different weather quantities and for a fair range of predictive
distributions.","['Ágnes Baran', 'Sándor Baran']","['stat.ML', 'cs.LG', 'stat.AP']",2022-07-15 16:38:14+00:00
http://arxiv.org/abs/2207.11146v1,VTrackIt: A Synthetic Self-Driving Dataset with Infrastructure and Pooled Vehicle Information,"Artificial intelligence solutions for Autonomous Vehicles (AVs) have been
developed using publicly available datasets such as Argoverse, ApolloScape,
Level5, and NuScenes. One major limitation of these datasets is the absence of
infrastructure and/or pooled vehicle information like lane line type, vehicle
speed, traffic signs, and intersections. Such information is necessary and not
complementary to eliminating high-risk edge cases. The rapid advancements in
Vehicle-to-Infrastructure and Vehicle-to-Vehicle technologies show promise that
infrastructure and pooled vehicle information will soon be accessible in near
real-time. Taking a leap in the future, we introduce the first comprehensive
synthetic dataset with intelligent infrastructure and pooled vehicle
information for advancing the next generation of AVs, named VTrackIt. We also
introduce the first deep learning model (InfraGAN) for trajectory predictions
that considers such information. Our experiments with InfraGAN show that the
comprehensive information offered by VTrackIt reduces the number of high-risk
edge cases. The VTrackIt dataset is available upon request under the Creative
Commons CC BY-NC-SA 4.0 license at http://vtrackit.irda.club.","['Mayuresh Savargaonkar', 'Abdallah Chehade']","['cs.CV', 'cs.AI', 'cs.LG', 'stat.ML']",2022-07-15 16:00:33+00:00
http://arxiv.org/abs/2207.07533v2,Selection of the Most Probable Best,"We consider an expected-value ranking and selection (R&S) problem where all k
solutions' simulation outputs depend on a common parameter whose uncertainty
can be modeled by a distribution. We define the most probable best (MPB) to be
the solution that has the largest probability of being optimal with respect to
the distribution and design an efficient sequential sampling algorithm to learn
the MPB when the parameter has a finite support. We derive the large deviations
rate of the probability of falsely selecting the MPB and formulate an optimal
computing budget allocation problem to find the rate-maximizing static sampling
ratios. The problem is then relaxed to obtain a set of optimality conditions
that are interpretable and computationally efficient to verify. We devise a
series of algorithms that replace the unknown means in the optimality
conditions with their estimates and prove the algorithms' sampling ratios
achieve the conditions as the simulation budget increases. Furthermore, we show
that the empirical performances of the algorithms can be significantly improved
by adopting the kernel ridge regression for mean estimation while achieving the
same asymptotic convergence results. The algorithms are benchmarked against a
state-of-the-art contextual R&S algorithm and demonstrated to have superior
empirical performances.","['Taeho Kim', 'Kyoung-kuk Kim', 'Eunhye Song']","['stat.ME', 'cs.LG', 'stat.ML']",2022-07-15 15:27:27+00:00
http://arxiv.org/abs/2207.07467v1,Deep Hedging: Continuous Reinforcement Learning for Hedging of General Portfolios across Multiple Risk Aversions,"We present a method for finding optimal hedging policies for arbitrary
initial portfolios and market states. We develop a novel actor-critic algorithm
for solving general risk-averse stochastic control problems and use it to learn
hedging strategies across multiple risk aversion levels simultaneously. We
demonstrate the effectiveness of the approach with a numerical example in a
stochastic volatility environment.","['Phillip Murray', 'Ben Wood', 'Hans Buehler', 'Magnus Wiese', 'Mikko S. Pakkanen']","['q-fin.CP', 'q-fin.RM', 'stat.ML']",2022-07-15 13:24:54+00:00
http://arxiv.org/abs/2207.07458v1,Joint Application of the Target Trial Causal Framework and Machine Learning Modeling to Optimize Antibiotic Therapy: Use Case on Acute Bacterial Skin and Skin Structure Infections due to Methicillin-resistant Staphylococcus aureus,"Bacterial infections are responsible for high mortality worldwide.
Antimicrobial resistance underlying the infection, and multifaceted patient's
clinical status can hamper the correct choice of antibiotic treatment.
Randomized clinical trials provide average treatment effect estimates but are
not ideal for risk stratification and optimization of therapeutic choice, i.e.,
individualized treatment effects (ITE). Here, we leverage large-scale
electronic health record data, collected from Southern US academic clinics, to
emulate a clinical trial, i.e., 'target trial', and develop a machine learning
model of mortality prediction and ITE estimation for patients diagnosed with
acute bacterial skin and skin structure infection (ABSSSI) due to
methicillin-resistant Staphylococcus aureus (MRSA). ABSSSI-MRSA is a
challenging condition with reduced treatment options - vancomycin is the
preferred choice, but it has non-negligible side effects. First, we use
propensity score matching to emulate the trial and create a treatment
randomized (vancomycin vs. other antibiotics) dataset. Next, we use this data
to train various machine learning methods (including boosted/LASSO logistic
regression, support vector machines, and random forest) and choose the best
model in terms of area under the receiver characteristic (AUC) through
bootstrap validation. Lastly, we use the models to calculate ITE and identify
possible averted deaths by therapy change. The out-of-bag tests indicate that
SVM and RF are the most accurate, with AUC of 81% and 78%, respectively, but
BLR/LASSO is not far behind (76%). By calculating the counterfactuals using the
BLR/LASSO, vancomycin increases the risk of death, but it shows a large
variation (odds ratio 1.2, 95% range 0.4-3.8) and the contribution to outcome
probability is modest. Instead, the RF exhibits stronger changes in ITE,
suggesting more complex treatment heterogeneity.","['Inyoung Jun', 'Simone Marini', 'Christina A. Boucher', 'J. Glenn Morris', 'Jiang Bian', 'Mattia Prosperi']","['stat.ML', 'cs.LG']",2022-07-15 13:08:15+00:00
http://arxiv.org/abs/2207.07411v1,Plex: Towards Reliability using Pretrained Large Model Extensions,"A recent trend in artificial intelligence is the use of pretrained models for
language and vision tasks, which have achieved extraordinary performance but
also puzzling failures. Probing these models' abilities in diverse ways is
therefore critical to the field. In this paper, we explore the reliability of
models, where we define a reliable model as one that not only achieves strong
predictive performance but also performs well consistently over many
decision-making tasks involving uncertainty (e.g., selective prediction, open
set recognition), robust generalization (e.g., accuracy and proper scoring
rules such as log-likelihood on in- and out-of-distribution datasets), and
adaptation (e.g., active learning, few-shot uncertainty). We devise 10 types of
tasks over 40 datasets in order to evaluate different aspects of reliability on
both vision and language domains. To improve reliability, we developed ViT-Plex
and T5-Plex, pretrained large model extensions for vision and language
modalities, respectively. Plex greatly improves the state-of-the-art across
reliability tasks, and simplifies the traditional protocol as it improves the
out-of-the-box performance and does not require designing scores or tuning the
model for each task. We demonstrate scaling effects over model sizes up to 1B
parameters and pretraining dataset sizes up to 4B examples. We also demonstrate
Plex's capabilities on challenging tasks including zero-shot open set
recognition, active learning, and uncertainty in conversational language
understanding.","['Dustin Tran', 'Jeremiah Liu', 'Michael W. Dusenberry', 'Du Phan', 'Mark Collier', 'Jie Ren', 'Kehang Han', 'Zi Wang', 'Zelda Mariet', 'Huiyi Hu', 'Neil Band', 'Tim G. J. Rudner', 'Karan Singhal', 'Zachary Nado', 'Joost van Amersfoort', 'Andreas Kirsch', 'Rodolphe Jenatton', 'Nithum Thain', 'Honglin Yuan', 'Kelly Buchanan', 'Kevin Murphy', 'D. Sculley', 'Yarin Gal', 'Zoubin Ghahramani', 'Jasper Snoek', 'Balaji Lakshminarayanan']","['cs.LG', 'stat.ML']",2022-07-15 11:39:37+00:00
http://arxiv.org/abs/2207.07250v1,On the Super-exponential Quantum Speedup of Equivariant Quantum Machine Learning Algorithms with SU($d$) Symmetry,"We introduce a framework of the equivariant convolutional algorithms which is
tailored for a number of machine-learning tasks on physical systems with
arbitrary SU($d$) symmetries. It allows us to enhance a natural model of
quantum computation--permutational quantum computing (PQC) [Quantum Inf.
Comput., 10, 470-497 (2010)] --and defines a more powerful model: PQC+. While
PQC was shown to be effectively classically simulatable, we exhibit a problem
which can be efficiently solved on PQC+ machine, whereas the best known
classical algorithms runs in $O(n!n^2)$ time, thus providing strong evidence
against PQC+ being classically simulatable. We further discuss practical
quantum machine learning algorithms which can be carried out in the paradigm of
PQC+.","['Han Zheng', 'Zimu Li', 'Junyu Liu', 'Sergii Strelchuk', 'Risi Kondor']","['quant-ph', 'cs.AI', 'cs.LG', 'math-ph', 'math.MP', 'stat.ML']",2022-07-15 01:41:53+00:00
http://arxiv.org/abs/2207.07235v2,Single Model Uncertainty Estimation via Stochastic Data Centering,"We are interested in estimating the uncertainties of deep neural networks,
which play an important role in many scientific and engineering problems. In
this paper, we present a striking new finding that an ensemble of neural
networks with the same weight initialization, trained on datasets that are
shifted by a constant bias gives rise to slightly inconsistent trained models,
where the differences in predictions are a strong indicator of epistemic
uncertainties. Using the neural tangent kernel (NTK), we demonstrate that this
phenomena occurs in part because the NTK is not shift-invariant. Since this is
achieved via a trivial input transformation, we show that this behavior can
therefore be approximated by training a single neural network -- using a
technique that we call $\Delta-$UQ -- that estimates uncertainty around
prediction by marginalizing out the effect of the biases during inference. We
show that $\Delta-$UQ's uncertainty estimates are superior to many of the
current methods on a variety of benchmarks -- outlier rejection, calibration
under distribution shift, and sequential design optimization of black box
functions. Code for $\Delta-$UQ can be accessed at
https://github.com/LLNL/DeltaUQ","['Jayaraman J. Thiagarajan', 'Rushil Anirudh', 'Vivek Narayanaswamy', 'Peer-Timo Bremer']","['cs.LG', 'cs.CV', 'stat.ML']",2022-07-14 23:54:54+00:00
http://arxiv.org/abs/2207.07218v2,On the Selection of Tuning Parameters for Patch-Stitching Embedding Methods,"While classical scaling, just like principal component analysis, is
parameter-free, other methods for embedding multivariate data require the
selection of one or several tuning parameters. This tuning can be difficult due
to the unsupervised nature of the situation. We propose a simple, almost
obvious, approach to supervise the choice of tuning parameter(s): minimize a
notion of stress. We apply this approach to the selection of the patch size in
a prototypical patch-stitching embedding method, both in the multidimensional
scaling (aka network localization) setting and in the dimensionality reduction
(aka manifold learning) setting. In our study, we uncover a new bias--variance
tradeoff phenomenon.","['Ery Arias-Castro', 'Phong Alain Chau']","['stat.ME', 'math.MG', 'math.ST', 'stat.ML', 'stat.TH']",2022-07-14 22:04:00+00:00
http://arxiv.org/abs/2207.07174v2,Attribute Graphs Underlying Molecular Generative Models: Path to Learning with Limited Data,"Training generative models that capture rich semantics of the data and
interpreting the latent representations encoded by such models are very
important problems in un-/self-supervised learning. In this work, we provide a
simple algorithm that relies on perturbation experiments on latent codes of a
pre-trained generative autoencoder to uncover an attribute graph that is
implied by the generative model. We perform perturbation experiments to check
for influence of a given latent variable on a subset of attributes. Given this,
we show that one can fit an effective graphical model that models a structural
equation model between latent codes taken as exogenous variables and attributes
taken as observed variables. One interesting aspect is that a single latent
variable controls multiple overlapping subsets of attributes unlike
conventional approaches that try to impose full independence. Using a
pre-trained generative autoencoder trained on a large dataset of small
molecules, we demonstrate that the graphical model between various molecular
attributes and latent codes learned by our algorithm can be used to predict a
specific property for molecules which are drawn from a different distribution.
We compare prediction models trained on various feature subsets chosen by
simple baselines, as well as existing causal discovery and sparse
learning/feature selection methods, with the ones in the derived Markov blanket
from our method. Results show empirically that the predictor that relies on our
Markov blanket attributes is robust to distribution shifts when transferred or
fine-tuned with a few samples from the new distribution, especially when
training data is limited.","['Samuel C. Hoffman', 'Payel Das', 'Karthikeyan Shanmugam', 'Kahini Wadhawan', 'Prasanna Sattigeri']","['cs.LG', 'stat.ML']",2022-07-14 19:20:30+00:00
http://arxiv.org/abs/2207.07150v2,Making Linear MDPs Practical via Contrastive Representation Learning,"It is common to address the curse of dimensionality in Markov decision
processes (MDPs) by exploiting low-rank representations. This motivates much of
the recent theoretical study on linear MDPs. However, most approaches require a
given representation under unrealistic assumptions about the normalization of
the decomposition or introduce unresolved computational challenges in practice.
Instead, we consider an alternative definition of linear MDPs that
automatically ensures normalization while allowing efficient representation
learning via contrastive estimation. The framework also admits
confidence-adjusted index algorithms, enabling an efficient and principled
approach to incorporating optimism or pessimism in the face of uncertainty. To
the best of our knowledge, this provides the first practical representation
learning method for linear MDPs that achieves both strong theoretical
guarantees and empirical performance. Theoretically, we prove that the proposed
algorithm is sample efficient in both the online and offline settings.
Empirically, we demonstrate superior performance over existing state-of-the-art
model-based and model-free algorithms on several benchmarks.","['Tianjun Zhang', 'Tongzheng Ren', 'Mengjiao Yang', 'Joseph E. Gonzalez', 'Dale Schuurmans', 'Bo Dai']","['cs.LG', 'stat.ML']",2022-07-14 18:18:02+00:00
http://arxiv.org/abs/2207.07105v1,Continuous-time Analysis for Variational Inequalities: An Overview and Desiderata,"Algorithms that solve zero-sum games, multi-objective agent objectives, or,
more generally, variational inequality (VI) problems are notoriously unstable
on general problems. Owing to the increasing need for solving such problems in
machine learning, this instability has been highlighted in recent years as a
significant research challenge. In this paper, we provide an overview of recent
progress in the use of continuous-time perspectives in the analysis and design
of methods targeting the broad VI problem class. Our presentation draws
parallels between single-objective problems and multi-objective problems,
highlighting the challenges of the latter. We also formulate various desiderata
for algorithms that apply to general VIs and we argue that achieving these
desiderata may profit from an understanding of the associated continuous-time
dynamics.","['Tatjana Chavdarova', 'Ya-Ping Hsieh', 'Michael I. Jordan']","['stat.ML', 'cs.LG', 'math.OC']",2022-07-14 17:58:02+00:00
