id,title,abstract,authors,categories,date
http://arxiv.org/abs/1805.05857v4,Glassy nature of the hard phase in inference problems,"An algorithmically hard phase was described in a range of inference problems:
even if the signal can be reconstructed with a small error from an information
theoretic point of view, known algorithms fail unless the noise-to-signal ratio
is sufficiently small. This hard phase is typically understood as a metastable
branch of the dynamical evolution of message passing algorithms. In this work
we study the metastable branch for a prototypical inference problem, the
low-rank matrix factorization, that presents a hard phase. We show that for
noise-to-signal ratios that are below the information theoretic threshold, the
posterior measure is composed of an exponential number of metastable glassy
states and we compute their entropy, called the complexity. We show that this
glassiness extends even slightly below the algorithmic threshold below which
the well-known approximate message passing (AMP) algorithm is able to closely
reconstruct the signal. Counter-intuitively, we find that the performance of
the AMP algorithm is not improved by taking into account the glassy nature of
the hard phase. This result provides further evidence that the hard phase in
inference problems is algorithmically impenetrable for some deep computational
reasons that remain to be uncovered.","['Fabrizio Antenucci', 'Silvio Franz', 'Pierfrancesco Urbani', 'Lenka Zdeborová']","['cond-mat.dis-nn', 'cond-mat.stat-mech', 'cs.IT', 'math.IT', 'math.ST', 'stat.ML', 'stat.TH']",2018-05-15 15:39:36+00:00
http://arxiv.org/abs/1805.05838v3,Gradient-Leaks: Understanding and Controlling Deanonymization in Federated Learning,"Federated Learning (FL) systems are gaining popularity as a solution to
training Machine Learning (ML) models from large-scale user data collected on
personal devices (e.g., smartphones) without their raw data leaving the device.
At the core of FL is a network of anonymous user devices sharing training
information (model parameter updates) computed locally on personal data.
However, the type and degree to which user-specific information is encoded in
the model updates is poorly understood. In this paper, we identify model
updates encode subtle variations in which users capture and generate data. The
variations provide a strong statistical signal, allowing an adversary to
effectively deanonymize participating devices using a limited set of auxiliary
data. We analyze resulting deanonymization attacks on diverse tasks on
real-world (anonymized) user-generated data across a range of closed- and
open-world scenarios. We study various strategies to mitigate the risks of
deanonymization. As random perturbation methods do not offer convincing
operating points, we propose data-augmentation strategies which introduces
adversarial biases in device data and thereby, offer substantial protection
against deanonymization threats with little effect on utility.","['Tribhuvanesh Orekondy', 'Seong Joon Oh', 'Yang Zhang', 'Bernt Schiele', 'Mario Fritz']","['cs.CR', 'cs.AI', 'cs.CV', 'cs.LG', 'stat.ML']",2018-05-15 15:12:45+00:00
http://arxiv.org/abs/1805.05827v1,Graph Signal Sampling via Reinforcement Learning,"We formulate the problem of sampling and recovering clustered graph signal as
a multi-armed bandit (MAB) problem. This formulation lends naturally to
learning sampling strategies using the well-known gradient MAB algorithm. In
particular, the sampling strategy is represented as a probability distribution
over the individual arms of the MAB and optimized using gradient ascent. Some
illustrative numerical experiments indicate that the sampling strategies based
on the gradient MAB algorithm outperform existing sampling methods.","['Oleksii Abramenko', 'Alexander Jung']","['stat.ML', 'cs.AI', 'cs.LG']",2018-05-15 14:46:45+00:00
http://arxiv.org/abs/1805.05826v1,A Purely End-to-end System for Multi-speaker Speech Recognition,"Recently, there has been growing interest in multi-speaker speech
recognition, where the utterances of multiple speakers are recognized from
their mixture. Promising techniques have been proposed for this task, but
earlier works have required additional training data such as isolated source
signals or senone alignments for effective learning. In this paper, we propose
a new sequence-to-sequence framework to directly decode multiple label
sequences from a single speech sequence by unifying source separation and
speech recognition functions in an end-to-end manner. We further propose a new
objective function to improve the contrast between the hidden vectors to avoid
generating similar hypotheses. Experimental results show that the model is
directly able to learn a mapping from a speech mixture to multiple label
sequences, achieving 83.1 % relative improvement compared to a model trained
without the proposed objective. Interestingly, the results are comparable to
those produced by previous end-to-end works featuring explicit separation and
recognition modules.","['Hiroshi Seki', 'Takaaki Hori', 'Shinji Watanabe', 'Jonathan Le Roux', 'John R. Hershey']","['cs.SD', 'cs.CL', 'eess.AS', 'stat.ML']",2018-05-15 14:45:33+00:00
http://arxiv.org/abs/1805.05809v3,Efficient end-to-end learning for quantizable representations,"Embedding representation learning via neural networks is at the core
foundation of modern similarity based search. While much effort has been put in
developing algorithms for learning binary hamming code representations for
search efficiency, this still requires a linear scan of the entire dataset per
each query and trades off the search accuracy through binarization. To this
end, we consider the problem of directly learning a quantizable embedding
representation and the sparse binary hash code end-to-end which can be used to
construct an efficient hash table not only providing significant search
reduction in the number of data but also achieving the state of the art search
accuracy outperforming previous state of the art deep metric learning methods.
We also show that finding the optimal sparse binary hash code in a mini-batch
can be computed exactly in polynomial time by solving a minimum cost flow
problem. Our results on Cifar-100 and on ImageNet datasets show the state of
the art search accuracy in precision@k and NMI metrics while providing up to
98X and 478X search speedup respectively over exhaustive linear search. The
source code is available at
https://github.com/maestrojeong/Deep-Hash-Table-ICML18","['Yeonwoo Jeong', 'Hyun Oh Song']","['cs.LG', 'cs.CV', 'stat.ML']",2018-05-15 14:32:31+00:00
http://arxiv.org/abs/1805.05751v3,Local Saddle Point Optimization: A Curvature Exploitation Approach,"Gradient-based optimization methods are the most popular choice for finding
local optima for classical minimization and saddle point problems. Here, we
highlight a systemic issue of gradient dynamics that arise for saddle point
problems, namely the presence of undesired stable stationary points that are no
local optima. We propose a novel optimization approach that exploits curvature
information in order to escape from these undesired stationary points. We prove
that different optimization methods, including gradient method and Adagrad,
equipped with curvature exploitation can escape non-optimal stationary points.
We also provide empirical results on common saddle point problems which confirm
the advantage of using curvature exploitation.","['Leonard Adolphs', 'Hadi Daneshmand', 'Aurelien Lucchi', 'Thomas Hofmann']","['cs.LG', 'math.OC', 'stat.ML']",2018-05-15 13:22:45+00:00
http://arxiv.org/abs/1805.05703v1,The Hierarchical Adaptive Forgetting Variational Filter,"A common problem in Machine Learning and statistics consists in detecting
whether the current sample in a stream of data belongs to the same distribution
as previous ones, is an isolated outlier or inaugurates a new distribution of
data. We present a hierarchical Bayesian algorithm that aims at learning a
time-specific approximate posterior distribution of the parameters describing
the distribution of the data observed. We derive the update equations of the
variational parameters of the approximate posterior at each time step for
models from the exponential family, and show that these updates find
interesting correspondents in Reinforcement Learning (RL). In this perspective,
our model can be seen as a hierarchical RL algorithm that learns a posterior
distribution according to a certain stability confidence that is, in turn,
learned according to its own stability confidence. Finally, we show some
applications of our generic model, first in a RL context, next with an adaptive
Bayesian Autoregressive model, and finally in the context of Stochastic
Gradient Descent optimization.",['Vincent Moens'],"['stat.ML', 'cs.LG']",2018-05-15 10:57:06+00:00
http://arxiv.org/abs/1805.05606v2,Nonparametric Bayesian volatility learning under microstructure noise,"In this work, we study the problem of learning the volatility under market
microstructure noise. Specifically, we consider noisy discrete time
observations from a stochastic differential equation and develop a novel
computational method to learn the diffusion coefficient of the equation. We
take a nonparametric Bayesian approach, where we \emph{a priori} model the
volatility function as piecewise constant. Its prior is specified via the
inverse Gamma Markov chain. Sampling from the posterior is accomplished by
incorporating the Forward Filtering Backward Simulation algorithm in the Gibbs
sampler. Good performance of the method is demonstrated on two representative
synthetic data examples. We also apply the method on a EUR/USD exchange rate
dataset. Finally we present a limit result on the prior distribution.","['Shota Gugushvili', 'Frank van der Meulen', 'Moritz Schauer', 'Peter Spreij']","['stat.ME', 'q-fin.ST', 'stat.ML', 'Primary: 62G20, Secondary: 62M05']",2018-05-15 07:32:18+00:00
http://arxiv.org/abs/1805.05536v1,Advances in Experience Replay,"This project combines recent advances in experience replay techniques,
namely, Combined Experience Replay (CER), Prioritized Experience Replay (PER),
and Hindsight Experience Replay (HER). We show the results of combinations of
these techniques with DDPG and DQN methods. CER always adds the most recent
experience to the batch. PER chooses which experiences should be replayed based
on how beneficial they will be towards learning. HER learns from failure by
substituting the desired goal with the achieved goal and recomputing the reward
function. The effectiveness of combinations of these experience replay
techniques is tested in a variety of OpenAI gym environments.","['Tracy Wan', 'Neil Xu']","['cs.LG', 'stat.ML']",2018-05-15 02:50:35+00:00
http://arxiv.org/abs/1805.05532v4,Knowledge Distillation with Adversarial Samples Supporting Decision Boundary,"Many recent works on knowledge distillation have provided ways to transfer
the knowledge of a trained network for improving the learning process of a new
one, but finding a good technique for knowledge distillation is still an open
problem. In this paper, we provide a new perspective based on a decision
boundary, which is one of the most important component of a classifier. The
generalization performance of a classifier is closely related to the adequacy
of its decision boundary, so a good classifier bears a good decision boundary.
Therefore, transferring information closely related to the decision boundary
can be a good attempt for knowledge distillation. To realize this goal, we
utilize an adversarial attack to discover samples supporting a decision
boundary. Based on this idea, to transfer more accurate information about the
decision boundary, the proposed algorithm trains a student classifier based on
the adversarial samples supporting the decision boundary. Experiments show that
the proposed method indeed improves knowledge distillation and achieves the
state-of-the-arts performance.","['Byeongho Heo', 'Minsik Lee', 'Sangdoo Yun', 'Jin Young Choi']","['cs.LG', 'cs.CV', 'stat.ML']",2018-05-15 02:42:40+00:00
http://arxiv.org/abs/1805.05502v5,Nonlinear Dimensionality Reduction for Discriminative Analytics of Multiple Datasets,"Principal component analysis (PCA) is widely used for feature extraction and
dimensionality reduction, with documented merits in diverse tasks involving
high-dimensional data. Standard PCA copes with one dataset at a time, but it is
challenged when it comes to analyzing multiple datasets jointly. In certain
data science settings however, one is often interested in extracting the most
discriminative information from one dataset of particular interest (a.k.a.
target data) relative to the other(s) (a.k.a. background data). To this end,
this paper puts forth a novel approach, termed discriminative (d) PCA, for such
discriminative analytics of multiple datasets. Under certain conditions, dPCA
is proved to be least-squares optimal in recovering the component vector unique
to the target data relative to background data. To account for nonlinear data
correlations, (linear) dPCA models for one or multiple background datasets are
generalized through kernel-based learning. Interestingly, all dPCA variants
admit an analytical solution obtainable with a single (generalized) eigenvalue
decomposition. Finally, corroborating dimensionality reduction tests using both
synthetic and real datasets are provided to validate the effectiveness of the
proposed methods.","['Jia Chen', 'Gang Wang', 'Georgios B. Giannakis']","['cs.LG', 'eess.SP', 'stat.AP', 'stat.ML']",2018-05-15 00:24:43+00:00
http://arxiv.org/abs/1805.05491v1,Crowdbreaks: Tracking Health Trends using Public Social Media Data and Crowdsourcing,"In the past decade, tracking health trends using social media data has shown
great promise, due to a powerful combination of massive adoption of social
media around the world, and increasingly potent hardware and software that
enables us to work with these new big data streams. At the same time, many
challenging problems have been identified. First, there is often a mismatch
between how rapidly online data can change, and how rapidly algorithms are
updated, which means that there is limited reusability for algorithms trained
on past data as their performance decreases over time. Second, much of the work
is focusing on specific issues during a specific past period in time, even
though public health institutions would need flexible tools to assess multiple
evolving situations in real time. Third, most tools providing such capabilities
are proprietary systems with little algorithmic or data transparency, and thus
little buy-in from the global public health and research community. Here, we
introduce Crowdbreaks, an open platform which allows tracking of health trends
by making use of continuous crowdsourced labelling of public social media
content. The system is built in a way which automatizes the typical workflow
from data collection, filtering, labelling and training of machine learning
classifiers and therefore can greatly accelerate the research process in the
public health domain. This work introduces the technical aspects of the
platform and explores its future use cases.","['Martin Mueller', 'Marcel Salathé']","['cs.CY', 'cs.CL', 'cs.SI', 'stat.ML']",2018-05-14 22:59:56+00:00
http://arxiv.org/abs/1805.05480v2,ABC-CDE: Towards Approximate Bayesian Computation with Complex High-Dimensional Data and Limited Simulations,"Approximate Bayesian Computation (ABC) is typically used when the likelihood
is either unavailable or intractable but where data can be simulated under
different parameter settings using a forward model. Despite the recent interest
in ABC, high-dimensional data and costly simulations still remain a bottleneck
in some applications. There is also no consensus as to how to best assess the
performance of such methods without knowing the true posterior. We show how a
nonparametric conditional density estimation (CDE) framework, which we refer to
as ABC-CDE, help address three nontrivial challenges in ABC: (i) how to
efficiently estimate the posterior distribution with limited simulations and
different types of data, (ii) how to tune and compare the performance of ABC
and related methods in estimating the posterior itself, rather than just
certain properties of the density, and (iii) how to efficiently choose among a
large set of summary statistics based on a CDE surrogate loss. We provide
theoretical and empirical evidence that justify ABC-CDE procedures that {\em
directly} estimate and assess the posterior based on an initial ABC sample, and
we describe settings where standard ABC and regression-based approaches are
inadequate.","['Rafael Izbicki', 'Ann B. Lee', 'Taylor Pospisil']","['stat.ME', 'stat.ML']",2018-05-14 22:05:38+00:00
http://arxiv.org/abs/1805.05456v1,Wearable Audio and IMU Based Shot Detection in Racquet Sports,"Wearables like smartwatches which are embedded with sensors and powerful
processors, provide a strong platform for development of analytics solutions in
sports domain. To analyze players' games, while motion sensor based shot
detection has been extensively studied in sports like Tennis, Golf, Baseball;
Table Tennis and Badminton are relatively less explored due to possible less
intense hand motion during shots. In our paper, we propose a novel,
computationally inexpensive and real-time system for shot detection in table
tennis, based on fusion of Inertial Measurement Unit (IMU) and audio sensor
data embedded in a wrist-worn wearable. The system builds upon our presented
methodology for synchronizing IMU and audio sensor input in time using detected
shots and achieves 95.6% accuracy. To our knowledge, it is the first
fusion-based solution for sports analysis in wearables. Shot detectors for
other racquet sports as well as further analytics to provide features like shot
classification, rally analysis and recommendations, can easily be built over
our proposed solution.","['Manish Sharma', 'Akash Anand', 'Rupika Srivastava', 'Lakshmi Kaligounder']","['cs.LG', 'cs.AI', 'stat.ML']",2018-05-14 21:31:59+00:00
http://arxiv.org/abs/1805.05396v2,Confidence Scoring Using Whitebox Meta-models with Linear Classifier Probes,"We propose a novel confidence scoring mechanism for deep neural networks
based on a two-model paradigm involving a base model and a meta-model. The
confidence score is learned by the meta-model observing the base model
succeeding/failing at its task. As features to the meta-model, we investigate
linear classifier probes inserted between the various layers of the base model.
Our experiments demonstrate that this approach outperforms various baselines in
a filtering task, i.e., task of rejecting samples with low confidence.
Experimental results are presented using CIFAR-10 and CIFAR-100 dataset with
and without added noise. We discuss the importance of confidence scoring to
bridge the gap between experimental and real-world applications.","['Tongfei Chen', 'Jiří Navrátil', 'Vijay Iyengar', 'Karthikeyan Shanmugam']","['cs.LG', 'stat.ML']",2018-05-14 19:23:51+00:00
http://arxiv.org/abs/1805.05383v2,Spatio-temporal Bayesian On-line Changepoint Detection with Model Selection,"Bayesian On-line Changepoint Detection is extended to on-line model selection
and non-stationary spatio-temporal processes. We propose spatially structured
Vector Autoregressions (VARs) for modelling the process between changepoints
(CPs) and give an upper bound on the approximation error of such models. The
resulting algorithm performs prediction, model selection and CP detection
on-line. Its time complexity is linear and its space complexity constant, and
thus it is two orders of magnitudes faster than its closest competitor. In
addition, it outperforms the state of the art for multivariate data.","['Jeremias Knoblauch', 'Theodoros Damoulas']","['stat.ML', 'cs.LG', 'stat.ME']",2018-05-14 18:59:04+00:00
http://arxiv.org/abs/1805.05287v2,A Cost-Effective Framework for Preference Elicitation and Aggregation,"We propose a cost-effective framework for preference elicitation and
aggregation under the Plackett-Luce model with features. Given a budget, our
framework iteratively computes the most cost-effective elicitation questions in
order to help the agents make a better group decision.
  We illustrate the viability of the framework with experiments on Amazon
Mechanical Turk, which we use to estimate the cost of answering different types
of elicitation questions. We compare the prediction accuracy of our framework
when adopting various information criteria that evaluate the expected
information gain from a question. Our experiments show carefully designed
information criteria are much more efficient, i.e., they arrive at the correct
answer using fewer queries, than randomly asking questions given the budget
constraint.","['Zhibing Zhao', 'Haoming Li', 'Junming Wang', 'Jeffrey Kephart', 'Nicholas Mattei', 'Hui Su', 'Lirong Xia']","['cs.LG', 'cs.AI', 'cs.HC', 'stat.ML']",2018-05-14 16:57:36+00:00
http://arxiv.org/abs/1805.05814v1,SHADE: Information-Based Regularization for Deep Learning,"Regularization is a big issue for training deep neural networks. In this
paper, we propose a new information-theory-based regularization scheme named
SHADE for SHAnnon DEcay. The originality of the approach is to define a prior
based on conditional entropy, which explicitly decouples the learning of
invariant representations in the regularizer and the learning of correlations
between inputs and labels in the data fitting term. Our second contribution is
to derive a stochastic version of the regularizer compatible with deep
learning, resulting in a tractable training scheme. We empirically validate the
efficiency of our approach to improve classification performances compared to
standard regularization schemes on several standard architectures.","['Michael Blot', 'Thomas Robert', 'Nicolas Thome', 'Matthieu Cord']","['stat.ML', 'cs.LG']",2018-05-14 14:21:23+00:00
http://arxiv.org/abs/1805.05185v1,Generative Adversarial Forests for Better Conditioned Adversarial Learning,"In recent times, many of the breakthroughs in various vision-related tasks
have revolved around improving learning of deep models; these methods have
ranged from network architectural improvements such as Residual Networks, to
various forms of regularisation such as Batch Normalisation. In essence, many
of these techniques revolve around better conditioning, allowing for deeper and
deeper models to be successfully learned. In this paper, we look towards better
conditioning Generative Adversarial Networks (GANs) in an unsupervised learning
setting. Our method embeds the powerful discriminating capabilities of a
decision forest into the discriminator of a GAN. This results in a better
conditioned model which learns in an extremely stable way. We demonstrate
empirical results which show both clear qualitative and quantitative evidence
of the effectiveness of our approach, gaining significant performance
improvements over several popular GAN-based approaches on the Oxford Flowers
and Aligned Celebrity Faces datasets.","['Yan Zuo', 'Gil Avraham', 'Tom Drummond']","['stat.ML', 'cs.LG']",2018-05-14 14:19:49+00:00
http://arxiv.org/abs/1805.05151v1,Domain Adaptation with Adversarial Training and Graph Embeddings,"The success of deep neural networks (DNNs) is heavily dependent on the
availability of labeled data. However, obtaining labeled data is a big
challenge in many real-world problems. In such scenarios, a DNN model can
leverage labeled and unlabeled data from a related domain, but it has to deal
with the shift in data distributions between the source and the target domains.
In this paper, we study the problem of classifying social media posts during a
crisis event (e.g., Earthquake). For that, we use labeled and unlabeled data
from past similar events (e.g., Flood) and unlabeled data for the current
event. We propose a novel model that performs adversarial learning based domain
adaptation to deal with distribution drifts and graph based semi-supervised
learning to leverage unlabeled data within a single unified deep learning
framework. Our experiments with two real-world crisis datasets collected from
Twitter demonstrate significant improvements over several baselines.","['Firoj Alam', 'Shafiq Joty', 'Muhammad Imran']","['cs.LG', 'stat.ML']",2018-05-14 12:54:47+00:00
http://arxiv.org/abs/1805.05133v2,Model selection with lasso-zero: adding straw to the haystack to better find needles,"The high-dimensional linear model $y = X \beta^0 + \epsilon$ is considered
and the focus is put on the problem of recovering the support $S^0$ of the
sparse vector $\beta^0.$ We introduce Lasso-Zero, a new $\ell_1$-based
estimator whose novelty resides in an ""overfit, then threshold"" paradigm and
the use of noise dictionaries concatenated to $X$ for overfitting the response.
To select the threshold, we employ the quantile universal threshold based on a
pivotal statistic that requires neither knowledge nor preliminary estimation of
the noise level. Numerical simulations show that Lasso-Zero performs well in
terms of support recovery and provides an excellent trade-off between high true
positive rate and low false discovery rate compared to competitors. Our
methodology is supported by theoretical results showing that when no noise
dictionary is used, Lasso-Zero recovers the signs of $\beta^0$ under weaker
conditions on $X$ and $S^0$ than the Lasso and achieves sign consistency for
correlated Gaussian designs. The use of noise dictionary improves the procedure
for low signals.","['Pascaline Descloux', 'Sylvain Sardy']","['stat.ME', 'stat.ML']",2018-05-14 12:03:13+00:00
http://arxiv.org/abs/1805.05071v3,KL-UCB-switch: optimal regret bounds for stochastic bandits from both a distribution-dependent and a distribution-free viewpoints,"We consider $K$-armed stochastic bandits and consider cumulative regret
bounds up to time $T$. We are interested in strategies achieving simultaneously
a distribution-free regret bound of optimal order $\sqrt{KT}$ and a
distribution-dependent regret that is asymptotically optimal, that is, matching
the $\kappa\ln T$ lower bound by Lai and Robbins (1985) and Burnetas and
Katehakis (1996), where $\kappa$ is the optimal problem-dependent constant.
This constant $\kappa$ depends on the model $\mathcal{D}$ considered (the
family of possible distributions over the arms). M\'enard and Garivier (2017)
provided strategies achieving such a bi-optimality in the parametric case of
models given by one-dimensional exponential families, while Lattimore (2016,
2018) did so for the family of (sub)Gaussian distributions with variance less
than $1$. We extend this result to the non-parametric case of all distributions
over $[0,1]$. We do so by combining the MOSS strategy by Audibert and Bubeck
(2009), which enjoys a distribution-free regret bound of optimal order
$\sqrt{KT}$, and the KL-UCB strategy by Capp\'e et al. (2013), for which we
provide in passing the first analysis of an optimal distribution-dependent
$\kappa\ln T$ regret bound in the model of all distributions over $[0,1]$. We
were able to obtain this non-parametric bi-optimality result while working hard
to streamline the proofs (of previously known regret bounds and thus of the new
analyses carried out); a second merit of the present contribution is therefore
to provide a review of proofs of classical regret bounds for index-based
strategies for $K$-armed stochastic bandits.","['Aurélien Garivier', 'Hédi Hadiji', 'Pierre Menard', 'Gilles Stoltz']","['stat.ML', 'cs.LG', 'math.ST', 'stat.TH']",2018-05-14 09:05:10+00:00
http://arxiv.org/abs/1805.05052v17,Machine Learning: The Basics,"Machine learning (ML) has become a commodity in our every-day lives. We
routinely ask ML empowered smartphones to suggest lovely food places or to
guide us through a strange place. ML methods have also become standard tools in
many fields of science and engineering. A plethora of ML applications transform
human lives at unprecedented pace and scale. This book portrays ML as the
combination of three basic components: data, model and loss. ML methods combine
these three components within computationally efficient implementations of the
basic scientific principle ""trial and error"". This principle consists of the
continuous adaptation of a hypothesis about a phenomenon that generates data.
ML methods use a hypothesis to compute predictions for future events. We
believe that thinking about ML as combinations of three components given by
data, model, and loss helps to navigate the steadily growing offer for
ready-to-use ML methods. Our three-component picture of ML allows a unified
treatment of a wide range of concepts and techniques which seem quite unrelated
at first sight. The regularization effect of early stopping in iterative
methods is due to the shrinking of the effective hypothesis space.
Privacy-preserving ML is obtained by particular choices for the features of
data points. Explainable ML methods are characterized by particular choices for
the hypothesis space. To make good use of ML tools it is instrumental to
understand its underlying principles at different levels of detail. On a lower
level, this tutorial helps ML engineers to choose suitable methods for the
application at hand. The book also offers a higher-level view on the
implementation of ML methods which is typically required to manage a team of ML
engineers and data scientists.",['Alexander Jung'],"['cs.LG', 'stat.ML', '97K80, 65Fxx', 'A.1; I.2; I.5; G.3; G.1']",2018-05-14 08:08:33+00:00
http://arxiv.org/abs/1805.05036v1,A Deep Learning Approach with an Attention Mechanism for Automatic Sleep Stage Classification,"Automatic sleep staging is a challenging problem and state-of-the-art
algorithms have not yet reached satisfactory performance to be used instead of
manual scoring by a sleep technician. Much research has been done to find good
feature representations that extract the useful information to correctly
classify each epoch into the correct sleep stage. While many useful features
have been discovered, the amount of features have grown to an extent that a
feature reduction step is necessary in order to avoid the curse of
dimensionality. One reason for the need of such a large feature set is that
many features are good for discriminating only one of the sleep stages and are
less informative during other stages. This paper explores how a second feature
representation over a large set of pre-defined features can be learned using an
auto-encoder with a selective attention for the current sleep stage in the
training batch. This selective attention allows the model to learn feature
representations that focuses on the more relevant inputs without having to
perform any dimensionality reduction of the input data. The performance of the
proposed algorithm is evaluated on a large data set of polysomnography (PSG)
night recordings of patients with sleep-disordered breathing. The performance
of the auto-encoder with selective attention is compared with a regular
auto-encoder and previous works using a deep belief network (DBN).","['Martin Längkvist', 'Amy Loutfi']","['cs.LG', 'q-bio.NC', 'stat.ML']",2018-05-14 07:36:26+00:00
http://arxiv.org/abs/1805.05021v3,A One-Class Classification Decision Tree Based on Kernel Density Estimation,"One-class Classification (OCC) is an area of machine learning which addresses
prediction based on unbalanced datasets. Basically, OCC algorithms achieve
training by means of a single class sample, with potentially some additional
counter-examples. The current OCC models give satisfaction in terms of
performance, but there is an increasing need for the development of
interpretable models. In the present work, we propose a one-class model which
addresses concerns of both performance and interpretability. Our hybrid OCC
method relies on density estimation as part of a tree-based learning algorithm,
called One-Class decision Tree (OC-Tree). Within a greedy and recursive
approach, our proposal rests on kernel density estimation to split a data
subset on the basis of one or several intervals of interest. Thus, the OC-Tree
encloses data within hyper-rectangles of interest which can be described by a
set of rules. Against state-of-the-art methods such as Cluster Support Vector
Data Description (ClusterSVDD), One-Class Support Vector Machine (OCSVM) and
isolation Forest (iForest), the OC-Tree performs favorably on a range of
benchmark datasets. Furthermore, we propose a real medical application for
which the OC-Tree has demonstrated its effectiveness, through the ability to
tackle interpretable diagnosis aid based on unbalanced datasets.","['Sarah Itani', 'Fabian Lecron', 'Philippe Fortemps']","['stat.ML', 'cs.LG']",2018-05-14 06:26:59+00:00
http://arxiv.org/abs/1805.08704v1,Replicating Active Appearance Model by Generator Network,"A recent Cell paper [Chang and Tsao, 2017] reports an interesting discovery.
For the face stimuli generated by a pre-trained active appearance model (AAM),
the responses of neurons in the areas of the primate brain that are responsible
for face recognition exhibit strong linear relationship with the shape
variables and appearance variables of the AAM that generates the face stimuli.
In this paper, we show that this behavior can be replicated by a deep
generative model called the generator network, which assumes that the observed
signals are generated by latent random variables via a top-down convolutional
neural network. Specifically, we learn the generator network from the face
images generated by a pre-trained AAM model using variational auto-encoder, and
we show that the inferred latent variables of the learned generator network
have strong linear relationship with the shape and appearance variables of the
AAM model that generates the face images. Unlike the AAM model that has an
explicit shape model where the shape variables generate the control points or
landmarks, the generator network has no such shape model and shape variables.
Yet the generator network can learn the shape knowledge in the sense that some
of the latent variables of the learned generator network capture the shape
variations in the face images generated by AAM.","['Tian Han', 'Jiawen Wu', 'Ying Nian Wu']","['cs.CV', 'cs.LG', 'stat.ML']",2018-05-14 04:54:00+00:00
http://arxiv.org/abs/1805.05010v2,Detecting Adversarial Samples for Deep Neural Networks through Mutation Testing,"Recently, it has been shown that deep neural networks (DNN) are subject to
attacks through adversarial samples. Adversarial samples are often crafted
through adversarial perturbation, i.e., manipulating the original sample with
minor modifications so that the DNN model labels the sample incorrectly. Given
that it is almost impossible to train perfect DNN, adversarial samples are
shown to be easy to generate. As DNN are increasingly used in safety-critical
systems like autonomous cars, it is crucial to develop techniques for defending
such attacks. Existing defense mechanisms which aim to make adversarial
perturbation challenging have been shown to be ineffective. In this work, we
propose an alternative approach. We first observe that adversarial samples are
much more sensitive to perturbations than normal samples. That is, if we impose
random perturbations on a normal and an adversarial sample respectively, there
is a significant difference between the ratio of label change due to the
perturbations. Observing this, we design a statistical adversary detection
algorithm called nMutant (inspired by mutation testing from software
engineering community). Our experiments show that nMutant effectively detects
most of the adversarial samples generated by recently proposed attacking
methods. Furthermore, we provide an error bound with certain statistical
significance along with the detection.","['Jingyi Wang', 'Jun Sun', 'Peixin Zhang', 'Xinyu Wang']","['cs.LG', 'stat.ML']",2018-05-14 04:48:24+00:00
http://arxiv.org/abs/1805.04982v1,Index Set Fourier Series Features for Approximating Multi-dimensional Periodic Kernels,"Periodicity is often studied in timeseries modelling with autoregressive
methods but is less popular in the kernel literature, particularly for higher
dimensional problems such as in textures, crystallography, and quantum
mechanics. Large datasets often make modelling periodicity untenable for
otherwise powerful non-parametric methods like Gaussian Processes (GPs) which
typically incur an $\mathcal{O}(N^3)$ computational burden and, consequently,
are unable to scale to larger datasets. To this end we introduce a method
termed \emph{Index Set Fourier Series Features} to tractably exploit
multivariate Fourier series and efficiently decompose periodic kernels on
higher-dimensional data into a series of basis functions. We show that our
approximation produces significantly less predictive error than alternative
approaches such as those based on random Fourier features and achieves better
generalisation on regression problems with periodic data.","['Anthony Tompkins', 'Fabio Ramos']","['stat.ML', 'cs.LG']",2018-05-14 01:52:02+00:00
http://arxiv.org/abs/1805.04958v1,Accelerating Message Passing for MAP with Benders Decomposition,"We introduce a novel mechanism to tighten the local polytope relaxation for
MAP inference in Markov random fields with low state space variables. We
consider a surjection of the variables to a set of hyper-variables and apply
the local polytope relaxation over these hyper-variables. The state space of
each individual hyper-variable is constructed to be enumerable while the vector
product of pairs is not easily enumerable making message passing inference
intractable.
  To circumvent the difficulty of enumerating the vector product of state
spaces of hyper-variables we introduce a novel Benders decomposition approach.
This produces an upper envelope describing the message constructed from affine
functions of the individual variables that compose the hyper-variable receiving
the message. The envelope is tight at the minimizers which are shared by the
true message. Benders rows are constructed to be Pareto optimal and are
generated using an efficient procedure targeted for binary problems.","['Julian Yarkony', 'Shaofei Wang']","['cs.LG', 'stat.ML']",2018-05-13 21:40:58+00:00
http://arxiv.org/abs/1805.04957v3,Compressed Sensing of Scanning Transmission Electron Microscopy (STEM) on Non-Rectangular Scans,"Scanning Transmission Electron Microscopy (STEM) has become the main stay for
materials characterization on atomic level, with applications ranging from
visualization of localized and extended defects to mapping order parameter
fields. In the last several years, attention was attracted by potential of STEM
to explore beam induced chemical processes and especially manipulating atomic
motion, enabling atom-by-atom fabrication. These applications, as well as
traditional imaging of beam sensitive materials, necessitate increasing dynamic
range of STEM between imaging and manipulation modes, and increasing absolute
scanning/imaging speeds, that can be achieved by combining sparse sensing
methods with non-rectangular scanning trajectories. Here we developed a general
method for real-time reconstruction of sparsely sampled images from high-speed,
non-invasive and diverse scanning pathways. This approach is demonstrated on
both the synthetic data where ground truth is known and the experimental STEM
data. This work lays the foundation for future tasks such as optimal design of
dose efficient scanning strategies and real-time adaptive inference and control
of e-beam induced atomic fabrication.","['Xin Li', 'Ondrej Dyck', 'Sergei V. Kalinin', 'Stephen Jesse']","['physics.ins-det', 'stat.ML']",2018-05-13 21:39:14+00:00
http://arxiv.org/abs/1805.04955v1,Low-pass Recurrent Neural Networks - A memory architecture for longer-term correlation discovery,"Reinforcement learning (RL) agents performing complex tasks must be able to
remember observations and actions across sizable time intervals. This is
especially true during the initial learning stages, when exploratory behaviour
can increase the delay between specific actions and their effects. Many new or
popular approaches for learning these distant correlations employ
backpropagation through time (BPTT), but this technique requires storing
observation traces long enough to span the interval between cause and effect.
Besides memory demands, learning dynamics like vanishing gradients and slow
convergence due to infrequent weight updates can reduce BPTT's practicality;
meanwhile, although online recurrent network learning is a developing topic,
most approaches are not efficient enough to use as replacements. We propose a
simple, effective memory strategy that can extend the window over which BPTT
can learn without requiring longer traces. We explore this approach empirically
on a few tasks and discuss its implications.","['Thomas Stepleton', 'Razvan Pascanu', 'Will Dabney', 'Siddhant M. Jayakumar', 'Hubert Soyer', 'Remi Munos']","['cs.LG', 'cs.AI', 'stat.ML']",2018-05-13 21:35:08+00:00
http://arxiv.org/abs/1805.04938v2,The Global Optimization Geometry of Shallow Linear Neural Networks,"We examine the squared error loss landscape of shallow linear neural
networks. We show---with significantly milder assumptions than previous
works---that the corresponding optimization problems have benign geometric
properties: there are no spurious local minima and the Hessian at every saddle
point has at least one negative eigenvalue. This means that at every saddle
point there is a directional negative curvature which algorithms can utilize to
further decrease the objective value. These geometric properties imply that
many local search algorithms (such as the gradient descent which is widely
utilized for training neural networks) can provably solve the training problem
with global convergence.","['Zhihui Zhu', 'Daniel Soudry', 'Yonina C. Eldar', 'Michael B. Wakin']","['cs.LG', 'stat.ML']",2018-05-13 20:09:09+00:00
http://arxiv.org/abs/1805.04933v1,Dyna: A Method of Momentum for Stochastic Optimization,"An algorithm is presented for momentum gradient descent optimization based on
the first-order differential equation of the Newtonian dynamics. The fictitious
mass is introduced to the dynamics of momentum for regularizing the adaptive
stepsize of each individual parameter. The dynamic relaxation is adapted for
stochastic optimization of nonlinear objective functions through an explicit
time integration with varying damping ratio. The adaptive stepsize is optimized
for each individual neural network layer based on the number of inputs. The
adaptive stepsize for every parameter over the entire neural network is
uniformly optimized with one upper bound, independent of sparsity, for better
overall convergence rate. The numerical implementation of the algorithm is
similar to the Adam Optimizer, possessing computational efficiency, similar
memory requirements, etc. There are three hyper-parameters in the algorithm
with clear physical interpretation. Preliminary trials show promise in
performance and convergence.",['Zhidong Han'],"['cs.LG', 'stat.ML']",2018-05-13 19:21:38+00:00
http://arxiv.org/abs/1805.04928v2,Doing the impossible: Why neural networks can be trained at all,"As deep neural networks grow in size, from thousands to millions to billions
of weights, the performance of those networks becomes limited by our ability to
accurately train them. A common naive question arises: if we have a system with
billions of degrees of freedom, don't we also need billions of samples to train
it? Of course, the success of deep learning indicates that reliable models can
be learned with reasonable amounts of data. Similar questions arise in protein
folding, spin glasses and biological neural networks. With effectively infinite
potential folding/spin/wiring configurations, how does the system find the
precise arrangement that leads to useful and robust results? Simple sampling of
the possible configurations until an optimal one is reached is not a viable
option even if one waited for the age of the universe. On the contrary, there
appears to be a mechanism in the above phenomena that forces them to achieve
configurations that live on a low-dimensional manifold, avoiding the curse of
dimensionality. In the current work we use the concept of mutual information
between successive layers of a deep neural network to elucidate this mechanism
and suggest possible ways of exploiting it to accelerate training. We show that
adding structure to the neural network that enforces higher mutual information
between layers speeds training and leads to more accurate results. High mutual
information between layers implies that the effective number of free parameters
is exponentially smaller than the raw number of tunable weights.","['Nathan O. Hodas', 'Panos Stinis']","['cs.LG', 'stat.ML']",2018-05-13 19:04:50+00:00
http://arxiv.org/abs/1805.04927v1,Lehmer Transform and its Theoretical Properties,"We propose a new class of transforms that we call {\it Lehmer Transform}
which is motivated by the {\it Lehmer mean function}. The proposed {\it Lehmer
transform} decomposes a function of a sample into their constituting
statistical moments. Theoretical properties of the proposed transform are
presented. This transform could be very useful to provide an alternative method
in analyzing non-stationary signals such as brain wave EEG.","['Masoud Ataei', 'Shengyuan Chen', 'Xiaogang Wang']","['stat.ML', 'cs.LG']",2018-05-13 19:04:25+00:00
http://arxiv.org/abs/1805.04912v1,Extendable Neural Matrix Completion,"Matrix completion is one of the key problems in signal processing and machine
learning, with applications ranging from image pro- cessing and data gathering
to classification and recommender sys- tems. Recently, deep neural networks
have been proposed as la- tent factor models for matrix completion and have
achieved state- of-the-art performance. Nevertheless, a major problem with
existing neural-network-based models is their limited capabilities to extend to
samples unavailable at the training stage. In this paper, we propose a deep
two-branch neural network model for matrix completion. The proposed model not
only inherits the predictive power of neural net- works, but is also capable of
extending to partially observed samples outside the training set, without the
need of retraining or fine-tuning. Experimental studies on popular movie rating
datasets prove the ef- fectiveness of our model compared to the state of the
art, in terms of both accuracy and extendability.","['Duc Minh Nguyen', 'Evaggelia Tsiligianni', 'Nikos Deligiannis']","['stat.ML', 'cs.AI', 'cs.LG']",2018-05-13 16:46:36+00:00
http://arxiv.org/abs/1805.04908v1,On the Practical Computational Power of Finite Precision RNNs for Language Recognition,"While Recurrent Neural Networks (RNNs) are famously known to be Turing
complete, this relies on infinite precision in the states and unbounded
computation time. We consider the case of RNNs with finite precision whose
computation time is linear in the input length. Under these limitations, we
show that different RNN variants have different computational power. In
particular, we show that the LSTM and the Elman-RNN with ReLU activation are
strictly stronger than the RNN with a squashing activation and the GRU. This is
achieved because LSTMs and ReLU-RNNs can easily implement counting behavior. We
show empirically that the LSTM does indeed learn to effectively use the
counting mechanism.","['Gail Weiss', 'Yoav Goldberg', 'Eran Yahav']","['cs.LG', 'cs.CL', 'stat.ML']",2018-05-13 16:28:32+00:00
http://arxiv.org/abs/1805.07297v2,General solutions for nonlinear differential equations: a rule-based self-learning approach using deep reinforcement learning,"A universal rule-based self-learning approach using deep reinforcement
learning (DRL) is proposed for the first time to solve nonlinear ordinary
differential equations and partial differential equations. The solver consists
of a deep neural network-structured actor that outputs candidate solutions, and
a critic derived only from physical rules (governing equations and boundary and
initial conditions). Solutions in discretized time are treated as multiple
tasks sharing the same governing equation, and the current step parameters
provide an ideal initialization for the next owing to the temporal continuity
of the solutions, which shows a transfer learning characteristic and indicates
that the DRL solver has captured the intrinsic nature of the equation. The
approach is verified through solving the Schr\""odinger, Navier-Stokes,
Burgers', Van der Pol, and Lorenz equations and an equation of motion. The
results indicate that the approach gives solutions with high accuracy, and the
solution process promises to get faster.","['Shiyin Wei', 'Xiaowei Jin', 'Hui Li']","['cs.LG', 'math.NA', 'stat.ML']",2018-05-13 15:16:47+00:00
http://arxiv.org/abs/1805.04874v3,GAN Q-learning,"Distributional reinforcement learning (distributional RL) has seen empirical
success in complex Markov Decision Processes (MDPs) in the setting of nonlinear
function approximation. However, there are many different ways in which one can
leverage the distributional approach to reinforcement learning. In this paper,
we propose GAN Q-learning, a novel distributional RL method based on generative
adversarial networks (GANs) and analyze its performance in simple tabular
environments, as well as OpenAI Gym. We empirically show that our algorithm
leverages the flexibility and blackbox approach of deep learning models while
providing a viable alternative to traditional methods.","['Thang Doan', 'Bogdan Mazoure', 'Clare Lyle']","['stat.ML', 'cs.LG']",2018-05-13 12:41:53+00:00
http://arxiv.org/abs/1805.04810v2,AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning,"Users in various web and mobile applications are vulnerable to attribute
inference attacks, in which an attacker leverages a machine learning classifier
to infer a target user's private attributes (e.g., location, sexual
orientation, political view) from its public data (e.g., rating scores, page
likes). Existing defenses leverage game theory or heuristics based on
correlations between the public data and attributes. These defenses are not
practical. Specifically, game-theoretic defenses require solving intractable
optimization problems, while correlation-based defenses incur large utility
loss of users' public data.
  In this paper, we present AttriGuard, a practical defense against attribute
inference attacks. AttriGuard is computationally tractable and has small
utility loss. Our AttriGuard works in two phases. Suppose we aim to protect a
user's private attribute. In Phase I, for each value of the attribute, we find
a minimum noise such that if we add the noise to the user's public data, then
the attacker's classifier is very likely to infer the attribute value for the
user. We find the minimum noise via adapting existing evasion attacks in
adversarial machine learning. In Phase II, we sample one attribute value
according to a certain probability distribution and add the corresponding noise
found in Phase I to the user's public data. We formulate finding the
probability distribution as solving a constrained convex optimization problem.
We extensively evaluate AttriGuard and compare it with existing methods using a
real-world dataset. Our results show that AttriGuard substantially outperforms
existing methods. Our work is the first one that shows evasion attacks can be
used as defensive techniques for privacy protection.","['Jinyuan Jia', 'Neil Zhenqiang Gong']","['cs.CR', 'stat.ML']",2018-05-13 02:32:48+00:00
http://arxiv.org/abs/1805.04807v1,Curriculum Adversarial Training,"Recently, deep learning has been applied to many security-sensitive
applications, such as facial authentication. The existence of adversarial
examples hinders such applications. The state-of-the-art result on defense
shows that adversarial training can be applied to train a robust model on MNIST
against adversarial examples; but it fails to achieve a high empirical
worst-case accuracy on a more complex task, such as CIFAR-10 and SVHN. In our
work, we propose curriculum adversarial training (CAT) to resolve this issue.
The basic idea is to develop a curriculum of adversarial examples generated by
attacks with a wide range of strengths. With two techniques to mitigate the
forgetting and the generalization issues, we demonstrate that CAT can improve
the prior art's empirical worst-case accuracy by a large margin of 25% on
CIFAR-10 and 35% on SVHN. At the same, the model's performance on
non-adversarial inputs is comparable to the state-of-the-art models.","['Qi-Zhi Cai', 'Min Du', 'Chang Liu', 'Dawn Song']","['cs.LG', 'cs.CR', 'stat.ML']",2018-05-13 02:10:56+00:00
http://arxiv.org/abs/1805.04785v2,An Optimal Policy for Dynamic Assortment Planning Under Uncapacitated Multinomial Logit Models,"We study the dynamic assortment planning problem, where for each arriving
customer, the seller offers an assortment of substitutable products and
customer makes the purchase among offered products according to an
uncapacitated multinomial logit (MNL) model. Since all the utility parameters
of MNL are unknown, the seller needs to simultaneously learn customers' choice
behavior and make dynamic decisions on assortments based on the current
knowledge. The goal of the seller is to maximize the expected revenue, or
equivalently, to minimize the expected regret. Although dynamic assortment
planning problem has received an increasing attention in revenue management,
most existing policies require the estimation of mean utility for each product
and the final regret usually involves the number of products $N$. The optimal
regret of the dynamic assortment planning problem under the most basic and
popular choice model---MNL model is still open. By carefully analyzing a
revenue potential function, we develop a trisection based policy combined with
adaptive confidence bound construction, which achieves an {item-independent}
regret bound of $O(\sqrt{T})$, where $T$ is the length of selling horizon. We
further establish the matching lower bound result to show the optimality of our
policy. There are two major advantages of the proposed policy. First, the
regret of all our policies has no dependence on $N$. Second, our policies are
almost assumption free: there is no assumption on mean utility nor any
""separability"" condition on the expected revenues for different assortments.
Our result also extends the unimodal bandit literature.","['Xi Chen', 'Yining Wang', 'Yuan Zhou']","['stat.ML', 'cs.LG']",2018-05-12 21:13:42+00:00
http://arxiv.org/abs/1805.04784v3,Nonlinear Metric Learning through Geodesic Interpolation within Lie Groups,"In this paper, we propose a nonlinear distance metric learning scheme based
on the fusion of component linear metrics. Instead of merging displacements at
each data point, our model calculates the velocities induced by the component
transformations, via a geodesic interpolation on a Lie transfor- mation group.
Such velocities are later summed up to produce a global transformation that is
guaranteed to be diffeomorphic. Consequently, pair-wise distances computed this
way conform to a smooth and spatially varying metric, which can greatly benefit
k-NN classification. Experiments on synthetic and real datasets demonstrate the
effectiveness of our model.","['Zhewei Wang', 'Bibo Shi', 'Charles D. Smith', 'Jundong Liu']","['cs.LG', 'stat.ML']",2018-05-12 21:12:20+00:00
http://arxiv.org/abs/1805.04770v2,Born Again Neural Networks,"Knowledge Distillation (KD) consists of transferring “knowledge” from one
machine learning model (the teacher) to another (the student). Commonly, the
teacher is a high-capacity model with formidable performance, while the student
is more compact. By transferring knowledge, one hopes to benefit from the
student’s compactness, without sacrificing too much performance. We study KD
from a new perspective: rather than compressing models, we train students
parameterized identically to their teachers. Surprisingly, these Born-Again
Networks (BANs), outperform their teachers significantly, both on computer
vision and language modeling tasks. Our experiments with BANs based on
DenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5%) and
CIFAR-100 (15.5%) datasets, by validation error. Additional experiments explore
two distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and
(ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate
the essential components of KD, demonstrating the effect of the teacher outputs
on both predicted and non-predicted classes.","['Tommaso Furlanello', 'Zachary C. Lipton', 'Michael Tschannen', 'Laurent Itti', 'Anima Anandkumar']","['stat.ML', 'cs.AI', 'cs.LG']",2018-05-12 19:48:50+00:00
http://arxiv.org/abs/1805.04756v3,Improving Predictive Uncertainty Estimation using Dropout -- Hamiltonian Monte Carlo,"Estimating predictive uncertainty is crucial for many computer vision tasks,
from image classification to autonomous driving systems. Hamiltonian Monte
Carlo (HMC) is an sampling method for performing Bayesian inference. On the
other hand, Dropout regularization has been proposed as an approximate model
averaging technique that tends to improve generalization in large scale models
such as deep neural networks. Although, HMC provides convergence guarantees for
most standard Bayesian models, it does not handle discrete parameters arising
from Dropout regularization. In this paper, we present a robust methodology for
improving predictive uncertainty in classification problems, based on Dropout
and Hamiltonian Monte Carlo. Even though Dropout induces a non-smooth energy
function with no such convergence guarantees, the resulting discretization of
the Hamiltonian proves empirical success. The proposed method allows to
effectively estimate the predictive accuracy and to provide better
generalization for difficult test examples.","['Diego Vergara', 'Sergio Hernández', 'Matias Valdenegro-Toro', 'Felipe Jorquera']","['cs.LG', 'stat.ML']",2018-05-12 18:11:33+00:00
http://arxiv.org/abs/1805.04755v1,A Simple and Effective Model-Based Variable Importance Measure,"In the era of ""big data"", it is becoming more of a challenge to not only
build state-of-the-art predictive models, but also gain an understanding of
what's really going on in the data. For example, it is often of interest to
know which, if any, of the predictors in a fitted model are relatively
influential on the predicted outcome. Some modern algorithms---like random
forests and gradient boosted decision trees---have a natural way of quantifying
the importance or relative influence of each feature. Other algorithms---like
naive Bayes classifiers and support vector machines---are not capable of doing
so and model-free approaches are generally used to measure each predictor's
importance. In this paper, we propose a standardized, model-based approach to
measuring predictor importance across the growing spectrum of supervised
learning algorithms. Our proposed method is illustrated through both simulated
and real data examples. The R code to reproduce all of the figures in this
paper is available in the supplementary materials.","['Brandon M. Greenwell', 'Bradley C. Boehmke', 'Andrew J. McCarthy']","['stat.ML', 'cs.LG']",2018-05-12 18:05:28+00:00
http://arxiv.org/abs/1805.04754v1,Incremental Learning Framework Using Cloud Computing,"High volume of data, perceived as either challenge or opportunity. Deep
learning architecture demands high volume of data to effectively back propagate
and train the weights without bias. At the same time, large volume of data
demands higher capacity of the machine where it could be executed seamlessly.
Budding data scientist along with many research professionals face frequent
disconnection issue with cloud computing framework (working without dedicated
connection) due to free subscription to the platform. Similar issues also
visible while working on local computer where computer may run out of resource
or power sometimes and researcher has to start training the models all over
again. In this paper, we intend to provide a way to resolve this issue and
progressively training the neural network even after having frequent
disconnection or resource outage without loosing much of the progress","['Kumarjit Pathak', 'Prabhukiran G', 'Jitin Kapila', 'Nikit Gawande']","['stat.ML', 'cs.LG']",2018-05-12 17:58:24+00:00
http://arxiv.org/abs/1805.05324v1,Extended pipeline for content-based feature engineering in music genre recognition,"We present a feature engineering pipeline for the construction of musical
signal characteristics, to be used for the design of a supervised model for
musical genre identification. The key idea is to extend the traditional
two-step process of extraction and classification with additive stand-alone
phases which are no longer organized in a waterfall scheme. The whole system is
realized by traversing backtrack arrows and cycles between various stages. In
order to give a compact and effective representation of the features, the
standard early temporal integration is combined with other selection and
extraction phases: on the one hand, the selection of the most meaningful
characteristics based on information gain, and on the other hand, the inclusion
of the nonlinear correlation between this subset of features, determined by an
autoencoder. The results of the experiments conducted on GTZAN dataset reveal a
noticeable contribution of this methodology towards the model's performance in
classification task.","['Tina Raissi', 'Alessandro Tibo', 'Paolo Bientinesi']","['cs.SD', 'cs.LG', 'eess.AS', 'stat.ML']",2018-05-12 16:47:01+00:00
http://arxiv.org/abs/1805.04740v1,Agreement Rate Initialized Maximum Likelihood Estimator for Ensemble Classifier Aggregation and Its Application in Brain-Computer Interface,"Ensemble learning is a powerful approach to construct a strong learner from
multiple base learners. The most popular way to aggregate an ensemble of
classifiers is majority voting, which assigns a sample to the class that most
base classifiers vote for. However, improved performance can be obtained by
assigning weights to the base classifiers according to their accuracy. This
paper proposes an agreement rate initialized maximum likelihood estimator
(ARIMLE) to optimally fuse the base classifiers. ARIMLE first uses a simplified
agreement rate method to estimate the classification accuracy of each base
classifier from the unlabeled samples, then employs the accuracies to
initialize a maximum likelihood estimator (MLE), and finally uses the
expectation-maximization algorithm to refine the MLE. Extensive experiments on
visually evoked potential classification in a brain-computer interface
application show that ARIMLE outperforms majority voting, and also achieves
better or comparable performance with several other state-of-the-art classifier
combination approaches.","['Dongrui Wu', 'Vernon J. Lawhern', 'Stephen Gordon', 'Brent J. Lance', 'Chin-Teng Lin']","['cs.LG', 'cs.HC', 'stat.ML']",2018-05-12 15:43:36+00:00
http://arxiv.org/abs/1805.04737v1,Offline EEG-Based Driver Drowsiness Estimation Using Enhanced Batch-Mode Active Learning (EBMAL) for Regression,"There are many important regression problems in real-world brain-computer
interface (BCI) applications, e.g., driver drowsiness estimation from EEG
signals. This paper considers offline analysis: given a pool of unlabeled EEG
epochs recorded during driving, how do we optimally select a small number of
them to label so that an accurate regression model can be built from them to
label the rest? Active learning is a promising solution to this problem, but
interestingly, to our best knowledge, it has not been used for regression
problems in BCI so far. This paper proposes a novel enhanced batch-mode active
learning (EBMAL) approach for regression, which improves upon a baseline active
learning algorithm by increasing the reliability, representativeness and
diversity of the selected samples to achieve better regression performance. We
validate its effectiveness using driver drowsiness estimation from EEG signals.
However, EBMAL is a general approach that can also be applied to many other
offline regression problems beyond BCI.","['Dongrui Wu', 'Vernon J. Lawhern', 'Stephen Gordon', 'Brent J. Lance', 'Chin-Teng Lin']","['cs.LG', 'cs.HC', 'stat.ML']",2018-05-12 15:36:05+00:00
http://arxiv.org/abs/1805.05781v1,Active Semi-supervised Transfer Learning (ASTL) for Offline BCI Calibration,"Single-trial classification of event-related potentials in
electroencephalogram (EEG) signals is a very important paradigm of
brain-computer interface (BCI). Because of individual differences, usually some
subject-specific calibration data are required to tailor the classifier for
each subject. Transfer learning has been extensively used to reduce such
calibration data requirement, by making use of auxiliary data from
similar/relevant subjects/tasks. However, all previous research assumes that
all auxiliary data have been labeled. This paper considers a more general
scenario, in which part of the auxiliary data could be unlabeled. We propose
active semi-supervised transfer learning (ASTL) for offline BCI calibration,
which integrates active learning, semi-supervised learning, and transfer
learning. Using a visual evoked potential oddball task and three different EEG
headsets, we demonstrate that ASTL can achieve consistently good performance
across subjects and headsets, and it outperforms some state-of-the-art
approaches in the literature.",['Dongrui Wu'],"['cs.LG', 'cs.HC', 'stat.ML']",2018-05-12 15:27:23+00:00
http://arxiv.org/abs/1805.04735v1,Pool-Based Sequential Active Learning for Regression,"Active learning is a machine learning approach for reducing the data labeling
effort. Given a pool of unlabeled samples, it tries to select the most useful
ones to label so that a model built from them can achieve the best possible
performance. This paper focuses on pool-based sequential active learning for
regression (ALR). We first propose three essential criteria that an ALR
approach should consider in selecting the most useful unlabeled samples:
informativeness, representativeness, and diversity, and compare four existing
ALR approaches against them. We then propose a new ALR approach using passive
sampling, which considers both the representativeness and the diversity in both
the initialization and subsequent iterations. Remarkably, this approach can
also be integrated with other existing ALR approaches in the literature to
further improve the performance. Extensive experiments on 11 UCI, CMU StatLib,
and UFL Media Core datasets from various domains verified the effectiveness of
our proposed ALR approaches.",['Dongrui Wu'],"['cs.LG', 'stat.ML']",2018-05-12 15:17:12+00:00
http://arxiv.org/abs/1805.04720v1,Do Outliers Ruin Collaboration?,"We consider the problem of learning a binary classifier from $n$ different
data sources, among which at most an $\eta$ fraction are adversarial. The
overhead is defined as the ratio between the sample complexity of learning in
this setting and that of learning the same hypothesis class on a single data
distribution. We present an algorithm that achieves an $O(\eta n + \ln n)$
overhead, which is proved to be worst-case optimal. We also discuss the
potential challenges to the design of a computationally efficient learning
algorithm with a small overhead.",['Mingda Qiao'],"['cs.LG', 'cs.DS', 'stat.ML']",2018-05-12 13:35:35+00:00
http://arxiv.org/abs/1805.04686v3,Task Transfer by Preference-Based Cost Learning,"The goal of task transfer in reinforcement learning is migrating the action
policy of an agent to the target task from the source task. Given their
successes on robotic action planning, current methods mostly rely on two
requirements: exactly-relevant expert demonstrations or the explicitly-coded
cost function on target task, both of which, however, are inconvenient to
obtain in practice. In this paper, we relax these two strong conditions by
developing a novel task transfer framework where the expert preference is
applied as a guidance. In particular, we alternate the following two steps:
Firstly, letting experts apply pre-defined preference rules to select related
expert demonstrates for the target task. Secondly, based on the selection
result, we learn the target cost function and trajectory distribution
simultaneously via enhanced Adversarial MaxEnt IRL and generate more
trajectories by the learned target distribution for the next preference
selection. The theoretical analysis on the distribution learning and
convergence of the proposed algorithm are provided. Extensive simulations on
several benchmarks have been conducted for further verifying the effectiveness
of the proposed method.","['Mingxuan Jing', 'Xiaojian Ma', 'Wenbing Huang', 'Fuchun Sun', 'Huaping Liu']","['cs.LG', 'cs.RO', 'stat.ML']",2018-05-12 09:08:14+00:00
http://arxiv.org/abs/1805.04634v1,Image-derived generative modeling of pseudo-macromolecular structures - towards the statistical assessment of Electron CryoTomography template matching,"Cellular Electron CryoTomography (CECT) is a 3D imaging technique that
captures information about the structure and spatial organization of
macromolecular complexes within single cells, in near-native state and at
sub-molecular resolution. Although template matching is often used to locate
macromolecules in a CECT image, it is insufficient as it only measures the
relative structural similarity. Therefore, it is preferable to assess the
statistical credibility of the decision through hypothesis testing, requiring
many templates derived from a diverse population of macromolecular structures.
Due to the very limited number of known structures, we need a generative model
to efficiently and reliably sample pseudo-structures from the complex
distribution of macromolecular structures. To address this challenge, we
propose a novel image-derived approach for performing hypothesis testing for
template matching by constructing generative models using the generative
adversarial network. Finally, we conducted hypothesis testing experiments for
template matching on both simulated and experimental subtomograms, allowing us
to conclude the identity of subtomograms with high statistical credibility and
significantly reducing false positives.","['Kai Wen Wang', 'Xiangrui Zeng', 'Xiaodan Liang', 'Zhiguang Huo', 'Eric P. Xing', 'Min Xu']","['q-bio.QM', 'cs.CV', 'stat.AP', 'stat.ML']",2018-05-12 02:00:30+00:00
http://arxiv.org/abs/1805.04609v3,Textual Membership Queries,"Human labeling of data can be very time-consuming and expensive, yet, in many
cases it is critical for the success of the learning process. In order to
minimize human labeling efforts, we propose a novel active learning solution
that does not rely on existing sources of unlabeled data. It uses a small
amount of labeled data as the core set for the synthesis of useful membership
queries (MQs) - unlabeled instances generated by an algorithm for human
labeling. Our solution uses modification operators, functions that modify
instances to some extent. We apply the operators on a small set of instances
(core set), creating a set of new membership queries. Using this framework, we
look at the instance space as a search space and apply search algorithms in
order to generate new examples highly relevant to the learner. We implement
this framework in the textual domain and test it on several text classification
tasks and show improved classifier performance as more MQs are labeled and
incorporated into the training set. To the best of our knowledge, this is the
first work on membership queries in the textual domain.","['Jonathan Zarecki', 'Shaul Markovitch']","['cs.LG', 'cs.CL', 'stat.ML']",2018-05-11 22:40:59+00:00
http://arxiv.org/abs/1805.04591v2,Robust and Scalable Models of Microbiome Dynamics,"Microbes are everywhere, including in and on our bodies, and have been shown
to play key roles in a variety of prevalent human diseases. Consequently, there
has been intense interest in the design of bacteriotherapies or ""bugs as
drugs,"" which are communities of bacteria administered to patients for specific
therapeutic applications. Central to the design of such therapeutics is an
understanding of the causal microbial interaction network and the population
dynamics of the organisms. In this work we present a Bayesian nonparametric
model and associated efficient inference algorithm that addresses the key
conceptual and practical challenges of learning microbial dynamics from time
series microbe abundance data. These challenges include high-dimensional (300+
strains of bacteria in the gut) but temporally sparse and non-uniformly sampled
data; high measurement noise; and, nonlinear and physically non-negative
dynamics. Our contributions include a new type of dynamical systems model for
microbial dynamics based on what we term interaction modules, or learned
clusters of latent variables with redundant interaction structure (reducing the
expected number of interaction coefficients from $O(n^2)$ to $O((\log n)^2)$);
a fully Bayesian formulation of the stochastic dynamical systems model that
propagates measurement and latent state uncertainty throughout the model; and
introduction of a temporally varying auxiliary variable technique to enable
efficient inference by relaxing the hard non-negativity constraint on states.
We apply our method to simulated and real data, and demonstrate the utility of
our technique for system identification from limited data and gaining new
biological insights into bacteriotherapy design.","['Travis E. Gibson', 'Georg K. Gerber']","['stat.ML', 'cs.LG']",2018-05-11 21:13:11+00:00
http://arxiv.org/abs/1805.04582v1,TensOrMachine: Probabilistic Boolean Tensor Decomposition,"Boolean tensor decomposition approximates data of multi-way binary
relationships as product of interpretable low-rank binary factors, following
the rules of Boolean algebra. Here, we present its first probabilistic
treatment. We facilitate scalable sampling-based posterior inference by
exploitation of the combinatorial structure of the factor conditionals. Maximum
a posteriori decompositions feature higher accuracies than existing techniques
throughout a wide range of simulated conditions. Moreover, the probabilistic
approach facilitates the treatment of missing data and enables model selection
with much greater accuracy. We investigate three real-world data-sets. First,
temporal interaction networks in a hospital ward and behavioural data of
university students demonstrate the inference of instructive latent patterns.
Next, we decompose a tensor with more than 10 billion data points, indicating
relations of gene expression in cancer patients. Not only does this demonstrate
scalability, it also provides an entirely novel perspective on relational
properties of continuous data and, in the present example, on the molecular
heterogeneity of cancer. Our implementation is available on GitHub:
https://github.com/TammoR/LogicalFactorisationMachines.","['Tammo Rukat', 'Chris C. Holmes', 'Christopher Yau']","['stat.ML', 'cs.AI', 'cs.LG', 'q-bio.GN', 'stat.AP']",2018-05-11 20:23:35+00:00
http://arxiv.org/abs/1805.04577v1,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions,"Error bound conditions (EBC) are properties that characterize the growth of
an objective function when a point is moved away from the optimal set. They
have recently received increasing attention in the field of optimization for
developing optimization algorithms with fast convergence. However, the studies
of EBC in statistical learning are hitherto still limited. The main
contributions of this paper are two-fold. First, we develop fast and
intermediate rates of empirical risk minimization (ERM) under EBC for risk
minimization with Lipschitz continuous, and smooth convex random functions.
Second, we establish fast and intermediate rates of an efficient stochastic
approximation (SA) algorithm for risk minimization with Lipschitz continuous
random functions, which requires only one pass of $n$ samples and adapts to
EBC. For both approaches, the convergence rates span a full spectrum between
$\widetilde O(1/\sqrt{n})$ and $\widetilde O(1/n)$ depending on the power
constant in EBC, and could be even faster than $O(1/n)$ in special cases for
ERM. Moreover, these convergence rates are automatically adaptive without using
any knowledge of EBC. Overall, this work not only strengthens the understanding
of ERM for statistical learning but also brings new fast stochastic algorithms
for solving a broad range of statistical learning problems.","['Mingrui Liu', 'Xiaoxuan Zhang', 'Lijun Zhang', 'Rong Jin', 'Tianbao Yang']","['stat.ML', 'cs.LG']",2018-05-11 20:03:54+00:00
http://arxiv.org/abs/1805.04567v1,Learning-induced categorical perception in a neural network model,"In human cognition, the expansion of perceived between-category distances and
compression of within-category distances is known as categorical perception
(CP). There are several hypotheses about the causes of CP (e.g., language,
learning, evolution) but no functional model. Whether CP is essential to
categorisation or simply a by-product of it is not yet clear, but evidence is
accumulating that CP can be induced by category learning. We provide a model
for learning-induced CP as expansion and compression of distances in
hidden-unit space in neural nets. Basic conditions from which the current model
predicts CP are described, and clues as to how these conditions might
generalize to more complex kinds of categorization begin to emerge.","['Christian Thériault', 'Fernanda Pérez-Gay', 'Dan Rivas', 'Stevan Harnad']","['cs.LG', 'stat.ML']",2018-05-11 19:18:27+00:00
http://arxiv.org/abs/1805.05773v1,Online Bandit Linear Optimization: A Study,"This article introduces the concepts around Online Bandit Linear Optimization
and explores an efficient setup called SCRiBLe (Self-Concordant Regularization
in Bandit Learning) created by Abernethy et. al.\cite{abernethy}. The SCRiBLe
setup and algorithm yield a $O(\sqrt{T})$ regret bound and polynomial run time
complexity bound on the dimension of the input space. In this article we build
up to the bandit linear optimization case and study SCRiBLe.","['Vikram Mullachery', 'Samarth Tiwari']","['cs.LG', 'cs.AI', 'stat.ML']",2018-05-11 18:12:19+00:00
http://arxiv.org/abs/1805.05452v1,Improved Predictive Models for Acute Kidney Injury with IDEAs: Intraoperative Data Embedded Analytics,"Acute kidney injury (AKI) is a common and serious complication after a
surgery which is associated with morbidity and mortality. The majority of
existing perioperative AKI risk score prediction models are limited in their
generalizability and do not fully utilize the physiological intraoperative
time-series data. Thus, there is a need for intelligent, accurate, and robust
systems, able to leverage information from large-scale data to predict
patient's risk of developing postoperative AKI. A retrospective single-center
cohort of 2,911 adult patients who underwent surgery at the University of
Florida Health has been used for this study. We used machine learning and
statistical analysis techniques to develop perioperative models to predict the
risk of AKI (risk during the first 3 days, 7 days, and until the discharge day)
before and after the surgery. In particular, we examined the improvement in
risk prediction by incorporating three intraoperative physiologic time series
data, i.e., mean arterial blood pressure, minimum alveolar concentration, and
heart rate. For an individual patient, the preoperative model produces a
probabilistic AKI risk score, which will be enriched by integrating
intraoperative statistical features through a machine learning stacking
approach inside a random forest classifier. We compared the performance of our
model based on the area under the receiver operating characteristics curve
(AUROC), accuracy and net reclassification improvement (NRI). The predictive
performance of the proposed model is better than the preoperative data only
model. For AKI-7day outcome: The AUC was 0.86 (accuracy was 0.78) in the
proposed model, while the preoperative AUC was 0.84 (accuracy 0.76).
Furthermore, with the integration of intraoperative features, we were able to
classify patients who were misclassified in the preoperative model.","['Lasith Adhikari', 'Tezcan Ozrazgat-Baslanti', 'Paul Thottakkara', 'Ashkan Ebadi', 'Amir Motaei', 'Parisa Rashidi', 'Xiaolin Li', 'Azra Bihorac']","['cs.CY', 'cs.LG', 'stat.ML']",2018-05-11 15:21:11+00:00
http://arxiv.org/abs/1805.04437v1,Cross-lingual Document Retrieval using Regularized Wasserstein Distance,"Many information retrieval algorithms rely on the notion of a good distance
that allows to efficiently compare objects of different nature. Recently, a new
promising metric called Word Mover's Distance was proposed to measure the
divergence between text passages. In this paper, we demonstrate that this
metric can be extended to incorporate term-weighting schemes and provide more
accurate and computationally efficient matching between documents using
entropic regularization. We evaluate the benefits of both extensions in the
task of cross-lingual document retrieval (CLDR). Our experimental results on
eight CLDR problems suggest that the proposed methods achieve remarkable
improvements in terms of Mean Reciprocal Rank compared to several baselines.","['Georgios Balikas', 'Charlotte Laclau', 'Ievgen Redko', 'Massih-Reza Amini']","['cs.CL', 'stat.ML']",2018-05-11 15:01:00+00:00
http://arxiv.org/abs/1805.04424v1,Novel Deep Learning Model for Traffic Sign Detection Using Capsule Networks,"Convolutional neural networks are the most widely used deep learning
algorithms for traffic signal classification till date but they fail to capture
pose, view, orientation of the images because of the intrinsic inability of max
pooling layer.This paper proposes a novel method for Traffic sign detection
using deep learning architecture called capsule networks that achieves
outstanding performance on the German traffic sign dataset.Capsule network
consists of capsules which are a group of neurons representing the
instantiating parameters of an object like the pose and orientation by using
the dynamic routing and route by agreement algorithms.unlike the previous
approaches of manual feature extraction,multiple deep neural networks with many
parameters,our method eliminates the manual effort and provides resistance to
the spatial variances.CNNs can be fooled easily using various adversary attacks
and capsule networks can overcome such attacks from the intruders and can offer
more reliability in traffic sign detection for autonomous vehicles.Capsule
network have achieved the state-of-the-art accuracy of 97.6% on German Traffic
Sign Recognition Benchmark dataset (GTSRB).",['Amara Dinesh Kumar'],"['cs.CV', 'cs.LG', 'stat.ML']",2018-05-11 14:34:15+00:00
http://arxiv.org/abs/1805.05409v2,"Machine Learning for Public Administration Research, with Application to Organizational Reputation","Machine learning methods have gained a great deal of popularity in recent
years among public administration scholars and practitioners. These techniques
open the door to the analysis of text, image and other types of data that allow
us to test foundational theories of public administration and to develop new
theories. Despite the excitement surrounding machine learning methods, clarity
regarding their proper use and potential pitfalls is lacking. This paper
attempts to fill this gap in the literature through providing a machine
learning ""guide to practice"" for public administration scholars and
practitioners. Here, we take a foundational view of machine learning and
describe how these methods can enrich public administration research and
practice through their ability develop new measures, tap into new sources of
data and conduct statistical inference and causal inference in a principled
manner. We then turn our attention to the pitfalls of using these methods such
as unvalidated measures and lack of interpretability. Finally, we demonstrate
how machine learning techniques can help us learn about organizational
reputation in federal agencies through an illustrated example using tweets from
13 executive federal agencies.","['L. Jason Anastasopoulos', 'Andrew B. Whitford']","['cs.CY', 'cs.LG', 'stat.ML']",2018-05-11 14:30:30+00:00
http://arxiv.org/abs/1805.09253v1,Federated Learning for Ultra-Reliable Low-Latency V2V Communications,"In this paper, a novel joint transmit power and resource allocation approach
for enabling ultra-reliable low-latency communication (URLLC) in vehicular
networks is proposed. The objective is to minimize the network-wide power
consumption of vehicular users (VUEs) while ensuring high reliability in terms
of probabilistic queuing delays. In particular, a reliability measure is
defined to characterize extreme events (i.e., when vehicles' queue lengths
exceed a predefined threshold with non-negligible probability) using extreme
value theory (EVT). Leveraging principles from federated learning (FL), the
distribution of these extreme events corresponding to the tail distribution of
queues is estimated by VUEs in a decentralized manner. Finally, Lyapunov
optimization is used to find the joint transmit power and resource allocation
policies for each VUE in a distributed manner. The proposed solution is
validated via extensive simulations using a Manhattan mobility model. It is
shown that FL enables the proposed distributed method to estimate the tail
distribution of queues with an accuracy that is very close to a centralized
solution with up to 79\% reductions in the amount of data that need to be
exchanged. Furthermore, the proposed method yields up to 60\% reductions of
VUEs with large queue lengths, without an additional power consumption,
compared to an average queue-based baseline. Compared to systems with fixed
power consumption and focusing on queue stability while minimizing average
power consumption, the reduction in extreme events of the proposed method is
about two orders of magnitude.","['Sumudu Samarakoon', 'Mehdi Bennis', 'Walid Saad', 'Merouane Debbah']","['cs.NI', 'cs.LG', 'stat.ML']",2018-05-11 11:31:42+00:00
http://arxiv.org/abs/1805.04276v2,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,"Program synthesis is the task of automatically generating a program
consistent with a specification. Recent years have seen proposal of a number of
neural approaches for program synthesis, many of which adopt a sequence
generation paradigm similar to neural machine translation, in which
sequence-to-sequence models are trained to maximize the likelihood of known
reference programs. While achieving impressive results, this strategy has two
key limitations. First, it ignores Program Aliasing: the fact that many
different programs may satisfy a given specification (especially with
incomplete specifications such as a few input-output examples). By maximizing
the likelihood of only a single reference program, it penalizes many
semantically correct programs, which can adversely affect the synthesizer
performance. Second, this strategy overlooks the fact that programs have a
strict syntax that can be efficiently checked. To address the first limitation,
we perform reinforcement learning on top of a supervised model with an
objective that explicitly maximizes the likelihood of generating semantically
correct programs. For addressing the second limitation, we introduce a training
procedure that directly maximizes the probability of generating syntactically
correct programs that fulfill the specification. We show that our contributions
lead to improved accuracy of the models, especially in cases where the training
data is limited.","['Rudy Bunel', 'Matthew Hausknecht', 'Jacob Devlin', 'Rishabh Singh', 'Pushmeet Kohli']","['cs.LG', 'stat.ML']",2018-05-11 08:45:24+00:00
http://arxiv.org/abs/1805.04272v2,An $O(N)$ Sorting Algorithm: Machine Learning Sort,"We propose an $O(N\cdot M)$ sorting algorithm by Machine Learning method,
which shows a huge potential sorting big data. This sorting algorithm can be
applied to parallel sorting and is suitable for GPU or TPU acceleration.
Furthermore, we discuss the application of this algorithm to sparse hash table.","['Hanqing Zhao', 'Yuehan Luo']","['cs.LG', 'cs.DS', 'stat.ML']",2018-05-11 08:28:55+00:00
http://arxiv.org/abs/1805.04246v3,Convex Programming Based Spectral Clustering,"Clustering is a fundamental task in data analysis, and spectral clustering
has been recognized as a promising approach to it. Given a graph describing the
relationship between data, spectral clustering explores the underlying cluster
structure in two stages. The first stage embeds the nodes of the graph in real
space, and the second stage groups the embedded nodes into several clusters.
The use of the $k$-means method in the grouping stage is currently standard
practice. We present a spectral clustering algorithm that uses convex
programming in the grouping stage and study how well it works. This algorithm
is designed based on the following observation. If a graph is well-clustered,
then the nodes with the largest degree in each cluster can be found by
computing an enclosing ellipsoid of the nodes embedded in real space, and the
clusters can be identified by using those nodes. We show that, for
well-clustered graphs, the algorithm can find clusters of nodes with minimal
conductance. We also give an experimental assessment of the algorithm's
performance.",['Tomohiko Mizutani'],"['cs.LG', 'stat.ML']",2018-05-11 06:11:03+00:00
http://arxiv.org/abs/1805.05189v1,Randomized Smoothing SVRG for Large-scale Nonsmooth Convex Optimization,"In this paper, we consider the problem of minimizing the average of a large
number of nonsmooth and convex functions. Such problems often arise in typical
machine learning problems as empirical risk minimization, but are
computationally very challenging. We develop and analyze a new algorithm that
achieves robust linear convergence rate, and both its time complexity and
gradient complexity are superior than state-of-art nonsmooth algorithms and
subgradient-based schemes. Besides, our algorithm works without any extra error
bound conditions on the objective function as well as the common
strongly-convex condition. We show that our algorithm has wide applications in
optimization and machine learning problems, and demonstrate experimentally that
it performs well on a large-scale ranking problem.",['Wenjie Huang'],"['stat.ML', 'cs.LG', 'math.OC']",2018-05-11 04:05:34+00:00
http://arxiv.org/abs/1805.04234v3,Distributed Deep Forest and its Application to Automatic Detection of Cash-out Fraud,"Internet companies are facing the need for handling large-scale machine
learning applications on a daily basis and distributed implementation of
machine learning algorithms which can handle extra-large scale tasks with great
performance is widely needed. Deep forest is a recently proposed deep learning
framework which uses tree ensembles as its building blocks and it has achieved
highly competitive results on various domains of tasks. However, it has not
been tested on extremely large scale tasks. In this work, based on our
parameter server system, we developed the distributed version of deep forest.
To meet the need for real-world tasks, many improvements are introduced to the
original deep forest model, including MART (Multiple Additive Regression Tree)
as base learners for efficiency and effectiveness consideration, the cost-based
method for handling prevalent class-imbalanced data, MART based feature
selection for high dimension data and different evaluation metrics for
automatically determining of the cascade level. We tested the deep forest model
on an extra-large scale task, i.e., automatic detection of cash-out fraud, with
more than 100 millions of training samples. Experimental results showed that
the deep forest model has the best performance according to the evaluation
metrics from different perspectives even with very little effort for parameter
tuning. This model can block fraud transactions in a large amount of money each
day. Even compared with the best-deployed model, the deep forest model can
additionally bring into a significant decrease in economic loss each day.","['Ya-Lin Zhang', 'Jun Zhou', 'Wenhao Zheng', 'Ji Feng', 'Longfei Li', 'Ziqi Liu', 'Ming Li', 'Zhiqiang Zhang', 'Chaochao Chen', 'Xiaolong Li', 'Zhi-Hua Zhou', 'YUAN', 'QI']","['cs.LG', 'stat.ML']",2018-05-11 03:17:21+00:00
http://arxiv.org/abs/1805.04193v1,An Unsupervised Clustering-Based Short-Term Solar Forecasting Methodology Using Multi-Model Machine Learning Blending,"Solar forecasting accuracy is affected by weather conditions, and weather
awareness forecasting models are expected to improve the performance. However,
it may not be available and reliable to classify different forecasting tasks by
using only meteorological weather categorization. In this paper, an
unsupervised clustering-based (UC-based) solar forecasting methodology is
developed for short-term (1-hour-ahead) global horizontal irradiance (GHI)
forecasting. This methodology consists of three parts: GHI time series
unsupervised clustering, pattern recognition, and UC-based forecasting. The
daily GHI time series is first clustered by an Optimized Cross-validated
ClUsteRing (OCCUR) method, which determines the optimal number of clusters and
best clustering results. Then, support vector machine pattern recognition
(SVM-PR) is adopted to recognize the category of a certain day using the first
few hours' data in the forecasting stage. GHI forecasts are generated by the
most suitable models in different clusters, which are built by a two-layer
Machine learning based Multi-Model (M3) forecasting framework. The developed
UC-based methodology is validated by using 1-year of data with six solar
features. Numerical results show that (i) UC-based models outperform non-UC
(all-in-one) models with the same M3 architecture by approximately 20%; (ii)
M3-based models also outperform the single-algorithm machine learning (SAML)
models by approximately 20%.","['Cong Feng', 'Mingjian Cui', 'Bri-Mathias Hodge', 'Siyuan Lu', 'Hendrik F. Hamann', 'Jie Zhang']","['cs.LG', 'stat.ML']",2018-05-10 22:17:51+00:00
http://arxiv.org/abs/1805.04514v2,Metatrace Actor-Critic: Online Step-size Tuning by Meta-gradient Descent for Reinforcement Learning Control,"Reinforcement learning (RL) has had many successes in both ""deep"" and
""shallow"" settings. In both cases, significant hyperparameter tuning is often
required to achieve good performance. Furthermore, when nonlinear function
approximation is used, non-stationarity in the state representation can lead to
learning instability. A variety of techniques exist to combat this --- most
notably large experience replay buffers or the use of multiple parallel actors.
These techniques come at the cost of moving away from the online RL problem as
it is traditionally formulated (i.e., a single agent learning online without
maintaining a large database of training examples). Meta-learning can
potentially help with both these issues by tuning hyperparameters online and
allowing the algorithm to more robustly adjust to non-stationarity in a
problem. This paper applies meta-gradient descent to derive a set of step-size
tuning algorithms specifically for online RL control with eligibility traces.
Our novel technique, Metatrace, makes use of an eligibility trace analogous to
methods like $TD(\lambda)$. We explore tuning both a single scalar step-size
and a separate step-size for each learned parameter. We evaluate Metatrace
first for control with linear function approximation in the classic mountain
car problem and then in a noisy, non-stationary version. Finally, we apply
Metatrace for control with nonlinear function approximation in 5 games in the
Arcade Learning Environment where we explore how it impacts learning speed and
robustness to initial step-size choice. Results show that the meta-step-size
parameter of Metatrace is easy to set, Metatrace can speed learning, and
Metatrace can allow an RL algorithm to deal with non-stationarity in the
learning task.","['Kenny Young', 'Baoxiang Wang', 'Matthew E. Taylor']","['cs.LG', 'cs.AI', 'stat.ML']",2018-05-10 20:00:50+00:00
http://arxiv.org/abs/1805.04051v3,Classification of Household Materials via Spectroscopy,"Recognizing an object's material can inform a robot on the object's fragility
or appropriate use. To estimate an object's material during manipulation, many
prior works have explored the use of haptic sensing. In this paper, we explore
a technique for robots to estimate the materials of objects using spectroscopy.
We demonstrate that spectrometers provide several benefits for material
recognition, including fast response times and accurate measurements with low
noise. Furthermore, spectrometers do not require direct contact with an object.
To explore this, we collected a dataset of spectral measurements from two
commercially available spectrometers during which a robotic platform interacted
with 50 flat material objects, and we show that a neural network model can
accurately analyze these measurements. Due to the similarity between
consecutive spectral measurements, our model achieved a material classification
accuracy of 94.6% when given only one spectral sample per object. Similar to
prior works with haptic sensors, we found that generalizing material
recognition to new objects posed a greater challenge, for which we achieved an
accuracy of 79.1% via leave-one-object-out cross-validation. Finally, we
demonstrate how a PR2 robot can leverage spectrometers to estimate the
materials of everyday objects found in the home. From this work, we find that
spectroscopy poses a promising approach for material classification during
robotic manipulation.","['Zackory Erickson', 'Nathan Luskey', 'Sonia Chernova', 'Charles C. Kemp']","['cs.RO', 'stat.ML']",2018-05-10 16:32:26+00:00
http://arxiv.org/abs/1805.04035v3,Scaling limit of the Stein variational gradient descent: the mean field regime,"We study an interacting particle system in $\mathbf{R}^d$ motivated by Stein
variational gradient descent [Q. Liu and D. Wang, NIPS 2016], a deterministic
algorithm for sampling from a given probability density with unknown
normalization. We prove that in the large particle limit the empirical measure
of the particle system converges to a solution of a non-local and nonlinear
PDE. We also prove global existence, uniqueness and regularity of the solution
to the limiting PDE. Finally, we prove that the solution to the PDE converges
to the unique invariant solution in long time limit.","['Jianfeng Lu', 'Yulong Lu', 'James Nolen']","['math.AP', 'stat.ME', 'stat.ML']",2018-05-10 16:02:53+00:00
http://arxiv.org/abs/1805.04018v2,Supervising Nyström Methods via Negative Margin Support Vector Selection,"The Nystr\""om methods have been popular techniques for scalable kernel based
learning. They approximate explicit, low-dimensional feature mappings for
kernel functions from the pairwise comparisons with the training data. However,
Nystr\""om methods are generally applied without the supervision provided by the
training labels in the classification/regression problems. This leads to
pairwise comparisons with randomly chosen training samples in the model.
Conversely, this work studies a supervised Nystr\""om method that chooses the
critical subsets of samples for the success of the Machine Learning model.
Particularly, we select the Nystr\""om support vectors via the negative margin
criterion, and create explicit feature maps that are more suitable for the
classification task on the data. Experimental results on six datasets show
that, without increasing the complexity over unsupervised techniques, our
method can significantly improve the classification performance achieved via
kernel approximation methods and reduce the number of features needed to reach
or exceed the performance of the full-dimensional kernel machines.","['Mert Al', 'Thee Chanyaswad', 'Sun-Yuan Kung']","['cs.LG', 'stat.ML']",2018-05-10 15:14:15+00:00
http://arxiv.org/abs/1805.03963v4,Monotone Learning with Rectified Wire Networks,"We introduce a new neural network model, together with a tractable and
monotone online learning algorithm. Our model describes feed-forward networks
for classification, with one output node for each class. The only nonlinear
operation is rectification using a ReLU function with a bias. However, there is
a rectifier on every edge rather than at the nodes of the network. There are
also weights, but these are positive, static, and associated with the nodes.
Our ""rectified wire"" networks are able to represent arbitrary Boolean
functions. Only the bias parameters, on the edges of the network, are learned.
Another departure in our approach, from standard neural networks, is that the
loss function is replaced by a constraint. This constraint is simply that the
value of the output node associated with the correct class should be zero. Our
model has the property that the exact norm-minimizing parameter update,
required to correctly classify a training item, is the solution to a quadratic
program that can be computed with a few passes through the network. We
demonstrate a training algorithm using this update, called sequential
deactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a
natural choice for the nodal weights, SDA has no hyperparameters other than
those describing the network structure. Our experiments explore behavior with
respect to network size and depth in a family of sparse expander networks.","['Veit Elser', 'Dan Schmidt', 'Jonathan Yedidia']","['cs.LG', 'cs.NE', 'math.OC', 'stat.ML']",2018-05-10 13:24:34+00:00
http://arxiv.org/abs/1805.03911v2,Labelling as an unsupervised learning problem,"Unravelling hidden patterns in datasets is a classical problem with many
potential applications. In this paper, we present a challenge whose objective
is to discover nonlinear relationships in noisy cloud of points. If a set of
point satisfies a nonlinear relationship that is unlikely to be due to
randomness, we will label the set with this relationship. Since points can
satisfy one, many or no such nonlinear relationships, cloud of points will
typically have one, multiple or no labels at all. This introduces the labelling
problem that will be studied in this paper.
  The objective of this paper is to develop a framework for the labelling
problem. We introduce a precise notion of a label, and we propose an algorithm
to discover such labels in a given dataset, which is then tested in synthetic
datasets. We also analyse, using tools from random matrix theory, the problem
of discovering false labels in the dataset.","['Terry Lyons', 'Imanol Perez Arribas']","['stat.ML', 'cs.LG']",2018-05-10 10:04:27+00:00
http://arxiv.org/abs/1805.03908v1,Towards a universal neural network encoder for time series,"We study the use of a time series encoder to learn representations that are
useful on data set types with which it has not been trained on. The encoder is
formed of a convolutional neural network whose temporal output is summarized by
a convolutional attention mechanism. This way, we obtain a compact,
fixed-length representation from longer, variable-length time series. We
evaluate the performance of the proposed approach on a well-known time series
classification benchmark, considering full adaptation, partial adaptation, and
no adaptation of the encoder to the new data type. Results show that such
strategies are competitive with the state-of-the-art, often outperforming
conceptually-matching approaches. Besides accuracy scores, the facility of
adaptation and the efficiency of pre-trained encoders make them an appealing
option for the processing of scarcely- or non-labeled time series.","['Joan Serrà', 'Santiago Pascual', 'Alexandros Karatzoglou']","['cs.LG', 'cs.NE', 'stat.ML']",2018-05-10 09:46:45+00:00
http://arxiv.org/abs/1805.03901v1,Loss-Calibrated Approximate Inference in Bayesian Neural Networks,"Current approaches in approximate inference for Bayesian neural networks
minimise the Kullback-Leibler divergence to approximate the true posterior over
the weights. However, this approximation is without knowledge of the final
application, and therefore cannot guarantee optimal predictions for a given
task. To make more suitable task-specific approximations, we introduce a new
loss-calibrated evidence lower bound for Bayesian neural networks in the
context of supervised learning, informed by Bayesian decision theory. By
introducing a lower bound that depends on a utility function, we ensure that
our approximation achieves higher utility than traditional methods for
applications that have asymmetric utility functions. Furthermore, in using
dropout inference, we highlight that our new objective is identical to that of
standard dropout neural networks, with an additional utility-dependent penalty
term. We demonstrate our new loss-calibrated model with an illustrative medical
example and a restricted model capacity experiment, and highlight failure modes
of the comparable weighted cross entropy approach. Lastly, we demonstrate the
scalability of our method to real world applications with per-pixel semantic
segmentation on an autonomous driving data set.","['Adam D. Cobb', 'Stephen J. Roberts', 'Yarin Gal']","['stat.ML', 'cs.LG']",2018-05-10 09:26:03+00:00
http://arxiv.org/abs/1805.03887v1,Scaling associative classification for very large datasets,"Supervised learning algorithms are nowadays successfully scaling up to
datasets that are very large in volume, leveraging the potential of in-memory
cluster-computing Big Data frameworks. Still, massive datasets with a number of
large-domain categorical features are a difficult challenge for any classifier.
Most off-the-shelf solutions cannot cope with this problem. In this work we
introduce DAC, a Distributed Associative Classifier. DAC exploits ensemble
learning to distribute the training of an associative classifier among parallel
workers and improve the final quality of the model. Furthermore, it adopts
several novel techniques to reach high scalability without sacrificing quality,
among which a preventive pruning of classification rules in the extraction
phase based on Gini impurity. We ran experiments on Apache Spark, on a real
large-scale dataset with more than 4 billion records and 800 million distinct
categories. The results showed that DAC improves on a state-of-the-art solution
in both prediction quality and execution time. Since the generated model is
human-readable, it can not only classify new records, but also allow
understanding both the logic behind the prediction and the properties of the
model, becoming a useful aid for decision makers.","['Luca Venturini', 'Elena Baralis', 'Paolo Garza']","['cs.LG', 'cs.AI', 'cs.DC', 'stat.ML']",2018-05-10 08:41:55+00:00
http://arxiv.org/abs/1805.03785v1,Deep Learning of Geometric Constellation Shaping including Fiber Nonlinearities,"A new geometric shaping method is proposed, leveraging unsupervised machine
learning to optimize the constellation design. The learned constellation
mitigates nonlinear effects with gains up to 0.13 bit/4D when trained with a
simplified fiber channel model.","['Rasmus T. Jones', 'Tobias A. Eriksson', 'Metodi P. Yankov', 'Darko Zibar']","['cs.IT', 'math.IT', 'stat.ML']",2018-05-10 02:08:15+00:00
http://arxiv.org/abs/1805.03779v3,k-Space Deep Learning for Accelerated MRI,"The annihilating filter-based low-rank Hankel matrix approach (ALOHA) is one
of the state-of-the-art compressed sensing approaches that directly
interpolates the missing k-space data using low-rank Hankel matrix completion.
The success of ALOHA is due to the concise signal representation in the k-space
domain thanks to the duality between structured low-rankness in the k-space
domain and the image domain sparsity. Inspired by the recent mathematical
discovery that links convolutional neural networks to Hankel matrix
decomposition using data-driven framelet basis, here we propose a fully
data-driven deep learning algorithm for k-space interpolation. Our network can
be also easily applied to non-Cartesian k-space trajectories by simply adding
an additional regridding layer. Extensive numerical experiments show that the
proposed deep learning method consistently outperforms the existing
image-domain deep learning approaches.","['Yoseob Han', 'Leonard Sunwoo', 'Jong Chul Ye']","['cs.CV', 'cs.LG', 'stat.ML']",2018-05-10 01:43:19+00:00
http://arxiv.org/abs/1805.03777v1,Deep Reinforcement Learning for Optimal Control of Space Heating,"Classical methods to control heating systems are often marred by suboptimal
performance, inability to adapt to dynamic conditions and unreasonable
assumptions e.g. existence of building models. This paper presents a novel deep
reinforcement learning algorithm which can control space heating in buildings
in a computationally efficient manner, and benchmarks it against other known
techniques. The proposed algorithm outperforms rule based control by between
5-10% in a simulation environment for a number of price signals. We conclude
that, while not optimal, the proposed algorithm offers additional practical
advantages such as faster computation times and increased robustness to
non-stationarities in building dynamics.","['Adam Nagy', 'Hussain Kazmi', 'Farah Cheaib', 'Johan Driesen']","['stat.AP', 'cs.SY', 'stat.ML']",2018-05-10 01:35:54+00:00
http://arxiv.org/abs/1805.03716v1,Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum,"LSTMs were introduced to combat vanishing gradients in simple RNNs by
augmenting them with gated additive recurrent connections. We present an
alternative view to explain the success of LSTMs: the gates themselves are
versatile recurrent models that provide more representational power than
previously appreciated. We do this by decoupling the LSTM's gates from the
embedded simple RNN, producing a new class of RNNs where the recurrence
computes an element-wise weighted sum of context-independent functions of the
input. Ablations on a range of problems demonstrate that the gating mechanism
alone performs as well as an LSTM in most settings, strongly suggesting that
the gates are doing much more in practice than just alleviating vanishing
gradients.","['Omer Levy', 'Kenton Lee', 'Nicholas FitzGerald', 'Luke Zettlemoyer']","['cs.CL', 'cs.AI', 'cs.LG', 'stat.ML']",2018-05-09 20:05:58+00:00
http://arxiv.org/abs/1805.03714v2,Foundations of Sequence-to-Sequence Modeling for Time Series,"The availability of large amounts of time series data, paired with the
performance of deep-learning algorithms on a broad class of problems, has
recently led to significant interest in the use of sequence-to-sequence models
for time series forecasting. We provide the first theoretical analysis of this
time series forecasting framework. We include a comparison of
sequence-to-sequence modeling to classical time series models, and as such our
theory can serve as a quantitative guide for practitioners choosing between
different modeling methodologies.","['Vitaly Kuznetsov', 'Zelda Mariet']","['cs.LG', 'cs.AI', 'stat.ML']",2018-05-09 20:03:37+00:00
http://arxiv.org/abs/1805.03620v1,On the Limitations of Unsupervised Bilingual Dictionary Induction,"Unsupervised machine translation---i.e., not assuming any cross-lingual
supervision signal, whether a dictionary, translations, or comparable
corpora---seems impossible, but nevertheless, Lample et al. (2018) recently
proposed a fully unsupervised machine translation (MT) model. The model relies
heavily on an adversarial, unsupervised alignment of word embedding spaces for
bilingual dictionary induction (Conneau et al., 2018), which we examine here.
Our results identify the limitations of current unsupervised MT: unsupervised
bilingual dictionary induction performs much worse on morphologically rich
languages that are not dependent marking, when monolingual corpora from
different domains or different embedding algorithms are used. We show that a
simple trick, exploiting a weak supervision signal from identical words,
enables more robust induction, and establish a near-perfect correlation between
unsupervised bilingual dictionary induction performance and a previously
unexplored graph similarity metric.","['Anders Søgaard', 'Sebastian Ruder', 'Ivan Vulić']","['cs.CL', 'cs.LG', 'stat.ML']",2018-05-09 17:08:03+00:00
http://arxiv.org/abs/1805.03616v3,A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization,"In this paper, we propose a deep learning approach to tackle the automatic
summarization tasks by incorporating topic information into the convolutional
sequence-to-sequence (ConvS2S) model and using self-critical sequence training
(SCST) for optimization. Through jointly attending to topics and word-level
alignment, our approach can improve coherence, diversity, and informativeness
of generated summaries via a biased probability generation mechanism. On the
other hand, reinforcement training, like SCST, directly optimizes the proposed
model with respect to the non-differentiable metric ROUGE, which also avoids
the exposure bias during inference. We carry out the experimental evaluation
with state-of-the-art methods over the Gigaword, DUC-2004, and LCSTS datasets.
The empirical results demonstrate the superiority of our proposed method in the
abstractive summarization.","['Li Wang', 'Junlin Yao', 'Yunzhe Tao', 'Li Zhong', 'Wei Liu', 'Qiang Du']","['cs.CL', 'cs.LG', 'stat.ML']",2018-05-09 16:56:41+00:00
http://arxiv.org/abs/1805.03591v1,Secure Mobile Edge Computing in IoT via Collaborative Online Learning,"To accommodate heterogeneous tasks in Internet of Things (IoT), a new
communication and computing paradigm termed mobile edge computing emerges that
extends computing services from the cloud to edge, but at the same time exposes
new challenges on security. The present paper studies online security-aware
edge computing under jamming attacks. Leveraging online learning tools, novel
algorithms abbreviated as SAVE-S and SAVE-A are developed to cope with the
stochastic and adversarial forms of jamming, respectively. Without utilizing
extra resources such as spectrum and transmission power to evade jamming
attacks, SAVE-S and SAVE-A can select the most reliable server to offload
computing tasks with minimal privacy and security concerns. It is analytically
established that without any prior information on future jamming and server
security risks, the proposed schemes can achieve ${\cal O}\big(\sqrt{T}\big)$
regret. Information sharing among devices can accelerate the security-aware
computing tasks. Incorporating the information shared by other devices, SAVE-S
and SAVE-A offer impressive improvements on the sublinear regret, which is
guaranteed by what is termed ""value of cooperation."" Effectiveness of the
proposed schemes is tested on both synthetic and real datasets.","['Bingcong Li', 'Tianyi Chen', 'Georgios B. Giannakis']","['cs.LG', 'stat.ML']",2018-05-09 15:39:17+00:00
http://arxiv.org/abs/1805.03586v2,Policy Optimization with Second-Order Advantage Information,"Policy optimization on high-dimensional continuous control tasks exhibits its
difficulty caused by the large variance of the policy gradient estimators. We
present the action subspace dependent gradient (ASDG) estimator which
incorporates the Rao-Blackwell theorem (RB) and Control Variates (CV) into a
unified framework to reduce the variance. To invoke RB, our proposed algorithm
(POSA) learns the underlying factorization structure among the action space
based on the second-order advantage information. POSA captures the quadratic
information explicitly and efficiently by utilizing the wide & deep
architecture. Empirical studies show that our proposed approach demonstrates
the performance improvements on high-dimensional synthetic settings and OpenAI
Gym's MuJoCo continuous control tasks.","['Jiajin Li', 'Baoxiang Wang']","['cs.LG', 'cs.AI', 'stat.ML']",2018-05-09 15:23:58+00:00
http://arxiv.org/abs/1805.03647v1,End-to-End Polyphonic Sound Event Detection Using Convolutional Recurrent Neural Networks with Learned Time-Frequency Representation Input,"Sound event detection systems typically consist of two stages: extracting
hand-crafted features from the raw audio waveform, and learning a mapping
between these features and the target sound events using a classifier.
Recently, the focus of sound event detection research has been mostly shifted
to the latter stage using standard features such as mel spectrogram as the
input for classifiers such as deep neural networks. In this work, we utilize
end-to-end approach and propose to combine these two stages in a single deep
neural network classifier. The feature extraction over the raw waveform is
conducted by a feedforward layer block, whose parameters are initialized to
extract the time-frequency representations. The feature extraction parameters
are updated during training, resulting with a representation that is optimized
for the specific task. This feature extraction block is followed by (and
jointly trained with) a convolutional recurrent network, which has recently
given state-of-the-art results in many sound recognition tasks. The proposed
system does not outperform a convolutional recurrent network with fixed
hand-crafted features. The final magnitude spectrum characteristics of the
feature extraction block parameters indicate that the most relevant information
for the given task is contained in 0 - 3 kHz frequency range, and this is also
supported by the empirical results on the SED performance.","['Emre Çakır', 'Tuomas Virtanen']","['cs.SD', 'cs.LG', 'eess.AS', 'stat.ML']",2018-05-09 15:10:57+00:00
http://arxiv.org/abs/1805.03553v1,On Visual Hallmarks of Robustness to Adversarial Malware,"A central challenge of adversarial learning is to interpret the resulting
hardened model. In this contribution, we ask how robust generalization can be
visually discerned and whether a concise view of the interactions between a
hardened decision map and input samples is possible. We first provide a means
of visually comparing a hardened model's loss behavior with respect to the
adversarial variants generated during training versus loss behavior with
respect to adversarial variants generated from other sources. This allows us to
confirm that the association of observed flatness of a loss landscape with
generalization that is seen with naturally trained models extends to
adversarially hardened models and robust generalization. To complement these
means of interpreting model parameter robustness we also use self-organizing
maps to provide a visual means of superimposing adversarial and natural
variants on a model's decision space, thus allowing the model's global
robustness to be comprehensively examined.","['Alex Huang', 'Abdullah Al-Dujaili', 'Erik Hemberg', ""Una-May O'Reilly""]","['cs.LG', 'cs.CR', 'cs.HC', 'stat.ML']",2018-05-09 14:28:42+00:00
http://arxiv.org/abs/1805.03551v2,A Unified Framework of Deep Neural Networks by Capsules,"With the growth of deep learning, how to describe deep neural networks
unifiedly is becoming an important issue. We first formalize neural networks
mathematically with their directed graph representations, and prove a
generation theorem about the induced networks of connected directed acyclic
graphs. Then, we set up a unified framework for deep learning with capsule
networks. This capsule framework could simplify the description of existing
deep neural networks, and provide a theoretical basis of graphic designing and
programming techniques for deep learning models, thus would be of great
significance to the advancement of deep learning.","['Yujian Li', 'Chuanhui Shan']","['cs.LG', 'stat.ML']",2018-05-09 14:23:17+00:00
http://arxiv.org/abs/1805.03504v2,Diffusion Based Network Embedding,"In network embedding, random walks play a fundamental role in preserving
network structures. However, random walk based embedding methods have two
limitations. First, random walk methods are fragile when the sampling frequency
or the number of node sequences changes. Second, in disequilibrium networks
such as highly biases networks, random walk methods often perform poorly due to
the lack of global network information. In order to solve the limitations, we
propose in this paper a network diffusion based embedding method. To solve the
first limitation, our method employs a diffusion driven process to capture both
depth information and breadth information. The time dimension is also attached
to node sequences that can strengthen information preserving. To solve the
second limitation, our method uses the network inference technique based on
cascades to capture the global network information. To verify the performance,
we conduct experiments on node classification tasks using the learned
representations. Results show that compared with random walk based methods,
diffusion based models are more robust when samplings under each node is rare.
We also conduct experiments on a highly imbalanced network. Results shows that
the proposed model are more robust under the biased network structure.","['Yong Shi', 'Minglong Lei', 'Peng Zhang', 'Lingfeng Niu']","['cs.LG', 'stat.ML']",2018-05-09 13:23:24+00:00
http://arxiv.org/abs/1805.03463v2,Dealing with Categorical and Integer-valued Variables in Bayesian Optimization with Gaussian Processes,"Bayesian Optimization (BO) methods are useful for optimizing functions that
are expen- sive to evaluate, lack an analytical expression and whose
evaluations can be contaminated by noise. These methods rely on a probabilistic
model of the objective function, typically a Gaussian process (GP), upon which
an acquisition function is built. The acquisition function guides the
optimization process and measures the expected utility of performing an
evaluation of the objective at a new point. GPs assume continous input
variables. When this is not the case, for example when some of the input
variables take categorical or integer values, one has to introduce extra
approximations. Consider a suggested input location taking values in the real
line. Before doing the evaluation of the objective, a common approach is to use
a one hot encoding approximation for categorical variables, or to round to the
closest integer, in the case of integer-valued variables. We show that this can
lead to problems in the optimization process and describe a more principled
approach to account for input variables that are categorical or integer-valued.
We illustrate in both synthetic and a real experiments the utility of our
approach, which significantly improves the results of standard BO methods using
Gaussian processes on problems with categorical or integer-valued variables.","['Eduardo C. Garrido-Merchán', 'Daniel Hernández-Lobato']","['stat.ML', 'cs.LG']",2018-05-09 11:51:52+00:00
http://arxiv.org/abs/1805.03444v4,Controlling the privacy loss with the input feature maps of the layers in convolutional neural networks,"We propose the method to sanitize the privacy of the IFM(Input Feature Map)s
that are fed into the layers of CNN(Convolutional Neural Network)s. The method
introduces the degree of the sanitization that makes the application using a
CNN be able to control the privacy loss represented as the ratio of the
probabilistic accuracies for original IFM and sanitized IFM. For the
sanitization of an IFM, the sample-and-hold based approximation scheme is
devised to satisfy an application-specific degree of the sanitization. The
scheme approximates an IFM by replacing all the samples in a window with the
non-zero sample closest to the mean of the sampling window. It also removes the
dependency on CNN configuration by unfolding multi-dimensional IFM tensors into
one-dimensional streams to be approximated.","['Woohyung Chun', 'Sung-Min Hong', 'Junho Huh', 'Inyup Kang']","['cs.LG', 'cs.CR', 'cs.CV', 'stat.ML']",2018-05-09 10:12:31+00:00
http://arxiv.org/abs/1805.03644v1,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,"We propose a novel regularizer to improve the training of Generative
Adversarial Networks (GANs). The motivation is that when the discriminator D
spreads out its model capacity in the right way, the learning signals given to
the generator G are more informative and diverse. These in turn help G to
explore better and discover the real data manifold while avoiding large
unstable jumps due to the erroneous extrapolation made by D. Our regularizer
guides the rectifier discriminator D to better allocate its model capacity, by
encouraging the binary activation patterns on selected internal layers of D to
have a high joint entropy. Experimental results on both synthetic data and real
datasets demonstrate improvements in stability and convergence speed of the GAN
training, as well as higher sample quality. The approach also leads to higher
classification accuracies in semi-supervised learning.","['Yanshuai Cao', 'Gavin Weiguang Ding', 'Kry Yik-Chau Lui', 'Ruitong Huang']","['cs.LG', 'stat.ML']",2018-05-09 06:31:24+00:00
http://arxiv.org/abs/1805.03359v2,Reward Estimation for Variance Reduction in Deep Reinforcement Learning,"Reinforcement Learning (RL) agents require the specification of a reward
signal for learning behaviours. However, introduction of corrupt or stochastic
rewards can yield high variance in learning. Such corruption may be a direct
result of goal misspecification, randomness in the reward signal, or
correlation of the reward with external factors that are not known to the
agent. Corruption or stochasticity of the reward signal can be especially
problematic in robotics, where goal specification can be particularly difficult
for complex tasks. While many variance reduction techniques have been studied
to improve the robustness of the RL process, handling such stochastic or
corrupted reward structures remains difficult. As an alternative for handling
this scenario in model-free RL methods, we suggest using an estimator for both
rewards and value functions. We demonstrate that this improves performance
under corrupted stochastic rewards in both the tabular and non-linear function
approximation settings for a variety of noise types and environments. The use
of reward estimation is a robust and easy-to-implement improvement for handling
corrupted reward signals in model-free RL.","['Joshua Romoff', 'Peter Henderson', 'Alexandre Piché', 'Vincent Francois-Lavet', 'Joelle Pineau']","['cs.LG', 'cs.AI', 'stat.ML']",2018-05-09 03:11:29+00:00
http://arxiv.org/abs/1805.03317v3,Subsampling Sequential Monte Carlo for Static Bayesian Models,"We show how to speed up Sequential Monte Carlo (SMC) for Bayesian inference
in large data problems by data subsampling. SMC sequentially updates a cloud of
particles through a sequence of distributions, beginning with a distribution
that is easy to sample from such as the prior and ending with the posterior
distribution. Each update of the particle cloud consists of three steps:
reweighting, resampling, and moving. In the move step, each particle is moved
using a Markov kernel; this is typically the most computationally expensive
part, particularly when the dataset is large. It is crucial to have an
efficient move step to ensure particle diversity. Our article makes two
important contributions. First, in order to speed up the SMC computation, we
use an approximately unbiased and efficient annealed likelihood estimator based
on data subsampling. The subsampling approach is more memory efficient than the
corresponding full data SMC, which is an advantage for parallel computation.
Second, we use a Metropolis within Gibbs kernel with two conditional updates. A
Hamiltonian Monte Carlo update makes distant moves for the model parameters,
and a block pseudo-marginal proposal is used for the particles corresponding to
the auxiliary variables for the data subsampling. We demonstrate both the
usefulness and limitations of the methodology for estimating four generalized
linear models and a generalized additive model with large datasets.","['David Gunawan', 'Khue-Dung Dang', 'Matias Quiroz', 'Robert Kohn', 'Minh-Ngoc Tran']","['stat.CO', 'stat.ME', 'stat.ML']",2018-05-08 23:17:01+00:00
http://arxiv.org/abs/1805.03294v1,Improved training of end-to-end attention models for speech recognition,"Sequence-to-sequence attention-based models on subword units allow simple
open-vocabulary end-to-end speech recognition. In this work, we show that such
models can achieve competitive results on the Switchboard 300h and LibriSpeech
1000h tasks. In particular, we report the state-of-the-art word error rates
(WER) of 3.54% on the dev-clean and 3.82% on the test-clean evaluation subsets
of LibriSpeech. We introduce a new pretraining scheme by starting with a high
time reduction factor and lowering it during training, which is crucial both
for convergence and final performance. In some experiments, we also use an
auxiliary CTC loss function to help the convergence. In addition, we train long
short-term memory (LSTM) language models on subword units. By shallow fusion,
we report up to 27% relative improvements in WER over the attention baseline
without a language model.","['Albert Zeyer', 'Kazuki Irie', 'Ralf Schlüter', 'Hermann Ney']","['cs.CL', 'cs.LG', 'stat.ML']",2018-05-08 21:27:04+00:00
