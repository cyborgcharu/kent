id,title,abstract,authors,categories,date
http://arxiv.org/abs/1809.04705v1,Distilled Wasserstein Learning for Word Embedding and Topic Modeling,"We propose a novel Wasserstein method with a distillation mechanism, yielding
joint learning of word embeddings and topics. The proposed method is based on
the fact that the Euclidean distance between word embeddings may be employed as
the underlying distance in the Wasserstein topic model. The word distributions
of topics, their optimal transports to the word distributions of documents, and
the embeddings of words are learned in a unified framework. When learning the
topic model, we leverage a distilled underlying distance matrix to update the
topic distributions and smoothly calculate the corresponding optimal
transports. Such a strategy provides the updating of word embeddings with
robust guidance, improving the algorithmic convergence. As an application, we
focus on patient admission records, in which the proposed method embeds the
codes of diseases and procedures and learns the topics of admissions, obtaining
superior performance on clinically-meaningful disease network construction,
mortality prediction as a function of admission codes, and procedure
recommendation.","['Hongteng Xu', 'Wenlin Wang', 'Wei Liu', 'Lawrence Carin']","['cs.LG', 'cs.CL', 'stat.ML']",2018-09-12 23:10:23+00:00
http://arxiv.org/abs/1809.04684v1,Fair lending needs explainable models for responsible recommendation,"The financial services industry has unique explainability and fairness
challenges arising from compliance and ethical considerations in credit
decisioning. These challenges complicate the use of model machine learning and
artificial intelligence methods in business decision processes.",['Jiahao Chen'],"['cs.LG', 'cs.AI', 'cs.CY', 'stat.AP', 'stat.ML', '91G40, 68T01', 'J.1; I.5.1']",2018-09-12 21:29:20+00:00
http://arxiv.org/abs/1809.04683v2,SAFE: A Neural Survival Analysis Model for Fraud Early Detection,"Many online platforms have deployed anti-fraud systems to detect and prevent
fraudulent activities. However, there is usually a gap between the time that a
user commits a fraudulent action and the time that the user is suspended by the
platform. How to detect fraudsters in time is a challenging problem. Most of
the existing approaches adopt classifiers to predict fraudsters given their
activity sequences along time. The main drawback of classification models is
that the prediction results between consecutive timestamps are often
inconsistent. In this paper, we propose a survival analysis based fraud early
detection model, SAFE, which maps dynamic user activities to survival
probabilities that are guaranteed to be monotonically decreasing along time.
SAFE adopts recurrent neural network (RNN) to handle user activity sequences
and directly outputs hazard values at each timestamp, and then, survival
probability derived from hazard values is deployed to achieve consistent
predictions. Because we only observe the user suspended time instead of the
fraudulent activity time in the training data, we revise the loss function of
the regular survival model to achieve fraud early detection. Experimental
results on two real world datasets demonstrate that SAFE outperforms both the
survival analysis model and recurrent neural network model alone as well as
state-of-the-art fraud early detection approaches.","['Panpan Zheng', 'Shuhan Yuan', 'Xintao Wu']","['cs.LG', 'cs.AI', 'cs.CR', 'stat.ML']",2018-09-12 21:28:26+00:00
http://arxiv.org/abs/1809.04682v2,Automatic Program Synthesis of Long Programs with a Learned Garbage Collector,"We consider the problem of generating automatic code given sample
input-output pairs. We train a neural network to map from the current state and
the outputs to the program's next statement. The neural network optimizes
multiple tasks concurrently: the next operation out of a set of high level
commands, the operands of the next statement, and which variables can be
dropped from memory. Using our method we are able to create programs that are
more than twice as long as existing state-of-the-art solutions, while improving
the success rate for comparable lengths, and cutting the run-time by two orders
of magnitude. Our code, including an implementation of various literature
baselines, is publicly available at https://github.com/amitz25/PCCoder","['Amit Zohar', 'Lior Wolf']","['cs.LG', 'cs.PL', 'stat.ML']",2018-09-12 21:25:28+00:00
http://arxiv.org/abs/1809.04673v1,A Unified Batch Online Learning Framework for Click Prediction,"We present a unified framework for Batch Online Learning (OL) for Click
Prediction in Search Advertisement. Machine Learning models once deployed, show
non-trivial accuracy and calibration degradation over time due to model
staleness. It is therefore necessary to regularly update models, and do so
automatically. This paper presents two paradigms of Batch Online Learning, one
which incrementally updates the model parameters via an early stopping
mechanism, and another which does so through a proximal regularization. We
argue how both these schemes naturally trade-off between old and new data. We
then theoretically and empirically show that these two seemingly different
schemes are closely related. Through extensive experiments, we demonstrate the
utility of of our OL framework; how the two OL schemes relate to each other and
how they trade-off between the new and historical data. We then compare batch
OL to full model retrains, and show how online learning is more robust to data
issues. We also demonstrate the long term impact of Online Learning, the role
of the initial Models in OL, the impact of delays in the update, and finally
conclude with some implementation details and challenges in deploying a real
world online learning system in production. While this paper mostly focuses on
application of click prediction for search advertisement, we hope that the
lessons learned here can be carried over to other problem domains.","['Rishabh Iyer', 'Nimit Acharya', 'Tanuja Bompada', 'Denis Charles', 'Eren Manavoglu']","['cs.LG', 'cs.AI', 'stat.ML']",2018-09-12 21:01:55+00:00
http://arxiv.org/abs/1809.04668v1,PARyOpt: A software for Parallel Asynchronous Remote Bayesian Optimization,"PARyOpt is a python based implementation of the Bayesian optimization routine
designed for remote and asynchronous function evaluations. Bayesian
optimization is especially attractive for computational optimization due to its
low cost function footprint as well as the ability to account for uncertainties
in data. A key challenge to efficiently deploy any optimization strategy on
distributed computing systems is the synchronization step, where data from
multiple function calls is assimilated to identify the next campaign of
function calls. Bayesian optimization provides an elegant approach to overcome
this issue via asynchronous updates. We formulate, develop and implement a
parallel, asynchronous variant of Bayesian optimization. The framework is
robust and resilient to external failures. We show how such asynchronous
evaluations help reduce the total optimization wall clock time for a suite of
test problems. Additionally, we show how the software design of the framework
allows easy extension to response surface reconstruction (Kriging), providing a
high performance software for autonomous exploration. The software is available
on PyPI, with examples and documentation.","['Balaji Sesha Sarath Pokuri', 'Alec Lofquist', 'Chad M Risko', 'Baskar Ganapathysubramanian']","['math.OC', 'cs.LG', 'stat.ML', '90C26', 'D.0; D.1.3; G.1.6; G.3']",2018-09-12 20:50:19+00:00
http://arxiv.org/abs/1809.04663v3,Creating Fair Models of Atherosclerotic Cardiovascular Disease Risk,"Guidelines for the management of atherosclerotic cardiovascular disease
(ASCVD) recommend the use of risk stratification models to identify patients
most likely to benefit from cholesterol-lowering and other therapies. These
models have differential performance across race and gender groups with
inconsistent behavior across studies, potentially resulting in an inequitable
distribution of beneficial therapy. In this work, we leverage adversarial
learning and a large observational cohort extracted from electronic health
records (EHRs) to develop a ""fair"" ASCVD risk prediction model with reduced
variability in error rates across groups. We empirically demonstrate that our
approach is capable of aligning the distribution of risk predictions
conditioned on the outcome across several groups simultaneously for models
built from high-dimensional EHR data. We also discuss the relevance of these
results in the context of the empirical trade-off between fairness and model
performance.","['Stephen Pfohl', 'Ben Marafino', 'Adrien Coulet', 'Fatima Rodriguez', 'Latha Palaniappan', 'Nigam H. Shah']","['cs.LG', 'stat.ML']",2018-09-12 20:28:29+00:00
http://arxiv.org/abs/1809.04598v2,Bayesian sparse reconstruction: a brute-force approach to astronomical imaging and machine learning,"We present a principled Bayesian framework for signal reconstruction, in
which the signal is modelled by basis functions whose number (and form, if
required) is determined by the data themselves. This approach is based on a
Bayesian interpretation of conventional sparse reconstruction and
regularisation techniques, in which sparsity is imposed through priors via
Bayesian model selection. We demonstrate our method for noisy 1- and
2-dimensional signals, including astronomical images. Furthermore, by using a
product-space approach, the number and type of basis functions can be treated
as integer parameters and their posterior distributions sampled directly. We
show that order-of-magnitude increases in computational efficiency are possible
from this technique compared to calculating the Bayesian evidences separately,
and that further computational gains are possible using it in combination with
dynamic nested sampling. Our approach can also be readily applied to neural
networks, where it allows the network architecture to be determined by the data
in a principled Bayesian manner by treating the number of nodes and hidden
layers as parameters.","['Edward Higson', 'Will Handley', 'Michael Hobson', 'Anthony Lasenby']","['astro-ph.IM', 'stat.ME', 'stat.ML']",2018-09-12 18:00:01+00:00
http://arxiv.org/abs/1809.04587v2,Distributed Chernoff Test: Optimal decision systems over networks,"We study ""active"" decision making over sensor networks where the sensors'
sequential probing actions are actively chosen by continuously learning from
past observations. We consider two network settings: with and without central
coordination. In the first case, the network nodes interact with each other
through a central entity, which plays the role of a fusion center. In the
second case, the network nodes interact in a fully distributed fashion. In both
of these scenarios, we propose sequential and adaptive hypothesis tests
extending the classic Chernoff test. We compare the performance of the proposed
tests to the optimal sequential test. In the presence of a fusion center, our
test achieves the same asymptotic optimality of the Chernoff test, minimizing
the risk, expressed by the expected cost required to reach a decision plus the
expected cost of making a wrong decision, when the observation cost per unit
time tends to zero. The test is also asymptotically optimal in the higher
moments of the time required to reach a decision. Additionally, the test is
parsimonious in terms of communications, and the expected number of channel
uses per network node tends to a small constant. In the distributed setup, our
test achieves the same asymptotic optimality of Chernoff's test, up to a
multiplicative constant in terms of both risk and the higher moments of the
decision time. Additionally, the test is parsimonious in terms of
communications in comparison to state-of-the-art schemes proposed in the
literature. The analysis of these tests is also extended to account for message
quantization and communication over channels with random erasures.","['Anshuka Rangi', 'Massimo Franceschetti', 'Stefano Marano']","['stat.ME', 'cs.IT', 'cs.MA', 'math.IT', 'stat.AP', 'stat.ML']",2018-09-12 17:51:30+00:00
http://arxiv.org/abs/1809.04578v2,"Simplicity Creates Inequity: Implications for Fairness, Stereotypes, and Interpretability","Algorithms are increasingly used to aid, or in some cases supplant, human
decision-making, particularly for decisions that hinge on predictions. As a
result, two additional features in addition to prediction quality have
generated interest: (i) to facilitate human interaction and understanding with
these algorithms, we desire prediction functions that are in some fashion
simple or interpretable; and (ii) because they influence consequential
decisions, we also want them to produce equitable allocations. We develop a
formal model to explore the relationship between the demands of simplicity and
equity. Although the two concepts appear to be motivated by qualitatively
distinct goals, we show a fundamental inconsistency between them. Specifically,
we formalize a general framework for producing simple prediction functions, and
in this framework we establish two basic results. First, every simple
prediction function is strictly improvable: there exists a more complex
prediction function that is both strictly more efficient and also strictly more
equitable. Put another way, using a simple prediction function both reduces
utility for disadvantaged groups and reduces overall welfare relative to other
options. Second, we show that simple prediction functions necessarily create
incentives to use information about individuals' membership in a disadvantaged
group --- incentives that weren't present before simplification, and that work
against these individuals. Thus, simplicity transforms disadvantage into bias
against the disadvantaged group. Our results are not only about algorithms but
about any process that produces simple models, and as such they connect to the
psychology of stereotypes and to an earlier economics literature on statistical
discrimination.","['Jon Kleinberg', 'Sendhil Mullainathan']","['cs.LG', 'cs.CY', 'cs.DS', 'cs.SI', 'stat.ML']",2018-09-12 17:40:18+00:00
http://arxiv.org/abs/1809.04564v3,On the Generalization of Stochastic Gradient Descent with Momentum,"While momentum-based accelerated variants of stochastic gradient descent
(SGD) are widely used when training machine learning models, there is little
theoretical understanding on the generalization error of such methods. In this
work, we first show that there exists a convex loss function for which the
stability gap for multiple epochs of SGD with standard heavy-ball momentum
(SGDM) becomes unbounded. Then, for smooth Lipschitz loss functions, we analyze
a modified momentum-based update rule, i.e., SGD with early momentum (SGDEM)
under a broad range of step-sizes, and show that it can train machine learning
models for multiple epochs with a guarantee for generalization. Finally, for
the special case of strongly convex loss functions, we find a range of momentum
such that multiple epochs of standard SGDM, as a special form of SGDEM, also
generalizes. Extending our results on generalization, we also develop an upper
bound on the expected true risk, in terms of the number of training steps,
sample size, and momentum. Our experimental evaluations verify the consistency
between the numerical results and our theoretical bounds. SGDEM improves the
generalization error of SGDM when training ResNet-18 on ImageNet in practical
distributed settings.","['Ali Ramezani-Kebrya', 'Kimon Antonakopoulos', 'Volkan Cevher', 'Ashish Khisti', 'Ben Liang']","['cs.LG', 'stat.ML']",2018-09-12 17:02:08+00:00
http://arxiv.org/abs/1809.04559v3,Benchmarking and Optimization of Gradient Boosting Decision Tree Algorithms,"Gradient boosting decision trees (GBDTs) have seen widespread adoption in
academia, industry and competitive data science due to their state-of-the-art
performance in many machine learning tasks. One relative downside to these
models is the large number of hyper-parameters that they expose to the
end-user. To maximize the predictive power of GBDT models, one must either
manually tune the hyper-parameters, or utilize automated techniques such as
those based on Bayesian optimization. Both of these approaches are
time-consuming since they involve repeatably training the model for different
sets of hyper-parameters. A number of software GBDT packages have started to
offer GPU acceleration which can help to alleviate this problem. In this paper,
we consider three such packages: XGBoost, LightGBM and Catboost. Firstly, we
evaluate the performance of the GPU acceleration provided by these packages
using large-scale datasets with varying shapes, sparsities and learning tasks.
Then, we compare the packages in the context of hyper-parameter optimization,
both in terms of how quickly each package converges to a good validation score,
and in terms of generalization performance.","['Andreea Anghel', 'Nikolaos Papandreou', 'Thomas Parnell', 'Alessandro De Palma', 'Haralampos Pozidis']","['cs.LG', 'stat.ML']",2018-09-12 16:51:18+00:00
http://arxiv.org/abs/1809.04547v2,Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization with Medical Applications,"Medical applications challenge today's text categorization techniques by
demanding both high accuracy and ease-of-interpretation. Although deep learning
has provided a leap ahead in accuracy, this leap comes at the sacrifice of
interpretability. To address this accuracy-interpretability challenge, we here
introduce, for the first time, a text categorization approach that leverages
the recently introduced Tsetlin Machine. In all brevity, we represent the terms
of a text as propositional variables. From these, we capture categories using
simple propositional formulae, such as: if ""rash"" and ""reaction"" and
""penicillin"" then Allergy. The Tsetlin Machine learns these formulae from a
labelled text, utilizing conjunctive clauses to represent the particular facets
of each category. Indeed, even the absence of terms (negated features) can be
used for categorization purposes. Our empirical comparison with Na\""ive Bayes,
decision trees, linear support vector machines (SVMs), random forest, long
short-term memory (LSTM) neural networks, and other techniques, is quite
conclusive. The Tsetlin Machine either performs on par with or outperforms all
of the evaluated methods on both the 20 Newsgroups and IMDb datasets, as well
as on a non-public clinical dataset. On average, the Tsetlin Machine delivers
the best recall and precision scores across the datasets. Finally, our GPU
implementation of the Tsetlin Machine executes 5 to 15 times faster than the
CPU implementation, depending on the dataset. We thus believe that our novel
approach can have a significant impact on a wide range of text analysis
applications, forming a promising starting point for deeper natural language
understanding with the Tsetlin Machine.","['Geir Thore Berge', 'Ole-Christoffer Granmo', 'Tor Oddbjørn Tveit', 'Morten Goodwin', 'Lei Jiao', 'Bernt Viggo Matheussen']","['cs.LG', 'stat.ML']",2018-09-12 16:34:44+00:00
http://arxiv.org/abs/1809.04542v1,The Inductive Bias of Restricted f-GANs,"Generative adversarial networks are a novel method for statistical inference
that have achieved much empirical success; however, the factors contributing to
this success remain ill-understood. In this work, we attempt to analyze
generative adversarial learning -- that is, statistical inference as the result
of a game between a generator and a discriminator -- with the view of
understanding how it differs from classical statistical inference solutions
such as maximum likelihood inference and the method of moments.
  Specifically, we provide a theoretical characterization of the distribution
inferred by a simple form of generative adversarial learning called restricted
f-GANs -- where the discriminator is a function in a given function class, the
distribution induced by the generator is restricted to lie in a pre-specified
distribution class and the objective is similar to a variational form of the
f-divergence. A consequence of our result is that for linear KL-GANs -- that
is, when the discriminator is a linear function over some feature space and f
corresponds to the KL-divergence -- the distribution induced by the optimal
generator is neither the maximum likelihood nor the method of moments solution,
but an interesting combination of both.","['Shuang Liu', 'Kamalika Chaudhuri']","['cs.LG', 'stat.ML']",2018-09-12 16:19:49+00:00
http://arxiv.org/abs/1809.04506v2,Combined Reinforcement Learning via Abstract Representations,"In the quest for efficient and robust reinforcement learning methods, both
model-free and model-based approaches offer advantages. In this paper we
propose a new way of explicitly bridging both approaches via a shared
low-dimensional learned encoding of the environment, meant to capture
summarizing abstractions. We show that the modularity brought by this approach
leads to good generalization while being computationally efficient, with
planning happening in a smaller latent state space. In addition, this approach
recovers a sufficient low-dimensional representation of the environment, which
opens up new strategies for interpretable AI, exploration and transfer
learning.","['Vincent François-Lavet', 'Yoshua Bengio', 'Doina Precup', 'Joelle Pineau']","['cs.LG', 'cs.AI', 'stat.ML']",2018-09-12 15:12:49+00:00
http://arxiv.org/abs/1809.04497v3,Hyperprior Induced Unsupervised Disentanglement of Latent Representations,"We address the problem of unsupervised disentanglement of latent
representations learnt via deep generative models. In contrast to current
approaches that operate on the evidence lower bound (ELBO), we argue that
statistical independence in the latent space of VAEs can be enforced in a
principled hierarchical Bayesian manner. To this effect, we augment the
standard VAE with an inverse-Wishart (IW) prior on the covariance matrix of the
latent code. By tuning the IW parameters, we are able to encourage (or
discourage) independence in the learnt latent dimensions. Extensive
experimental results on a range of datasets (2DShapes, 3DChairs, 3DFaces and
CelebA) show our approach to outperform the $\beta$-VAE and is competitive with
the state-of-the-art FactorVAE. Our approach achieves significantly better
disentanglement and reconstruction on a new dataset (CorrelatedEllipses) which
introduces correlations between the factors of variation.","['Abdul Fatir Ansari', 'Harold Soh']","['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']",2018-09-12 14:53:19+00:00
http://arxiv.org/abs/1809.04487v1,Discovering Topical Interactions in Text-based Cascades using Hidden Markov Hawkes Processes,"Social media conversations unfold based on complex interactions between
users, topics and time. While recent models have been proposed to capture
network strengths between users, users' topical preferences and temporal
patterns between posting and response times, interaction patterns between
topics has not been studied. We propose the Hidden Markov Hawkes Process (HMHP)
that incorporates topical Markov Chains within Hawkes processes to jointly
model topical interactions along with user-user and user-topic patterns. We
propose a Gibbs sampling algorithm for HMHP that jointly infers the network
strengths, diffusion paths, the topics of the posts as well as the topic-topic
interactions. We show using experiments on real and semi-synthetic data that
HMHP is able to generalize better and recover the network strengths, topics and
diffusion paths more accurately than state-of-the-art baselines. More
interestingly, HMHP finds insightful interactions between topics in real tweets
which no existing model is able to do.","['Srikanta Bedathur', 'Indrajit Bhattacharya', 'Jayesh Choudhari', 'Anirban Dasgupta']","['cs.LG', 'stat.ML']",2018-09-12 14:36:27+00:00
http://arxiv.org/abs/1809.04481v3,But How Does It Work in Theory? Linear SVM with Random Features,"We prove that, under low noise assumptions, the support vector machine with
$N\ll m$ random features (RFSVM) can achieve the learning rate faster than
$O(1/\sqrt{m})$ on a training set with $m$ samples when an optimized feature
map is used. Our work extends the previous fast rate analysis of random
features method from least square loss to 0-1 loss. We also show that the
reweighted feature selection method, which approximates the optimized feature
map, helps improve the performance of RFSVM in experiments on a synthetic data
set.","['Yitong Sun', 'Anna Gilbert', 'Ambuj Tewari']","['cs.LG', 'stat.ML']",2018-09-12 14:29:05+00:00
http://arxiv.org/abs/1809.04474v1,Multi-task Deep Reinforcement Learning with PopArt,"The reinforcement learning community has made great strides in designing
algorithms capable of exceeding human performance on specific tasks. These
algorithms are mostly trained one task at the time, each new task requiring to
train a brand new agent instance. This means the learning algorithm is general,
but each solution is not; each agent can only solve the one task it was trained
on. In this work, we study the problem of learning to master not one but
multiple sequential-decision tasks at once. A general issue in multi-task
learning is that a balance must be found between the needs of multiple tasks
competing for the limited resources of a single learning system. Many learning
algorithms can get distracted by certain tasks in the set of tasks to solve.
Such tasks appear more salient to the learning process, for instance because of
the density or magnitude of the in-task rewards. This causes the algorithm to
focus on those salient tasks at the expense of generality. We propose to
automatically adapt the contribution of each task to the agent's updates, so
that all tasks have a similar impact on the learning dynamics. This resulted in
state of the art performance on learning to play all games in a set of 57
diverse Atari games. Excitingly, our method learned a single trained policy -
with a single set of weights - that exceeds median human performance. To our
knowledge, this was the first time a single agent surpassed human-level
performance on this multi-task domain. The same approach also demonstrated
state of the art performance on a set of 30 tasks in the 3D reinforcement
learning platform DeepMind Lab.","['Matteo Hessel', 'Hubert Soyer', 'Lasse Espeholt', 'Wojciech Czarnecki', 'Simon Schmitt', 'Hado van Hasselt']","['cs.LG', 'stat.ML']",2018-09-12 14:17:00+00:00
http://arxiv.org/abs/1809.04430v3,Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy,"Over half a million individuals are diagnosed with head and neck cancer each
year worldwide. Radiotherapy is an important curative treatment for this
disease, but it requires manual time consuming delineation of radio-sensitive
organs at risk (OARs). This planning process can delay treatment, while also
introducing inter-operator variability with resulting downstream radiation dose
differences. While auto-segmentation algorithms offer a potentially time-saving
solution, the challenges in defining, quantifying and achieving expert
performance remain. Adopting a deep learning approach, we demonstrate a 3D
U-Net architecture that achieves expert-level performance in delineating 21
distinct head and neck OARs commonly segmented in clinical practice. The model
was trained on a dataset of 663 deidentified computed tomography (CT) scans
acquired in routine clinical practice and with both segmentations taken from
clinical practice and segmentations created by experienced radiographers as
part of this research, all in accordance with consensus OAR definitions. We
demonstrate the model's clinical applicability by assessing its performance on
a test set of 21 CT scans from clinical practice, each with the 21 OARs
segmented by two independent experts. We also introduce surface Dice similarity
coefficient (surface DSC), a new metric for the comparison of organ
delineation, to quantify deviation between OAR surface contours rather than
volumes, better reflecting the clinical task of correcting errors in the
automated organ segmentations. The model's generalisability is then
demonstrated on two distinct open source datasets, reflecting different centres
and countries to model training. With appropriate validation studies and
regulatory approvals, this system could improve the efficiency, consistency,
and safety of radiotherapy pathways.","['Stanislav Nikolov', 'Sam Blackwell', 'Alexei Zverovitch', 'Ruheena Mendes', 'Michelle Livne', 'Jeffrey De Fauw', 'Yojan Patel', 'Clemens Meyer', 'Harry Askham', 'Bernardino Romera-Paredes', 'Christopher Kelly', 'Alan Karthikesalingam', 'Carlton Chu', 'Dawn Carnell', 'Cheng Boon', ""Derek D'Souza"", 'Syed Ali Moinuddin', 'Bethany Garie', 'Yasmin McQuinlan', 'Sarah Ireland', 'Kiarna Hampton', 'Krystle Fuller', 'Hugh Montgomery', 'Geraint Rees', 'Mustafa Suleyman', 'Trevor Back', 'Cían Hughes', 'Joseph R. Ledsam', 'Olaf Ronneberger']","['cs.CV', 'cs.LG', 'cs.NE', 'physics.med-ph', 'stat.ML']",2018-09-12 13:42:38+00:00
http://arxiv.org/abs/1809.04429v1,Gradient-based Representational Similarity Analysis with Searchlight for Analyzing fMRI Data,"Representational Similarity Analysis (RSA) aims to explore similarities
between neural activities of different stimuli. Classical RSA techniques employ
the inverse of the covariance matrix to explore a linear model between the
neural activities and task events. However, calculating the inverse of a
large-scale covariance matrix is time-consuming and can reduce the stability
and robustness of the final analysis. Notably, it becomes severe when the
number of samples is too large. For facing this shortcoming, this paper
proposes a novel RSA method called gradient-based RSA (GRSA). Moreover, the
proposed method is not restricted to a linear model. In fact, there is a
growing interest in finding more effective ways of using multi-subject and
whole-brain fMRI data. Searchlight technique can extend RSA from the localized
brain regions to the whole-brain regions with smaller memory footprint in each
process. Based on Searchlight, we propose a new method called Spatiotemporal
Searchlight GRSA (SSL-GRSA) that generalizes our ROI-based GRSA algorithm to
the whole-brain data. Further, our approach can handle some computational
challenges while dealing with large-scale, multi-subject fMRI data.
Experimental studies on multi-subject datasets confirm that both proposed
approaches achieve superior performance to other state-of-the-art RSA
algorithms.","['Xiaoliang Sheng', 'Muhammad Yousefnezhad', 'Tonglin Xu', 'Ning Yuan', 'Daoqiang Zhang']","['q-bio.NC', 'cs.LG', 'stat.ML']",2018-09-12 13:40:59+00:00
http://arxiv.org/abs/1809.04400v1,Learning Deep Mixtures of Gaussian Process Experts Using Sum-Product Networks,"While Gaussian processes (GPs) are the method of choice for regression tasks,
they also come with practical difficulties, as inference cost scales cubic in
time and quadratic in memory. In this paper, we introduce a natural and
expressive way to tackle these problems, by incorporating GPs in sum-product
networks (SPNs), a recently proposed tractable probabilistic model allowing
exact and efficient inference. In particular, by using GPs as leaves of an SPN
we obtain a novel flexible prior over functions, which implicitly represents an
exponentially large mixture of local GPs. Exact and efficient posterior
inference in this model can be done in a natural interplay of the inference
mechanisms in GPs and SPNs. Thereby, each GP is -- similarly as in a mixture of
experts approach -- responsible only for a subset of data points, which
effectively reduces inference cost in a divide and conquer fashion. We show
that integrating GPs into the SPN framework leads to a promising probabilistic
regression model which is: (1) computational and memory efficient, (2) allows
efficient and exact posterior inference, (3) is flexible enough to mix
different kernel functions, and (4) naturally accounts for non-stationarities
in time series. In a variate of experiments, we show that the SPN-GP model can
learn input dependent parameters and hyper-parameters and is on par with or
outperforms the traditional GPs as well as state of the art approximations on
real-world data.","['Martin Trapp', 'Robert Peharz', 'Carl E. Rasmussen', 'Franz Pernkopf']","['cs.LG', 'stat.ML']",2018-09-12 13:12:21+00:00
http://arxiv.org/abs/1809.04379v3,Bayesian Semi-supervised Learning with Graph Gaussian Processes,"We propose a data-efficient Gaussian process-based Bayesian approach to the
semi-supervised learning problem on graphs. The proposed model shows extremely
competitive performance when compared to the state-of-the-art graph neural
networks on semi-supervised learning benchmark experiments, and outperforms the
neural networks in active learning experiments where labels are scarce.
Furthermore, the model does not require a validation data set for early
stopping to control over-fitting. Our model can be viewed as an instance of
empirical distribution regression weighted locally by network connectivity. We
further motivate the intuitive construction of the model with a Bayesian linear
model interpretation where the node features are filtered by an operator
related to the graph Laplacian. The method can be easily implemented by
adapting off-the-shelf scalable variational inference algorithms for Gaussian
processes.","['Yin Cheng Ng', 'Nicolo Colombo', 'Ricardo Silva']","['cs.LG', 'cs.SI', 'stat.ML']",2018-09-12 12:26:00+00:00
http://arxiv.org/abs/1809.04359v1,Training Deep Neural Networks with Different Datasets In-the-wild: The Emotion Recognition Paradigm,"A novel procedure is presented in this paper, for training a deep
convolutional and recurrent neural network, taking into account both the
available training data set and some information extracted from similar
networks trained with other relevant data sets. This information is included in
an extended loss function used for the network training, so that the network
can have an improved performance when applied to the other data sets, without
forgetting the learned knowledge from the original data set. Facial expression
and emotion recognition in-the-wild is the test bed application that is used to
demonstrate the improved performance achieved using the proposed approach. In
this framework, we provide an experimental study on categorical emotion
recognition using datasets from a very recent related emotion recognition
challenge.","['Dimitrios Kollias', 'Stefanos Zafeiriou']","['cs.LG', 'cs.AI', 'cs.HC', 'stat.ML']",2018-09-12 11:16:31+00:00
http://arxiv.org/abs/1809.04356v4,Deep learning for time series classification: a review,"Time Series Classification (TSC) is an important and challenging problem in
data mining. With the increase of time series data availability, hundreds of
TSC algorithms have been proposed. Among these methods, only a few have
considered Deep Neural Networks (DNNs) to perform this task. This is surprising
as deep learning has seen very successful applications in the last years. DNNs
have indeed revolutionized the field of computer vision especially with the
advent of novel deeper architectures such as Residual and Convolutional Neural
Networks. Apart from images, sequential data such as text and audio can also be
processed with DNNs to reach state-of-the-art performance for document
classification and speech recognition. In this article, we study the current
state-of-the-art performance of deep learning algorithms for TSC by presenting
an empirical study of the most recent DNN architectures for TSC. We give an
overview of the most successful deep learning applications in various time
series domains under a unified taxonomy of DNNs for TSC. We also provide an
open source deep learning framework to the TSC community where we implemented
each of the compared approaches and evaluated them on a univariate TSC
benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By
training 8,730 deep learning models on 97 time series datasets, we propose the
most exhaustive study of DNNs for TSC to date.","['Hassan Ismail Fawaz', 'Germain Forestier', 'Jonathan Weber', 'Lhassane Idoumghar', 'Pierre-Alain Muller']","['cs.LG', 'cs.AI', 'stat.ML']",2018-09-12 10:55:33+00:00
http://arxiv.org/abs/1809.04294v4,Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data,"Continuous-time Bayesian networks (CTBNs) constitute a general and powerful
framework for modeling continuous-time stochastic processes on networks. This
makes them particularly attractive for learning the directed structures among
interacting entities. However, if the available data is incomplete, one needs
to simulate the prohibitively complex CTBN dynamics. Existing approximation
techniques, such as sampling and low-order variational methods, either scale
unfavorably in system size, or are unsatisfactory in terms of accuracy.
Inspired by recent advances in statistical physics, we present a new
approximation scheme based on cluster-variational methods significantly
improving upon existing variational approximations. We can analytically
marginalize the parameters of the approximate CTBN, as these are of secondary
importance for structure learning. This recovers a scalable scheme for direct
structure learning from incomplete and noisy time-series data. Our approach
outperforms existing methods in terms of scalability.","['Dominik Linzner', 'Heinz Koeppl']","['stat.ML', 'cs.LG']",2018-09-12 07:56:01+00:00
http://arxiv.org/abs/1809.04281v3,Music Transformer,"Music relies heavily on repetition to build structure and meaning.
Self-reference occurs on multiple timescales, from motifs to phrases to reusing
of entire sections of music, such as in pieces with ABA structure. The
Transformer (Vaswani et al., 2017), a sequence model based on self-attention,
has achieved compelling results in many generation tasks that require
maintaining long-range coherence. This suggests that self-attention might also
be well-suited to modeling music. In musical composition and performance,
however, relative timing is critically important. Existing approaches for
representing relative positional information in the Transformer modulate
attention based on pairwise distance (Shaw et al., 2018). This is impractical
for long sequences such as musical compositions since their memory complexity
for intermediate relative information is quadratic in the sequence length. We
propose an algorithm that reduces their intermediate memory requirement to
linear in the sequence length. This enables us to demonstrate that a
Transformer with our modified relative attention mechanism can generate
minute-long compositions (thousands of steps, four times the length modeled in
Oore et al., 2018) with compelling structure, generate continuations that
coherently elaborate on a given motif, and in a seq2seq setup generate
accompaniments conditioned on melodies. We evaluate the Transformer with our
relative attention mechanism on two datasets, JSB Chorales and
Piano-e-Competition, and obtain state-of-the-art results on the latter.","['Cheng-Zhi Anna Huang', 'Ashish Vaswani', 'Jakob Uszkoreit', 'Noam Shazeer', 'Ian Simon', 'Curtis Hawthorne', 'Andrew M. Dai', 'Matthew D. Hoffman', 'Monica Dinculescu', 'Douglas Eck']","['cs.LG', 'cs.SD', 'eess.AS', 'stat.ML']",2018-09-12 07:15:26+00:00
http://arxiv.org/abs/1809.04279v3,Discretely Relaxing Continuous Variables for tractable Variational Inference,"We explore a new research direction in Bayesian variational inference with
discrete latent variable priors where we exploit Kronecker matrix algebra for
efficient and exact computations of the evidence lower bound (ELBO). The
proposed ""DIRECT"" approach has several advantages over its predecessors; (i) it
can exactly compute ELBO gradients (i.e. unbiased, zero-variance gradient
estimates), eliminating the need for high-variance stochastic gradient
estimators and enabling the use of quasi-Newton optimization methods; (ii) its
training complexity is independent of the number of training points, permitting
inference on large datasets; and (iii) its posterior samples consist of sparse
and low-precision quantized integers which permit fast inference on hardware
limited devices. In addition, our DIRECT models can exactly compute statistical
moments of the parameterized predictive posterior without relying on Monte
Carlo sampling. The DIRECT approach is not practical for all likelihoods,
however, we identify a popular model structure which is practical, and
demonstrate accurate inference using latent variables discretized as extremely
low-precision 4-bit quantized integers. While the ELBO computations considered
in the numerical studies require over $10^{2352}$ log-likelihood evaluations,
we train on datasets with over two-million points in just seconds.","['Trefor W. Evans', 'Prasanth B. Nair']","['stat.ML', 'cs.LG']",2018-09-12 07:05:30+00:00
http://arxiv.org/abs/1809.04270v2,MotherNets: Rapid Deep Ensemble Learning,"Ensembles of deep neural networks significantly improve generalization
accuracy. However, training neural network ensembles requires a large amount of
computational resources and time. State-of-the-art approaches either train all
networks from scratch leading to prohibitive training cost that allows only
very small ensemble sizes in practice, or generate ensembles by training a
monolithic architecture, which results in lower model diversity and decreased
prediction accuracy. We propose MotherNets to enable higher accuracy and
practical training cost for large and diverse neural network ensembles: A
MotherNet captures the structural similarity across some or all members of a
deep neural network ensemble which allows us to share data movement and
computation costs across these networks. We first train a single or a small set
of MotherNets and, subsequently, we generate the target ensemble networks by
transferring the function from the trained MotherNet(s). Then, we continue to
train these ensemble networks, which now converge drastically faster compared
to training from scratch. MotherNets handle ensembles with diverse
architectures by clustering ensemble networks of similar architecture and
training a separate MotherNet for every cluster. MotherNets also use clustering
to control the accuracy vs. training cost tradeoff. We show that compared to
state-of-the-art approaches such as Snapshot Ensembles, Knowledge Distillation,
and TreeNets, MotherNets provide a new Pareto frontier for the
accuracy-training cost tradeoff. Crucially, training cost and accuracy
improvements continue to scale as we increase the ensemble size (2 to 3 percent
reduced absolute test error rate and up to 35 percent faster training compared
to Snapshot Ensembles). We verify these benefits over numerous neural network
architectures and large data sets.","['Abdul Wasay', 'Brian Hentschel', 'Yuze Liao', 'Sanyuan Chen', 'Stratos Idreos']","['cs.LG', 'stat.ML']",2018-09-12 06:36:31+00:00
http://arxiv.org/abs/1809.04262v1,Extracting Fairness Policies from Legal Documents,"Machine Learning community is recently exploring the implications of bias and
fairness with respect to the AI applications. The definition of fairness for
such applications varies based on their domain of application. The policies
governing the use of such machine learning system in a given context are
defined by the constitutional laws of nations and regulatory policies enforced
by the organizations that are involved in the usage. Fairness related laws and
policies are often spread across the large documents like constitution,
agreements, and organizational regulations. These legal documents have long
complex sentences in order to achieve rigorousness and robustness. Automatic
extraction of fairness policies, or in general, any specific kind of policies
from large legal corpus can be very useful for the study of bias and fairness
in the context of AI applications.
  We attempted to automatically extract fairness policies from publicly
available law documents using two approaches based on semantic relatedness. The
experiments reveal how classical Wordnet-based similarity and vector-based
similarity differ in addressing this task. We have shown that similarity based
on word vectors beats the classical approach with a large margin, whereas other
vector representations of senses and sentences fail to even match the classical
baseline. Further, we have presented thorough error analysis and reasoning to
explain the results with appropriate examples from the dataset for deeper
insights.","['Rashmi Nagpal', 'Chetna Wadhwa', 'Mallika Gupta', 'Samiulla Shaikh', 'Sameep Mehta', 'Vikram Goyal']","['cs.LG', 'cs.IR', 'stat.ML']",2018-09-12 05:44:23+00:00
http://arxiv.org/abs/1809.04249v5,A Fast Globally Linearly Convergent Algorithm for the Computation of Wasserstein Barycenters,"We consider the problem of computing a Wasserstein barycenter for a set of
discrete probability distributions with finite supports, which finds many
applications in areas such as statistics, machine learning and image
processing. When the support points of the barycenter are pre-specified, this
problem can be modeled as a linear programming (LP) problem whose size can be
extremely large. To handle this large-scale LP, we analyse the structure of its
dual problem, which is conceivably more tractable and can be reformulated as a
well-structured convex problem with 3 kinds of block variables and a coupling
linear equality constraint. We then adapt a symmetric Gauss-Seidel based
alternating direction method of multipliers (sGS-ADMM) to solve the resulting
dual problem and establish its global convergence and global linear convergence
rate. As a critical component for efficient computation, we also show how all
the subproblems involved can be solved exactly and efficiently. This makes our
method suitable for computing a Wasserstein barycenter on a large-scale data
set, without introducing an entropy regularization term as is commonly
practiced. In addition, our sGS-ADMM can be used as a subroutine in an
alternating minimization method to compute a barycenter when its support points
are not pre-specified. Numerical results on synthetic data sets and image data
sets demonstrate that our method is highly competitive for solving large-scale
Wasserstein barycenter problems, in comparison to two existing representative
methods and the commercial software Gurobi.","['Lei Yang', 'Jia Li', 'Defeng Sun', 'Kim-Chuan Toh']","['math.OC', 'stat.ML']",2018-09-12 04:13:48+00:00
http://arxiv.org/abs/1809.04216v1,On Markov Chain Gradient Descent,"Stochastic gradient methods are the workhorse (algorithms) of large-scale
optimization problems in machine learning, signal processing, and other
computational sciences and engineering. This paper studies Markov chain
gradient descent, a variant of stochastic gradient descent where the random
samples are taken on the trajectory of a Markov chain. Existing results of this
method assume convex objectives and a reversible Markov chain and thus have
their limitations. We establish new non-ergodic convergence under wider step
sizes, for nonconvex problems, and for non-reversible finite-state Markov
chains. Nonconvexity makes our method applicable to broader problem classes.
Non-reversible finite-state Markov chains, on the other hand, can mix
substatially faster. To obtain these results, we introduce a new technique that
varies the mixing levels of the Markov chains. The reported numerical results
validate our contributions.","['Tao Sun', 'Yuejiao Sun', 'Wotao Yin']","['math.OC', 'stat.ML']",2018-09-12 01:39:13+00:00
http://arxiv.org/abs/1809.09219v1,Fast Signal Recovery from Saturated Measurements by Linear Loss and Nonconvex Penalties,"Sign information is the key to overcoming the inevitable saturation error in
compressive sensing systems, which causes information loss and results in bias.
For sparse signal recovery from saturation, we propose to use a linear loss to
improve the effectiveness from existing methods that utilize hard
constraints/hinge loss for sign consistency. Due to the use of linear loss, an
analytical solution in the update progress is obtained, and some nonconvex
penalties are applicable, e.g., the minimax concave penalty, the $\ell_0$ norm,
and the sorted $\ell_1$ norm. Theoretical analysis reveals that the estimation
error can still be bounded. Generally, with linear loss and nonconvex
penalties, the recovery performance is significantly improved, and the
computational time is largely saved, which is verified by the numerical
experiments.","['Fan He', 'Xiaolin Huang', 'Yipeng Liu', 'Ming Yan']","['cs.IT', 'cs.LG', 'math.IT', 'math.OC', 'stat.ML']",2018-09-12 01:05:43+00:00
http://arxiv.org/abs/1809.04206v3,Temporal Pattern Attention for Multivariate Time Series Forecasting,"Forecasting multivariate time series data, such as prediction of electricity
consumption, solar power production, and polyphonic piano pieces, has numerous
valuable applications. However, complex and non-linear interdependencies
between time steps and series complicate the task. To obtain accurate
prediction, it is crucial to model long-term dependency in time series data,
which can be achieved to some good extent by recurrent neural network (RNN)
with attention mechanism. Typical attention mechanism reviews the information
at each previous time step and selects the relevant information to help
generate the outputs, but it fails to capture the temporal patterns across
multiple time steps. In this paper, we propose to use a set of filters to
extract time-invariant temporal patterns, which is similar to transforming time
series data into its ""frequency domain"". Then we proposed a novel attention
mechanism to select relevant time series, and use its ""frequency domain""
information for forecasting. We applied the proposed model on several
real-world tasks and achieved state-of-the-art performance in all of them with
only one exception.","['Shun-Yao Shih', 'Fan-Keng Sun', 'Hung-yi Lee']","['cs.LG', 'cs.CL', 'stat.ML']",2018-09-12 00:40:40+00:00
http://arxiv.org/abs/1809.04198v1,"Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals","We show that many machine learning goals, such as improved fairness metrics,
can be expressed as constraints on the model's predictions, which we call rate
constraints. We study the problem of training non-convex models subject to
these rate constraints (or any non-convex and non-differentiable constraints).
In the non-convex setting, the standard approach of Lagrange multipliers may
fail. Furthermore, if the constraints are non-differentiable, then one cannot
optimize the Lagrangian with gradient-based methods. To solve these issues, we
introduce the proxy-Lagrangian formulation. This new formulation leads to an
algorithm that produces a stochastic classifier by playing a two-player
non-zero-sum game solving for what we call a semi-coarse correlated
equilibrium, which in turn corresponds to an approximately optimal and feasible
solution to the constrained optimization problem. We then give a procedure
which shrinks the randomized solution down to one that is a mixture of at most
$m+1$ deterministic solutions, given $m$ constraints. This culminates in
algorithms that can solve non-convex constrained optimization problems with
possibly non-differentiable and non-convex constraints with theoretical
guarantees. We provide extensive experimental results enforcing a wide range of
policy goals including different fairness metrics, and other goals on accuracy,
coverage, recall, and churn.","['Andrew Cotter', 'Heinrich Jiang', 'Serena Wang', 'Taman Narayan', 'Maya Gupta', 'Seungil You', 'Karthik Sridharan']","['cs.LG', 'cs.AI', 'cs.GT', 'math.OC', 'stat.ML']",2018-09-11 23:41:47+00:00
http://arxiv.org/abs/1809.04197v2,Change-Point Detection on Hierarchical Circadian Models,"This paper addresses the problem of change-point detection on sequences of
high-dimensional and heterogeneous observations, which also possess a periodic
temporal structure. Due to the dimensionality problem, when the time between
change-points is on the order of the dimension of the model parameters, drifts
in the underlying distribution can be misidentified as changes. To overcome
this limitation, we assume that the observations lie in a lower-dimensional
manifold that admits a latent variable representation. In particular, we
propose a hierarchical model that is computationally feasible, widely
applicable to heterogeneous data and robust to missing instances. Additionally,
the observations' periodic dependencies are captured by non-stationary periodic
covariance functions. The proposed technique is particularly fitted to (and
motivated by) the problem of detecting changes in human behavior using
smartphones and its application to relapse detection in psychiatric patients.
Finally, we validate the technique on synthetic examples and we demonstrate its
utility in the detection of behavioral changes using real data acquired by
smartphones.","['Pablo Moreno-Muñoz', 'David Ramírez', 'Antonio Artés-Rodríguez']","['stat.ML', 'cs.LG']",2018-09-11 23:36:31+00:00
http://arxiv.org/abs/1809.04188v4,Layerwise Perturbation-Based Adversarial Training for Hard Drive Health Degree Prediction,"With the development of cloud computing and big data, the reliability of data
storage systems becomes increasingly important. Previous researchers have shown
that machine learning algorithms based on SMART attributes are effective
methods to predict hard drive failures. In this paper, we use SMART attributes
to predict hard drive health degrees which are helpful for taking different
fault tolerant actions in advance. Given the highly imbalanced SMART datasets,
it is a nontrivial work to predict the health degree precisely. The proposed
model would encounter overfitting and biased fitting problems if it is trained
by the traditional methods. In order to resolve this problem, we propose two
strategies to better utilize imbalanced data and improve performance. Firstly,
we design a layerwise perturbation-based adversarial training method which can
add perturbations to any layers of a neural network to improve the
generalization of the network. Secondly, we extend the training method to the
semi-supervised settings. Then, it is possible to utilize unlabeled data that
have a potential of failure to further improve the performance of the model.
Our extensive experiments on two real-world hard drive datasets demonstrate the
superiority of the proposed schemes for both supervised and semi-supervised
classification. The model trained by the proposed method can correctly predict
the hard drive health status 5 and 15 days in advance. Finally, we verify the
generality of the proposed training method in other similar anomaly detection
tasks where the dataset is imbalanced. The results argue that the proposed
methods are applicable to other domains.","['Jianguo Zhang', 'Ji Wang', 'Lifang He', 'Zhao Li', 'Philip S. Yu']","['cs.LG', 'stat.ML']",2018-09-11 22:43:19+00:00
http://arxiv.org/abs/1809.04184v1,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,"The design of neural network architectures is an important component for
achieving state-of-the-art performance with machine learning systems across a
broad array of tasks. Much work has endeavored to design and build
architectures automatically through clever construction of a search space
paired with simple learning algorithms. Recent progress has demonstrated that
such meta-learning methods may exceed scalable human-invented architectures on
image classification tasks. An open question is the degree to which such
methods may generalize to new domains. In this work we explore the construction
of meta-learning techniques for dense image prediction focused on the tasks of
scene parsing, person-part segmentation, and semantic image segmentation.
Constructing viable search spaces in this domain is challenging because of the
multi-scale representation of visual information and the necessity to operate
on high resolution imagery. Based on a survey of techniques in dense image
prediction, we construct a recursive search space and demonstrate that even
with efficient random search, we can identify architectures that outperform
human-invented architectures and achieve state-of-the-art performance on three
dense prediction tasks including 82.7\% on Cityscapes (street scene parsing),
71.3\% on PASCAL-Person-Part (person-part segmentation), and 87.9\% on PASCAL
VOC 2012 (semantic image segmentation). Additionally, the resulting
architecture is more computationally efficient, requiring half the parameters
and half the computational cost as previous state of the art systems.","['Liang-Chieh Chen', 'Maxwell D. Collins', 'Yukun Zhu', 'George Papandreou', 'Barret Zoph', 'Florian Schroff', 'Hartwig Adam', 'Jonathon Shlens']","['cs.CV', 'cs.LG', 'stat.ML']",2018-09-11 22:36:01+00:00
http://arxiv.org/abs/1809.04176v1,Phaseless Subspace Tracking,"This work takes the first steps towards solving the ""phaseless subspace
tracking"" (PST) problem. PST involves recovering a time sequence of signals (or
images) from phaseless linear projections of each signal under the following
structural assumption: the signal sequence is generated from a much lower
dimensional subspace (than the signal dimension) and this subspace can change
over time, albeit gradually. It can be simply understood as a dynamic
(time-varying subspace) extension of the low-rank phase retrieval problem
studied in recent work.","['Seyedehsara Nayer', 'Namrata Vaswani']","['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",2018-09-11 21:30:56+00:00
http://arxiv.org/abs/1809.04157v1,Heated-Up Softmax Embedding,"Metric learning aims at learning a distance which is consistent with the
semantic meaning of the samples. The problem is generally solved by learning an
embedding for each sample such that the embeddings of samples of the same
category are compact while the embeddings of samples of different categories
are spread-out in the feature space. We study the features extracted from the
second last layer of a deep neural network based classifier trained with the
cross entropy loss on top of the softmax layer. We show that training
classifiers with different temperature values of softmax function leads to
features with different levels of compactness. Leveraging these insights, we
propose a ""heating-up"" strategy to train a classifier with increasing
temperatures, leading the corresponding embeddings to achieve state-of-the-art
performance on a variety of metric learning benchmarks.","['Xu Zhang', 'Felix Xinnan Yu', 'Svebor Karaman', 'Wei Zhang', 'Shih-Fu Chang']","['cs.LG', 'cs.CV', 'stat.ML']",2018-09-11 20:56:02+00:00
http://arxiv.org/abs/1809.04127v1,Poisoning Attacks to Graph-Based Recommender Systems,"Recommender system is an important component of many web services to help
users locate items that match their interests. Several studies showed that
recommender systems are vulnerable to poisoning attacks, in which an attacker
injects fake data to a given system such that the system makes recommendations
as the attacker desires. However, these poisoning attacks are either agnostic
to recommendation algorithms or optimized to recommender systems that are not
graph-based. Like association-rule-based and matrix-factorization-based
recommender systems, graph-based recommender system is also deployed in
practice, e.g., eBay, Huawei App Store. However, how to design optimized
poisoning attacks for graph-based recommender systems is still an open problem.
In this work, we perform a systematic study on poisoning attacks to graph-based
recommender systems. Due to limited resources and to avoid detection, we assume
the number of fake users that can be injected into the system is bounded. The
key challenge is how to assign rating scores to the fake users such that the
target item is recommended to as many normal users as possible. To address the
challenge, we formulate the poisoning attacks as an optimization problem,
solving which determines the rating scores for the fake users. We also propose
techniques to solve the optimization problem. We evaluate our attacks and
compare them with existing attacks under white-box (recommendation algorithm
and its parameters are known), gray-box (recommendation algorithm is known but
its parameters are unknown), and black-box (recommendation algorithm is
unknown) settings using two real-world datasets. Our results show that our
attack is effective and outperforms existing attacks for graph-based
recommender systems. For instance, when 1% fake users are injected, our attack
can make a target item recommended to 580 times more normal users in certain
scenarios.","['Minghong Fang', 'Guolei Yang', 'Neil Zhenqiang Gong', 'Jia Liu']","['cs.IR', 'cs.CR', 'cs.LG', 'stat.ML', 'D.4.6; E.3; I.2.6']",2018-09-11 19:50:41+00:00
http://arxiv.org/abs/1809.04121v1,Cartesian Neural Network Constitutive Models for Data-driven Elasticity Imaging,"Elasticity images map biomechanical properties of soft tissues to aid in the
detection and diagnosis of pathological states. In particular, quasi-static
ultrasonic (US) elastography techniques use force-displacement measurements
acquired during an US scan to parameterize the spatio-temporal stress-strain
behavior. Current methods use a model-based inverse approach to estimate the
parameters associated with a chosen constitutive model. However, model-based
methods rely on simplifying assumptions of tissue biomechanical properties,
often limiting elastography to imaging one or two linear-elastic parameters.
  We previously described a data-driven method for building neural network
constitutive models (NNCMs) that learn stress-strain relationships from
force-displacement data. Using measurements acquired on gelatin phantoms, we
demonstrated the ability of NNCMs to characterize linear-elastic mechanical
properties without an initial model assumption and thus circumvent the
mathematical constraints typically encountered in classic model-based
approaches to the inverse problem. While successful, we were required to use a
priori knowledge of the internal object shape to define the spatial
distribution of regions exhibiting different material properties.
  Here, we introduce Cartesian neural network constitutive models (CaNNCMs)
that are capable of using data to model both linear-elastic mechanical
properties and their distribution in space. We demonstrate the ability of
CaNNCMs to capture arbitrary material property distributions using
stress-strain data from simulated phantoms. Furthermore, we show that a trained
CaNNCM can be used to reconstruct a Young's modulus image. CaNNCMs are an
important step toward data-driven modeling and imaging the complex mechanical
properties of soft tissues.","['Cameron Hoerig', 'Jamshid Ghaboussi', 'Michael F. Insana']","['cs.LG', 'stat.ML']",2018-09-11 19:41:30+00:00
http://arxiv.org/abs/1809.04110v1,Joint Embedding of Meta-Path and Meta-Graph for Heterogeneous Information Networks,"Meta-graph is currently the most powerful tool for similarity search on
heterogeneous information networks,where a meta-graph is a composition of
meta-paths that captures the complex structural information. However, current
relevance computing based on meta-graph only considers the complex structural
information, but ignores its embedded meta-paths information. To address this
problem, we proposeMEta-GrAph-based network embedding models, called MEGA and
MEGA++, respectively. The MEGA model uses normalized relevance or similarity
measures that are derived from a meta-graph and its embedded meta-paths between
nodes simultaneously, and then leverages tensor decomposition method to perform
node embedding. The MEGA++ further facilitates the use of coupled tensor-matrix
decomposition method to obtain a joint embedding for nodes, which
simultaneously considers the hidden relations of all meta information of a
meta-graph.Extensive experiments on two real datasets demonstrate thatMEGA and
MEGA++ are more effective than state-of-the-art approaches.","['Lichao Sun', 'Lifang He', 'Zhipeng Huang', 'Bokai Cao', 'Congying Xia', 'Xiaokai Wei', 'Philip S. Yu']","['cs.SI', 'cs.LG', 'stat.ML']",2018-09-11 19:03:31+00:00
http://arxiv.org/abs/1809.04091v5,Quantum Algorithms for Structured Prediction,"We introduce two quantum algorithms for solving structured prediction
problems. We first show that a stochastic gradient descent that uses the
quantum minimum finding algorithm and takes its probabilistic failure into
account solves the structured prediction problem with a runtime that scales
with the square root of the size of the label space, and in $\widetilde
O\left(1/\epsilon\right)$ with respect to the precision, $\epsilon$, of the
solution. Motivated by robust inference techniques in machine learning, we then
introduce another quantum algorithm that solves a smooth approximation of the
structured prediction problem with a similar quantum speedup in the size of the
label space and a similar scaling in the precision parameter. In doing so, we
analyze a variant of stochastic gradient descent for convex optimization in the
presence of an additive error in the calculation of the gradients, and show
that its convergence rate does not deteriorate if the additive errors are of
the order $O(\sqrt\epsilon)$. This algorithm uses quantum Gibbs sampling at
temperature $\Omega (\epsilon)$ as a subroutine. Based on these theoretical
observations, we propose a method for using quantum Gibbs samplers to combine
feedforward neural networks with probabilistic graphical models for quantum
machine learning. Our numerical results using Monte Carlo simulations on an
image tagging task demonstrate the benefit of the approach.","['Behrooz Sepehry', 'Ehsan Iranmanesh', 'Michael P. Friedlander', 'Pooya Ronagh']","['cs.LG', 'cs.CC', 'math.OC', 'quant-ph', 'stat.ML']",2018-09-11 18:04:11+00:00
http://arxiv.org/abs/1809.06219v2,Ensemble learning with 3D convolutional neural networks for connectome-based prediction,"The specificty and sensitivity of resting state functional MRI (rs-fMRI)
measurements depend on pre-processing choices, such as the parcellation scheme
used to define regions of interest (ROIs). In this study, we critically
evaluate the effect of brain parcellations on machine learning models applied
to rs-fMRI data. Our experiments reveal a remarkable trend: On average, models
with stochastic parcellations consistently perform as well as models with
widely used atlases at the same spatial scale. We thus propose an ensemble
learning strategy to combine the predictions from models trained on
connectivity data extracted using different (e.g., stochastic) parcellations.
We further present an implementation of our ensemble learning strategy with a
novel 3D Convolutional Neural Network (CNN) approach. The proposed CNN approach
takes advantage of the full-resolution 3D spatial structure of rs-fMRI data and
fits non-linear predictive models. Our ensemble CNN framework overcomes the
limitations of traditional machine learning models for connectomes that often
rely on region-based summary statistics and/or linear models. We showcase our
approach on a classification (autism patients versus healthy controls) and a
regression problem (prediction of subject's age), and report promising results.","['Meenakshi Khosla', 'Keith Jamison', 'Amy Kuceyeski', 'Mert R. Sabuncu']","['cs.CV', 'cs.LG', 'stat.ML']",2018-09-11 17:55:10+00:00
http://arxiv.org/abs/1809.04461v1,DeepProteomics: Protein family classification using Shallow and Deep Networks,"The knowledge regarding the function of proteins is necessary as it gives a
clear picture of biological processes. Nevertheless, there are many protein
sequences found and added to the databases but lacks functional annotation. The
laboratory experiments take a considerable amount of time for annotation of the
sequences. This arises the need to use computational techniques to classify
proteins based on their functions. In our work, we have collected the data from
Swiss-Prot containing 40433 proteins which is grouped into 30 families. We pass
it to recurrent neural network(RNN), long short term memory(LSTM) and gated
recurrent unit(GRU) model and compare it by applying trigram with deep neural
network and shallow neural network on the same dataset. Through this approach,
we could achieve maximum of around 78% accuracy for the classification of
protein families.","['Anu Vazhayil', 'Vinayakumar R', 'Soman KP']","['q-bio.QM', 'cs.LG', 'cs.NE', 'stat.ML']",2018-09-11 17:48:01+00:00
http://arxiv.org/abs/1809.06693v1,Capsule Deep Neural Network for Recognition of Historical Graffiti Handwriting,"Automatic recognition of the historical letters (XI-XVIII centuries) carved
on the stoned walls of St.Sophia cathedral in Kyiv (Ukraine) was demonstrated
by means of capsule deep learning neural network. It was applied to the image
dataset of the carved Glagolitic and Cyrillic letters (CGCL), which was
assembled and pre-processed recently for recognition and prediction by machine
learning methods
(https://www.kaggle.com/yoctoman/graffiti-st-sophia-cathedral-kyiv). CGCL
dataset contains >4000 images for glyphs of 34 letters which are hardly
recognized by experts even in contrast to notMNIST dataset with the better
images of 10 letters taken from different fonts. Despite the much worse quality
of CGCL dataset and extremely low number of samples (in comparison to notMNIST
dataset) the capsule network model demonstrated much better results than the
previously used convolutional neural network (CNN). The validation accuracy
(and validation loss) was higher (lower) for capsule network model than for CNN
without data augmentation even. The area under curve (AUC) values for receiver
operating characteristic (ROC) were also higher for the capsule network model
than for CNN model: 0.88-0.93 (capsule network) and 0.50 (CNN) without data
augmentation, 0.91-0.95 (capsule network) and 0.51 (CNN) with lossless data
augmentation, and similar results of 0.91-0.93 (capsule network) and 0.9 (CNN)
in the regime of lossless data augmentation only. The confusion matrixes were
much better for capsule network than for CNN model and gave the much lower type
I (false positive) and type II (false negative) values in all three regimes of
data augmentation. These results supports the previous claims that capsule-like
networks allow to reduce error rates not only on MNIST digit dataset, but on
the other notMNIST letter dataset and the more complex CGCL handwriting
graffiti letter dataset also.","['Nikita Gordienko', 'Yuriy Kochura', 'Vlad Taran', 'Gang Peng', 'Yuri Gordienko', 'Sergii Stirenko']","['cs.CV', 'cs.CY', 'cs.LG', 'stat.ML']",2018-09-11 17:02:13+00:00
http://arxiv.org/abs/1809.04019v1,"Training and Prediction Data Discrepancies: Challenges of Text Classification with Noisy, Historical Data","Industry datasets used for text classification are rarely created for that
purpose. In most cases, the data and target predictions are a by-product of
accumulated historical data, typically fraught with noise, present in both the
text-based document, as well as in the targeted labels. In this work, we
address the question of how well performance metrics computed on noisy,
historical data reflect the performance on the intended future machine learning
model input. The results demonstrate the utility of dirty training datasets
used to build prediction models for cleaner (and different) prediction inputs.","['Emilia Apostolova', 'R. Andrew Kreek']","['cs.IR', 'cs.CL', 'cs.LG', 'stat.ML']",2018-09-11 16:43:52+00:00
http://arxiv.org/abs/1809.03986v2,"Efficient Statistics, in High Dimensions, from Truncated Samples","We provide an efficient algorithm for the classical problem, going back to
Galton, Pearson, and Fisher, of estimating, with arbitrary accuracy the
parameters of a multivariate normal distribution from truncated samples.
Truncated samples from a $d$-variate normal ${\cal
N}(\mathbf{\mu},\mathbf{\Sigma})$ means a samples is only revealed if it falls
in some subset $S \subseteq \mathbb{R}^d$; otherwise the samples are hidden and
their count in proportion to the revealed samples is also hidden. We show that
the mean $\mathbf{\mu}$ and covariance matrix $\mathbf{\Sigma}$ can be
estimated with arbitrary accuracy in polynomial-time, as long as we have oracle
access to $S$, and $S$ has non-trivial measure under the unknown $d$-variate
normal distribution. Additionally we show that without oracle access to $S$,
any non-trivial estimation is impossible.","['Constantinos Daskalakis', 'Themis Gouleakis', 'Christos Tzamos', 'Manolis Zampetakis']","['math.ST', 'cs.DS', 'cs.LG', 'stat.CO', 'stat.ML', 'stat.TH']",2018-09-11 15:42:43+00:00
http://arxiv.org/abs/1809.04423v2,Can a Compact Neuronal Circuit Policy be Re-purposed to Learn Simple Robotic Control?,"We propose a neural information processing system which is obtained by
re-purposing the function of a biological neural circuit model, to govern
simulated and real-world control tasks. Inspired by the structure of the
nervous system of the soil-worm, C. elegans, we introduce Neuronal Circuit
Policies (NCPs), defined as the model of biological neural circuits
reparameterized for the control of an alternative task. We learn instances of
NCPs to control a series of robotic tasks, including the autonomous parking of
a real-world rover robot. For reconfiguration of the purpose of the neural
circuit, we adopt a search-based optimization algorithm. Neuronal circuit
policies perform on par and in some cases surpass the performance of
contemporary deep learning models with the advantage leveraging significantly
fewer learnable parameters and realizing interpretable dynamics at the
cell-level.","['Ramin Hasani', 'Mathias Lechner', 'Alexander Amini', 'Daniela Rus', 'Radu Grosu']","['cs.LG', 'cs.AI', 'cs.NE', 'cs.RO', 'stat.ML']",2018-09-11 15:05:12+00:00
http://arxiv.org/abs/1809.03864v1,Response Characterization for Auditing Cell Dynamics in Long Short-term Memory Networks,"In this paper, we introduce a novel method to interpret recurrent neural
networks (RNNs), particularly long short-term memory networks (LSTMs) at the
cellular level. We propose a systematic pipeline for interpreting individual
hidden state dynamics within the network using response characterization
methods. The ranked contribution of individual cells to the network's output is
computed by analyzing a set of interpretable metrics of their decoupled step
and sinusoidal responses. As a result, our method is able to uniquely identify
neurons with insightful dynamics, quantify relationships between dynamical
properties and test accuracy through ablation analysis, and interpret the
impact of network capacity on a network's dynamical distribution. Finally, we
demonstrate generalizability and scalability of our method by evaluating a
series of different benchmark sequential datasets.","['Ramin M. Hasani', 'Alexander Amini', 'Mathias Lechner', 'Felix Naser', 'Radu Grosu', 'Daniela Rus']","['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']",2018-09-11 13:27:36+00:00
http://arxiv.org/abs/1809.03839v3,Unsupervised Domain Adaptation Based on Source-guided Discrepancy,"Unsupervised domain adaptation is the problem setting where data generating
distributions in the source and target domains are different, and labels in the
target domain are unavailable. One important question in unsupervised domain
adaptation is how to measure the difference between the source and target
domains. A previously proposed discrepancy that does not use the source domain
labels requires high computational cost to estimate and may lead to a loose
generalization error bound in the target domain. To mitigate these problems, we
propose a novel discrepancy called source-guided discrepancy (S-disc), which
exploits labels in the source domain. As a consequence, S-disc can be computed
efficiently with a finite sample convergence guarantee. In addition, we show
that S-disc can provide a tighter generalization error bound than the one based
on an existing discrepancy. Finally, we report experimental results that
demonstrate the advantages of S-disc over the existing discrepancies.","['Seiichi Kuroki', 'Nontawat Charoenphakdee', 'Han Bao', 'Junya Honda', 'Issei Sato', 'Masashi Sugiyama']","['cs.LG', 'stat.ML']",2018-09-11 13:11:30+00:00
http://arxiv.org/abs/1809.03832v3,Learning Rate Adaptation for Federated and Differentially Private Learning,"We propose an algorithm for the adaptation of the learning rate for
stochastic gradient descent (SGD) that avoids the need for validation set use.
The idea for the adaptiveness comes from the technique of extrapolation: to get
an estimate for the error against the gradient flow which underlies SGD, we
compare the result obtained by one full step and two half-steps. The algorithm
is applied in two separate frameworks: federated and differentially private
learning. Using examples of deep neural networks we empirically show that the
adaptive algorithm is competitive with manually tuned commonly used
optimisation methods for differentially privately training. We also show that
it works robustly in the case of federated learning unlike commonly used
optimisation methods.","['Antti Koskela', 'Antti Honkela']","['stat.ML', 'cs.CR', 'cs.LG']",2018-09-11 13:04:19+00:00
http://arxiv.org/abs/1809.03817v1,Predicting Blood Glucose with an LSTM and Bi-LSTM Based Deep Neural Network,"A deep learning network was used to predict future blood glucose levels, as
this can permit diabetes patients to take action before imminent hyperglycaemia
and hypoglycaemia. A sequential model with one long-short-term memory (LSTM)
layer, one bidirectional LSTM layer and several fully connected layers was used
to predict blood glucose levels for different prediction horizons. The method
was trained and tested on 26 datasets from 20 real patients. The proposed
network outperforms the baseline methods in terms of all evaluation criteria.","['Qingnan Sun', 'Marko V. Jankovic', 'Lia Bally', 'Stavroula G. Mougiakakou']","['cs.LG', 'q-bio.QM', 'stat.ML']",2018-09-11 12:26:46+00:00
http://arxiv.org/abs/1809.07695v4,Multitask Learning on Graph Neural Networks: Learning Multiple Graph Centrality Measures with a Unified Network,"The application of deep learning to symbolic domains remains an active
research endeavour. Graph neural networks (GNN), consisting of trained neural
modules which can be arranged in different topologies at run time, are sound
alternatives to tackle relational problems which lend themselves to graph
representations. In this paper, we show that GNNs are capable of multitask
learning, which can be naturally enforced by training the model to refine a
single set of multidimensional embeddings $\in \mathbb{R}^d$ and decode them
into multiple outputs by connecting MLPs at the end of the pipeline. We
demonstrate the multitask learning capability of the model in the relevant
relational problem of estimating network centrality measures, focusing
primarily on producing rankings based on these measures, i.e. is vertex $v_1$
more central than vertex $v_2$ given centrality $c$?. We then show that a GNN
can be trained to develop a \emph{lingua franca} of vertex embeddings from
which all relevant information about any of the trained centrality measures can
be decoded. The proposed model achieves $89\%$ accuracy on a test dataset of
random instances with up to 128 vertices and is shown to generalise to larger
problem sizes. The model is also shown to obtain reasonable accuracy on a
dataset of real world instances with up to 4k vertices, vastly surpassing the
sizes of the largest instances with which the model was trained ($n=128$).
Finally, we believe that our contributions attest to the potential of GNNs in
symbolic domains in general and in relational learning in particular.","['Pedro H. C. Avelar', 'Henrique Lemos', 'Marcelo O. R. Prates', 'Luis Lamb']","['cs.SI', 'cs.AI', 'cs.LG', 'cs.NE', 'stat.ML']",2018-09-11 12:01:37+00:00
http://arxiv.org/abs/1809.03779v3,Probabilistic approach to limited-data computed tomography reconstruction,"In this work, we consider the inverse problem of reconstructing the internal
structure of an object from limited x-ray projections. We use a Gaussian
process prior to model the target function and estimate its (hyper)parameters
from measured data. In contrast to other established methods, this comes with
the advantage of not requiring any manual parameter tuning, which usually
arises in classical regularization strategies. Our method uses a basis function
expansion technique for the Gaussian process which significantly reduces the
computational complexity and avoids the need for numerical integration. The
approach also allows for reformulation of come classical regularization methods
as Laplacian and Tikhonov regularization as Gaussian process regression, and
hence provides an efficient algorithm and principled means for their parameter
tuning. Results from simulated and real data indicate that this approach is
less sensitive to streak artifacts as compared to the commonly used method of
filtered backprojection.","['Zenith Purisha', 'Carl Jidling', 'Niklas Wahlström', 'Simo Särkkä', 'Thomas B. Schön']","['cs.CV', 'cs.LG', 'stat.ML']",2018-09-11 10:16:44+00:00
http://arxiv.org/abs/1809.03776v2,Solving Non-identifiable Latent Feature Models,"Latent feature models (LFM)s are widely employed for extracting latent
structures of data. While offering high, parameter estimation is difficult with
LFMs because of the combinational nature of latent features, and
non-identifiability is a particularly difficult problem when parameter
estimation is not unique and there exists equivalent solutions. In this paper,
a necessary and sufficient condition for non-identifiability is shown. The
condition is significantly related to dependency of features, and this implies
that non-identifiability may often occur in real-world applications. A novel
method for parameter estimation that solves the non-identifiability problem is
also proposed. This method can be combined as a post-process with existing
methods and can find an appropriate solution by hopping efficiently through
equivalent solutions. We have evaluated the effectiveness of the method on both
synthetic and real-world datasets.","['Ryota Suzuki', 'Shingo Takahashi', 'Murtuza Petladwala', 'Shigeru Kohmoto']","['cs.LG', 'stat.ML']",2018-09-11 10:11:48+00:00
http://arxiv.org/abs/1809.03721v2,Deep Asymmetric Networks with a Set of Node-wise Variant Activation Functions,"This work presents deep asymmetric networks with a set of node-wise variant
activation functions. The nodes' sensitivities are affected by activation
function selections such that the nodes with smaller indices become
increasingly more sensitive. As a result, features learned by the nodes are
sorted by the node indices in the order of their importance. Asymmetric
networks not only learn input features but also the importance of those
features. Nodes of lesser importance in asymmetric networks can be pruned to
reduce the complexity of the networks, and the pruned networks can be retrained
without incurring performance losses. We validate the feature-sorting property
using both shallow and deep asymmetric networks as well as deep asymmetric
networks transferred from famous networks.","['Jinhyeok Jang', 'Hyunjoong Cho', 'Jaehong Kim', 'Jaeyeon Lee', 'Seungjoon Yang']","['cs.LG', 'cs.CV', 'cs.NE', 'eess.SP', 'stat.ML']",2018-09-11 08:09:25+00:00
http://arxiv.org/abs/1809.04445v1,"Structured and Unstructured Outlier Identification for Robust PCA: A Non iterative, Parameter free Algorithm","Robust PCA, the problem of PCA in the presence of outliers has been
extensively investigated in the last few years. Here we focus on Robust PCA in
the outlier model where each column of the data matrix is either an inlier or
an outlier. Most of the existing methods for this model assumes either the
knowledge of the dimension of the lower dimensional subspace or the fraction of
outliers in the system. However in many applications knowledge of these
parameters is not available. Motivated by this we propose a parameter free
outlier identification method for robust PCA which a) does not require the
knowledge of outlier fraction, b) does not require the knowledge of the
dimension of the underlying subspace, c) is computationally simple and fast d)
can handle structured and unstructured outliers. Further, analytical guarantees
are derived for outlier identification and the performance of the algorithm is
compared with the existing state of the art methods in both real and synthetic
data for various outlier structures.","['Vishnu Menon', 'Sheetal Kalyani']","['stat.ML', 'cs.LG']",2018-09-11 07:47:57+00:00
http://arxiv.org/abs/1809.03702v1,Sparse Attentive Backtracking: Temporal CreditAssignment Through Reminding,"Learning long-term dependencies in extended temporal sequences requires
credit assignment to events far back in the past. The most common method for
training recurrent neural networks, back-propagation through time (BPTT),
requires credit information to be propagated backwards through every single
step of the forward computation, potentially over thousands or millions of time
steps. This becomes computationally expensive or even infeasible when used with
long sequences. Importantly, biological brains are unlikely to perform such
detailed reverse replay over very long sequences of internal states (consider
days, months, or years.) However, humans are often reminded of past memories or
mental states which are associated with the current mental state. We consider
the hypothesis that such memory associations between past and present could be
used for credit assignment through arbitrarily long sequences, propagating the
credit assigned to the current state to the associated past state. Based on
this principle, we study a novel algorithm which only back-propagates through a
few of these temporal skip connections, realized by a learned attention
mechanism that associates current states with relevant past states. We
demonstrate in experiments that our method matches or outperforms regular BPTT
and truncated BPTT in tasks involving particularly long-term dependencies, but
without requiring the biologically implausible backward replay through the
whole history of states. Additionally, we demonstrate that the proposed method
transfers to longer sequences significantly better than LSTMs trained with BPTT
and LSTMs trained with full self-attention.","['Nan Rosemary Ke', 'Anirudh Goyal', 'Olexa Bilaniuk', 'Jonathan Binas', 'Michael C. Mozer', 'Chris Pal', 'Yoshua Bengio']","['cs.LG', 'stat.ML']",2018-09-11 07:04:47+00:00
http://arxiv.org/abs/1809.03672v5,Deep Interest Evolution Network for Click-Through Rate Prediction,"Click-through rate~(CTR) prediction, whose goal is to estimate the
probability of the user clicks, has become one of the core tasks in advertising
systems. For CTR prediction model, it is necessary to capture the latent user
interest behind the user behavior data. Besides, considering the changing of
the external environment and the internal cognition, user interest evolves over
time dynamically. There are several CTR prediction methods for interest
modeling, while most of them regard the representation of behavior as the
interest directly, and lack specially modeling for latent interest behind the
concrete behavior. Moreover, few work consider the changing trend of interest.
In this paper, we propose a novel model, named Deep Interest Evolution
Network~(DIEN), for CTR prediction. Specifically, we design interest extractor
layer to capture temporal interests from history behavior sequence. At this
layer, we introduce an auxiliary loss to supervise interest extracting at each
step. As user interests are diverse, especially in the e-commerce system, we
propose interest evolving layer to capture interest evolving process that is
relative to the target item. At interest evolving layer, attention mechanism is
embedded into the sequential structure novelly, and the effects of relative
interests are strengthened during interest evolution. In the experiments on
both public and industrial datasets, DIEN significantly outperforms the
state-of-the-art solutions. Notably, DIEN has been deployed in the display
advertisement system of Taobao, and obtained 20.7\% improvement on CTR.","['Guorui Zhou', 'Na Mou', 'Ying Fan', 'Qi Pi', 'Weijie Bian', 'Chang Zhou', 'Xiaoqiang Zhu', 'Kun Gai']","['stat.ML', 'cs.IR', 'cs.LG', 'I.2.6']",2018-09-11 03:52:37+00:00
http://arxiv.org/abs/1809.03659v2,New models for symbolic data analysis,"Symbolic data analysis (SDA) is an emerging area of statistics concerned with
understanding and modelling data that takes distributional form (i.e. symbols),
such as random lists, intervals and histograms. It was developed under the
premise that the statistical unit of interest is the symbol, and that inference
is required at this level. Here we consider a different perspective, which
opens a new research direction in the field of SDA. We assume that, as with a
standard statistical analysis, inference is required at the level of
individual-level data. However, the individual-level data are aggregated into
symbols - group-based distributional-valued summaries - prior to the analysis.
In this way, large and complex datasets can be reduced to a smaller number of
distributional summaries, that may be analysed more efficiently than the
original dataset. As such, we develop SDA techniques as a new approach for the
analysis of big data. In particular we introduce a new general method for
constructing likelihood functions for symbolic data based on a desired
probability model for the underlying measurement-level data, while only
observing the distributional summaries. This approach opens the door for new
classes of symbol design and construction, in addition to developing SDA as a
viable tool to enable and improve upon classical data analyses, particularly
for very large and complex datasets. We illustrate this new direction for SDA
research through several real and simulated data analyses.","['Boris Beranger', 'Huan Lin', 'Scott A. Sisson']","['stat.CO', 'stat.ME', 'stat.ML']",2018-09-11 02:36:10+00:00
http://arxiv.org/abs/1809.06213v1,Context-Dependent Diffusion Network for Visual Relationship Detection,"Visual relationship detection can bridge the gap between computer vision and
natural language for scene understanding of images. Different from pure object
recognition tasks, the relation triplets of subject-predicate-object lie on an
extreme diversity space, such as \textit{person-behind-person} and
\textit{car-behind-building}, while suffering from the problem of combinatorial
explosion. In this paper, we propose a context-dependent diffusion network
(CDDN) framework to deal with visual relationship detection. To capture the
interactions of different object instances, two types of graphs, word semantic
graph and visual scene graph, are constructed to encode global context
interdependency. The semantic graph is built through language priors to model
semantic correlations across objects, whilst the visual scene graph defines the
connections of scene objects so as to utilize the surrounding scene
information. For the graph-structured data, we design a diffusion network to
adaptively aggregate information from contexts, which can effectively learn
latent representations of visual relationships and well cater to visual
relationship detection in view of its isomorphic invariance to graphs.
Experiments on two widely-used datasets demonstrate that our proposed method is
more effective and achieves the state-of-the-art performance.","['Zhen Cui', 'Chunyan Xu', 'Wenming Zheng', 'Jian Yang']","['cs.CV', 'cs.CL', 'cs.LG', 'stat.ML']",2018-09-11 02:13:45+00:00
http://arxiv.org/abs/1809.03655v1,An Efficient ADMM-Based Algorithm to Nonconvex Penalized Support Vector Machines,"Support vector machines (SVMs) with sparsity-inducing nonconvex penalties
have received considerable attentions for the characteristics of automatic
classification and variable selection. However, it is quite challenging to
solve the nonconvex penalized SVMs due to their nondifferentiability,
nonsmoothness and nonconvexity. In this paper, we propose an efficient
ADMM-based algorithm to the nonconvex penalized SVMs. The proposed algorithm
covers a large class of commonly used nonconvex regularization terms including
the smooth clipped absolute deviation (SCAD) penalty, minimax concave penalty
(MCP), log-sum penalty (LSP) and capped-$\ell_1$ penalty. The computational
complexity analysis shows that the proposed algorithm enjoys low computational
cost. Moreover, the convergence of the proposed algorithm is guaranteed.
Extensive experimental evaluations on five benchmark datasets demonstrate the
superior performance of the proposed algorithm to other three state-of-the-art
approaches.","['Lei Guan', 'Linbo Qiao', 'Dongsheng Li', 'Tao Sun', 'Keshi Ge', 'Xicheng Lu']","['stat.ML', 'cs.LG']",2018-09-11 02:08:15+00:00
http://arxiv.org/abs/1809.04441v2,An empirical learning-based validation procedure for simulation workflow,"Simulation workflow is a top-level model for the design and control of
simulation process. It connects multiple simulation components with time and
interaction restrictions to form a complete simulation system. Before the
construction and evaluation of the component models, the validation of
upper-layer simulation workflow is of the most importance in a simulation
system. However, the methods especially for validating simulation workflow is
very limit. Many of the existing validation techniques are domain-dependent
with cumbersome questionnaire design and expert scoring. Therefore, this paper
present an empirical learning-based validation procedure to implement a
semi-automated evaluation for simulation workflow. First, representative
features of general simulation workflow and their relations with validation
indices are proposed. The calculation process of workflow credibility based on
Analytic Hierarchy Process (AHP) is then introduced. In order to make full use
of the historical data and implement more efficient validation, four learning
algorithms, including back propagation neural network (BPNN), extreme learning
machine (ELM), evolving new-neuron (eNFN) and fast incremental gaussian mixture
model (FIGMN), are introduced for constructing the empirical relation between
the workflow credibility and its features. A case study on a landing-process
simulation workflow is established to test the feasibility of the proposed
procedure. The experimental results also provide some useful overview of the
state-of-the-art learning algorithms on the credibility evaluation of
simulation models.","['Zhuqing Liu', 'Liyuanjun Lai', 'Lin Zhang']","['cs.LG', 'stat.ML']",2018-09-11 00:48:04+00:00
http://arxiv.org/abs/1809.03627v2,ClusterGAN : Latent Space Clustering in Generative Adversarial Networks,"Generative Adversarial networks (GANs) have obtained remarkable success in
many unsupervised learning tasks and unarguably, clustering is an important
unsupervised learning problem. While one can potentially exploit the
latent-space back-projection in GANs to cluster, we demonstrate that the
cluster structure is not retained in the GAN latent space.
  In this paper, we propose ClusterGAN as a new mechanism for clustering using
GANs. By sampling latent variables from a mixture of one-hot encoded variables
and continuous latent variables, coupled with an inverse network (which
projects the data to the latent space) trained jointly with a clustering
specific loss, we are able to achieve clustering in the latent space. Our
results show a remarkable phenomenon that GANs can preserve latent space
interpolation across categories, even though the discriminator is never exposed
to such vectors. We compare our results with various clustering baselines and
demonstrate superior performance on both synthetic and real datasets.","['Sudipto Mukherjee', 'Himanshu Asnani', 'Eugene Lin', 'Sreeram Kannan']","['cs.LG', 'stat.ML']",2018-09-10 23:00:37+00:00
http://arxiv.org/abs/1809.04440v2,Learning-based Efficient Graph Similarity Computation via Multi-Scale Convolutional Set Matching,"Graph similarity computation is one of the core operations in many
graph-based applications, such as graph similarity search, graph database
analysis, graph clustering, etc. Since computing the exact distance/similarity
between two graphs is typically NP-hard, a series of approximate methods have
been proposed with a trade-off between accuracy and speed. Recently, several
data-driven approaches based on neural networks have been proposed, most of
which model the graph-graph similarity as the inner product of their
graph-level representations, with different techniques proposed for generating
one embedding per graph. However, using one fixed-dimensional embedding per
graph may fail to fully capture graphs in varying sizes and link structures, a
limitation that is especially problematic for the task of graph similarity
computation, where the goal is to find the fine-grained difference between two
graphs. In this paper, we address the problem of graph similarity computation
from another perspective, by directly matching two sets of node embeddings
without the need to use fixed-dimensional vectors to represent whole graphs for
their similarity computation. The model, GraphSim, achieves the
state-of-the-art performance on four real-world graph datasets under six out of
eight settings (here we count a specific dataset and metric combination as one
setting), compared to existing popular methods for approximate Graph Edit
Distance (GED) and Maximum Common Subgraph (MCS) computation.","['Yunsheng Bai', 'Hao Ding', 'Yizhou Sun', 'Wei Wang']","['cs.LG', 'stat.ML']",2018-09-10 22:48:49+00:00
http://arxiv.org/abs/1809.04069v2,Estimate the Warfarin Dose by Ensemble of Machine Learning Algorithms,"Warfarin dosing remains challenging due to narrow therapeutic index and
highly individual variability. Incorrect warfarin dosing is associated with
devastating adverse events. Remarkable efforts have been made to develop the
machine learning based warfarin dosing algorithms incorporating clinical
factors and genetic variants such as polymorphisms in CYP2C9 and VKORC1. The
most widely validated pharmacogenetic algorithm is the IWPC algorithm based on
multivariate linear regression (MLR). However, with only a single algorithm,
the prediction performance may reach an upper limit even with optimal
parameters. Here, we present novel algorithms using stacked generalization
frameworks to estimate the warfarin dose, within which different types of
machine learning algorithms function together through a meta-machine learning
model to maximize the prediction accuracy. Compared to the IWPC-derived MLR
algorithm, Stack 1 and 2 based on stacked generalization frameworks performed
significantly better overall. Subgroup analysis revealed that the mean of the
percentage of patients whose predicted dose of warfarin within 20% of the
actual stable therapeutic dose (mean percentage within 20%) for Stack 1 was
improved by 12.7% (from 42.47% to 47.86%) in Asians and by 13.5% (from 22.08%
to 25.05%) in the low-dose group compared to that for MLR, respectively. These
data suggest that our algorithms would especially benefit patients required low
warfarin maintenance dose, as subtle changes in warfarin dose could lead to
adverse clinical events (thrombosis or bleeding) in patients with low dose. Our
study offers novel pharmacogenetic algorithms for clinical trials and practice.","['Zhiyuan Ma', 'Ping Wang', 'Zehui Gao', 'Ruobing Wang', 'Koroush Khalighi']","['q-bio.QM', 'cs.LG', 'stat.ML']",2018-09-10 22:18:37+00:00
http://arxiv.org/abs/1809.04432v1,Addressing the Fundamental Tension of PCGML with Discriminative Learning,"Procedural content generation via machine learning (PCGML) is typically
framed as the task of fitting a generative model to full-scale examples of a
desired content distribution. This approach presents a fundamental tension: the
more design effort expended to produce detailed training examples for shaping a
generator, the lower the return on investment from applying PCGML in the first
place. In response, we propose the use of discriminative models (which capture
the validity of a design rather the distribution of the content) trained on
positive and negative examples. Through a modest modification of
WaveFunctionCollapse, a commercially-adopted PCG approach that we characterize
as using elementary machine learning, we demonstrate a new mode of control for
learning-based generators. We demonstrate how an artist might craft a focused
set of additional positive and negative examples by critique of the generator's
previous outputs. This interaction mode bridges PCGML with mixed-initiative
design assistance tools by working with a machine to define a space of valid
designs rather than just one new design.","['Isaac Karth', 'Adam M. Smith']","['cs.LG', 'stat.ML']",2018-09-10 20:04:59+00:00
http://arxiv.org/abs/1809.03566v2,Collapsed Variational Inference for Nonparametric Bayesian Group Factor Analysis,"Group factor analysis (GFA) methods have been widely used to infer the common
structure and the group-specific signals from multiple related datasets in
various fields including systems biology and neuroimaging. To date, most
available GFA models require Gibbs sampling or slice sampling to perform
inference, which prevents the practical application of GFA to large-scale data.
In this paper we present an efficient collapsed variational inference (CVI)
algorithm for the nonparametric Bayesian group factor analysis (NGFA) model
built upon an hierarchical beta Bernoulli process. Our CVI algorithm proceeds
by marginalizing out the group-specific beta process parameters, and then
approximating the true posterior in the collapsed space using mean field
methods. Experimental results on both synthetic and real-world data demonstrate
the effectiveness of our CVI algorithm for the NGFA compared with
state-of-the-art GFA methods.","['Sikun Yang', 'Heinz Koeppl']","['cs.LG', 'stat.ML']",2018-09-10 19:50:56+00:00
http://arxiv.org/abs/1809.03561v1,Quantile Regression for Qualifying Match of GEFCom2017 Probabilistic Load Forecasting,"We present a simple quantile regression-based forecasting method that was
applied in a probabilistic load forecasting framework of the Global Energy
Forecasting Competition 2017 (GEFCom2017). The hourly load data is log
transformed and split into a long-term trend component and a remainder term.
The key forecasting element is the quantile regression approach for the
remainder term that takes into account weekly and annual seasonalities such as
their interactions. Temperature information is only used to stabilize the
forecast of the long-term trend component. Public holidays information is
ignored. Still, the forecasting method placed second in the open data track and
fourth in the definite data track with our forecasting method, which is
remarkable given simplicity of the model. The method also outperforms the
Vanilla benchmark consistently.",['Florian Ziel'],"['stat.AP', 'stat.CO', 'stat.ME', 'stat.ML', 'stat.OT', '62M10, 62J07, 62P30, 62P12, 37M10', 'G.3; I.5']",2018-09-10 19:31:15+00:00
http://arxiv.org/abs/1809.03548v2,VPE: Variational Policy Embedding for Transfer Reinforcement Learning,"Reinforcement Learning methods are capable of solving complex problems, but
resulting policies might perform poorly in environments that are even slightly
different. In robotics especially, training and deployment conditions often
vary and data collection is expensive, making retraining undesirable.
Simulation training allows for feasible training times, but on the other hand
suffers from a reality-gap when applied in real-world settings. This raises the
need of efficient adaptation of policies acting in new environments. We
consider this as a problem of transferring knowledge within a family of similar
Markov decision processes.
  For this purpose we assume that Q-functions are generated by some
low-dimensional latent variable. Given such a Q-function, we can find a master
policy that can adapt given different values of this latent variable. Our
method learns both the generative mapping and an approximate posterior of the
latent variables, enabling identification of policies for new tasks by
searching only in the latent space, rather than the space of all policies. The
low-dimensional space, and master policy found by our method enables policies
to quickly adapt to new environments. We demonstrate the method on both a
pendulum swing-up task in simulation, and for simulation-to-real transfer on a
pushing task.","['Isac Arnekvist', 'Danica Kragic', 'Johannes A. Stork']","['cs.LG', 'stat.ML']",2018-09-10 18:55:19+00:00
http://arxiv.org/abs/1809.03541v1,Bayesian Patchworks: An Approach to Case-Based Reasoning,"Doctors often rely on their past experience in order to diagnose patients.
For a doctor with enough experience, almost every patient would have
similarities to key cases seen in the past, and each new patient could be
viewed as a mixture of these key past cases. Because doctors often tend to
reason this way, an efficient computationally aided diagnostic tool that thinks
in the same way might be helpful in locating key past cases of interest that
could assist with diagnosis. This article develops a novel mathematical model
to mimic the type of logical thinking that physicians use when considering past
cases. The proposed model can also provide physicians with explanations that
would be similar to the way they would naturally reason about cases. The
proposed method is designed to yield predictive accuracy, computational
efficiency, and insight into medical data; the key element is the insight into
medical data, in some sense we are automating a complicated process that
physicians might perform manually. We finally implemented the result of this
work on two publicly available healthcare datasets, for heart disease
prediction and breast cancer prediction.","['Ramin Moghaddass', 'Cynthia Rudin']","['cs.AI', 'cs.LG', 'stat.ML']",2018-09-10 18:40:46+00:00
http://arxiv.org/abs/1809.03538v1,Convolutional Graph Auto-encoder: A Deep Generative Neural Architecture for Probabilistic Spatio-temporal Solar Irradiance Forecasting,"Machine Learning on graph-structured data is an important and omnipresent
task for a vast variety of applications including anomaly detection and dynamic
network analysis. In this paper, a deep generative model is introduced to
capture continuous probability densities corresponding to the nodes of an
arbitrary graph. In contrast to all learning formulations in the area of
discriminative pattern recognition, we propose a scalable generative
optimization/algorithm theoretically proved to capture distributions at the
nodes of a graph. Our model is able to generate samples from the probability
densities learned at each node. This probabilistic data generation model, i.e.
convolutional graph auto-encoder (CGAE), is devised based on the localized
first-order approximation of spectral graph convolutions, deep learning, and
the variational Bayesian inference. We apply our CGAE to a new problem, the
spatio-temporal probabilistic solar irradiance prediction. Multiple solar
radiation measurement sites in a wide area in northern states of the US are
modeled as an undirected graph. Using our proposed model, the distribution of
future irradiance given historical radiation observations is estimated for
every site/node. Numerical results on the National Solar Radiation Database
show state-of-the-art performance for probabilistic radiation prediction on
geographically distributed irradiance data in terms of reliability, sharpness,
and continuous ranked probability score.","['Mahdi Khodayar', 'Saeed Mohammadi', 'Mohammad Khodayar', 'Jianhui Wang', 'Guangyi Liu']","['cs.LG', 'stat.ML']",2018-09-10 18:31:53+00:00
http://arxiv.org/abs/1809.03534v1,Energy Disaggregation via Deep Temporal Dictionary Learning,"This paper addresses the energy disaggregation problem, i.e. decomposing the
electricity signal of a whole home to its operating devices. First, we cast the
problem as a dictionary learning (DL) problem where the key electricity
patterns representing consumption behaviors are extracted for each device and
stored in a dictionary matrix. The electricity signal of each device is then
modeled by a linear combination of such patterns with sparse coefficients that
determine the contribution of each device in the total electricity. Although
popular, the classic DL approach is prone to high error in real-world
applications including energy disaggregation, as it merely finds linear
dictionaries. Moreover, this method lacks a recurrent structure; thus, it is
unable to leverage the temporal structure of energy signals. Motivated by such
shortcomings, we propose a novel optimization program where the dictionary and
its sparse coefficients are optimized simultaneously with a deep neural model
extracting powerful nonlinear features from the energy signals. A long
short-term memory auto-encoder (LSTM-AE) is proposed with tunable time
dependent states to capture the temporal behavior of energy signals for each
device. We learn the dictionary in the space of temporal features captured by
the LSTM-AE rather than the original space of the energy signals; hence, in
contrast to the traditional DL, here, a nonlinear dictionary is learned using
powerful temporal features extracted from our deep model. Real experiments on
the publicly available Reference Energy Disaggregation Dataset (REDD) show
significant improvement compared to the state-of-the-art methodologies in terms
of the disaggregation accuracy and F-score metrics.","['Mahdi Khodayar', 'Jianhui Wang', 'Zhaoyu Wang']","['cs.LG', 'stat.ML']",2018-09-10 18:26:39+00:00
http://arxiv.org/abs/1809.03474v3,Universal Multi-Party Poisoning Attacks,"In this work, we demonstrate universal multi-party poisoning attacks that
adapt and apply to any multi-party learning process with arbitrary interaction
pattern between the parties. More generally, we introduce and study
$(k,p)$-poisoning attacks in which an adversary controls $k\in[m]$ of the
parties, and for each corrupted party $P_i$, the adversary submits some
poisoned data $\mathcal{T}'_i$ on behalf of $P_i$ that is still
``$(1-p)$-close'' to the correct data $\mathcal{T}_i$ (e.g., $1-p$ fraction of
$\mathcal{T}'_i$ is still honestly generated). We prove that for any ``bad''
property $B$ of the final trained hypothesis $h$ (e.g., $h$ failing on a
particular test example or having ``large'' risk) that has an arbitrarily small
constant probability of happening without the attack, there always is a
$(k,p)$-poisoning attack that increases the probability of $B$ from $\mu$ to by
$\mu^{1-p \cdot k/m} = \mu + \Omega(p \cdot k/m)$. Our attack only uses clean
labels, and it is online.
  More generally, we prove that for any bounded function $f(x_1,\dots,x_n) \in
[0,1]$ defined over an $n$-step random process $\mathbf{X} = (x_1,\dots,x_n)$,
an adversary who can override each of the $n$ blocks with even dependent
probability $p$ can increase the expected output by at least $\Omega(p \cdot
\mathrm{Var}[f(\mathbf{x})])$.","['Saeed Mahloujifar', 'Mohammad Mahmoody', 'Ameer Mohammed']","['cs.LG', 'cs.CC', 'cs.CR', 'stat.ML']",2018-09-10 17:47:24+00:00
http://arxiv.org/abs/1809.03470v1,ViZDoom Competitions: Playing Doom from Pixels,"This paper presents the first two editions of Visual Doom AI Competition,
held in 2016 and 2017. The challenge was to create bots that compete in a
multi-player deathmatch in a first-person shooter (FPS) game, Doom. The bots
had to make their decisions based solely on visual information, i.e., a raw
screen buffer. To play well, the bots needed to understand their surroundings,
navigate, explore, and handle the opponents at the same time. These aspects,
together with the competitive multi-agent aspect of the game, make the
competition a unique platform for evaluating the state of the art reinforcement
learning algorithms. The paper discusses the rules, solutions, results, and
statistics that give insight into the agents' behaviors. Best-performing agents
are described in more detail. The results of the competition lead to the
conclusion that, although reinforcement learning can produce capable Doom bots,
they still are not yet able to successfully compete against humans in this
game. The paper also revisits the ViZDoom environment, which is a flexible,
easy to use, and efficient 3D platform for research for vision-based
reinforcement learning, based on a well-recognized first-person perspective
game Doom.","['Marek Wydmuch', 'Michał Kempka', 'Wojciech Jaśkowski']","['cs.AI', 'cs.CV', 'cs.LG', 'stat.ML']",2018-09-10 17:41:39+00:00
http://arxiv.org/abs/1809.03497v1,A Correlation Maximization Approach for Cross Domain Co-Embeddings,"Although modern recommendation systems can exploit the structure in users'
item feedback, most are powerless in the face of new users who provide no
structure for them to exploit. In this paper we introduce ImplicitCE, an
algorithm for recommending items to new users during their sign-up flow.
ImplicitCE works by transforming users' implicit feedback towards auxiliary
domain items into an embedding in the target domain item embedding space.
ImplicitCE learns these embedding spaces and transformation function in an
end-to-end fashion and can co-embed users and items with any differentiable
similarity function. To train ImplicitCE we explore methods for maximizing the
correlations between model predictions and users' affinities and introduce
Sample Correlation Update, a novel and extremely simple training strategy.
Finally, we show that ImplicitCE trained with Sample Correlation Update
outperforms a variety of state of the art algorithms and loss functions on both
a large scale Twitter dataset and the DBLP dataset.",['Dan Shiebler'],"['cs.IR', 'cs.LG', 'stat.ML']",2018-09-10 17:20:04+00:00
http://arxiv.org/abs/1809.03461v3,Physics-Information-Aided Kriging: Constructing Covariance Functions using Stochastic Simulation Models,"In this work, we propose a new Gaussian process regression (GPR) method:
physics information aided Kriging (PhIK). In the standard data-driven Kriging,
the unknown function of interest is usually treated as a Gaussian process with
assumed stationary covariance with hyperparameters estimated from data. In
PhIK, we compute the mean and covariance function from realizations of
available stochastic models, e.g., from realizations of governing stochastic
partial differential equations solutions. Such constructed Gaussian process
generally is non-stationary, and does not assume a specific form of the
covariance function. Our approach avoids the optimization step in data-driven
GPR methods to identify the hyperparameters. More importantly, we prove that
the physical constraints in the form of a deterministic linear operator are
guaranteed in the resulting prediction. We also provide an error estimate in
preserving the physical constraints when errors are included in the stochastic
model realizations. To reduce the computational cost of obtaining stochastic
model realizations, we propose a multilevel Monte Carlo estimate of the mean
and covariance functions. Further, we present an active learning algorithm that
guides the selection of additional observation locations. The efficiency and
accuracy of PhIK are demonstrated for reconstructing a partially known modified
Branin function, studying a three-dimensional heat transfer problem and
learning a conservative tracer distribution from sparse concentration
measurements.","['Xiu Yang', 'Guzel Tartakovsky', 'Alexandre Tartakovsky']","['stat.ML', 'cs.LG']",2018-09-10 17:04:31+00:00
http://arxiv.org/abs/1809.03447v1,Expert-augmented actor-critic for ViZDoom and Montezumas Revenge,"We propose an expert-augmented actor-critic algorithm, which we evaluate on
two environments with sparse rewards: Montezumas Revenge and a demanding maze
from the ViZDoom suite. In the case of Montezumas Revenge, an agent trained
with our method achieves very good results consistently scoring above 27,000
points (in many experiments beating the first world). With an appropriate
choice of hyperparameters, our algorithm surpasses the performance of the
expert data. In a number of experiments, we have observed an unreported bug in
Montezumas Revenge which allowed the agent to score more than 800,000 points.","['Michał Garmulewicz', 'Henryk Michalewski', 'Piotr Miłoś']","['cs.LG', 'stat.ML']",2018-09-10 16:36:22+00:00
http://arxiv.org/abs/1809.03428v3,Not Just Privacy: Improving Performance of Private Deep Learning in Mobile Cloud,"The increasing demand for on-device deep learning services calls for a highly
efficient manner to deploy deep neural networks (DNNs) on mobile devices with
limited capacity. The cloud-based solution is a promising approach to enabling
deep learning applications on mobile devices where the large portions of a DNN
are offloaded to the cloud. However, revealing data to the cloud leads to
potential privacy risk. To benefit from the cloud data center without the
privacy risk, we design, evaluate, and implement a cloud-based framework ARDEN
which partitions the DNN across mobile devices and cloud data centers. A simple
data transformation is performed on the mobile device, while the
resource-hungry training and the complex inference rely on the cloud data
center. To protect the sensitive information, a lightweight privacy-preserving
mechanism consisting of arbitrary data nullification and random noise addition
is introduced, which provides strong privacy guarantee. A rigorous privacy
budget analysis is given. Nonetheless, the private perturbation to the original
data inevitably has a negative impact on the performance of further inference
on the cloud side. To mitigate this influence, we propose a noisy training
method to enhance the cloud-side network robustness to perturbed data. Through
the sophisticated design, ARDEN can not only preserve privacy but also improve
the inference performance. To validate the proposed ARDEN, a series of
experiments based on three image datasets and a real mobile application are
conducted. The experimental results demonstrate the effectiveness of ARDEN.
Finally, we implement ARDEN on a demo system to verify its practicality.","['Ji Wang', 'Jianguo Zhang', 'Weidong Bao', 'Xiaomin Zhu', 'Bokai Cao', 'Philip S. Yu']","['cs.LG', 'cs.AI', 'cs.DC', 'stat.ML']",2018-09-10 16:09:58+00:00
http://arxiv.org/abs/1809.03416v2,Identifying Relationships Among Sentences in Court Case Transcripts Using Discourse Relations,"Case Law has a significant impact on the proceedings of legal cases.
Therefore, the information that can be obtained from previous court cases is
valuable to lawyers and other legal officials when performing their duties.
This paper describes a methodology of applying discourse relations between
sentences when processing text documents related to the legal domain. In this
study, we developed a mechanism to classify the relationships that can be
observed among sentences in transcripts of United States court cases. First, we
defined relationship types that can be observed between sentences in court case
transcripts. Then we classified pairs of sentences according to the
relationship type by combining a machine learning model and a rule-based
approach. The results obtained through our system were evaluated using human
judges. To the best of our knowledge, this is the first study where discourse
relationships between sentences have been used to determine relationships among
sentences in legal court case transcripts.","['Gathika Ratnayaka', 'Thejan Rupasinghe', 'Nisansa de Silva', 'Menuka Warushavithana', 'Viraj Gamage', 'Amal Shehan Perera']","['cs.CL', 'cs.LG', 'stat.ML']",2018-09-10 15:55:15+00:00
http://arxiv.org/abs/1809.03402v1,Does Your Phone Know Your Touch?,"This paper explores supervised techniques for continuous anomaly detection
from biometric touch screen data. A capacitive sensor array used to mimic a
touch screen as used to collect touch and swipe gestures from participants. The
gestures are recorded over fixed segments of time, with position and force
measured for each gesture. Support Vector Machine, Logistic Regression, and
Gaussian mixture models were tested to learn individual touch patterns. Test
results showed true negative and true positive scores of over 95% accuracy for
all gesture types, with logistic regression models far outperforming the other
methods. A more expansive and varied data collection over longer periods of
time is needed to determine pragmatic usage of these results.","['John Peruzzi', 'Phillip Andrew Wingard', 'David Zucker']","['cs.LG', 'cs.CR', 'stat.ML']",2018-09-10 15:39:07+00:00
http://arxiv.org/abs/1809.03400v2,A Moral Framework for Understanding of Fair ML through Economic Models of Equality of Opportunity,"We map the recently proposed notions of algorithmic fairness to economic
models of Equality of opportunity (EOP)---an extensively studied ideal of
fairness in political philosophy. We formally show that through our conceptual
mapping, many existing definition of algorithmic fairness, such as predictive
value parity and equality of odds, can be interpreted as special cases of EOP.
In this respect, our work serves as a unifying moral framework for
understanding existing notions of algorithmic fairness. Most importantly, this
framework allows us to explicitly spell out the moral assumptions underlying
each notion of fairness, and interpret recent fairness impossibility results in
a new light. Last but not least and inspired by luck egalitarian models of EOP,
we propose a new family of measures for algorithmic fairness. We illustrate our
proposal empirically and show that employing a measure of algorithmic
(un)fairness when its underlying moral assumptions are not satisfied, can have
devastating consequences for the disadvantaged group's welfare.","['Hoda Heidari', 'Michele Loi', 'Krishna P. Gummadi', 'Andreas Krause']","['cs.LG', 'econ.TH', 'stat.ML']",2018-09-10 15:33:51+00:00
http://arxiv.org/abs/1809.03385v1,SPASS: Scientific Prominence Active Search System with Deep Image Captioning Network,"Planetary exploration missions with Mars rovers are complicated, which
generally require elaborated task planning by human experts, from the path to
take to the images to capture. NASA has been using this process to acquire over
22 million images from the planet Mars. In order to improve the degree of
automation and thus efficiency in this process, we propose a system for
planetary rovers to actively search for prominence of prespecified scientific
features in captured images. Scientists can prespecify such search tasks in
natural language and upload them to a rover, on which the deployed system
constantly captions captured images with a deep image captioning network and
compare the auto-generated captions to the prespecified search tasks by certain
metrics so as to prioritize those images for transmission. As a beneficial side
effect, the proposed system can also be deployed to ground-based planetary data
systems as a content-based search engine.",['Dicong Qiu'],"['cs.LG', 'cs.CV', 'cs.IR', 'cs.RO', 'stat.ML']",2018-09-10 15:18:37+00:00
http://arxiv.org/abs/1809.03368v1,Probabilistic Binary Neural Networks,"Low bit-width weights and activations are an effective way of combating the
increasing need for both memory and compute power of Deep Neural Networks. In
this work, we present a probabilistic training method for Neural Network with
both binary weights and activations, called BLRNet. By embracing stochasticity
during training, we circumvent the need to approximate the gradient of
non-differentiable functions such as sign(), while still obtaining a fully
Binary Neural Network at test time. Moreover, it allows for anytime ensemble
predictions for improved performance and uncertainty estimates by sampling from
the weight distribution. Since all operations in a layer of the BLRNet operate
on random variables, we introduce stochastic versions of Batch Normalization
and max pooling, which transfer well to a deterministic network at test time.
We evaluate the BLRNet on multiple standardized benchmarks.","['Jorn W. T. Peters', 'Max Welling']","['cs.LG', 'stat.ML']",2018-09-10 14:51:08+00:00
http://arxiv.org/abs/1809.03363v1,Torchbearer: A Model Fitting Library for PyTorch,"We introduce torchbearer, a model fitting library for pytorch aimed at
researchers working on deep learning or differentiable programming. The
torchbearer library provides a high level metric and callback API that can be
used for a wide range of applications. We also include a series of built in
callbacks that can be used for: model persistence, learning rate decay,
logging, data visualization and more. The extensive documentation includes an
example library for deep learning and dynamic programming problems and can be
found at http://torchbearer.readthedocs.io. The code is licensed under the MIT
License and available at https://github.com/ecs-vlc/torchbearer.","['Ethan Harris', 'Matthew Painter', 'Jonathon Hare']","['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']",2018-09-10 14:46:35+00:00
http://arxiv.org/abs/1809.03272v3,Privacy-Preserving Deep Learning via Weight Transmission,"This paper considers the scenario that multiple data owners wish to apply a
machine learning method over the combined dataset of all owners to obtain the
best possible learning output but do not want to share the local datasets owing
to privacy concerns. We design systems for the scenario that the stochastic
gradient descent (SGD) algorithm is used as the machine learning method because
SGD (or its variants) is at the heart of recent deep learning techniques over
neural networks. Our systems differ from existing systems in the following
features: {\bf (1)} any activation function can be used, meaning that no
privacy-preserving-friendly approximation is required; {\bf (2)} gradients
computed by SGD are not shared but the weight parameters are shared instead;
and {\bf (3)} robustness against colluding parties even in the extreme case
that only one honest party exists. We prove that our systems, while
privacy-preserving, achieve the same learning accuracy as SGD and hence retain
the merit of deep learning with respect to accuracy. Finally, we conduct
several experiments using benchmark datasets, and show that our systems
outperform previous system in terms of learning accuracies.","['Le Trieu Phong', 'Tran Thi Phuong']","['cs.LG', 'cs.AI', 'cs.CR', 'stat.ML', '68P25, 94A60']",2018-09-10 12:36:05+00:00
http://arxiv.org/abs/1809.03214v1,Adaptive Behavior Generation for Autonomous Driving using Deep Reinforcement Learning with Compact Semantic States,"Making the right decision in traffic is a challenging task that is highly
dependent on individual preferences as well as the surrounding environment.
Therefore it is hard to model solely based on expert knowledge. In this work we
use Deep Reinforcement Learning to learn maneuver decisions based on a compact
semantic state representation. This ensures a consistent model of the
environment across scenarios as well as a behavior adaptation function,
enabling on-line changes of desired behaviors without re-training. The input
for the neural network is a simulated object list similar to that of Radar or
Lidar sensors, superimposed by a relational semantic scene description. The
state as well as the reward are extended by a behavior adaptation function and
a parameterization respectively. With little expert knowledge and a set of
mid-level actions, it can be seen that the agent is capable to adhere to
traffic rules and learns to drive safely in a variety of situations.","['Peter Wolf', 'Karl Kurzer', 'Tobias Wingert', 'Florian Kuhnt', 'J. Marius Zöllner']","['cs.LG', 'cs.RO', 'stat.ML']",2018-09-10 09:35:27+00:00
http://arxiv.org/abs/1809.03207v4,Beyond the Selected Completely At Random Assumption for Learning from Positive and Unlabeled Data,"Most positive and unlabeled data is subject to selection biases. The labeled
examples can, for example, be selected from the positive set because they are
easier to obtain or more obviously positive. This paper investigates how
learning can be ena BHbled in this setting. We propose and theoretically
analyze an empirical-risk-based method for incorporating the labeling
mechanism. Additionally, we investigate under which assumptions learning is
possible when the labeling mechanism is not fully understood and propose a
practical method to enable this. Our empirical analysis supports the
theoretical results and shows that taking into account the possibility of a
selection bias, even when the labeling mechanism is unknown, improves the
trained classifiers.","['Jessa Bekker', 'Pieter Robberechts', 'Jesse Davis']","['cs.LG', 'stat.ML']",2018-09-10 09:23:32+00:00
http://arxiv.org/abs/1809.03185v1,Shallow vs deep learning architectures for white matter lesion segmentation in the early stages of multiple sclerosis,"In this work, we present a comparison of a shallow and a deep learning
architecture for the automated segmentation of white matter lesions in MR
images of multiple sclerosis patients. In particular, we train and test both
methods on early stage disease patients, to verify their performance in
challenging conditions, more similar to a clinical setting than what is
typically provided in multiple sclerosis segmentation challenges. Furthermore,
we evaluate a prototype naive combination of the two methods, which refines the
final segmentation. All methods were trained on 32 patients, and the evaluation
was performed on a pure test set of 73 cases. Results show low lesion-wise
false positives (30%) for the deep learning architecture, whereas the shallow
architecture yields the best Dice coefficient (63%) and volume difference
(19%). Combining both shallow and deep architectures further improves the
lesion-wise metrics (69% and 26% lesion-wise true and false positive rate,
respectively).","['Francesco La Rosa', 'Mário João Fartaria', 'Tobias Kober', 'Jonas Richiardi', 'Cristina Granziera', 'Jean-Philippe Thiran', 'Meritxell Bach Cuadra']","['cs.LG', 'cs.CV', 'stat.ML']",2018-09-10 08:50:34+00:00
http://arxiv.org/abs/1809.03149v2,Learning Adaptive Display Exposure for Real-Time Advertising,"In E-commerce advertising, where product recommendations and product ads are
presented to users simultaneously, the traditional setting is to display ads at
fixed positions. However, under such a setting, the advertising system loses
the flexibility to control the number and positions of ads, resulting in
sub-optimal platform revenue and user experience. Consequently, major
e-commerce platforms (e.g., Taobao.com) have begun to consider more flexible
ways to display ads. In this paper, we investigate the problem of advertising
with adaptive exposure: can we dynamically determine the number and positions
of ads for each user visit under certain business constraints so that the
platform revenue can be increased? More specifically, we consider two types of
constraints: request-level constraint ensures user experience for each user
visit, and platform-level constraint controls the overall platform monetization
rate. We model this problem as a Constrained Markov Decision Process with
per-state constraint (psCMDP) and propose a constrained two-level reinforcement
learning approach to decompose the original problem into two relatively
independent sub-problems. To accelerate policy learning, we also devise a
constrained hindsight experience replay mechanism. Experimental evaluations on
industry-scale real-world datasets demonstrate the merits of our approach in
both obtaining higher revenue under the constraints and the effectiveness of
the constrained hindsight experience replay mechanism.","['Weixun Wang', 'Junqi Jin', 'Jianye Hao', 'Chunjie Chen', 'Chuan Yu', 'Weinan Zhang', 'Jun Wang', 'Xiaotian Hao', 'Yixi Wang', 'Han Li', 'Jian Xu', 'Kun Gai']","['cs.LG', 'cs.AI', 'stat.ML']",2018-09-10 06:15:42+00:00
http://arxiv.org/abs/1809.03140v1,Deep MR Image Super-Resolution Using Structural Priors,"High resolution magnetic resonance (MR) images are desired for accurate
diagnostics. In practice, image resolution is restricted by factors like
hardware, cost and processing constraints. Recently, deep learning methods have
been shown to produce compelling state of the art results for image
super-resolution. Paying particular attention to desired hi-resolution MR image
structure, we propose a new regularized network that exploits image priors,
namely a low-rank structure and a sharpness prior to enhance deep MR image
superresolution. Our contributions are then incorporating these priors in an
analytically tractable fashion in the learning of a convolutional neural
network (CNN) that accomplishes the super-resolution task. This is particularly
challenging for the low rank prior, since the rank is not a differentiable
function of the image matrix (and hence the network parameters), an issue we
address by pursuing differentiable approximations of the rank. Sharpness is
emphasized by the variance of the Laplacian which we show can be implemented by
a fixed {\em feedback} layer at the output of the network. Experiments
performed on two publicly available MR brain image databases exhibit promising
results particularly when training imagery is limited.","['Venkateswararao Cherukuri', 'Tiantong Guo', 'Steven J. Schiff', 'Vishal Monga']","['cs.LG', 'cs.CV', 'eess.IV', 'stat.ML']",2018-09-10 05:20:26+00:00
http://arxiv.org/abs/1809.03137v3,Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers,"Online Multi-Object Tracking (MOT) from videos is a challenging computer
vision task which has been extensively studied for decades. Most of the
existing MOT algorithms are based on the Tracking-by-Detection (TBD) paradigm
combined with popular machine learning approaches which largely reduce the
human effort to tune algorithm parameters. However, the commonly used
supervised learning approaches require the labeled data (e.g., bounding boxes),
which is expensive for videos. Also, the TBD framework is usually suboptimal
since it is not end-to-end, i.e., it considers the task as detection and
tracking, but not jointly. To achieve both label-free and end-to-end learning
of MOT, we propose a Tracking-by-Animation framework, where a differentiable
neural model first tracks objects from input frames and then animates these
objects into reconstructed frames. Learning is then driven by the
reconstruction error through backpropagation. We further propose a
Reprioritized Attentive Tracking to improve the robustness of data association.
Experiments conducted on both synthetic and real video datasets show the
potential of the proposed model. Our project page is publicly available at:
https://github.com/zhen-he/tracking-by-animation","['Zhen He', 'Jian Li', 'Daxue Liu', 'Hangen He', 'David Barber']","['cs.CV', 'cs.LG', 'stat.ML']",2018-09-10 04:59:25+00:00
http://arxiv.org/abs/1809.03113v6,Certified Adversarial Robustness with Additive Noise,"The existence of adversarial data examples has drawn significant attention in
the deep-learning community; such data are seemingly minimally perturbed
relative to the original data, but lead to very different outputs from a
deep-learning algorithm. Although a significant body of work on developing
defensive models has been considered, most such models are heuristic and are
often vulnerable to adaptive attacks. Defensive methods that provide
theoretical robustness guarantees have been studied intensively, yet most fail
to obtain non-trivial robustness when a large-scale model and data are present.
To address these limitations, we introduce a framework that is scalable and
provides certified bounds on the norm of the input manipulation for
constructing adversarial examples. We establish a connection between robustness
against adversarial perturbation and additive random noise, and propose a
training strategy that can significantly improve the certified bounds. Our
evaluation on MNIST, CIFAR-10 and ImageNet suggests that the proposed method is
scalable to complicated models and large data sets, while providing competitive
robustness to state-of-the-art provable defense methods.","['Bai Li', 'Changyou Chen', 'Wenlin Wang', 'Lawrence Carin']","['cs.LG', 'cs.CR', 'stat.ML']",2018-09-10 03:03:06+00:00
http://arxiv.org/abs/1809.03090v2,Approximation and Estimation for High-Dimensional Deep Learning Networks,"It has been experimentally observed in recent years that multi-layer
artificial neural networks have a surprising ability to generalize, even when
trained with far more parameters than observations. Is there a theoretical
basis for this? The best available bounds on their metric entropy and
associated complexity measures are essentially linear in the number of
parameters, which is inadequate to explain this phenomenon. Here we examine the
statistical risk (mean squared predictive error) of multi-layer networks with
$\ell^1$-type controls on their parameters and with ramp activation functions
(also called lower-rectified linear units). In this setting, the risk is shown
to be upper bounded by $[(L^3 \log d)/n]^{1/2}$, where $d$ is the input
dimension to each layer, $L$ is the number of layers, and $n$ is the sample
size. In this way, the input dimension can be much larger than the sample size
and the estimator can still be accurate, provided the target function has such
$\ell^1$ controls and that the sample size is at least moderately large
compared to $L^3\log d$. The heart of the analysis is the development of a
sampling strategy that demonstrates the accuracy of a sparse covering of deep
ramp networks. Lower bounds show that the identified risk is close to being
optimal.","['Andrew R. Barron', 'Jason M. Klusowski']","['stat.ML', 'cs.LG']",2018-09-10 02:21:40+00:00
http://arxiv.org/abs/1809.03084v3,Efficient Counterfactual Learning from Bandit Feedback,"What is the most statistically efficient way to do off-policy evaluation and
optimization with batch data from bandit feedback? For log data generated by
contextual bandit algorithms, we consider offline estimators for the expected
reward from a counterfactual policy. Our estimators are shown to have lowest
variance in a wide class of estimators, achieving variance reduction relative
to standard estimators. We then apply our estimators to improve advertisement
design by a major advertisement company. Consistent with the theoretical
result, our estimators allow us to improve on the existing bandit algorithm
with more statistical confidence compared to a state-of-the-art benchmark.","['Yusuke Narita', 'Shota Yasui', 'Kohei Yata']","['cs.LG', 'cs.AI', 'cs.IR', 'stat.ME', 'stat.ML']",2018-09-10 02:08:14+00:00
http://arxiv.org/abs/1809.03073v1,Sample Complexity of Nonparametric Semi-Supervised Learning,"We study the sample complexity of semi-supervised learning (SSL) and
introduce new assumptions based on the mismatch between a mixture model learned
from unlabeled data and the true mixture model induced by the (unknown) class
conditional distributions. Under these assumptions, we establish an
$\Omega(K\log K)$ labeled sample complexity bound without imposing parametric
assumptions, where $K$ is the number of classes. Our results suggest that even
in nonparametric settings it is possible to learn a near-optimal classifier
using only a few labeled samples. Unlike previous theoretical work which
focuses on binary classification, we consider general multiclass classification
($K>2$), which requires solving a difficult permutation learning problem. This
permutation defines a classifier whose classification error is controlled by
the Wasserstein distance between mixing measures, and we provide finite-sample
results characterizing the behaviour of the excess risk of this classifier.
Finally, we describe three algorithms for computing these estimators based on a
connection to bipartite graph matching, and perform experiments to illustrate
the superiority of the MLE over the majority vote estimator.","['Chen Dan', 'Liu Leqi', 'Bryon Aragam', 'Pradeep Ravikumar', 'Eric P. Xing']","['cs.LG', 'cs.AI', 'math.ST', 'stat.ML', 'stat.TH']",2018-09-10 01:12:26+00:00
http://arxiv.org/abs/1809.03063v2,The Curse of Concentration in Robust Learning: Evasion and Poisoning Attacks from Concentration of Measure,"Many modern machine learning classifiers are shown to be vulnerable to
adversarial perturbations of the instances. Despite a massive amount of work
focusing on making classifiers robust, the task seems quite challenging. In
this work, through a theoretical study, we investigate the adversarial risk and
robustness of classifiers and draw a connection to the well-known phenomenon of
concentration of measure in metric measure spaces. We show that if the metric
probability space of the test instance is concentrated, any classifier with
some initial constant error is inherently vulnerable to adversarial
perturbations.
  One class of concentrated metric probability spaces are the so-called Levy
families that include many natural distributions. In this special case, our
attacks only need to perturb the test instance by at most $O(\sqrt n)$ to make
it misclassified, where $n$ is the data dimension. Using our general result
about Levy instance spaces, we first recover as special case some of the
previously proved results about the existence of adversarial examples. However,
many more Levy families are known (e.g., product distribution under the Hamming
distance) for which we immediately obtain new attacks that find adversarial
examples of distance $O(\sqrt n)$.
  Finally, we show that concentration of measure for product spaces implies the
existence of forms of ""poisoning"" attacks in which the adversary tampers with
the training data with the goal of degrading the classifier. In particular, we
show that for any learning algorithm that uses $m$ training examples, there is
an adversary who can increase the probability of any ""bad property"" (e.g.,
failing on a particular test instance) that initially happens with
non-negligible probability to $\approx 1$ by substituting only $\tilde{O}(\sqrt
m)$ of the examples with other (still correctly labeled) examples.","['Saeed Mahloujifar', 'Dimitrios I. Diochnos', 'Mohammad Mahmoody']","['cs.LG', 'cs.CC', 'cs.CR', 'stat.ML']",2018-09-09 23:57:29+00:00
http://arxiv.org/abs/1809.03062v3,Analysis of the Generalization Error: Empirical Risk Minimization over Deep Artificial Neural Networks Overcomes the Curse of Dimensionality in the Numerical Approximation of Black-Scholes Partial Differential Equations,"The development of new classification and regression algorithms based on
empirical risk minimization (ERM) over deep neural network hypothesis classes,
coined deep learning, revolutionized the area of artificial intelligence,
machine learning, and data analysis. In particular, these methods have been
applied to the numerical solution of high-dimensional partial differential
equations with great success. Recent simulations indicate that deep
learning-based algorithms are capable of overcoming the curse of dimensionality
for the numerical solution of Kolmogorov equations, which are widely used in
models from engineering, finance, and the natural sciences. The present paper
considers under which conditions ERM over a deep neural network hypothesis
class approximates the solution of a $d$-dimensional Kolmogorov equation with
affine drift and diffusion coefficients and typical initial values arising from
problems in computational finance up to error $\varepsilon$. We establish that,
with high probability over draws of training samples, such an approximation can
be achieved with both the size of the hypothesis class and the number of
training samples scaling only polynomially in $d$ and $\varepsilon^{-1}$. It
can be concluded that ERM over deep neural network hypothesis classes overcomes
the curse of dimensionality for the numerical solution of linear Kolmogorov
equations with affine coefficients.","['Julius Berner', 'Philipp Grohs', 'Arnulf Jentzen']","['cs.LG', 'cs.NA', 'math.NA', 'stat.ML', '60H30, 65C30, 62M45, 68T05']",2018-09-09 23:50:37+00:00
